<!doctype html><html lang=en-us><head><meta charset=utf-8><title>DaemonSet | Lotus Docs Example Site</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=keywords content="Documentation,Hugo,Hugo Theme,Bootstrap"><meta name=author content="Colin Wilson - Lotus Labs"><meta name=email content="support@aigis.uk"><meta name=website content="https://lotusdocs.dev"><meta name=Version content="v0.1.0"><link rel=icon href=https://blahvalf.github.io/favicon.ico sizes=any><link rel=icon type=image/svg+xml href=https://blahvalf.github.io/favicon.svg><link rel=apple-touch-icon sizes=180x180 href=https://blahvalf.github.io/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://blahvalf.github.io/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://blahvalf.github.io/favicon-16x16.png><link rel=manifest crossorigin=use-credentials href=https://blahvalf.github.io/site.webmanifest><meta property="og:title" content="DaemonSet"><meta property="og:description" content="本文将为您介绍 DaemonSet 的基本概念。
什么是 DaemonSet？ linkDaemonSet 确保全部（或者一些）Node 上运行一个 Pod 的副本。当有 Node 加入集群时，也会为他们新增一个 Pod 。当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。
使用 DaemonSet 的一些典型用法：

运行集群存储 daemon，例如在每个 Node 上运行 glusterd、ceph。
在每个 Node 上运行日志收集 daemon，例如fluentd、logstash。
在每个 Node 上运行监控 daemon，例如 Prometheus Node Exporter、collectd、Datadog 代理、New Relic 代理，或 Ganglia gmond。

一个简单的用法是，在所有的 Node 上都存在一个 DaemonSet，将被作为每种类型的 daemon 使用。
一个稍微复杂的用法可能是，对单独的每种类型的 daemon 使用多个 DaemonSet，但具有不同的标志，和/或对不同硬件类型具有不同的内存、CPU要求。"><meta property="og:type" content="article"><meta property="og:url" content="https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/deamonset/"><meta property="og:image" content="https://blahvalf.github.io/opengraph/card-base-2_hu_4bafebd639eba260.png"><meta property="article:section" content="docs"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://blahvalf.github.io/opengraph/card-base-2_hu_4bafebd639eba260.png"><meta name=twitter:title content="DaemonSet"><meta name=twitter:description content="本文将为您介绍 DaemonSet 的基本概念。
什么是 DaemonSet？ linkDaemonSet 确保全部（或者一些）Node 上运行一个 Pod 的副本。当有 Node 加入集群时，也会为他们新增一个 Pod 。当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。
使用 DaemonSet 的一些典型用法：

运行集群存储 daemon，例如在每个 Node 上运行 glusterd、ceph。
在每个 Node 上运行日志收集 daemon，例如fluentd、logstash。
在每个 Node 上运行监控 daemon，例如 Prometheus Node Exporter、collectd、Datadog 代理、New Relic 代理，或 Ganglia gmond。

一个简单的用法是，在所有的 Node 上都存在一个 DaemonSet，将被作为每种类型的 daemon 使用。
一个稍微复杂的用法可能是，对单独的每种类型的 daemon 使用多个 DaemonSet，但具有不同的标志，和/或对不同硬件类型具有不同的内存、CPU要求。"><link rel=alternate type=application/atom+xml title="Atom feed for My New Hugo Site" href=/index.xml><script>(()=>{var t=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,e=localStorage.getItem("theme");t&&e===null&&(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")),t&&e==="dark"&&document.documentElement.setAttribute("data-dark-mode",""),e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script><script type=text/javascript src=https://blahvalf.github.io/docs/js/flexsearch.bundle.min.f5159d5a2151ffbb653996ec17eaff7da4e04c286bd879fc41839d36a5586f3f20eaead0b6089de48f9adc669cdee771.js integrity=sha384-9RWdWiFR/7tlOZbsF+r/faTgTChr2Hn8QYOdNqVYbz8g6urQtgid5I+a3Gac3udx crossorigin=anonymous></script><link rel=preconnect href=https://fonts.gstatic.com/><link rel=preconnect href=https://fonts.gstatic.com/ crossorigin><link href="https://fonts.googleapis.com/css?family=Inter:300,400,600,700|Fira+Code:500,700&display=block" rel=stylesheet><link rel=stylesheet href=/docs/scss/style.min.4c5fa9c08f95877bc2682d6faa056a62706c546ef29e7d986102520046b465930a94653c18b40d9201e6da9504f45393.css integrity=sha384-TF+pwI+Vh3vCaC1vqgVqYnBsVG7ynn2YYQJSAEa0ZZMKlGU8GLQNkgHm2pUE9FOT crossorigin=anonymous></head><body><div class=content><div class="page-wrapper toggled"><nav id=sidebar class=sidebar-wrapper><div class=sidebar-brand><a href=/ aria-label=HomePage alt=HomePage><svg id="Layer_1" viewBox="0 0 250 250"><path d="m143 39.5c-18 0-18 18-18 18s0-18-18-18H22c-2.76.0-5 2.24-5 5v143c0 2.76 2.24 5 5 5h76c7.2.0 8.64 11.52 8.93 16.13.07 1.05.95 1.87 2 1.87h32.14c1.06.0 1.94-.82 2-1.87.29-4.61 1.73-16.13 8.93-16.13h76c2.76.0 5-2.24 5-5V44.5c0-2.76-2.24-5-5-5h-85zM206 163c0 1.38-1.12 2.5-2.5 2.5H143c-18 0-18 18-18 18s0-18-18-18H46.5c-1.38.0-2.5-1.12-2.5-2.5V69c0-1.38 1.12-2.5 2.5-2.5H98c7.2.0 8.64 11.52 8.93 16.13.07 1.05.95 1.87 2 1.87h32.14c1.06.0 1.94-.82 2-1.87.29-4.61 1.73-16.13 8.93-16.13h51.5c1.38.0 2.5 1.12 2.5 2.5v94z" style="fill:#06f"/></svg></a></div><div class=sidebar-content style="height:calc(100% - 131px)"><ul class=sidebar-menu><li class=sidebar-dropdown><button class=btn>
<i class="material-icons me-2">bolt</i>
成长</button><div class=sidebar-submenu><ul><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/develop/ask/>如何提问：提问的智慧</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/develop/analysis/>问题分析：5W2H</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/develop/demand/>个人需求：马斯洛理论</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/develop/value/>个人价值：冰山模型</a></li></ul></div></li><li class="sidebar-dropdown current active"><button class=btn>
<i class="material-icons me-2">webhook</i>
信息技术</button><div class="sidebar-submenu d-block"><ul><li class="sidebar-dropdown nested current active"><button class=btn>
软件</button><div class="sidebar-submenu d-block"><ul><li class="sidebar-dropdown nested current active"><button class=btn>
云原生</button><div class="sidebar-submenu d-block"><ul><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_arch/>K8s架构</a></li><li class="sidebar-dropdown nested current active"><button class=btn>
K8s集群控制</button><div class="sidebar-submenu d-block"><ul><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/resources/>资源对象</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/pod/>Pod</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/node/>Node</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/namespace/>Namespace</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/label/>Label</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/annotation/>Annotation</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/taint_toleration/>Taint & Toleration</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/garbage-collection/>垃圾回收</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/scheduling/>资源调度</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/qos/>Qos 服务质量等级</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/deployment/>Deployment</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/statefulset/>StatefulSet</a></li><li class=current><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/deamonset/>DaemonSet</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/replicaset/>ReplicationController 和 ReplicaSet</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/job_cronjob/>Job & CronJob</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/ingress/>Ingress</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/custom_hpa/>自定义指标 HPA</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/admission_controller/>准入控制器（Admission Controller）</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/k8s_rs_manager/revision_generation/>ResourceVersion & Generation</a></li></ul></div></li><li class="sidebar-dropdown nested"><button class=btn>
服务发现</button><div class=sidebar-submenu><ul><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/service-discovery/service/>Service</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/service-discovery/topology-aware-routing/>拓扑感知路由</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/service-discovery/ingress/>Ingress</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/service-discovery/gateway/>GatewayAPI</a></li></ul></div></li><li class="sidebar-dropdown nested"><button class=btn>
认证</button><div class=sidebar-submenu><ul><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/auth/serviceaccount/>ServiceAccount</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/auth/rbac/>RBAC</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/auth/networkpolicy/>NetworkPolicy</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/auth/spiffe/>SPIFFE</a></li></ul></div></li><li class="sidebar-dropdown nested"><button class=btn>
存储</button><div class=sidebar-submenu><ul><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/storage/secret/>Secret</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/storage/configmap/>ConfigMap</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/storage/volume/>Volume</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/storage/pv/>持久化卷（Persistent Volume）</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/storage/storageclass/>StorageClass</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/storage/local-persistent-storage/>本地持久化存储</a></li></ul></div></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/resource_oversold/>资源超卖</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/cloud/autoscale/>Cluster Autoscaler</a></li></ul></div></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/serven_rules/>设计模式与七大原则</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/software/clean_arch/>简洁架构</a></li></ul></div></li><li class="sidebar-dropdown nested"><button class=btn>
通信</button><div class=sidebar-submenu><ul></ul></div></li><li class="sidebar-dropdown nested"><button class=btn>
数据</button><div class=sidebar-submenu><ul><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/data/data_classification/>数据存储类型及特点</a></li></ul></div></li><li class="sidebar-dropdown nested"><button class=btn>
安全</button><div class=sidebar-submenu><ul><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/secure/basic_cryptography/>密码学基础</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/secure/modern_cryptography/>现代密码学</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/information/secure/cryptographic_protocol/>密码协议</a></li></ul></div></li><li class="sidebar-dropdown nested"><button class=btn>
AIGC</button><div class=sidebar-submenu><ul></ul></div></li><li class="sidebar-dropdown nested"><button class=btn>
杂</button><div class=sidebar-submenu><ul></ul></div></li></ul></div></li><li><a class=sidebar-root-link href=https://blahvalf.github.io/docs/math/><i class="material-icons me-2">calculate</i>
数学</a></li><li class=sidebar-dropdown><button class=btn>
<i class="material-icons me-2">moving</i>
经济</button><div class=sidebar-submenu><ul><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/economy/microeconomics_base/>微观经济学基础</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/economy/macroeconomics_base/>宏观经济学基础</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/economy/financial_market_base/>金融市场基础</a></li></ul></div></li><li><a class=sidebar-root-link href=https://blahvalf.github.io/docs/history/><i class="material-icons me-2">history</i>
历史</a></li><li class=sidebar-dropdown><button class=btn>
<i class="material-icons me-2">book</i>
杂</button><div class=sidebar-submenu><ul><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/mix/list/>摩旅清单</a></li><li class="sidebar-dropdown nested"><button class=btn>
Mermaid@v10.6.1 Syntax</button><div class=sidebar-submenu><ul><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/mix/mermaid/syntax/c4/>C4 Diagrams</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/mix/mermaid/syntax/classdiagram/>Class diagrams</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/mix/mermaid/syntax/entityrelationshipdiagram/>Entity Relationship Diagrams</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/mix/mermaid/syntax/examples/>Examples</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/mix/mermaid/syntax/flowchart/>Flowcharts - Basic Syntax</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/mix/mermaid/syntax/gantt/>Gantt diagrams</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/mix/mermaid/syntax/gitgraph/>Gitgraph Diagrams</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/mix/mermaid/syntax/mindmap/>Mindmap</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/mix/mermaid/syntax/pie/>Pie chart diagrams</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/mix/mermaid/syntax/quadrantchart/>Quadrant Chart</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/mix/mermaid/syntax/requirementdiagram/>Requirement Diagram</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/mix/mermaid/syntax/sankey/>Sankey diagram (v10.3.0+)</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/mix/mermaid/syntax/sequencediagram/>Sequence diagrams</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/mix/mermaid/syntax/statediagram/>State diagrams</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/mix/mermaid/syntax/timeline/>Timeline Diagram</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/mix/mermaid/syntax/userjourney/>User Journey Diagram</a></li><li><a class=sidebar-nested-link href=https://blahvalf.github.io/docs/mix/mermaid/syntax/xychart/>XY Chart</a></li></ul></div></li></ul></div></li></ul></div><ul class="sidebar-footer list-unstyled mb-0"></ul></nav><main class="page-content bg-transparent"><div id=top-header class="top-header d-print-none"><div class="header-bar d-flex justify-content-between"><div class="d-flex align-items-center"><a href=/ class="logo-icon me-3" aria-label=HomePage alt=HomePage><div class=small><svg id="Layer_1" viewBox="0 0 250 250"><path d="m143 39.5c-18 0-18 18-18 18s0-18-18-18H22c-2.76.0-5 2.24-5 5v143c0 2.76 2.24 5 5 5h76c7.2.0 8.64 11.52 8.93 16.13.07 1.05.95 1.87 2 1.87h32.14c1.06.0 1.94-.82 2-1.87.29-4.61 1.73-16.13 8.93-16.13h76c2.76.0 5-2.24 5-5V44.5c0-2.76-2.24-5-5-5h-85zM206 163c0 1.38-1.12 2.5-2.5 2.5H143c-18 0-18 18-18 18s0-18-18-18H46.5c-1.38.0-2.5-1.12-2.5-2.5V69c0-1.38 1.12-2.5 2.5-2.5H98c7.2.0 8.64 11.52 8.93 16.13.07 1.05.95 1.87 2 1.87h32.14c1.06.0 1.94-.82 2-1.87.29-4.61 1.73-16.13 8.93-16.13h51.5c1.38.0 2.5 1.12 2.5 2.5v94z" style="fill:#06f"/></svg></div><div class=big><svg id="Layer_1" viewBox="0 0 250 250"><path d="m143 39.5c-18 0-18 18-18 18s0-18-18-18H22c-2.76.0-5 2.24-5 5v143c0 2.76 2.24 5 5 5h76c7.2.0 8.64 11.52 8.93 16.13.07 1.05.95 1.87 2 1.87h32.14c1.06.0 1.94-.82 2-1.87.29-4.61 1.73-16.13 8.93-16.13h76c2.76.0 5-2.24 5-5V44.5c0-2.76-2.24-5-5-5h-85zM206 163c0 1.38-1.12 2.5-2.5 2.5H143c-18 0-18 18-18 18s0-18-18-18H46.5c-1.38.0-2.5-1.12-2.5-2.5V69c0-1.38 1.12-2.5 2.5-2.5H98c7.2.0 8.64 11.52 8.93 16.13.07 1.05.95 1.87 2 1.87h32.14c1.06.0 1.94-.82 2-1.87.29-4.61 1.73-16.13 8.93-16.13h51.5c1.38.0 2.5 1.12 2.5 2.5v94z" style="fill:#06f"/></svg></div></a><button id=close-sidebar class="btn btn-icon btn-soft">
<span class="material-icons size-20 menu-icon align-middle">menu</span>
</button>
<button id=flexsearch-button class="ms-3 btn btn-soft" data-bs-toggle=collapse data-bs-target=#FlexSearchCollapse aria-expanded=false aria-controls=FlexSearchCollapse>
<span class="material-icons size-20 menu-icon align-middle">search</span>
<span class="flexsearch-button-placeholder ms-1 me-2 d-none d-sm-block">Search</span><div class="d-none d-sm-block"><span class=flexsearch-button-keys><kbd class=flexsearch-button-cmd-key><svg width="44" height="15"><path d="M2.118 11.5A1.519 1.519.0 011 11.042 1.583 1.583.0 011 8.815a1.519 1.519.0 011.113-.458h.715V6.643h-.71A1.519 1.519.0 011 6.185 1.519 1.519.0 01.547 5.071 1.519 1.519.0 011 3.958 1.519 1.519.0 012.118 3.5a1.519 1.519.0 011.114.458A1.519 1.519.0 013.69 5.071v.715H5.4V5.071A1.564 1.564.0 016.976 3.5 1.564 1.564.0 018.547 5.071 1.564 1.564.0 016.976 6.643H6.261V8.357h.715a1.575 1.575.0 011.113 2.685 1.583 1.583.0 01-2.227.0A1.519 1.519.0 015.4 9.929V9.214H3.69v.715a1.519 1.519.0 01-.458 1.113A1.519 1.519.0 012.118 11.5zm0-.857a.714.714.0 00.715-.714V9.214H2.118a.715.715.0 100 1.429zm4.858.0a.715.715.0 100-1.429H6.261v.715a.714.714.0 00.715.714zM3.69 8.357H5.4V6.643H3.69zM2.118 5.786h.715V5.071a.714.714.0 00-.715-.714.715.715.0 00-.5 1.22A.686.686.0 002.118 5.786zm4.143.0h.715a.715.715.0 00.5-1.22.715.715.0 00-1.22.5z" fill="currentColor"/><path d="M12.4 11.475H11.344l3.879-7.95h1.056z" fill="currentColor"/><path d="M25.073 5.384l-.864.576a2.121 2.121.0 00-1.786-.923 2.207 2.207.0 00-2.266 2.326 2.206 2.206.0 002.266 2.325 2.1 2.1.0 001.782-.918l.84.617a3.108 3.108.0 01-2.622 1.293 3.217 3.217.0 01-3.349-3.317 3.217 3.217.0 013.349-3.317A3.046 3.046.0 0125.073 5.384z" fill="currentColor"/><path d="M30.993 5.142h-2.07v5.419H27.891V5.142h-2.07V4.164h5.172z" fill="currentColor"/><path d="M34.67 4.164c1.471.0 2.266.658 2.266 1.851.0 1.087-.832 1.809-2.134 1.855l2.107 2.691h-1.28L33.591 7.87H33.07v2.691H32.038v-6.4zm-1.6.969v1.8h1.572c.832.0 1.22-.3 1.22-.918s-.411-.882-1.22-.882z" fill="currentColor"/><path d="M42.883 10.561H38.31v-6.4h1.033V9.583h3.54z" fill="currentColor"/></svg>
</kbd><kbd class=flexsearch-button-key><svg width="15" height="15"><path d="M5.926 12.279H4.41L9.073 2.721H10.59z" fill="currentColor"/></svg></kbd></span></div></button></div><div class="d-flex align-items-center"><ul class="list-unstyled mb-0"></ul><button id=mode class="btn btn-icon btn-default ms-2" type=button aria-label="Toggle user interface mode">
<span class=toggle-dark><svg height="30" width="30" viewBox="0 0 48 48" fill="currentColor"><title>Enable dark mode</title><path d="M24 42q-7.5.0-12.75-5.25T6 24t5.25-12.75T24 6q.4.0.85.025.45.025 1.15.075-1.8 1.6-2.8 3.95t-1 4.95q0 4.5 3.15 7.65Q28.5 25.8 33 25.8q2.6.0 4.95-.925T41.9 22.3q.05.6.075.975Q42 23.65 42 24q0 7.5-5.25 12.75T24 42zm0-3q5.45.0 9.5-3.375t5.05-7.925q-1.25.55-2.675.825Q34.45 28.8 33 28.8q-5.75.0-9.775-4.025T19.2 15q0-1.2.25-2.575t.9-3.125q-4.9 1.35-8.125 5.475Q9 18.9 9 24q0 6.25 4.375 10.625T24 39zm-.2-14.85z"/></svg>
</span><span class=toggle-light><svg height="30" width="30" viewBox="0 0 48 48" fill="currentColor"><title>Enable light mode</title><path d="M24 31q2.9.0 4.95-2.05T31 24t-2.05-4.95T24 17t-4.95 2.05T17 24t2.05 4.95T24 31zm0 3q-4.15.0-7.075-2.925T14 24t2.925-7.075T24 14t7.075 2.925T34 24t-2.925 7.075T24 34zM3.5 25.5q-.65.0-1.075-.425Q2 24.65 2 24t.425-1.075Q2.85 22.5 3.5 22.5h5q.65.0 1.075.425Q10 23.35 10 24t-.425 1.075T8.5 25.5zm36 0q-.65.0-1.075-.425Q38 24.65 38 24t.425-1.075T39.5 22.5h5q.65.0 1.075.425Q46 23.35 46 24t-.425 1.075-1.075.425zM24 10q-.65.0-1.075-.425Q22.5 9.15 22.5 8.5v-5q0-.65.425-1.075Q23.35 2 24 2t1.075.425T25.5 3.5v5q0 .65-.425 1.075Q24.65 10 24 10zm0 36q-.65.0-1.075-.425T22.5 44.5v-5q0-.65.425-1.075Q23.35 38 24 38t1.075.425.425 1.075v5q0 .65-.425 1.075Q24.65 46 24 46zM12 14.1l-2.85-2.8q-.45-.45-.425-1.075.025-.625.425-1.075.45-.45 1.075-.45t1.075.45L14.1 12q.4.45.4 1.05.0.6-.4 1-.4.45-1.025.45T12 14.1zm24.7 24.75L33.9 36q-.4-.45-.4-1.075t.45-1.025q.4-.45 1-.45t1.05.45l2.85 2.8q.45.45.425 1.075-.025.625-.425 1.075-.45.45-1.075.45t-1.075-.45zM33.9 14.1q-.45-.45-.45-1.05.0-.6.45-1.05l2.8-2.85q.45-.45 1.075-.425.625.025 1.075.425.45.45.45 1.075t-.45 1.075L36 14.1q-.4.4-1.025.4t-1.075-.4zM9.15 38.85q-.45-.45-.45-1.075t.45-1.075L12 33.9q.45-.45 1.05-.45.6.0 1.05.45.45.45.45 1.05.0.6-.45 1.05l-2.8 2.85q-.45.45-1.075.425-.625-.025-1.075-.425zM24 24z"/></svg></span></button></div></div><div class=collapse id=FlexSearchCollapse><div class=flexsearch-container><div class=flexsearch-keymap><li><kbd class=flexsearch-button-cmd-key><svg width="15" height="15" aria-label="Arrow down" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M7.5 3.5v8m3-3-3 3-3-3"/></g></svg></kbd>
<kbd class=flexsearch-button-cmd-key><svg width="15" height="15" aria-label="Arrow up" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M7.5 11.5v-8m3 3-3-3-3 3"/></g></svg></kbd>
<span class=flexsearch-key-label>to navigate</span></li><li><kbd class=flexsearch-button-cmd-key><svg width="15" height="15" aria-label="Enter key" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M12 3.53088v3c0 1-1 2-2 2H4m3 3-3-3 3-3"/></g></svg></kbd>
<span class=flexsearch-key-label>to select</span></li><li><kbd class=flexsearch-button-cmd-key><svg width="15" height="15" aria-label="Escape key" role="img"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M13.6167 8.936c-.1065.3583-.6883.962-1.4875.962-.7993.0-1.653-.9165-1.653-2.1258v-.5678c0-1.2548.7896-2.1016 1.653-2.1016s1.3601.4778 1.4875 1.0724M9 6c-.1352-.4735-.7506-.9219-1.46-.8972-.7092.0246-1.344.57-1.344 1.2166s.4198.8812 1.3445.9805C8.465 7.3992 8.968 7.9337 9 8.5s-.454 1.398-1.4595 1.398C6.6593 9.898 6 9 5.963 8.4851m-1.4748.5368c-.2635.5941-.8099.876-1.5443.876s-1.7073-.6248-1.7073-2.204v-.4603c0-1.0416.721-2.131 1.7073-2.131.9864.0 1.6425 1.031 1.5443 2.2492h-2.956"/></g></svg></kbd>
<span class=flexsearch-key-label>to close</span></li></div><form class="flexsearch position-relative flex-grow-1 ms-2 me-2"><div class="d-flex flex-row"><input id=flexsearch class=form-control type=search placeholder=Search aria-label=Search autocomplete=off>
<button id=hideFlexsearch type=button class="ms-2 btn btn-soft">
cancel</button></div><div id=suggestions class="shadow rounded-1 d-none"></div></form></div></div></div><div class=container-fluid><div class=layout-spacing><div class="d-md-flex justify-content-between align-items-center"><nav aria-label=breadcrumb class="d-inline-block pb-2 mt-1 mt-sm-0"><ul id=breadcrumbs class="breadcrumb bg-transparent mb-0" itemscope itemtype=https://schema.org/BreadcrumbList><li class="breadcrumb-item text-capitalize active" aria-current=page itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a itemprop=item href=/docs/><i class="material-icons size-20 align-text-bottom" itemprop=name>Home</i>
</a><meta itemprop=position content='1'></li><li class="breadcrumb-item text-capitalize" itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a itemprop=item href=/docs/information/><span itemprop=name>信息技术</span>
</a><meta itemprop=position content='2'></li><li class="breadcrumb-item text-capitalize" itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a itemprop=item href=/docs/information/software/><span itemprop=name>软件</span>
</a><meta itemprop=position content='3'></li><li class="breadcrumb-item text-capitalize" itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a itemprop=item href=/docs/information/software/cloud/><span itemprop=name>云原生</span>
</a><meta itemprop=position content='4'></li><li class="breadcrumb-item text-capitalize" itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><a itemprop=item href=/docs/information/software/cloud/k8s_rs_manager/><span itemprop=name>K8s集群控制</span>
</a><meta itemprop=position content='5'></li><li class="breadcrumb-item text-capitalize active" itemprop=itemListElement itemscope itemtype=https://schema.org/ListItem><span itemprop=name>DaemonSet</span>
<meta itemprop=position content='6'></li></ul></nav></div><div class="row flex-xl-nowrap"><div class="docs-toc col-xl-3 d-xl-block"><toc><div class="fw-bold text-uppercase mb-2">On this page</div><nav id=toc><ul><li><ul><li><a href=#什么是-daemonset>什么是 DaemonSet？</a></li><li><a href=#编写-daemonset-spec>编写 DaemonSet Spec</a><ul><li><a href=#必需字段>必需字段</a></li><li><a href=#pod-模板>Pod 模板</a></li><li><a href=#pod-selector>Pod Selector</a></li><li><a href=#仅在相同的-node-上运行-pod>仅在相同的 Node 上运行 Pod</a></li></ul></li><li><a href=#如何调度-daemon-pod>如何调度 Daemon Pod</a></li><li><a href=#与-daemon-pod-通信>与 Daemon Pod 通信</a></li><li><a href=#更新-daemonset>更新 DaemonSet</a><ul><li><a href=#init-脚本>init 脚本</a></li><li><a href=#裸-pod>裸 Pod</a></li><li><a href=#静态-pod>静态 Pod</a></li><li><a href=#replication-controller>Replication Controller</a></li></ul></li></ul></li></ul></nav></toc></div><div class="docs-toc-mobile d-print-none d-xl-none"><button id=toc-dropdown-btn class="btn-secondary dropdown-toggle" type=button data-bs-toggle=dropdown data-bs-offset=0,0 aria-expanded=false>
Table of Contents</button><nav id=toc-mobile><ul class=dropdown-menu><li><ul><li><a href=#什么是-daemonset>什么是 DaemonSet？</a></li><li><a href=#编写-daemonset-spec>编写 DaemonSet Spec</a><ul><li><a href=#必需字段>必需字段</a></li><li><a href=#pod-模板>Pod 模板</a></li><li><a href=#pod-selector>Pod Selector</a></li><li><a href=#仅在相同的-node-上运行-pod>仅在相同的 Node 上运行 Pod</a></li></ul></li><li><a href=#如何调度-daemon-pod>如何调度 Daemon Pod</a></li><li><a href=#与-daemon-pod-通信>与 Daemon Pod 通信</a></li><li><a href=#更新-daemonset>更新 DaemonSet</a><ul><li><a href=#init-脚本>init 脚本</a></li><li><a href=#裸-pod>裸 Pod</a></li><li><a href=#静态-pod>静态 Pod</a></li><li><a href=#replication-controller>Replication Controller</a></li></ul></li></ul></li></ul></nav></div><div class="docs-content col-12 col-xl-9 mt-0"><div class="mb-0 d-flex"><i class="material-icons title-icon me-2">article</i><h1 class="content-title mb-0">DaemonSet</h1></div><p class="lead mb-3"></p><div id=content class=main-content data-bs-spy=scroll data-bs-root-margin="0px 0px -65%" data-bs-target=#toc-mobile><div data-prismjs-copy data-prismjs-copy-success data-prismjs-copy-error><p>本文将为您介绍 DaemonSet 的基本概念。</p><h2 id=什么是-daemonset>什么是 DaemonSet？ <a href=#%e4%bb%80%e4%b9%88%e6%98%af-daemonset class=anchor aria-hidden=true><i class="material-icons align-middle">link</i></a></h2><p><em>DaemonSet</em> 确保全部（或者一些）Node 上运行一个 Pod 的副本。当有 Node 加入集群时，也会为他们新增一个 Pod 。当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。</p><p>使用 DaemonSet 的一些典型用法：</p><ul><li>运行集群存储 daemon，例如在每个 Node 上运行 <code>glusterd</code>、<code>ceph</code>。</li><li>在每个 Node 上运行日志收集 daemon，例如<code>fluentd</code>、<code>logstash</code>。</li><li>在每个 Node 上运行监控 daemon，例如 <a href=https://github.com/prometheus/node_exporter rel=external target=_blank>Prometheus Node Exporter<svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" d="M14 5c-.552.0-1-.448-1-1s.448-1 1-1h6c.552.0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1V6.414l-7.293 7.293c-.391.39-1.024.39-1.414.0-.391-.391-.391-1.024.0-1.414L17.586 5H14zM5 7c-.552.0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552.0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1V19c0 1.657-1.343 3-3 3H5c-1.657.0-3-1.343-3-3V8c0-1.657 1.343-3 3-3h4.563c.552.0 1 .448 1 1s-.448 1-1 1H5z"/></svg></a>、<code>collectd</code>、Datadog 代理、New Relic 代理，或 Ganglia <code>gmond</code>。</li></ul><p>一个简单的用法是，在所有的 Node 上都存在一个 DaemonSet，将被作为每种类型的 daemon 使用。
一个稍微复杂的用法可能是，对单独的每种类型的 daemon 使用多个 DaemonSet，但具有不同的标志，和/或对不同硬件类型具有不同的内存、CPU要求。</p><h2 id=编写-daemonset-spec>编写 DaemonSet Spec <a href=#%e7%bc%96%e5%86%99-daemonset-spec class=anchor aria-hidden=true><i class="material-icons align-middle">link</i></a></h2><h3 id=必需字段>必需字段 <a href=#%e5%bf%85%e9%9c%80%e5%ad%97%e6%ae%b5 class=anchor aria-hidden=true><i class="material-icons align-middle">link</i></a></h3><p>和其它所有 Kubernetes 配置一样，DaemonSet 需要 <code>apiVersion</code>、<code>kind</code> 和 <code>metadata</code>字段。有关配置文件的通用信息，详见文档 <a href=https://kubernetes.io/docs/user-guide/deploying-applications/ rel=external target=_blank>部署应用<svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" d="M14 5c-.552.0-1-.448-1-1s.448-1 1-1h6c.552.0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1V6.414l-7.293 7.293c-.391.39-1.024.39-1.414.0-.391-.391-.391-1.024.0-1.414L17.586 5H14zM5 7c-.552.0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552.0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1V19c0 1.657-1.343 3-3 3H5c-1.657.0-3-1.343-3-3V8c0-1.657 1.343-3 3-3h4.563c.552.0 1 .448 1 1s-.448 1-1 1H5z"/></svg></a>、<a href=https://kubernetes.io/docs/user-guide/configuring-containers/ rel=external target=_blank>配置容器<svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" d="M14 5c-.552.0-1-.448-1-1s.448-1 1-1h6c.552.0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1V6.414l-7.293 7.293c-.391.39-1.024.39-1.414.0-.391-.391-.391-1.024.0-1.414L17.586 5H14zM5 7c-.552.0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552.0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1V19c0 1.657-1.343 3-3 3H5c-1.657.0-3-1.343-3-3V8c0-1.657 1.343-3 3-3h4.563c.552.0 1 .448 1 1s-.448 1-1 1H5z"/></svg></a> 和资源管理。</p><p>DaemonSet 也需要一个 <code>.spec</code>配置段。</p><h3 id=pod-模板>Pod 模板 <a href=#pod-%e6%a8%a1%e6%9d%bf class=anchor aria-hidden=true><i class="material-icons align-middle">link</i></a></h3><p><code>.spec</code> 唯一必需的字段是 <code>.spec.template</code>。</p><p><code>.spec.template</code> 是一个 <a href=https://kubernetes.io/docs/user-guide/replication-controller/#pod-template rel=external target=_blank>Pod 模板<svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" d="M14 5c-.552.0-1-.448-1-1s.448-1 1-1h6c.552.0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1V6.414l-7.293 7.293c-.391.39-1.024.39-1.414.0-.391-.391-.391-1.024.0-1.414L17.586 5H14zM5 7c-.552.0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552.0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1V19c0 1.657-1.343 3-3 3H5c-1.657.0-3-1.343-3-3V8c0-1.657 1.343-3 3-3h4.563c.552.0 1 .448 1 1s-.448 1-1 1H5z"/></svg></a>。
它与 <a href=https://kubernetes.io/docs/user-guide/pods rel=external target=_blank>Pod<svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" d="M14 5c-.552.0-1-.448-1-1s.448-1 1-1h6c.552.0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1V6.414l-7.293 7.293c-.391.39-1.024.39-1.414.0-.391-.391-.391-1.024.0-1.414L17.586 5H14zM5 7c-.552.0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552.0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1V19c0 1.657-1.343 3-3 3H5c-1.657.0-3-1.343-3-3V8c0-1.657 1.343-3 3-3h4.563c.552.0 1 .448 1 1s-.448 1-1 1H5z"/></svg></a> 具有相同的 schema，除了它是嵌套的，而且不具有 <code>apiVersion</code> 或 <code>kind</code> 字段。</p><p>Pod 除了必须字段外，在 DaemonSet 中的 Pod 模板必须指定合理的标签（查看 <a href=/docs/information/software/cloud/k8s_rs_manager/deamonset/#pod-selector>pod selector</a>）。</p><p>在 DaemonSet 中的 Pod 模板必需具有一个值为 <code>Always</code> 的 <a href=https://kubernetes.io/docs/user-guide/pod-states rel=external target=_blank><code>RestartPolicy</code><svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" d="M14 5c-.552.0-1-.448-1-1s.448-1 1-1h6c.552.0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1V6.414l-7.293 7.293c-.391.39-1.024.39-1.414.0-.391-.391-.391-1.024.0-1.414L17.586 5H14zM5 7c-.552.0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552.0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1V19c0 1.657-1.343 3-3 3H5c-1.657.0-3-1.343-3-3V8c0-1.657 1.343-3 3-3h4.563c.552.0 1 .448 1 1s-.448 1-1 1H5z"/></svg></a>，或者未指定它的值，默认是 <code>Always</code>。</p><h3 id=pod-selector>Pod Selector <a href=#pod-selector class=anchor aria-hidden=true><i class="material-icons align-middle">link</i></a></h3><p><code>.spec.selector</code> 字段表示 Pod Selector，它与 <a href=https://kubernetes.io/docs/concepts/jobs/run-to-completion-finite-workloads/ rel=external target=_blank>Job<svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" d="M14 5c-.552.0-1-.448-1-1s.448-1 1-1h6c.552.0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1V6.414l-7.293 7.293c-.391.39-1.024.39-1.414.0-.391-.391-.391-1.024.0-1.414L17.586 5H14zM5 7c-.552.0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552.0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1V19c0 1.657-1.343 3-3 3H5c-1.657.0-3-1.343-3-3V8c0-1.657 1.343-3 3-3h4.563c.552.0 1 .448 1 1s-.448 1-1 1H5z"/></svg></a> 或其它资源的 <code>.spec.selector</code> 的原理是相同的。</p><p><code>spec.selector</code> 表示一个对象，它由如下两个字段组成：</p><ul><li><code>matchLabels</code> - 与 <a href=https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller/ rel=external target=_blank>ReplicationController<svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" d="M14 5c-.552.0-1-.448-1-1s.448-1 1-1h6c.552.0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1V6.414l-7.293 7.293c-.391.39-1.024.39-1.414.0-.391-.391-.391-1.024.0-1.414L17.586 5H14zM5 7c-.552.0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552.0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1V19c0 1.657-1.343 3-3 3H5c-1.657.0-3-1.343-3-3V8c0-1.657 1.343-3 3-3h4.563c.552.0 1 .448 1 1s-.448 1-1 1H5z"/></svg></a> 的 <code>.spec.selector</code> 的原理相同。</li><li><code>matchExpressions</code> - 允许构建更加复杂的 Selector，可以通过指定 key、value 列表，以及与 key 和 value 列表的相关的操作符。</li></ul><p>当上述两个字段都指定时，结果表示的是 AND 关系。</p><p>如果指定了 <code>.spec.selector</code>，必须与 <code>.spec.template.metadata.labels</code> 相匹配。如果没有指定，它们默认是等价的。如果与它们配置的不匹配，则会被 API 拒绝。</p><p>如果 Pod 的 label 与 selector 匹配，或者直接基于其它的 DaemonSet、或者 Controller（例如 ReplicationController），也不可以创建任何 Pod。
否则 DaemonSet Controller 将认为那些 Pod 是它创建的。Kubernetes 不会阻止这样做。一个场景是，可能希望在一个具有不同值的、用来测试用的 Node 上手动创建 Pod。</p><h3 id=仅在相同的-node-上运行-pod>仅在相同的 Node 上运行 Pod <a href=#%e4%bb%85%e5%9c%a8%e7%9b%b8%e5%90%8c%e7%9a%84-node-%e4%b8%8a%e8%bf%90%e8%a1%8c-pod class=anchor aria-hidden=true><i class="material-icons align-middle">link</i></a></h3><p>如果指定了 <code>.spec.template.spec.nodeSelector</code>，DaemonSet Controller 将在能够匹配上 <a href=https://kubernetes.io/docs/concepts/configuration/assign-pod-node/ rel=external target=_blank>Node Selector<svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" d="M14 5c-.552.0-1-.448-1-1s.448-1 1-1h6c.552.0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1V6.414l-7.293 7.293c-.391.39-1.024.39-1.414.0-.391-.391-.391-1.024.0-1.414L17.586 5H14zM5 7c-.552.0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552.0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1V19c0 1.657-1.343 3-3 3H5c-1.657.0-3-1.343-3-3V8c0-1.657 1.343-3 3-3h4.563c.552.0 1 .448 1 1s-.448 1-1 1H5z"/></svg></a> 的 Node 上创建 Pod。
类似这种情况，可以指定 <code>.spec.template.spec.affinity</code>，然后 DaemonSet Controller 将在能够匹配上 <a href=https://kubernetes.io/docs/concepts/configuration/assign-pod-node/ rel=external target=_blank>Node Affinity<svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" d="M14 5c-.552.0-1-.448-1-1s.448-1 1-1h6c.552.0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1V6.414l-7.293 7.293c-.391.39-1.024.39-1.414.0-.391-.391-.391-1.024.0-1.414L17.586 5H14zM5 7c-.552.0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552.0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1V19c0 1.657-1.343 3-3 3H5c-1.657.0-3-1.343-3-3V8c0-1.657 1.343-3 3-3h4.563c.552.0 1 .448 1 1s-.448 1-1 1H5z"/></svg></a> 的 Node 上创建 Pod。
如果根本就没有指定，则 DaemonSet Controller 将在所有 Node 上创建 Pod。</p><h2 id=如何调度-daemon-pod>如何调度 Daemon Pod <a href=#%e5%a6%82%e4%bd%95%e8%b0%83%e5%ba%a6-daemon-pod class=anchor aria-hidden=true><i class="material-icons align-middle">link</i></a></h2><p>正常情况下，Pod 运行在哪个机器上是由 Kubernetes 调度器进行选择的。然而，由 Daemon Controller 创建的 Pod 已经确定了在哪个机器上（Pod 创建时指定了 <code>.spec.nodeName</code>），因此：</p><ul><li>DaemonSet Controller 并不关心一个 Node 的 <a href=https://kubernetes.io/docs/admin/node/#manual-node-administration rel=external target=_blank><code>unschedulable</code><svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" d="M14 5c-.552.0-1-.448-1-1s.448-1 1-1h6c.552.0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1V6.414l-7.293 7.293c-.391.39-1.024.39-1.414.0-.391-.391-.391-1.024.0-1.414L17.586 5H14zM5 7c-.552.0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552.0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1V19c0 1.657-1.343 3-3 3H5c-1.657.0-3-1.343-3-3V8c0-1.657 1.343-3 3-3h4.563c.552.0 1 .448 1 1s-.448 1-1 1H5z"/></svg></a> 字段。</li><li>DaemonSet Controller 可以创建 Pod，即使调度器还没有被启动，这对集群启动是非常有帮助的。</li></ul><p>Daemon Pod 关心 <a href=https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#taints-and-tolerations-beta-feature rel=external target=_blank>Taint 和 Toleration<svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" d="M14 5c-.552.0-1-.448-1-1s.448-1 1-1h6c.552.0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1V6.414l-7.293 7.293c-.391.39-1.024.39-1.414.0-.391-.391-.391-1.024.0-1.414L17.586 5H14zM5 7c-.552.0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552.0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1V19c0 1.657-1.343 3-3 3H5c-1.657.0-3-1.343-3-3V8c0-1.657 1.343-3 3-3h4.563c.552.0 1 .448 1 1s-.448 1-1 1H5z"/></svg></a>，它们会为没有指定 <code>tolerationSeconds</code> 的 <code>node.alpha.kubernetes.io/notReady</code> 和 <code>node.alpha.kubernetes.io/unreachable</code> 的 Taint，而创建具有 <code>NoExecute</code> 的 Toleration。这确保了当 alpha 特性的 <code>TaintBasedEvictions</code> 被启用，当 Node 出现故障，比如网络分区，这时它们将不会被清除掉（当 <code>TaintBasedEvictions</code> 特性没有启用，在这些场景下也不会被清除，但会因为 NodeController 的硬编码行为而被清除，Toleration 是不会的）。</p><h2 id=与-daemon-pod-通信>与 Daemon Pod 通信 <a href=#%e4%b8%8e-daemon-pod-%e9%80%9a%e4%bf%a1 class=anchor aria-hidden=true><i class="material-icons align-middle">link</i></a></h2><p>与 DaemonSet 中的 Pod 进行通信，几种可能的模式如下：</p><ul><li><strong>Push</strong>：配置 DaemonSet 中的 Pod 向其它 Service 发送更新，例如统计数据库。它们没有客户端。</li><li><strong>NodeIP 和已知端口</strong>：DaemonSet 中的 Pod 可以使用 <code>hostPort</code>，从而可以通过 Node IP 访问到 Pod。客户端能通过某种方法知道 Node IP 列表，并且基于此也可以知道端口。</li><li><strong>DNS</strong>：创建具有相同 Pod Selector 的 <a href=https://kubernetes.io/docs/user-guide/services/#headless-services rel=external target=_blank>Headless Service<svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" d="M14 5c-.552.0-1-.448-1-1s.448-1 1-1h6c.552.0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1V6.414l-7.293 7.293c-.391.39-1.024.39-1.414.0-.391-.391-.391-1.024.0-1.414L17.586 5H14zM5 7c-.552.0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552.0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1V19c0 1.657-1.343 3-3 3H5c-1.657.0-3-1.343-3-3V8c0-1.657 1.343-3 3-3h4.563c.552.0 1 .448 1 1s-.448 1-1 1H5z"/></svg></a>，然后通过使用 <code>endpoints</code> 资源或从 DNS 检索到多个 A 记录来发现 DaemonSet。</li><li><strong>Service</strong>：创建具有相同 Pod Selector 的 Service，并使用该 Service 访问到某个随机 Node 上的 daemon。（没有办法访问到特定 Node）</li></ul><h2 id=更新-daemonset>更新 DaemonSet <a href=#%e6%9b%b4%e6%96%b0-daemonset class=anchor aria-hidden=true><i class="material-icons align-middle">link</i></a></h2><p>如果修改了 Node Label，DaemonSet 将立刻向新匹配上的 Node 添加 Pod，同时删除新近无法匹配上的 Node 上的 Pod。</p><p>可以修改 DaemonSet 创建的 Pod。然而，不允许对 Pod 的所有字段进行更新。当下次 Node（即使具有相同的名称）被创建时，DaemonSet Controller 还会使用最初的模板。</p><p>可以删除一个 DaemonSet。如果使用 <code>kubectl</code> 并指定 <code>--cascade=false</code> 选项，则 Pod 将被保留在 Node 上。然后可以创建具有不同模板的新 DaemonSet。具有不同模板的新 DaemonSet 将鞥能够通过 Label 匹配识别所有已经存在的 Pod。它不会修改或删除它们，即使是错误匹配了 Pod 模板。通过删除 Pod 或者 删除 Node，可以强制创建新的 Pod。</p><p>在 Kubernetes 1.6 或以后版本，可以在 DaemonSet 上 <a href=https://kubernetes.io/docs/tasks/manage-daemon/update-daemon-set/ rel=external target=_blank>执行滚动升级<svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" d="M14 5c-.552.0-1-.448-1-1s.448-1 1-1h6c.552.0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1V6.414l-7.293 7.293c-.391.39-1.024.39-1.414.0-.391-.391-.391-1.024.0-1.414L17.586 5H14zM5 7c-.552.0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552.0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1V19c0 1.657-1.343 3-3 3H5c-1.657.0-3-1.343-3-3V8c0-1.657 1.343-3 3-3h4.563c.552.0 1 .448 1 1s-.448 1-1 1H5z"/></svg></a>。</p><h3 id=init-脚本>init 脚本 <a href=#init-%e8%84%9a%e6%9c%ac class=anchor aria-hidden=true><i class="material-icons align-middle">link</i></a></h3><p>很可能通过直接在一个 Node 上启动 daemon 进程（例如，使用 <code>init</code>、<code>upstartd</code>、或 <code>systemd</code>）。这非常好，然而基于 DaemonSet 来运行这些进程有如下一些好处：</p><ul><li>像对待应用程序一样，具备为 daemon 提供监控和管理日志的能力。</li><li>为 daemon 和应用程序使用相同的配置语言和工具（如 Pod 模板、<code>kubectl</code>）。</li><li>Kubernetes 未来版本可能会支持对 DaemonSet 创建 Pod 与 Node升级工作流进行集成。</li><li>在资源受限的容器中运行 daemon，能够增加 daemon 和应用容器的隔离性。然而这也实现了在容器中运行 daemon，但却不能在 Pod 中运行（例如，直接基于 Docker 启动）。</li></ul><h3 id=裸-pod>裸 Pod <a href=#%e8%a3%b8-pod class=anchor aria-hidden=true><i class="material-icons align-middle">link</i></a></h3><p>可能要直接创建 Pod，同时指定其运行在特定的 Node 上。
然而，DaemonSet 替换了由于任何原因被删除或终止的 Pod，例如 Node 失败、例行节点维护，比如内核升级。由于这个原因，我们应该使用 DaemonSet 而不是单独创建 Pod。</p><h3 id=静态-pod>静态 Pod <a href=#%e9%9d%99%e6%80%81-pod class=anchor aria-hidden=true><i class="material-icons align-middle">link</i></a></h3><p>很可能，通过在一个指定目录下编写文件来创建 Pod，该目录受 Kubelet 所监视。这些 Pod 被称为 <a href=https://kubernetes.io/docs/concepts/cluster-administration/static-pod/ rel=external target=_blank>静态 Pod<svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" d="M14 5c-.552.0-1-.448-1-1s.448-1 1-1h6c.552.0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1V6.414l-7.293 7.293c-.391.39-1.024.39-1.414.0-.391-.391-.391-1.024.0-1.414L17.586 5H14zM5 7c-.552.0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552.0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1V19c0 1.657-1.343 3-3 3H5c-1.657.0-3-1.343-3-3V8c0-1.657 1.343-3 3-3h4.563c.552.0 1 .448 1 1s-.448 1-1 1H5z"/></svg></a>。
不像 DaemonSet，静态 Pod 不受 kubectl 和 其它 Kubernetes API 客户端管理。静态 Pod 不依赖于 apiserver，这使得它们在集群启动的情况下非常有用。
而且，未来静态 Pod 可能会被废弃掉。</p><h3 id=replication-controller>Replication Controller <a href=#replication-controller class=anchor aria-hidden=true><i class="material-icons align-middle">link</i></a></h3><p>DaemonSet 与 <a href=https://kubernetes.io/docs/user-guide/replication-controller rel=external target=_blank>Replication Controller<svg width="16" height="16" viewBox="0 0 24 24"><path fill="currentColor" d="M14 5c-.552.0-1-.448-1-1s.448-1 1-1h6c.552.0 1 .448 1 1v6c0 .552-.448 1-1 1s-1-.448-1-1V6.414l-7.293 7.293c-.391.39-1.024.39-1.414.0-.391-.391-.391-1.024.0-1.414L17.586 5H14zM5 7c-.552.0-1 .448-1 1v11c0 .552.448 1 1 1h11c.552.0 1-.448 1-1v-4.563c0-.552.448-1 1-1s1 .448 1 1V19c0 1.657-1.343 3-3 3H5c-1.657.0-3-1.343-3-3V8c0-1.657 1.343-3 3-3h4.563c.552.0 1 .448 1 1s-.448 1-1 1H5z"/></svg></a> 非常类似，它们都能创建 Pod，这些 Pod 都具有不期望被终止的进程（例如，Web 服务器、存储服务器）。
为无状态的 Service 使用 Replication Controller，像 frontend，实现对副本的数量进行扩缩容、平滑升级，比之于精确控制 Pod 运行在某个主机上要重要得多。需要 Pod 副本总是运行在全部或特定主机上，并需要先于其他 Pod 启动，当这被认为非常重要时，应该使用 Daemon Controller。</p></div></div><div><hr class=doc-hr><div id=doc-nav class=d-print-none><div class="row flex-xl-nowrap"><div class="col-sm-6 pt-2 doc-next"><a href=/docs/information/software/cloud/k8s_rs_manager/statefulset/><div class="card h-100 my-1"><div class="card-body py-2"><p class="card-title fs-5 fw-semibold lh-base mb-0"><i class="material-icons align-middle">navigate_before</i> StatefulSet</p><p class="card-text ms-2"></p></div></div></a></div><div class="col-sm-6 pt-2 doc-prev"><a class=ms-auto href=/docs/information/software/cloud/k8s_rs_manager/replicaset/><div class="card h-100 my-1 text-end"><div class="card-body py-2"><p class="card-title fs-5 fw-semibold lh-base mb-0">ReplicationController 和 ReplicaSet <i class="material-icons align-middle">navigate_next</i></p><p class="card-text me-2"></p></div></div></a></div></div></div></div></div></div></div></div><footer class="shadow py-3 d-print-none"><div class=container-fluid><div class="row align-items-center"><div class=col><div class="text-sm-start text-center mx-md-2"><p class=mb-0>© 2025 Blahvalf.</p></div></div></div></div></footer></main></div></div><button onclick=topFunction() id=back-to-top aria-label="Back to Top Button" class="back-to-top fs-5"><svg width="24" height="24"><path d="M12 10.224l-6.3 6.3-1.38-1.372L12 7.472l7.68 7.68-1.38 1.376z" style="fill:#fff"/></svg></button>
<script>(()=>{var e=document.getElementById("mode");e!==null&&(window.matchMedia("(prefers-color-scheme: dark)").addEventListener("change",e=>{e.matches?(localStorage.setItem("theme","dark"),document.documentElement.setAttribute("data-dark-mode","")):(localStorage.setItem("theme","light"),document.documentElement.removeAttribute("data-dark-mode"))}),e.addEventListener("click",()=>{document.documentElement.toggleAttribute("data-dark-mode"),localStorage.setItem("theme",document.documentElement.hasAttribute("data-dark-mode")?"dark":"light")}),localStorage.getItem("theme")==="dark"?document.documentElement.setAttribute("data-dark-mode",""):document.documentElement.removeAttribute("data-dark-mode"))})()</script><script src=/docs/js/bootstrap.c7927bdd82eceb076739257add3f4b0e11379da037c07d5c7110daeb6de0e3edcb2de867604550f88815157e4ec4ddb7.js integrity=sha384-x5J73YLs6wdnOSV63T9LDhE3naA3wH1ccRDa623g4+3LLehnYEVQ+IgVFX5OxN23 defer></script><script type=text/javascript src=https://blahvalf.github.io/docs/js/bundle.min.482e4e9c7213a721af4f033c69129711f8e6b00e365c43dffa349a62a94367dfdeaefb02c723d750a5571347dbe04edd.js integrity=sha384-SC5OnHITpyGvTwM8aRKXEfjmsA42XEPf+jSaYqlDZ9/ervsCxyPXUKVXE0fb4E7d crossorigin=anonymous defer></script><script type=module>
    var suggestions = document.getElementById('suggestions');
    var search = document.getElementById('flexsearch');

    const flexsearchContainer = document.getElementById('FlexSearchCollapse');

    const hideFlexsearchBtn = document.getElementById('hideFlexsearch');

    const configObject = { toggle: false }
    const flexsearchContainerCollapse = new Collapse(flexsearchContainer, configObject) 

    if (search !== null) {
        document.addEventListener('keydown', inputFocus);
        flexsearchContainer.addEventListener('shown.bs.collapse', function () {
            search.focus();
        });
        
        var topHeader = document.getElementById("top-header");
        document.addEventListener('click', function(elem) {
            if (!flexsearchContainer.contains(elem.target) && !topHeader.contains(elem.target))
                flexsearchContainerCollapse.hide();
        });
    }

    hideFlexsearchBtn.addEventListener('click', () =>{
        flexsearchContainerCollapse.hide()
    })

    function inputFocus(e) {
        if (e.ctrlKey && e.key === '/') {
            e.preventDefault();
            flexsearchContainerCollapse.toggle();
        }
        if (e.key === 'Escape' ) {
            search.blur();
            
            flexsearchContainerCollapse.hide();
        }
    };

    document.addEventListener('click', function(event) {

    var isClickInsideElement = suggestions.contains(event.target);

    if (!isClickInsideElement) {
        suggestions.classList.add('d-none');
    }

    });

    


    document.addEventListener('keydown',suggestionFocus);

    function suggestionFocus(e) {
    const suggestionsHidden = suggestions.classList.contains('d-none');
    if (suggestionsHidden) return;

    const focusableSuggestions= [...suggestions.querySelectorAll('a')];
    if (focusableSuggestions.length === 0) return;

    const index = focusableSuggestions.indexOf(document.activeElement);

    if (e.key === "ArrowUp") {
        e.preventDefault();
        const nextIndex = index > 0 ? index - 1 : 0;
        focusableSuggestions[nextIndex].focus();
    }
    else if (e.key === "ArrowDown") {
        e.preventDefault();
        const nextIndex= index + 1 < focusableSuggestions.length ? index + 1 : index;
        focusableSuggestions[nextIndex].focus();
    }

    }

    


    (function(){

    var index = new FlexSearch.Document({
        
        tokenize: "forward",
        minlength:  0 ,
        cache:  100 ,
        optimize:  true ,
        document: {
        id: 'id',
        store: [
            "href", "title", "description"
        ],
        index: ["title", "description", "content"]
        }
    });


    


    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    


    

    

    index.add(
            {
                id:  0 ,
                href: "\/docs\/information\/software\/cloud\/k8s_arch\/",
                title: "K8s架构",
                description: "系统架构 linkKubernetes 最初源于谷歌内部的 Borg，提供了面向应用的容器集群部署和管理系统。Kubernetes 的目标旨在消除编排物理 / 虚拟计算，网络和存储基础设施的负担，并使应用程序运营商和开发人员完全将重点放在以容器为中心的原语上进行自助运营。Kubernetes 也提供稳定、兼容的基础（平台），用于构建定制化的 workflows 和更高级的自动化任务。 Kubernetes 具备完善的集群管理能力，包括多层次的安全防护和准入机制、多租户应用支撑能力、透明的服务注册和服务发现机制、内建负载均衡器、故障发现和自我修复能力、服务滚动升级和在线扩容、可扩展的资源自动调度机制、多粒度的资源配额管理能力。Kubernetes 还提供完善的管理工具，涵盖开发、部署测试、运维监控等各个环节。\nKubernetes 借鉴了 Borg 的设计理念，比如 Pod、Service、Label 和单 Pod 单 IP 等。Kubernetes 的整体架构跟 Borg 非常像，如下图所示。\ngraph TD subgraph 外部用户 K[kubectl] end subgraph Master节点 A[API ServerREST模式] AD[Admission校验/变更] S[Storageetcd] CM[Controller Manager] SCH[Scheduler] end subgraph Node节点 K1[kubelet] K2[kubelet] P1[Pod] P2[Pod] C1[Container] C2[Container] C3[Container] end 网络((Internet)) --\u003e FW[Firewall] FW --\u003e PR[Proxy] K -- 认证请求 --\u003e A A \u003c-- Valid \u0026 Mutex --\u003e AD A -- 存储 --\u003e S CM \u003c-- 监听/读写/资源变更 --\u003e A A \u003c-- 读写/调度 --\u003e SCH A \u003c-- 获取状态/更新状态 --\u003e K1 K1 --\u003e P1 --\u003e C1 \u0026 C2 K1 --\u003e P2 --\u003e C3 PR -. 流量代理 .-\u003e P1 PR -. 流量代理 .-\u003e P2 classDef master fill:#f9f,stroke:#333; classDef node fill:#ccf,stroke:#333; classDef pod fill:#cff,stroke:#333; class K1,K2,PR node; class A,AD,S,CM,SCH master; class P1,P2 pod; Kubernetes 主要由以下几个核心组件组成：\n",
                content: "系统架构 linkKubernetes 最初源于谷歌内部的 Borg，提供了面向应用的容器集群部署和管理系统。Kubernetes 的目标旨在消除编排物理 / 虚拟计算，网络和存储基础设施的负担，并使应用程序运营商和开发人员完全将重点放在以容器为中心的原语上进行自助运营。Kubernetes 也提供稳定、兼容的基础（平台），用于构建定制化的 workflows 和更高级的自动化任务。 Kubernetes 具备完善的集群管理能力，包括多层次的安全防护和准入机制、多租户应用支撑能力、透明的服务注册和服务发现机制、内建负载均衡器、故障发现和自我修复能力、服务滚动升级和在线扩容、可扩展的资源自动调度机制、多粒度的资源配额管理能力。Kubernetes 还提供完善的管理工具，涵盖开发、部署测试、运维监控等各个环节。\nKubernetes 借鉴了 Borg 的设计理念，比如 Pod、Service、Label 和单 Pod 单 IP 等。Kubernetes 的整体架构跟 Borg 非常像，如下图所示。\ngraph TD subgraph 外部用户 K[kubectl] end subgraph Master节点 A[API ServerREST模式] AD[Admission校验/变更] S[Storageetcd] CM[Controller Manager] SCH[Scheduler] end subgraph Node节点 K1[kubelet] K2[kubelet] P1[Pod] P2[Pod] C1[Container] C2[Container] C3[Container] end 网络((Internet)) --\u003e FW[Firewall] FW --\u003e PR[Proxy] K -- 认证请求 --\u003e A A \u003c-- Valid \u0026 Mutex --\u003e AD A -- 存储 --\u003e S CM \u003c-- 监听/读写/资源变更 --\u003e A A \u003c-- 读写/调度 --\u003e SCH A \u003c-- 获取状态/更新状态 --\u003e K1 K1 --\u003e P1 --\u003e C1 \u0026 C2 K1 --\u003e P2 --\u003e C3 PR -. 流量代理 .-\u003e P1 PR -. 流量代理 .-\u003e P2 classDef master fill:#f9f,stroke:#333; classDef node fill:#ccf,stroke:#333; classDef pod fill:#cff,stroke:#333; class K1,K2,PR node; class A,AD,S,CM,SCH master; class P1,P2 pod; Kubernetes 主要由以下几个核心组件组成：\netcd 保存了整个集群的状态； apiserver 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API 注册和发现等机制； controller manager 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等； scheduler 负责资源的调度，按照预定的调度策略将 Pod 调度到相应的机器上； kubelet 负责维护容器的生命周期，同时也负责 Volume（CSI）和网络（CNI）的管理； Container runtime 负责镜像管理以及 Pod 和容器的真正运行（CRI）； kube-proxy 负责为 Service 提供 cluster 内部的服务发现和负载均衡； 除了核心组件，还有一些推荐的插件，其中有的已经成为 CNCF 中的托管项目：\nCoreDNS 负责为整个集群提供 DNS 服务 Ingress Controller 为服务提供外网入口 Prometheus 提供资源监控 Dashboard 提供 GUI Federation 提供跨可用区的集群 graph TD subgraph Control Plane APIServer[APIServer] \u003c--\u003e |grpc|ETCD[ETCD] Controller[Controller Manager] \u003c--\u003e|Controller Loops with protobuf| APIServer Scheduler[Kube-Scheduler] \u003c--\u003e|Bind Pod to Node with protobuf| APIServer end User(User) --\u003e |Json|APIServer subgraph Node Kubelet(Kubelet) \u003c--\u003e|with protobuf| APIServer Kubelet --\u003e|CRI| ContainerRuntime[Container Runtime] ContainerRuntime --\u003e|OCI| OS(OS) Kubelet--\u003e|CNI|NetWork[CNI Network] OS --\u003e Hardware(Hardware) end classDef control fill:#e6f7ff,stroke:#1890ff; classDef node fill:#e8f5e9,stroke:#4caf50; classDef infra fill:#f5f5f5,stroke:#9e9e9e; class ControlPlane,APIServer,ETCD,Controller,Scheduler control; class Node,Kubelet,ContainerRuntime,NetWork node; class OS,Hardware,User infra; K8s设计理念 link分层架构 linkKubernetes 设计理念和功能其实就是一个类似 Linux 的分层架构。\n核心层：Kubernetes 最核心的功能，对外提供 API 构建高层的应用，对内提供插件式应用执行环境 应用层：部署（无状态应用、有状态应用、批处理任务、集群应用等）和路由（服务发现、DNS 解析等） 管理层：系统度量（如基础设施、容器和网络的度量），自动化（如自动扩展、动态 Provision 等）以及策略管理（RBAC、Quota、PSP、NetworkPolicy 等） 接口层：kubectl 命令行工具、客户端 SDK 以及集群联邦 生态系统：在接口层之上的庞大容器集群管理调度的生态系统，可以划分为两个范畴 Kubernetes 外部：日志、监控、配置管理、CI、CD、Workflow、FaaS、OTS 应用、ChatOps 等 Kubernetes 内部：CRI、CNI、CVI、镜像仓库、Cloud Provider、集群自身的配置和管理等 云原生生态系统 接口层：客户端库和实用工具 管理层：自动化和策略管理 应用层：部署和路由 核心层：Kubernetes API和执行环境 容器运行时接口(CRI) 容器网络接口(CNI) 容器存储接口(CSI) 镜像仓库 云供应商 身份供应商 API 设计原则 link对于云计算系统，系统 API 实际上处于系统设计的统领地位，正如本文前面所说，Kubernetes 集群系统每支持一项新功能，引入一项新技术，一定会新引入对应的 API 对象，支持对该功能的管理操作，理解掌握的 API，就好比抓住了 Kubernetes 系统的牛鼻子。Kubernetes 系统 API 的设计有以下几条原则：\n所有 API 应该是声明式的。正如前文所说，声明式的操作，相对于命令式操作，对于重复操作的效果是稳定的，这对于容易出现数据丢失或重复的分布式环境来说是很重要的。另外，声明式操作更容易被用户使用，可以使系统向用户隐藏实现的细节，隐藏实现的细节的同时，也就保留了系统未来持续优化的可能性。此外，声明式的 API，同时隐含了所有的 API 对象都是名词性质的，例如 Service、Volume 这些 API 都是名词，这些名词描述了用户所期望得到的一个目标分布式对象。 API 对象是彼此互补而且可组合的。这里面实际是鼓励 API 对象尽量实现面向对象设计时的要求，即 “高内聚，松耦合”，对业务相关的概念有一个合适的分解，提高分解出来的对象的可重用性。事实上，Kubernetes 这种分布式系统管理平台，也是一种业务系统，只不过它的业务就是调度和管理容器服务。 高层 API 以操作意图为基础设计。如何能够设计好 API，跟如何能用面向对象的方法设计好应用系统有相通的地方，高层设计一定是从业务出发，而不是过早的从技术实现出发。因此，针对 Kubernetes 的高层 API 设计，一定是以 Kubernetes 的业务为基础出发，也就是以系统调度管理容器的操作意图为基础设计。 低层 API 根据高层 API 的控制需要设计。设计实现低层 API 的目的，是为了被高层 API 使用，考虑减少冗余、提高重用性的目的，低层 API 的设计也要以需求为基础，要尽量抵抗受技术实现影响的诱惑。 尽量避免简单封装，不要有在外部 API 无法显式知道的内部隐藏的机制。简单的封装，实际没有提供新的功能，反而增加了对所封装 API 的依赖性。内部隐藏的机制也是非常不利于系统维护的设计方式，例如 StatefulSet 和 ReplicaSet，本来就是两种 Pod 集合，那么 Kubernetes 就用不同 API 对象来定义它们，而不会说只用同一个 ReplicaSet，内部通过特殊的算法再来区分这个 ReplicaSet 是有状态的还是无状态。 API 操作复杂度与对象数量成正比。这一条主要是从系统性能角度考虑，要保证整个系统随着系统规模的扩大，性能不会迅速变慢到无法使用，那么最低的限定就是 API 的操作复杂度不能超过 O(N)，N 是对象的数量，否则系统就不具备水平伸缩性了。 API 对象状态不能依赖于网络连接状态。由于众所周知，在分布式环境下，网络连接断开是经常发生的事情，因此要保证 API 对象状态能应对网络的不稳定，API 对象的状态就不能依赖于网络连接状态。 尽量避免让操作机制依赖于全局状态，因为在分布式系统中要保证全局状态的同步是非常困难的。 控制机制设计原则 link 控制逻辑应该只依赖于当前状态。这是为了保证分布式系统的稳定可靠，对于经常出现局部错误的分布式系统，如果控制逻辑只依赖当前状态，那么就非常容易将一个暂时出现故障的系统恢复到正常状态，因为你只要将该系统重置到某个稳定状态，就可以自信的知道系统的所有控制逻辑会开始按照正常方式运行。 假设任何错误的可能，并做容错处理。在一个分布式系统中出现局部和临时错误是大概率事件。错误可能来自于物理系统故障，外部系统故障也可能来自于系统自身的代码错误，依靠自己实现的代码不会出错来保证系统稳定其实也是难以实现的，因此要设计对任何可能错误的容错处理。 尽量避免复杂状态机，控制逻辑不要依赖无法监控的内部状态。因为分布式系统各个子系统都是不能严格通过程序内部保持同步的，所以如果两个子系统的控制逻辑如果互相有影响，那么子系统就一定要能互相访问到影响控制逻辑的状态，否则，就等同于系统里存在不确定的控制逻辑。 假设任何操作都可能被任何操作对象拒绝，甚至被错误解析。由于分布式系统的复杂性以及各子系统的相对独立性，不同子系统经常来自不同的开发团队，所以不能奢望任何操作被另一个子系统以正确的方式处理，要保证出现错误的时候，操作级别的错误不会影响到系统稳定性。 每个模块都可以在出错后自动恢复。由于分布式系统中无法保证系统各个模块是始终连接的，因此每个模块要有自我修复的能力，保证不会因为连接不到其他模块而自我崩溃。 每个模块都可以在必要时优雅地降级服务。所谓优雅地降级服务，是对系统鲁棒性的要求，即要求在设计实现模块时划分清楚基本功能和高级功能，保证基本功能不会依赖高级功能，这样同时就保证了不会因为高级功能出现故障而导致整个模块崩溃。根据这种理念实现的系统，也更容易快速地增加新的高级功能，因为不必担心引入高级功能影响原有的基本功能。 Kubernetes 的核心技术概念和 API 对象 linkAPI 对象是 Kubernetes 集群中的管理操作单元。Kubernetes 集群系统每支持一项新功能，引入一项新技术，一定会新引入对应的 API 对象，支持对该功能的管理操作。例如副本集 Replica Set 对应的 API 对象是 RS。\n每个 API 对象都有 3 大类属性：元数据 metadata、规范 spec 和状态 status。元数据是用来标识 API 对象的，每个对象都至少有 3 个元数据：namespace，name 和 uid；除此以外还有各种各样的标签 labels 用来标识和匹配不同的对象，例如用户可以用标签 env 来标识区分不同的服务部署环境，分别用 env=dev、env=testing、env=production 来标识开发、测试、生产的不同服务。规范描述了用户期望 Kubernetes 集群中的分布式系统达到的理想状态（Desired State），例如用户可以通过复制控制器 Replication Controller 设置期望的 Pod 副本数为 3；status 描述了系统实际当前达到的状态（Status），例如系统当前实际的 Pod 副本数为 2；那么复制控制器当前的程序逻辑就是自动启动新的 Pod，争取达到副本数为 3。\nKubernetes 中所有的配置都是通过 API 对象的 spec 去设置的，也就是用户通过配置系统的理想状态来改变系统，这是 Kubernetes 重要设计理念之一，即所有的操作都是声明式（Declarative）的而不是命令式（Imperative）的。声明式操作在分布式系统中的好处是稳定，不怕丢操作或运行多次，例如设置副本数为 3 的操作运行多次也还是一个结果，而给副本数加 1 的操作就不是声明式的，运行多次结果就错了。\nPod linkKubernetes 有很多技术概念，同时对应很多 API 对象，最重要的也是最基础的是 Pod。Pod 是在 Kubernetes 集群中运行部署应用或服务的最小单元，它是可以支持多容器的。Pod 的设计理念是支持多个容器在一个 Pod 中共享网络地址和文件系统，可以通过进程间通信和文件共享这种简单高效的方式组合完成服务。Pod 对多容器的支持是 K8 最基础的设计理念。比如你运行一个操作系统发行版的软件仓库，一个 Nginx 容器用来发布软件，另一个容器专门用来从源仓库做同步，这两个容器的镜像不太可能是一个团队开发的，但是他们一块儿工作才能提供一个微服务；这种情况下，不同的团队各自开发构建自己的容器镜像，在部署的时候组合成一个微服务对外提供服务。\nPod 是 Kubernetes 集群中所有业务类型的基础，可以看作运行在 Kubernetes 集群中的小机器人，不同类型的业务就需要不同类型的小机器人去执行。目前 Kubernetes 中的业务主要可以分为长期伺服型（long-running）、批处理型（batch）、节点后台支撑型（node-daemon）和有状态应用型（stateful application）；分别对应的小机器人控制器为 Deployment、Job、DaemonSet 和 StatefulSet，本文后面会一一介绍。\n副本控制器（Replication Controller，RC） linkRC 是 Kubernetes 集群中最早的保证 Pod 高可用的 API 对象。通过监控运行中的 Pod 来保证集群中运行指定数目的 Pod 副本。指定的数目可以是多个也可以是 1 个；少于指定数目，RC 就会启动运行新的 Pod 副本；多于指定数目，RC 就会杀死多余的 Pod 副本。即使在指定数目为 1 的情况下，通过 RC 运行 Pod 也比直接运行 Pod 更明智，因为 RC 也可以发挥它高可用的能力，保证永远有 1 个 Pod 在运行。RC 是 Kubernetes 较早期的技术概念，只适用于长期伺服型的业务类型，比如控制小机器人提供高可用的 Web 服务。\n副本集（Replica Set，RS） linkRS 是新一代 RC，提供同样的高可用能力，区别主要在于 RS 后来居上，能支持更多种类的匹配模式。副本集对象一般不单独使用，而是作为 Deployment 的理想状态参数使用。\n部署（Deployment） link部署表示用户对 Kubernetes 集群的一次更新操作。部署是一个比 RS 应用模式更广的 API 对象，可以是创建一个新的服务，更新一个新的服务，也可以是滚动升级一个服务。滚动升级一个服务，实际是创建一个新的 RS，然后逐渐将新 RS 中副本数增加到理想状态，将旧 RS 中的副本数减小到 0 的复合操作；这样一个复合操作用一个 RS 是不太好描述的，所以用一个更通用的 Deployment 来描述。以 Kubernetes 的发展方向，未来对所有长期伺服型的的业务的管理，都会通过 Deployment 来管理。\n服务（Service） linkRC、RS 和 Deployment 只是保证了支撑服务的微服务 Pod 的数量，但是没有解决如何访问这些服务的问题。一个 Pod 只是一个运行服务的实例，随时可能在一个节点上停止，在另一个节点以一个新的 IP 启动一个新的 Pod，因此不能以确定的 IP 和端口号提供服务。要稳定地提供服务需要服务发现和负载均衡能力。服务发现完成的工作，是针对客户端访问的服务，找到对应的的后端服务实例。在 K8 集群中，客户端需要访问的服务就是 Service 对象。每个 Service 会对应一个集群内部有效的虚拟 IP，集群内部通过虚拟 IP 访问一个服务。在 Kubernetes 集群中微服务的负载均衡是由 Kube-proxy 实现的。Kube-proxy 是 Kubernetes 集群内部的负载均衡器。它是一个分布式代理服务器，在 Kubernetes 的每个节点上都有一个；这一设计体现了它的伸缩性优势，需要访问服务的节点越多，提供负载均衡能力的 Kube-proxy 就越多，高可用节点也随之增多。与之相比，我们平时在服务器端做个反向代理做负载均衡，还要进一步解决反向代理的负载均衡和高可用问题。\n任务（Job） linkJob 是 Kubernetes 用来控制批处理型任务的 API 对象。批处理业务与长期伺服业务的主要区别是批处理业务的运行有头有尾，而长期伺服业务在用户不停止的情况下永远运行。Job 管理的 Pod 根据用户的设置把任务成功完成就自动退出了。成功完成的标志根据不同的 spec.completions 策略而不同：单 Pod 型任务有一个 Pod 成功就标志完成；定数成功型任务保证有 N 个任务全部成功；工作队列型任务根据应用确认的全局成功而标志成功。\n后台支撑服务集（DaemonSet） link长期伺服型和批处理型服务的核心在业务应用，可能有些节点运行多个同类业务的 Pod，有些节点上又没有这类 Pod 运行；而后台支撑型服务的核心关注点在 Kubernetes 集群中的节点（物理机或虚拟机），要保证每个节点上都有一个此类 Pod 运行。节点可能是所有集群节点也可能是通过 nodeSelector 选定的一些特定节点。典型的后台支撑型服务包括，存储，日志和监控等在每个节点上支持 Kubernetes 集群运行的服务。\n有状态服务集（StatefulSet） linkKubernetes 在 1.3 版本里发布了 Alpha 版的 PetSet 功能，在 1.5 版本里将 PetSet 功能升级到了 Beta 版本，并重新命名为 StatefulSet，最终在 1.9 版本里成为正式 GA 版本。在云原生应用的体系里，有下面两组近义词；第一组是无状态（stateless）、牲畜（cattle）、无名（nameless）、可丢弃（disposable）；第二组是有状态（stateful）、宠物（pet）、有名（having name）、不可丢弃（non-disposable）。RC 和 RS 主要是控制提供无状态服务的，其所控制的 Pod 的名字是随机设置的，一个 Pod 出故障了就被丢弃掉，在另一个地方重启一个新的 Pod，名字变了。名字和启动在哪儿都不重要，重要的只是 Pod 总数；而 StatefulSet 是用来控制有状态服务，StatefulSet 中的每个 Pod 的名字都是事先确定的，不能更改。StatefulSet 中 Pod 的名字的作用，并不是《千与千寻》的人性原因，而是关联与该 Pod 对应的状态。\n对于 RC 和 RS 中的 Pod，一般不挂载存储或者挂载共享存储，保存的是所有 Pod 共享的状态，Pod 像牲畜一样没有分别（这似乎也确实意味着失去了人性特征）；对于 StatefulSet 中的 Pod，每个 Pod 挂载自己独立的存储，如果一个 Pod 出现故障，从其他节点启动一个同样名字的 Pod，要挂载上原来 Pod 的存储继续以它的状态提供服务。\n适合于 StatefulSet 的业务包括数据库服务 MySQL 和 PostgreSQL，集群化管理服务 ZooKeeper、etcd 等有状态服务。StatefulSet 的另一种典型应用场景是作为一种比普通容器更稳定可靠的模拟虚拟机的机制。传统的虚拟机正是一种有状态的宠物，运维人员需要不断地维护它，容器刚开始流行时，我们用容器来模拟虚拟机使用，所有状态都保存在容器里，而这已被证明是非常不安全、不可靠的。使用 StatefulSet，Pod 仍然可以通过漂移到不同节点提供高可用，而存储也可以通过外挂的存储来提供高可靠性，StatefulSet 做的只是将确定的 Pod 与确定的存储关联起来保证状态的连续性。\n集群联邦（Federation） linkKubernetes 在 1.3 版本里发布了 beta 版的 Federation 功能。在云计算环境中，服务的作用距离范围从近到远一般可以有：同主机（Host，Node）、跨主机同可用区（Available Zone）、跨可用区同地区（Region）、跨地区同服务商（Cloud Service Provider）、跨云平台。Kubernetes 的设计定位是单一集群在同一个地域内，因为同一个地区的网络性能才能满足 Kubernetes 的调度和计算存储连接要求。而联合集群服务就是为提供跨 Region 跨服务商 Kubernetes 集群服务而设计的。\n每个 Kubernetes Federation 有自己的分布式存储、API Server 和 Controller Manager。用户可以通过 Federation 的 API Server 注册该 Federation 的成员 Kubernetes Cluster。当用户通过 Federation 的 API Server 创建、更改 API 对象时，Federation API Server 会在自己所有注册的子 Kubernetes Cluster 都创建一份对应的 API 对象。在提供业务请求服务时，Kubernetes Federation 会先在自己的各个子 Cluster 之间做负载均衡，而对于发送到某个具体 Kubernetes Cluster 的业务请求，会依照这个 Kubernetes Cluster 独立提供服务时一样的调度模式去做 Kubernetes Cluster 内部的负载均衡。而 Cluster 之间的负载均衡是通过域名服务的负载均衡来实现的。\nFederation V1 的设计是尽量不影响 Kubernetes Cluster 现有的工作机制，这样对于每个子 Kubernetes 集群来说，并不需要更外层的有一个 Kubernetes Federation，也就是意味着所有现有的 Kubernetes 代码和机制不需要因为 Federation 功能有任何变化。\n目前正在开发的 Federation V2，在保留现有 Kubernetes API 的同时，会开发新的 Federation 专用的 API 接口，详细内容可以在 这里 找到。\n存储卷（Volume） linkKubernetes 集群中的存储卷跟 Docker 的存储卷有些类似，只不过 Docker 的存储卷作用范围为一个容器，而 Kubernetes 的存储卷的生命周期和作用范围是一个 Pod。每个 Pod 中声明的存储卷由 Pod 中的所有容器共享。Kubernetes 支持非常多的存储卷类型，特别的，支持多种公有云平台的存储，包括 AWS，Google 和 Azure 云；支持多种分布式存储包括 GlusterFS 和 Ceph；也支持较容易使用的主机本地目录 emptyDir, hostPath 和 NFS。Kubernetes 还支持使用 Persistent Volume Claim 即 PVC 这种逻辑存储，使用这种存储，使得存储的使用者可以忽略后台的实际存储技术（例如 AWS，Google 或 GlusterFS 和 Ceph），而将有关存储实际技术的配置交给存储管理员通过 Persistent Volume 来配置。\n持久存储卷（Persistent Volume，PV）和持久存储卷声明（Persistent Volume Claim，PVC） linkPV 和 PVC 使得 Kubernetes 集群具备了存储的逻辑抽象能力，使得在配置 Pod 的逻辑里可以忽略对实际后台存储技术的配置，而把这项配置的工作交给 PV 的配置者，即集群的管理者。存储的 PV 和 PVC 的这种关系，跟计算的 Node 和 Pod 的关系是非常类似的；PV 和 Node 是资源的提供者，根据集群的基础设施变化而变化，由 Kubernetes 集群管理员配置；而 PVC 和 Pod 是资源的使用者，根据业务服务的需求变化而变化，有 Kubernetes 集群的使用者即服务的管理员来配置。\n节点（Node） linkKubernetes 集群中的计算能力由 Node 提供，最初 Node 称为服务节点 Minion，后来改名为 Node。Kubernetes 集群中的 Node 也就等同于 Mesos 集群中的 Slave 节点，是所有 Pod 运行所在的工作主机，可以是物理机也可以是虚拟机。不论是物理机还是虚拟机，工作主机的统一特征是上面要运行 kubelet 管理节点上运行的容器。\n密钥对象（Secret） linkSecret 是用来保存和传递密码、密钥、认证凭证这些敏感信息的对象。使用 Secret 的好处是可以避免把敏感信息明文写在配置文件里。在 Kubernetes 集群中配置和使用服务不可避免的要用到各种敏感信息实现登录、认证等功能，例如访问 AWS 存储的用户名密码。为了避免将类似的敏感信息明文写在所有需要使用的配置文件中，可以将这些信息存入一个 Secret 对象，而在配置文件中通过 Secret 对象引用这些敏感信息。这种方式的好处包括：意图明确，避免重复，减少暴漏机会。\n用户帐户（User Account）和服务帐户（Service Account） link顾名思义，用户帐户为人提供账户标识，而服务账户为计算机进程和 Kubernetes 集群中运行的 Pod 提供账户标识。用户帐户和服务帐户的一个区别是作用范围；用户帐户对应的是人的身份，人的身份与服务的 namespace 无关，所以用户账户是跨 namespace 的；而服务帐户对应的是一个运行中程序的身份，与特定 namespace 是相关的。\n命名空间（Namespace） link命名空间为 Kubernetes 集群提供虚拟的隔离作用，Kubernetes 集群初始有两个命名空间，分别是默认命名空间 default 和系统命名空间 kube-system，除此以外，管理员可以可以创建新的命名空间满足需要。\nRBAC 访问授权 linkKubernetes 在 1.3 版本中发布了 alpha 版的基于角色的访问控制（Role-based Access Control，RBAC）的授权模式。相对于基于属性的访问控制（Attribute-based Access Control，ABAC），RBAC 主要是引入了角色（Role）和角色绑定（RoleBinding）的抽象概念。在 ABAC 中，Kubernetes 集群中的访问策略只能跟用户直接关联；而在 RBAC 中，访问策略可以跟某个角色关联，具体的用户在跟一个或多个角色相关联。显然，RBAC 像其他新功能一样，每次引入新功能，都会引入新的 API 对象，从而引入新的概念抽象，而这一新的概念抽象一定会使集群服务管理和使用更容易扩展和重用。\n开放容器接口 link容器运行时接口（CRI） linkCRI（Container Runtime Interface，容器运行时接口）是 Kubernetes 中的一个核心抽象层，用于标准化 Kubernetes 与不同容器运行时之间的交互。它的核心目标是解耦 Kubernetes 组件（如 kubelet）与具体的容器运行时，使 Kubernetes 能够灵活支持多种容器技术（containerd、dockerd…）。\nCRI 中定义了 容器 和 镜像 的服务的接口，因为容器运行时与镜像的生命周期是彼此隔离的，因此需要定义两个服务。该接口使用 Protocol Buffer，基于 gRPC，在 Kubernetes v1.10 + 版本中是在 pkg/kubelet/apis/cri/runtime/v1alpha2 的 api.proto 中定义的。\nContainer Runtime 实现了 CRI gRPC Server，包括 RuntimeService 和 ImageService。该 gRPC Server 需要监听本地的 Unix socket，而 kubelet 则作为 gRPC Client 运行。\nRuntimeService处理与容器运行时相关的操作，管理容器的整个生命周期。\nImageService处理与容器镜像相关的操作，管理镜像的拉取、存储和清理。\ngraph LR subgraph Kubelet grpcclient[gRPC Client] end subgraph CRI_Shim grpcserver[gRPC Server] end subgraph Container_Runtime runtime[Runtime Daemon] container1[Container 1] container2[Container 2] container3[Container 3] end grpcclient -- \"gRPC 请求 (Create/Start/Stop)\" --\u003e grpcserver grpcserver -- \"CRI 命令 (containerd/CRI-O)\" --\u003e runtime runtime -. \"容器生命周期管理\" .-\u003e container1 runtime -. \"容器生命周期管理\" .-\u003e container2 runtime -. \"容器生命周期管理\" .-\u003e container3 容器网络接口（CNI） linkCNI是Kubernetes网络插件的基础接口规范，它定义了容器运行时（如kubelet）与网络插件之间的交互协议。通过CNI，不同的网络方案（如Calico、Flannel、Weave、Cilium等）可以灵活接入Kubernetes，实现Pod之间的网络通信。\nCNI 设计的基本思路是：容器运行时创建网络命令空间 (network namepsace) 后，然后由 CNI 插件负责网络配置，最后启动容器内的应用。CNI 定义了两个插件， CNI plugin 主要用于负责配置网络，以及负责容器地址的 IPAM plugin。我们以容器的启动为例，介绍这两个插件的应用。\nkubelet 在启动容器之前，先启用 Pause 容器。 Pause 容器启动之前创建网络 namespace。 如果 Kubelet 配置了 CNI，会调用对应的 CNI 插件 CNI 插件执行网络配置操作，如创建虚拟网卡、加入网络空间等。 CNI 调用 ipam 分配地址。 启动 Pod 内其他容器，并共享 Pause 容器内网络空间。 graph LR subgraph 主机 A[容器运行时] --\u003e|1.调用| B(CNI插件) B --\u003e|2.读取| C[/etc/cni/net.d/conf\\] B --\u003e|3.调用| D[IPAM] D --\u003e|4.分配IP| B B --\u003e|5.创建veth| E[网络设备] E --\u003e|6.连接网桥| F[主机网络] end A --\u003e|7.返回配置| G[容器网络栈] 容器存储接口（CSI） link早期 Kubernetes 存储插件（如 in-tree 卷插件）与核心代码深度绑定，导致：新增存储类型需修改 Kubernetes 源码，升级和维护困难。用户受限于 Kubernetes 官方支持的存储类型。\nK8s CSI（Container Storage Interface） 是 Kubernetes 中用于标准化存储插件开发的接口规范，旨在将存储系统的实现与 Kubernetes 核心代码解耦，使第三方存储提供商（如云厂商、存储厂商）能更灵活地为集群提供持久化存储服务。\nCSI Driver：由存储提供商实现，包含：\nIdentity Service：报告驱动名称和兼容性。 Controller Service：管理卷的创建/删除、快照等。 Node Service：在节点上执行卷挂载/卸载操作。 Kubernetes 侧组件：\nexternal-provisioner：监听 PVC（PersistentVolumeClaim），触发卷创建。 external-attacher：将卷绑定到节点。 node-driver-registrar：向 Kubelet 注册 CSI 驱动。 工作流程，以创建存储卷为例\n用户创建 PersistentVolumeClaim（PVC）。 CSI Driver 的 Controller Service 收到请求，调用云存储 API 创建存储卷。 Node Service 在目标节点挂载卷，供 Pod 使用。 StorageClass：定义动态存储的配置策略，是连接 PVC 和 CSI 驱动的桥梁。\nPV：存储资源的实体，动态场景下由 CSI 驱动自动创建。\nPVC：用户请求存储的抽象，触发 CSI 驱动的动态配置流程。\n"
            }
        );
    index.add(
            {
                id:  1 ,
                href: "\/docs\/information\/software\/cloud\/storage\/secret\/",
                title: "Secret",
                description: "Secret 解决了密码、token、密钥等敏感数据的配置问题，而不需要把这些敏感数据暴露到镜像或者 Pod Spec 中。Secret 可以以 Volume 或者环境变量的方式使用。\nSecret 有三种类型：\nService Account ：用来访问 Kubernetes API，由 Kubernetes 自动创建，并且会自动挂载到 Pod 的 /run/secrets/kubernetes.io/serviceaccount 目录中； Opaque ：base64 编码格式的 Secret，用来存储密码、密钥等； kubernetes.io/dockerconfigjson ：用来存储私有 docker registry 的认证信息。 Opaque Secret linkOpaque 类型的数据是一个 map 类型，要求 value 是 base64 编码格式：\n$ echo -n \"admin\" | base64 YWRtaW4= $ echo -n \"1f2d1e2e67df\" | base64 MWYyZDFlMmU2N2Rm secrets.yml\napiVersion: v1 kind: Secret metadata: name: mysecret type: Opaque data: password: MWYyZDFlMmU2N2Rm username: YWRtaW4= 接着，就可以创建 secret 了：kubectl create -f secrets.yml。\n",
                content: "Secret 解决了密码、token、密钥等敏感数据的配置问题，而不需要把这些敏感数据暴露到镜像或者 Pod Spec 中。Secret 可以以 Volume 或者环境变量的方式使用。\nSecret 有三种类型：\nService Account ：用来访问 Kubernetes API，由 Kubernetes 自动创建，并且会自动挂载到 Pod 的 /run/secrets/kubernetes.io/serviceaccount 目录中； Opaque ：base64 编码格式的 Secret，用来存储密码、密钥等； kubernetes.io/dockerconfigjson ：用来存储私有 docker registry 的认证信息。 Opaque Secret linkOpaque 类型的数据是一个 map 类型，要求 value 是 base64 编码格式：\n$ echo -n \"admin\" | base64 YWRtaW4= $ echo -n \"1f2d1e2e67df\" | base64 MWYyZDFlMmU2N2Rm secrets.yml\napiVersion: v1 kind: Secret metadata: name: mysecret type: Opaque data: password: MWYyZDFlMmU2N2Rm username: YWRtaW4= 接着，就可以创建 secret 了：kubectl create -f secrets.yml。\n创建好 secret 之后，有两种方式来使用它：\n以 Volume 方式 以环境变量方式 将 Secret 挂载到 Volume 中 link apiVersion: v1 kind: Pod metadata: labels: name: db name: db spec: volumes: - name: secrets secret: secretName: mysecret containers: - image: gcr.io/my_project_id/pg:v1 name: db volumeMounts: - name: secrets mountPath: \"/etc/secrets\" readOnly: true ports: - name: cp containerPort: 5432 hostPort: 5432 将 Secret 导出到环境变量中 link apiVersion: extensions/v1beta1 kind: Deployment metadata: name: wordpress-deployment spec: replicas: 2 strategy: type: RollingUpdate template: metadata: labels: app: wordpress visualize: \"true\" spec: containers: - name: \"wordpress\" image: \"wordpress\" ports: - containerPort: 80 env: - name: WORDPRESS_DB_USER valueFrom: secretKeyRef: name: mysecret key: username - name: WORDPRESS_DB_PASSWORD valueFrom: secretKeyRef: name: mysecret key: password kubernetes.io/dockerconfigjson link可以直接用 kubectl 命令来创建用于 docker registry 认证的 secret：\n$ kubectl create secret docker-registry myregistrykey --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAIL secret \"myregistrykey\" created. 也可以直接读取 ~/.docker/config.json 的内容来创建：\n$ cat ~/.docker/config.json | base64 $ cat \u003e myregistrykey.yaml \u003c"
            }
        );
    index.add(
            {
                id:  2 ,
                href: "\/docs\/information\/software\/cloud\/service-discovery\/service\/",
                title: "Service",
                description: "Kubernetes Pod 是有生命周期的，它们可以被创建，也可以被销毁，然而一旦被销毁生命就永远结束。通过 ReplicationController 能够动态地创建和销毁 Pod。 每个 Pod 都会获取它自己的 IP 地址，即使这些 IP 地址不总是稳定可依赖的。这会导致一个问题：在 Kubernetes 集群中，如果一组 Pod（称为 backend）为其它 Pod （称为 frontend）提供服务，那么 frontend Pod 该如何发现和连接哪些 backend Pod 呢？\n",
                content: "Kubernetes Pod 是有生命周期的，它们可以被创建，也可以被销毁，然而一旦被销毁生命就永远结束。通过 ReplicationController 能够动态地创建和销毁 Pod。 每个 Pod 都会获取它自己的 IP 地址，即使这些 IP 地址不总是稳定可依赖的。这会导致一个问题：在 Kubernetes 集群中，如果一组 Pod（称为 backend）为其它 Pod （称为 frontend）提供服务，那么 frontend Pod 该如何发现和连接哪些 backend Pod 呢？\n关于 Service linkKubernetes Service 定义了这样一种抽象：Pod 的逻辑分组，一种可以访问它们的策略 —— 通常称为微服务。这一组 Pod 能够被 Service 访问到，通常是通过 Label Selector（查看下面了解，为什么可能需要没有 selector 的 Service）实现的。\n举个例子，假设有一个用于图片处理的运行了三个副本的 backend。这些副本是可互换的 —— frontend 不需要关心它们调用了哪个 backend 副本。然而组成这一组 backend 程序的 Pod 实际上可能会发生变化，frontend 客户端不应该也没必要知道，而且也不需要跟踪这组 backend 的状态。Service 定义的抽象能够解耦这种关联。\n对 Kubernetes 集群中的应用，Kubernetes 提供了简单的 Endpoints API，只要 Service 中的一组 Pod 发生变更，应用程序就会被更新。对非 Kubernetes 集群中的应用，Kubernetes 提供了基于 VIP 的网桥的方式访问 Service，再由 Service 重定向到 backend Pod。\n定义 Service link一个 Service 在 Kubernetes 中是一个 REST 对象，和 Pod 类似。 像所有的 REST 对象一样， Service 定义可以基于 POST 方式，请求 apiserver 创建新的实例。\n例如，假定有一组 Pod，它们对外暴露了 9376 端口，同时还被打上 \"app=MyApp\" 标签。\nkind: Service apiVersion: v1 metadata: name: my-service spec: selector: app: MyApp ports: - protocol: TCP port: 80 targetPort: 9376 上述配置将创建一个名称为 “my-service” 的 Service 对象，它会将请求代理到 9376 TCP 端口，具有标签 \"app=MyApp\" 的 Pod 上。这个 Service 将被指派一个 IP 地址（通常称为 “Cluster IP”），它会被服务的代理使用（见下面）。Service selector的控制器将会持续扫描符合条件的Pod，扫描结果会更新到名称为my-service的Endpoints对象上。\n需要注意的是， Service 能够将一个接收端口映射到任意的 targetPort。默认情况下，targetPort 将被设置为与 port 字段相同的值。targetPort 可以是一个字符串，引用了 backend Pod 的端口的名称。但是，实际指派给该端口名称的端口号，在每个 backend Pod 中可能并不相同。对于部署和设计 Service ，这种方式会提供更大的灵活性。例如，可以在 backend 软件下一个版本中，修改 Pod 暴露的端口，并不会中断客户端的调用。\nKubernetes Service 支持 TCP 和 UDP 协议，默认为 TCP 协议。\n没有 selector 的 Service linkService 抽象了该如何访问 Kubernetes Pod，但也能够抽象其它类型的 backend，例如：\n希望在生产环境中使用外部的数据库集群，但测试环境使用自己的数据库。 希望服务指向另一个 Namespace 中或其它集群中的服务。 正在将工作负载转移到 Kubernetes 集群，和运行在 Kubernetes 集群之外的 backend。 在任何这些场景中，都能够定义没有 selector 的 Service ：\nkind: Service apiVersion: v1 metadata: name: my-service spec: ports: - protocol: TCP port: 80 targetPort: 9376 由于这个 Service 没有 selector，就不会创建相关的 Endpoints 对象。可以手动将 Service 映射到指定的 Endpoints：\nkind: Endpoints apiVersion: v1 metadata: name: my-service subsets: - addresses: - ip: 1.2.3.4 ports: - port: 9376 注意：Endpoint IP 地址不能是 loopback（127.0.0.0/8）、 link-local（169.254.0.0/16）、或者 link-local 多播（224.0.0.0/24）。\n访问没有 selector 的 Service，与有 selector 的 Service 的原理相同。请求将被路由到用户定义的 Endpoint（该示例中为 1.2.3.4:9376）。\nExternalName Service 是 Service 的特例，它没有 selector，也没有定义任何的端口和 Endpoint。相反地，对于运行在集群外部的服务，它通过返回该外部服务的别名这种方式来提供服务。\nkind: Service apiVersion: v1 metadata: name: my-service namespace: prod spec: type: ExternalName externalName: my.database.example.com 当查询主机 my-service.prod.svc.CLUSTER时，集群的 DNS 服务将返回一个值为 my.database.example.com 的 CNAME 记录。访问这个服务的工作方式与其它的相同，唯一不同的是重定向发生在 DNS 层，而且不会进行代理或转发。如果后续决定要将数据库迁移到 Kubernetes 集群中，可以启动对应的 Pod，增加合适的 Selector 或 Endpoint，修改 Service 的 type。\nVIP 和 Service 代理 link在 Kubernetes 集群中，每个 Node 运行一个 kube-proxy 进程。kube-proxy 负责为 Service 实现了一种 VIP（虚拟 IP）的形式，而不是 ExternalName 的形式。\n在 Kubernetes v1.0 版本，代理完全在 userspace，Service 是 “4层”（TCP/UDP over IP）概念。\n在 Kubernetes v1.1 版本，新增了 iptables 代理，但并不是默认的运行模式。新增了 Ingress API（beta 版），用来表示 “7层”（HTTP）服务。\n从 Kubernetes v1.2 起，默认就是 iptables 代理。\n在 Kubernetes v1.8.0-beta.0 中，添加了ipvs代理。\nuserspace 代理模式 link这种模式，kube-proxy 会监视 Kubernetes master 对 Service 对象和 Endpoints 对象的添加和移除。 对每个 Service，它会在本地 Node 上打开一个端口（随机选择）。\n任何连接到“代理端口”的请求，都会被代理到 Service 的backend Pods 中的某个上面（如 Endpoints 所报告的一样）。 使用哪个 backend Pod，是基于 Service 的 SessionAffinity 来确定的。\n最后，它安装 iptables 规则，捕获到达该 Service 的 clusterIP（是虚拟 IP）和 Port 的请求，并重定向到代理端口，代理端口再代理请求到 backend Pod。\n网络返回的结果是，任何到达 Service 的 IP:Port 的请求，都会被代理到一个合适的 backend，不需要客户端知道关于 Kubernetes、Service、或 Pod 的任何信息。\n默认的策略是，通过 round-robin 算法来选择 backend Pod。 实现基于客户端 IP 的会话亲和性，可以通过设置 service.spec.sessionAffinity 的值为 \"ClientIP\" （默认值为 \"None\"）。\nflowchart TD classDef client fill:#cff,stroke:#333; classDef control fill:#fcf,stroke:#333; classDef proxy fill:#9f9,stroke:#333; classDef backend fill:#f99,stroke:#333; subgraph Node Client[Client]:::client --\u003e ServiceIP[\"Service IP (IPTables)\"] ServiceIP --\u003e KubeProxy[kube-proxy]:::proxy end APIServer[APIServer]:::control --\u003e KubeProxy KubeProxy --\u003e Backend1[\"backend1(labels: app=myapp)\"]:::backend KubeProxy --\u003e Backend2[\"backend2(labels: app=myapp)\"]:::backend KubeProxy --\u003e Backend3[\"backend3(labels: app=myapp)\"]:::backend linkStyle 0,1 stroke:#09f,stroke-width:2px linkStyle 2 stroke:#f90,stroke-width:2px linkStyle 3,4,5 stroke:#f09,stroke-width:1.5px iptables 代理模式 link这种模式，kube-proxy 会监视 Kubernetes master 对 Service 对象和 Endpoints 对象的添加和移除。 对每个 Service，它会安装 iptables 规则，从而捕获到达该 Service 的 clusterIP（虚拟 IP）和端口的请求，进而将请求重定向到 Service 的一组 backend 中的某个上面。对于每个 Endpoints 对象，它也会安装 iptables 规则，这个规则会选择一个 backend Pod。\n默认的策略是，随机选择一个 backend。实现基于客户端 IP 的会话亲和性，可以将 service.spec.sessionAffinity 的值设置为 \"ClientIP\" （默认值为 \"None\"）。\n和 userspace 代理类似，网络返回的结果是，任何到达 Service 的 IP:Port 的请求，都会被代理到一个合适的 backend，不需要客户端知道关于 Kubernetes、Service、或 Pod 的任何信息。\n这应该比 userspace 代理更快、更可靠。然而，不像 userspace 代理，如果初始选择的 Pod 没有响应，iptables 代理不能自动地重试另一个 Pod，所以它需要依赖 readiness probes。\nflowchart TD classDef client fill:#cff,stroke:#333; classDef control fill:#fcf,stroke:#333; classDef proxy fill:#9f9,stroke:#333; classDef backend fill:#f99,stroke:#333; subgraph Node Client[Client]:::client --\u003e ServiceIP[\"Service IP (IPTables)\"] KubeProxy[kube-proxy]:::proxy --\u003e ServiceIP end APIServer[APIServer]:::control --\u003e KubeProxy ServiceIP --\u003e Backend1[\"backend1(labels: app=myapp)\"]:::backend ServiceIP --\u003e Backend2[\"backend2(labels: app=myapp)\"]:::backend ServiceIP --\u003e Backend3[\"backend3(labels: app=myapp)\"]:::backend linkStyle 0,1 stroke:#09f,stroke-width:2px linkStyle 2 stroke:#f90,stroke-width:2px linkStyle 3,4,5 stroke:#f09,stroke-width:1.5px ipvs 代理模式 link这种模式，kube-proxy会监视Kubernetes Service对象和Endpoints，调用netlink接口以相应地创建ipvs规则并定期与Kubernetes Service对象和Endpoints对象同步ipvs规则，以确保ipvs状态与期望一致。访问服务时，流量将被重定向到其中一个后端Pod。\n与iptables类似，ipvs基于netfilter 的 hook 功能，但使用哈希表作为底层数据结构并在内核空间中工作。这意味着ipvs可以更快地重定向流量，并且在同步代理规则时具有更好的性能。此外，ipvs为负载均衡算法提供了更多选项，例如：\nrr：轮询调度 lc：最小连接数 dh：目标哈希 sh：源哈希 sed：最短期望延迟 nq： 不排队调度 注意： ipvs模式假定在运行kube-proxy之前在节点上都已经安装了IPVS内核模块。当kube-proxy以ipvs代理模式启动时，kube-proxy将验证节点上是否安装了IPVS模块，如果未安装，则kube-proxy将回退到iptables代理模式。\nflowchart TD classDef client fill:#cff,stroke:#333; classDef control fill:#fcf,stroke:#333; classDef proxy fill:#9f9,stroke:#333; classDef backend fill:#f99,stroke:#333; subgraph Node Client[Client]:::client --\u003e ServiceIP[\"Service IP (IPTables)\"] KubeProxy[kube-proxy]:::proxy --\u003e ServiceIP end APIServer[APIServer]:::control --\u003e KubeProxy ServiceIP --\u003e Backend1[\"backend1(labels: app=myapp)\"]:::backend ServiceIP --\u003e Backend2[\"backend2(labels: app=myapp)\"]:::backend ServiceIP --\u003e Backend3[\"backend3(labels: app=myapp)\"]:::backend linkStyle 0,1 stroke:#09f,stroke-width:2px linkStyle 2 stroke:#f90,stroke-width:2px linkStyle 3,4,5 stroke:#f09,stroke-width:1.5px 多端口 Service link很多 Service 需要暴露多个端口。对于这种情况，Kubernetes 支持在 Service 对象中定义多个端口。 当使用多个端口时，必须给出所有的端口的名称，这样 Endpoint 就不会产生歧义，例如：\nkind: Service apiVersion: v1 metadata: name: my-service spec: selector: app: MyApp ports: - name: http protocol: TCP port: 80 targetPort: 9376 - name: https protocol: TCP port: 443 targetPort: 9377 选择自己的 IP 地址 link在 Service 创建的请求中，可以通过设置 spec.clusterIP 字段来指定自己的集群 IP 地址。 比如，希望替换一个已经存在的 DNS 条目，或者遗留系统已经配置了一个固定的 IP 且很难重新配置。 用户选择的 IP 地址必须合法，并且这个 IP 地址在 service-cluster-ip-range CIDR 范围内，这对 API Server 来说是通过一个标识来指定的。 如果 IP 地址不合法，API Server 会返回 HTTP 状态码 422，表示值不合法。\n为何不使用 round-robin DNS？ link一个不时出现的问题是，为什么我们都使用 VIP 的方式，而不使用标准的 round-robin DNS，有如下几个原因：\n长久以来，DNS 库都没能认真对待 DNS TTL、缓存域名查询结果 很多应用只查询一次 DNS 并缓存了结果 就算应用和库能够正确查询解析，每个客户端反复重解析造成的负载也是非常难以管理的 我们尽力阻止用户做那些对他们没有好处的事情，如果很多人都来问这个问题，我们可能会选择实现它。\n服务发现 linkKubernetes 支持2种基本的服务发现模式 —— 环境变量和 DNS。\n环境变量 link当 Pod 运行在 Node 上，kubelet 会为每个活跃的 Service 添加一组环境变量。它同时支持 Docker links 兼容 变量（查看 makeLinkVariables）、简单的 {SVCNAME}_SERVICE_HOST 和 {SVCNAME}_SERVICE_PORT 变量，这里 Service 的名称需大写，横线被转换成下划线。\n举个例子，一个名称为 \"redis-master\" 的 Service 暴露了 TCP 端口 6379，同时给它分配了 Cluster IP 地址 10.0.0.11，这个 Service 生成了如下环境变量：\nREDIS_MASTER_SERVICE_HOST=10.0.0.11 REDIS_MASTER_SERVICE_PORT=6379 REDIS_MASTER_PORT=tcp://10.0.0.11:6379 REDIS_MASTER_PORT_6379_TCP=tcp://10.0.0.11:6379 REDIS_MASTER_PORT_6379_TCP_PROTO=tcp REDIS_MASTER_PORT_6379_TCP_PORT=6379 REDIS_MASTER_PORT_6379_TCP_ADDR=10.0.0.11 这意味着需要有顺序的要求 —— Pod 想要访问的任何 Service 必须在 Pod 自己之前被创建，否则这些环境变量就不会被赋值。DNS 并没有这个限制。\nDNS link一个可选（尽管强烈推荐）集群插件 是 DNS 服务器。\nDNS 服务器监视着创建新 Service 的 Kubernetes API，从而为每一个 Service 创建一组 DNS 记录。如果整个集群的 DNS 一直被启用，那么所有的 Pod 应该能够自动对 Service 进行名称解析。\n例如，有一个名称为 \"my-service\" 的 Service，它在 Kubernetes 集群中名为 \"my-ns\" 的 Namespace 中，为 \"my-service.my-ns\" 创建了一条 DNS 记录。\n在名称为 \"my-ns\" 的 Namespace 中的 Pod 应该能够简单地通过名称查询找到 \"my-service\"。在另一个 Namespace 中的 Pod 必须限定名称为 \"my-service.my-ns\"。这些名称查询的结果是 Cluster IP。\nKubernetes 也支持对端口名称的 DNS SRV（Service）记录。如果名称为 \"my-service.my-ns\" 的 Service 有一个名为 \"http\" 的 TCP 端口，可以对 \"_http._tcp.my-service.my-ns\" 执行 DNS SRV 查询，得到 \"http\" 的端口号。\nKubernetes DNS 服务器是唯一的一种能够访问 ExternalName 类型的 Service 的方式。\n更多信息可以查看 DNS Pod 和 Service。\nHeadless Service link有时不需要或不想要负载均衡，以及单独的 Service IP。遇到这种情况，可以通过指定 Cluster IP（spec.clusterIP）的值为 \"None\" 来创建 Headless Service。\n这个选项允许开发人员自由寻找他们自己的方式，从而降低与 Kubernetes 系统的耦合性。应用仍然可以使用一种自注册的模式和适配器，对其它需要发现机制的系统能够很容易地基于这个 API 来构建。\n对这类 Service 并不会分配 Cluster IP，kube-proxy 不会处理它们，而且平台也不会为它们进行负载均衡和路由。DNS 如何实现自动配置，依赖于 Service 是否定义了 selector。\n配置 Selector link对定义了 selector 的 Headless Service，Endpoint 控制器在 API 中创建了 Endpoints 记录，并且修改 DNS 配置返回 A 记录（地址），通过这个地址直接到达 Service 的后端 Pod 上。\n不配置 Selector link对没有定义 selector 的 Headless Service，Endpoint 控制器不会创建 Endpoints 记录。然而 DNS 系统会查找和配置，无论是：\nExternalName 类型 Service 的 CNAME 记录 记录：与 Service 共享一个名称的任何 Endpoints，以及所有其它类型 发布服务 —— 服务类型 link对一些应用（如 Frontend）的某些部分，可能希望通过外部（Kubernetes 集群外部）IP 地址暴露 Service。\nKubernetes ServiceTypes 允许指定一个需要的类型的 Service，默认是 ClusterIP 类型。\nType 的取值以及行为如下：\nClusterIP：通过集群的内部 IP 暴露服务，选择该值，服务只能够在集群内部可以访问，这也是默认的 ServiceType。 NodePort：通过每个 Node 上的 IP 和静态端口（NodePort）暴露服务。NodePort 服务会路由到 ClusterIP 服务，这个 ClusterIP 服务会自动创建。通过请求 :，可以从集群的外部访问一个 NodePort 服务。 LoadBalancer：使用云提供商的负载均衡器，可以向外部暴露服务。外部的负载均衡器可以路由到 NodePort 服务和 ClusterIP 服务。 ExternalName：通过返回 CNAME 和它的值，可以将服务映射到 externalName 字段的内容（例如， foo.bar.example.com）。 没有任何类型代理被创建，这只有 Kubernetes 1.7 或更高版本的 kube-dns 才支持。 NodePort 类型 link如果设置 type 的值为 \"NodePort\"，Kubernetes master 将从给定的配置范围内（默认：30000-32767）分配端口，每个 Node 将从该端口（每个 Node 上的同一端口）代理到 Service。该端口将通过 Service 的 spec.ports[*].nodePort 字段被指定。\n如果需要指定的端口号，可以配置 nodePort 的值，系统将分配这个端口，否则调用 API 将会失败（比如，需要关心端口冲突的可能性）。\n这可以让开发人员自由地安装他们自己的负载均衡器，并配置 Kubernetes 不能完全支持的环境参数，或者直接暴露一个或多个 Node 的 IP 地址。\n需要注意的是，Service 将能够通过 :spec.ports[*].nodePort 和 spec.clusterIp:spec.ports[*].port 而对外可见。\nLoadBalancer 类型 link使用支持外部负载均衡器的云提供商的服务，设置 type 的值为 \"LoadBalancer\"，将为 Service 提供负载均衡器。负载均衡器是异步创建的，关于被提供的负载均衡器的信息将会通过 Service 的 status.loadBalancer 字段被发布出去。\nkind: Service apiVersion: v1 metadata: name: my-service spec: selector: app: MyApp ports: - protocol: TCP port: 80 targetPort: 9376 nodePort: 30061 clusterIP: 10.0.171.239 loadBalancerIP: 78.11.24.19 type: LoadBalancer status: loadBalancer: ingress: - ip: 146.148.47.155 来自外部负载均衡器的流量将直接打到 backend Pod 上，不过实际它们是如何工作的，这要依赖于云提供商。在这些情况下，将根据用户设置的 loadBalancerIP 来创建负载均衡器。\n某些云提供商允许设置 loadBalancerIP。如果没有设置 loadBalancerIP，将会给负载均衡器指派一个临时 IP。\n如果设置了 loadBalancerIP，但云提供商并不支持这种特性，那么设置的 loadBalancerIP 值将会被忽略掉。\nExternalName linkExternalName 类型的服务将服务映射到一个 DNS 名称，而不是典型的选择器，如 my-service 或 cassandra。使用 spec.externalName 参数指定这些服务。\n例如，这个服务定义将 prod 命名空间中的 my-service 映射到 my.database.example.com。\napiVersion: v1 kind: Service metadata: name: my-service namespace: prod spec: type: ExternalName externalName: my.database.example.com 注意：ExternalName 接受 IPv4 地址字符串，但它是由数字组成的 DNS 名称，而不是 IP 地址。类似于 IPv4 地址的 ExternalNames 不能被 CoreDNS 或 ingress-nginx 解析，因为 ExternalName 的目的是指定一个规范的 DNS 名称。要硬编码一个 IP 地址，请考虑使用 Headless Service。\n警告\n对于一些常见的协议，包括 HTTP 和 HTTPS，你使用 ExternalName 可能会有问题。如果使用 ExternalName，那么你集群内的客户端使用的主机名与 ExternalName 引用的名称不同。\n对于使用主机名的协议，这种差异可能导致错误或意外的响应。HTTP请求将有一个源服务器不承认的 Host: header，TLS 服务器将不能提供与客户端连接的主机名相匹配的证书。\n外部 IP link如果外部的 IP 路由到集群中一个或多个 Node 上，Kubernetes Service 会被暴露给这些 externalIPs。通过外部 IP（作为目的 IP 地址）进入到集群，打到 Service 的端口上的流量，将会被路由到 Service 的 Endpoint 上。externalIPs 不会被 Kubernetes 管理，它属于集群管理员的职责范畴。\n根据 Service 的规定，externalIPs 可以同任意的 ServiceType 来一起指定。在下面的例子中，my-service 可以在 80.11.12.10:80（外部 IP:端口）上被客户端访问。\nkind: Service apiVersion: v1 metadata: name: my-service spec: selector: app: MyApp ports: - name: http protocol: TCP port: 80 targetPort: 9376 externalIPs: - 80.11.12.10 不足之处 link为 VIP 使用 userspace 代理，将只适合小型到中型规模的集群，不能够扩展到上千 Service 的大型集群。查看 最初设计方案 获取更多细节。\n使用 userspace 代理，隐藏了访问 Service 的数据包的源 IP 地址。这使得一些类型的防火墙无法起作用。iptables 代理不会隐藏 Kubernetes 集群内部的 IP 地址，但却要求客户端请求必须通过一个负载均衡器或 Node 端口。\nType 字段支持嵌套功能 —— 每一层需要添加到上一层里面。不会严格要求所有云提供商（例如，GCE 就没必要为了使一个 LoadBalancer 能工作而分配一个 NodePort，但是 AWS 需要 ），但当前 API 是强制要求的。\n未来工作 link未来我们能预见到，代理策略可能会变得比简单的 round-robin 均衡策略有更多细微的差别，比如 master 选举或分片。我们也能想到，某些 Service 将具有 “真正” 的负载均衡器，这种情况下 VIP 将简化数据包的传输。\n在未来的版本中，Kubernetes 打算改进对 L7（HTTP）Service 的支持。为 Service 实现更加灵活的请求进入模式，这些 Service 包含当前 ClusterIP、NodePort 和 LoadBalancer 模式等。\n关于虚拟 IP 的细节 link对很多想使用 Service 的人来说，前面的信息应该足够了。然而，有很多内部原理性的内容，还是值去理解的。\n避免冲突 linkKubernetes 最主要的哲学之一，是用户不应该暴露那些能够导致他们操作失败、但又不是他们的过错的场景。这种场景下，让我们来看一下网络端口 —— 用户不应该必须选择一个端口号，而且该端口还有可能与其他用户的冲突。这就是说，在彼此隔离状态下仍然会出现失败。\n为了使用户能够为他们的 Service 选择一个端口号，我们必须确保不能有2个 Service 发生冲突。我们可以通过为每个 Service 分配它们自己的 IP 地址来实现。\n为了保证每个 Service 被分配到一个唯一的 IP，需要一个内部的分配器能够原子地更新 etcd 中的一个全局分配映射表，这个更新操作要先于创建每一个 Service。\n为了使 Service 能够获取到 IP，这个映射表对象必须在注册中心存在，否则创建 Service 将会失败，指示一个 IP 不能被分配。 一个后台 Controller 的职责是创建映射表（从 Kubernetes 的旧版本迁移过来，旧版本中是通过在内存中加锁的方式实现），并检查由于管理员干预和清除任意 IP 造成的不合理分配，这些 IP 被分配了但当前没有 Service 使用它们。\nIP 和 VIP link不像 Pod 的 IP 地址，它实际路由到一个固定的目的地，Service 的 IP 实际上不能通过单个主机来进行应答。相反，我们使用 iptables（Linux 中的数据包处理逻辑）来定义一个虚拟IP地址（VIP），它可以根据需要透明地进行重定向。当客户端连接到 VIP 时，它们的流量会自动地传输到一个合适的 Endpoint。环境变量和 DNS，实际上会根据 Service 的 VIP 和端口来进行填充。\nUserspace link作为一个例子，考虑前面提到的图片处理应用程序。\n当创建 backend Service 时，Kubernetes master 会给它指派一个虚拟 IP 地址，比如 10.0.0.1。假设 Service 的端口是 1234，该 Service 会被集群中所有的 kube-proxy 实例观察到。当代理看到一个新的 Service， 它会打开一个新的端口，建立一个从该 VIP 重定向到新端口的 iptables，并开始接收请求连接。\n当一个客户端连接到一个 VIP，iptables 规则开始起作用，它会重定向该数据包到 Service代理 的端口。Service代理 选择一个 backend，并将客户端的流量代理到 backend 上。\n这意味着 Service 的所有者能够选择任何他们想使用的端口，而不存在冲突的风险。客户端可以简单地连接到一个 IP 和端口，而不需要知道实际访问了哪些 Pod。\nIptables link再次考虑前面提到的图片处理应用程序。\n当创建 backend Service 时，Kubernetes master 会给它指派一个虚拟 IP 地址，比如 10.0.0.1。假设 Service 的端口是 1234，该 Service 会被集群中所有的 kube-proxy 实例观察到。当代理看到一个新的 Service， 它会安装一系列的 iptables 规则，从 VIP 重定向到 per-Service 规则。该 per-Service 规则连接到 per-Endpoint 规则，该 per-Endpoint 规则会重定向（目标 NAT）到 backend。\n当一个客户端连接到一个 VIP，iptables 规则开始起作用。一个 backend 会被选择（或者根据会话亲和性，或者随机），数据包被重定向到这个 backend。\n不像 userspace 代理，数据包从来不拷贝到用户空间，kube-proxy 不是必须为该 VIP 工作而运行，并且客户端 IP 是不可更改的。 当流量打到 Node 的端口上，或通过负载均衡器，会执行相同的基本流程，但是在那些案例中客户端 IP 是可以更改的。\nAPI 对象 link在 Kubernetes REST API 中，Service 是 top-level 资源。\n更多信息 link 使用 Service 连接 Frontend 到 Backend - kubernetes.io "
            }
        );
    index.add(
            {
                id:  3 ,
                href: "\/docs\/information\/software\/cloud\/auth\/serviceaccount\/",
                title: "ServiceAccount",
                description: "ServiceAccount 为 Pod 中的进程提供身份信息。\n注意：本文是关于 Service Account 的用户指南，管理指南另见 Service Account 的集群管理指南 。\n本文档描述的关于 Service Account 的行为只有当您按照 Kubernetes 项目建议的方式搭建起集群的情况下才有效。您的集群管理员可能在您的集群中有自定义配置，这种情况下该文档可能并不适用。\n当您（真人用户）访问集群（例如使用kubectl命令）时，apiserver 会将您认证为一个特定的 User Account（目前通常是admin，除非您的系统管理员自定义了集群配置）。Pod 容器中的进程也可以与 apiserver 联系。 当它们在联系 apiserver 的时候，它们会被认证为一个特定的 Service Account（例如default）。\n使用默认的 Service Account 访问 API server link当您创建 pod 的时候，如果您没有指定一个 service account，系统会自动得在与该pod 相同的 namespace 下为其指派一个default service account。如果您获取刚创建的 pod 的原始 json 或 yaml 信息（例如使用kubectl get pods/podename -o yaml命令），您将看到spec.serviceAccountName字段已经被设置为 default。\n您可以在 pod 中使用自动挂载的 service account 凭证来访问 API，如 Accessing the Cluster 中所描述。\n",
                content: "ServiceAccount 为 Pod 中的进程提供身份信息。\n注意：本文是关于 Service Account 的用户指南，管理指南另见 Service Account 的集群管理指南 。\n本文档描述的关于 Service Account 的行为只有当您按照 Kubernetes 项目建议的方式搭建起集群的情况下才有效。您的集群管理员可能在您的集群中有自定义配置，这种情况下该文档可能并不适用。\n当您（真人用户）访问集群（例如使用kubectl命令）时，apiserver 会将您认证为一个特定的 User Account（目前通常是admin，除非您的系统管理员自定义了集群配置）。Pod 容器中的进程也可以与 apiserver 联系。 当它们在联系 apiserver 的时候，它们会被认证为一个特定的 Service Account（例如default）。\n使用默认的 Service Account 访问 API server link当您创建 pod 的时候，如果您没有指定一个 service account，系统会自动得在与该pod 相同的 namespace 下为其指派一个default service account。如果您获取刚创建的 pod 的原始 json 或 yaml 信息（例如使用kubectl get pods/podename -o yaml命令），您将看到spec.serviceAccountName字段已经被设置为 default。\n您可以在 pod 中使用自动挂载的 service account 凭证来访问 API，如 Accessing the Cluster 中所描述。\nService account 是否能够取得访问 API 的许可取决于您使用的 授权插件和策略。\n在 1.6 以上版本中，您可以选择取消为 service account 自动挂载 API 凭证，只需在 service account 中设置 automountServiceAccountToken: false：\napiVersion: v1 kind: ServiceAccount metadata: name: build-robot automountServiceAccountToken: false ... 在 1.6 以上版本中，您也可以选择只取消单个 pod 的 API 凭证自动挂载：\napiVersion: v1 kind: Pod metadata: name: my-pod spec: serviceAccountName: build-robot automountServiceAccountToken: false ... 如果在 pod 和 service account 中同时设置了 automountServiceAccountToken , pod 设置中的优先级更高。\n使用多个Service Account link每个 namespace 中都有一个默认的叫做 default 的 service account 资源。\n您可以使用以下命令列出 namespace 下的所有 serviceAccount 资源。\n$ kubectl get serviceAccounts NAME SECRETS AGE default 1 1d 您可以像这样创建一个 ServiceAccount 对象：\n$ cat \u003e /tmp/serviceaccount.yaml \u003c"
            }
        );
    index.add(
            {
                id:  4 ,
                href: "\/docs\/information\/software\/cloud\/",
                title: "云原生",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  5 ,
                href: "\/docs\/develop\/ask\/",
                title: "如何提问：提问的智慧",
                description: "一、提问的本质与哲学意义 link1. 提问是人类认知的基石 link 认知革命的核心：苏格拉底通过“产婆术”提问法，引导对话者自我反思，揭示了提问作为知识生产的核心动力。爱因斯坦更直言：“提问的能力比回答更重要”。 科学进步的引擎：伽利略质疑亚里士多德的“强弱决定子女性别”理论，通过实证提问推动科学革命。亚里士多德亦指出“提问是进步的源泉”。 2. 提问的哲学分类 link 优质提问的四个维度（粟津恭一郎理论）： 轻松提问：建立信任（如“最近工作顺利吗？”）。 劣质提问：引发防御（如“你为什么总犯错？”）。 沉重提问：触及深层需求（如“十年后你希望成为什么样的人？”）。 优质提问：激发行动与发现（如“如果重新开始，你会采取哪些不同策略？”）。 二、高效提问的核心方法论 link1. 提问前的准备：明确目标与边界 link 目标导向：明确提问意图（获取信息/解决问题/启发思考），例如职场中避免泛泛而问“如何提高积极性”，转而聚焦“如何在项目压力下保持团队动力”。 设定边界：限定问题范围。对比两种提问： 低效：“如何写出好文章？” 高效：“如何在3天内完成一篇针对Z世代用户的爆款短视频脚本？” 2. 提问的架构设计 link 开放式 vs 封闭式： 封闭式（“你是否同意？”）适合快速决策，但限制思考； 开放式（“你认为这个方案的潜在风险是什么？”）激发深度讨论。 结构化提问法（适用于复杂问题）： 背景层（“当前用户留存率是多少？”）； 冲突层（“哪些因素导致留存率下降？”）； 解决层（“哪些策略可能提升30%留存率？”）。 3. 提问的语言艺术 link 避免主观偏见：用“能否解释这个数据的变化趋势？”替代“你的数据是不是有误？”。 积极倾听与追问：通过“能否举例说明？”或“您提到的‘用户体验’具体指哪些方面？”深化对话。 三、场景化提问策略 link1. 教育场景：从被动吸收到主动探究 link 学生提问技巧：\n错题复盘三步骤（网页6案例）： 明确卡点（“这道题的解题思路中，哪一步我不理解？”）； 分享尝试（“我试过代入公式A，但结果不符”）； 寻求反馈（“您建议我调整计算顺序还是检查前提条件？”）。 知识结构图法：将错题转化为逻辑图谱，通过提问梳理因果关系。 教师提问设计：\n批判性思维激发：如《杨修之死》教学中追问“曹操杀杨修时为何无人求情？”； 分层提问法：从记忆性提问（“文章主旨？”）到创造性提问（“如果你是作者，会如何改写结局？”）。 2. 职场场景：从信息获取到影响力构建 link 向上管理提问术：\n目的前置法：将“领导明天有空吗？”改为“关于X项目的资源协调方案，您认为哪些部分需要优先讨论？明天下午2点可否预留20分钟？”。 假设性提问：“如果预算增加20%，您认为我们应该优先投入产品研发还是市场扩张？”。 团队协作提问框架：\nSCQA模型（情境-冲突-问题-答案）： 情境（S）：“当前用户投诉率上升至5%”； 冲突（C）：“但客服响应时间已缩短30%”； 问题（Q）：“哪些未被发现的环节导致矛盾？”； 答案（A）：“建议重新梳理用户旅程图，定位断点”。 3. 科研与创新：从解构到重构 link 颠覆性提问法： 第一性原理提问：特斯拉通过“电池的物理成本下限是多少？”重构电动汽车定价模型。 跨学科嫁接：“区块链技术如何解决医疗数据孤岛问题？”。 四、提问的伦理与文化维度 link1. 尊重与被尊重：提问中的权力平衡 link 文化敏感性：在权威文化中采用“建议式提问”（“是否可以考虑……”）而非直接质疑。 共情式提问：心理咨询中的“你觉得这种情绪背后可能有什么需求？”。 2. 提问的陷阱与规避 link 劣质提问的特征： 模糊性（“如何成功？”）； 诱导性（“你不认为这个方案很差吗？”）； 攻击性（“你连这都不懂？”）。 五、案例深度解析 link案例1：伽利略的“5个女儿之问” link 背景：比罗教授宣称“父亲强弱决定子女性别”，伽利略反驳：“邻居强壮却生5女，何解？”。 智慧解析： 以具体案例挑战抽象理论； 用事实反驳权威，坚持“科学必须符合现实”； 展现“质疑-验证-重构”的科学提问范式。 案例2：知识结构图法提升学习效率 link 实践效果：学生小郑通过提炼错题关键点（如数学题的“已知条件-问题链”），2个月内从班级中游跃居前三。 方法论延伸： “是何-为何-如何”三问法（语文阅读分析）； “输入-加工-输出”提问循环（网页6的“教给别人”记忆法）。 六、提问能力的终身训练 link1. 日常训练工具 link 提问日记：每日记录3个优质问题并评估效果； 苏格拉底式自问：对任何结论追问“为什么成立？”“反例是否存在？”。 2. 进阶修炼方向 link 元问题意识：在提问中反思“当前问题是否触及本质？”； 系统思维提问：通过“要素-连接-功能”三层次分析复杂系统。 结语：提问不仅是获取答案的工具，更是重塑认知、推动变革的杠杆。从伽利略的颠覆性质疑到现代职场的高效沟通，提问的智慧贯穿人类文明的每一次跃迁。唯有保持“童真式追问”（胡适“问题丹”），方能在不确定的时代锚定思想的航向。\n",
                content: "一、提问的本质与哲学意义 link1. 提问是人类认知的基石 link 认知革命的核心：苏格拉底通过“产婆术”提问法，引导对话者自我反思，揭示了提问作为知识生产的核心动力。爱因斯坦更直言：“提问的能力比回答更重要”。 科学进步的引擎：伽利略质疑亚里士多德的“强弱决定子女性别”理论，通过实证提问推动科学革命。亚里士多德亦指出“提问是进步的源泉”。 2. 提问的哲学分类 link 优质提问的四个维度（粟津恭一郎理论）： 轻松提问：建立信任（如“最近工作顺利吗？”）。 劣质提问：引发防御（如“你为什么总犯错？”）。 沉重提问：触及深层需求（如“十年后你希望成为什么样的人？”）。 优质提问：激发行动与发现（如“如果重新开始，你会采取哪些不同策略？”）。 二、高效提问的核心方法论 link1. 提问前的准备：明确目标与边界 link 目标导向：明确提问意图（获取信息/解决问题/启发思考），例如职场中避免泛泛而问“如何提高积极性”，转而聚焦“如何在项目压力下保持团队动力”。 设定边界：限定问题范围。对比两种提问： 低效：“如何写出好文章？” 高效：“如何在3天内完成一篇针对Z世代用户的爆款短视频脚本？” 2. 提问的架构设计 link 开放式 vs 封闭式： 封闭式（“你是否同意？”）适合快速决策，但限制思考； 开放式（“你认为这个方案的潜在风险是什么？”）激发深度讨论。 结构化提问法（适用于复杂问题）： 背景层（“当前用户留存率是多少？”）； 冲突层（“哪些因素导致留存率下降？”）； 解决层（“哪些策略可能提升30%留存率？”）。 3. 提问的语言艺术 link 避免主观偏见：用“能否解释这个数据的变化趋势？”替代“你的数据是不是有误？”。 积极倾听与追问：通过“能否举例说明？”或“您提到的‘用户体验’具体指哪些方面？”深化对话。 三、场景化提问策略 link1. 教育场景：从被动吸收到主动探究 link 学生提问技巧：\n错题复盘三步骤（网页6案例）： 明确卡点（“这道题的解题思路中，哪一步我不理解？”）； 分享尝试（“我试过代入公式A，但结果不符”）； 寻求反馈（“您建议我调整计算顺序还是检查前提条件？”）。 知识结构图法：将错题转化为逻辑图谱，通过提问梳理因果关系。 教师提问设计：\n批判性思维激发：如《杨修之死》教学中追问“曹操杀杨修时为何无人求情？”； 分层提问法：从记忆性提问（“文章主旨？”）到创造性提问（“如果你是作者，会如何改写结局？”）。 2. 职场场景：从信息获取到影响力构建 link 向上管理提问术：\n目的前置法：将“领导明天有空吗？”改为“关于X项目的资源协调方案，您认为哪些部分需要优先讨论？明天下午2点可否预留20分钟？”。 假设性提问：“如果预算增加20%，您认为我们应该优先投入产品研发还是市场扩张？”。 团队协作提问框架：\nSCQA模型（情境-冲突-问题-答案）： 情境（S）：“当前用户投诉率上升至5%”； 冲突（C）：“但客服响应时间已缩短30%”； 问题（Q）：“哪些未被发现的环节导致矛盾？”； 答案（A）：“建议重新梳理用户旅程图，定位断点”。 3. 科研与创新：从解构到重构 link 颠覆性提问法： 第一性原理提问：特斯拉通过“电池的物理成本下限是多少？”重构电动汽车定价模型。 跨学科嫁接：“区块链技术如何解决医疗数据孤岛问题？”。 四、提问的伦理与文化维度 link1. 尊重与被尊重：提问中的权力平衡 link 文化敏感性：在权威文化中采用“建议式提问”（“是否可以考虑……”）而非直接质疑。 共情式提问：心理咨询中的“你觉得这种情绪背后可能有什么需求？”。 2. 提问的陷阱与规避 link 劣质提问的特征： 模糊性（“如何成功？”）； 诱导性（“你不认为这个方案很差吗？”）； 攻击性（“你连这都不懂？”）。 五、案例深度解析 link案例1：伽利略的“5个女儿之问” link 背景：比罗教授宣称“父亲强弱决定子女性别”，伽利略反驳：“邻居强壮却生5女，何解？”。 智慧解析： 以具体案例挑战抽象理论； 用事实反驳权威，坚持“科学必须符合现实”； 展现“质疑-验证-重构”的科学提问范式。 案例2：知识结构图法提升学习效率 link 实践效果：学生小郑通过提炼错题关键点（如数学题的“已知条件-问题链”），2个月内从班级中游跃居前三。 方法论延伸： “是何-为何-如何”三问法（语文阅读分析）； “输入-加工-输出”提问循环（网页6的“教给别人”记忆法）。 六、提问能力的终身训练 link1. 日常训练工具 link 提问日记：每日记录3个优质问题并评估效果； 苏格拉底式自问：对任何结论追问“为什么成立？”“反例是否存在？”。 2. 进阶修炼方向 link 元问题意识：在提问中反思“当前问题是否触及本质？”； 系统思维提问：通过“要素-连接-功能”三层次分析复杂系统。 结语：提问不仅是获取答案的工具，更是重塑认知、推动变革的杠杆。从伽利略的颠覆性质疑到现代职场的高效沟通，提问的智慧贯穿人类文明的每一次跃迁。唯有保持“童真式追问”（胡适“问题丹”），方能在不确定的时代锚定思想的航向。\n"
            }
        );
    index.add(
            {
                id:  6 ,
                href: "\/docs\/information\/secure\/basic_cryptography\/",
                title: "密码学基础",
                description: "定义与目标 link密码学是研究如何保护信息安全的科学。\n核心目标：\n机密性（Confidentiality）：确保信息仅能被授权方读取（如加密电子邮件）。 完整性（Integrity）：防止信息被篡改（如数字签名验证文件未被修改）。 认证性（Authentication）：验证通信双方身份的真实性（如登录密码或生物识别）。 不可否认性（Non-repudiation）：防止发送者事后否认其行为（如区块链交易记录）。 分类 link 技术原理分类 对称密码（Symmetric Cryptography） 定义：加密与解密使用同一密钥，也称为私钥密码。 分组密码：将明文分为固定长度的块进行加密（如AES、DES、3DES） 结构：Feistel网络（DES）、SPN结构（AES） 流密码：将明文逐位加密（如RC4、ChaCha20） 特点：速度快，适合大数据量加密，但密钥分发困难。 应用场景：文件加密（AES）、无线通信（GSM中的A5/1算法） 非对称密码（Asymmetric Cryptography） 定义：使用公钥加密、私钥解密，或私钥签名、公钥验证，也称公钥密码。 基于数论难题：RSA（大整数分解）、Diffie-Hellman（离散对数） 基于椭圆曲线：ECC（椭圆曲线离散对数） 特点：解决密钥分发问题，但计算效率低于对称加密。 应用场景：数字签名（RSA）、密钥交换（Diffie-Hellman）、证书认证（X.509） 哈希函数（Hash Function） 定义：将任意长度输入映射为固定长度的输出（哈希值），具备单向性和抗碰撞性 传统哈希：SHA-256（比特币）、SHA-3（Keccak算法） 已淘汰算法：MD5（因碰撞攻击被弃用） 特点：不可逆，常用于数据完整性验证和密码存储（加盐哈希） 应用场景：区块链Merkle树、文件校验 功能目标分类 加密与解密 目标：保护数据机密性 技术：对称加密（AES）、非对称加密（RSA） 数字签名（Digital Signature） 目标：实现认证性和不可否认性。 流程：发送方用私钥签名，接收方用公钥验证。 算法：RSA签名、ECDSA（比特币交易签名）。 消息认证码（MAC） 目标：验证数据来源和完整性。 技术：HMAC（基于哈希的MAC）、CMAC（基于分组密码的MAC）。 密钥交换（Key Exchange） 目标：安全协商共享密钥 算法：Diffie-Hellman、ECDH（椭圆曲线Diffie-Hellman） 应用场景分类 网络通信安全 SSL/TLS：混合使用对称加密（AES）和非对称加密（RSA/ECC）。 VPN：IPsec协议中的ESP加密与AH认证。 区块链与数字货币 椭圆曲线签名：比特币的ECDSA。 零知识证明：Zcash的zk-SNARKs。 隐私保护技术 同态加密（Homomorphic Encryption）：允许在加密数据上直接运算（如医疗数据分析）。 安全多方计算（MPC）：多方协作计算数据，但各自隐私数据不泄露。 古典密码 link古典密码学主要关注信息的保密书写和传递，以及与其相对应的破译方法。\n理解密码学基础：揭示加密核心思想（混淆与扩散），为现代密码学（如AES的S盒设计）奠定基础。 掌握密码分析入门：频率分析、卡西斯基试验等攻击方法，是密码分析思维的起点。 替换密码 link原理：将明文中的字符替换为另一字符（或符号）。\n典型设计：\n",
                content: "定义与目标 link密码学是研究如何保护信息安全的科学。\n核心目标：\n机密性（Confidentiality）：确保信息仅能被授权方读取（如加密电子邮件）。 完整性（Integrity）：防止信息被篡改（如数字签名验证文件未被修改）。 认证性（Authentication）：验证通信双方身份的真实性（如登录密码或生物识别）。 不可否认性（Non-repudiation）：防止发送者事后否认其行为（如区块链交易记录）。 分类 link 技术原理分类 对称密码（Symmetric Cryptography） 定义：加密与解密使用同一密钥，也称为私钥密码。 分组密码：将明文分为固定长度的块进行加密（如AES、DES、3DES） 结构：Feistel网络（DES）、SPN结构（AES） 流密码：将明文逐位加密（如RC4、ChaCha20） 特点：速度快，适合大数据量加密，但密钥分发困难。 应用场景：文件加密（AES）、无线通信（GSM中的A5/1算法） 非对称密码（Asymmetric Cryptography） 定义：使用公钥加密、私钥解密，或私钥签名、公钥验证，也称公钥密码。 基于数论难题：RSA（大整数分解）、Diffie-Hellman（离散对数） 基于椭圆曲线：ECC（椭圆曲线离散对数） 特点：解决密钥分发问题，但计算效率低于对称加密。 应用场景：数字签名（RSA）、密钥交换（Diffie-Hellman）、证书认证（X.509） 哈希函数（Hash Function） 定义：将任意长度输入映射为固定长度的输出（哈希值），具备单向性和抗碰撞性 传统哈希：SHA-256（比特币）、SHA-3（Keccak算法） 已淘汰算法：MD5（因碰撞攻击被弃用） 特点：不可逆，常用于数据完整性验证和密码存储（加盐哈希） 应用场景：区块链Merkle树、文件校验 功能目标分类 加密与解密 目标：保护数据机密性 技术：对称加密（AES）、非对称加密（RSA） 数字签名（Digital Signature） 目标：实现认证性和不可否认性。 流程：发送方用私钥签名，接收方用公钥验证。 算法：RSA签名、ECDSA（比特币交易签名）。 消息认证码（MAC） 目标：验证数据来源和完整性。 技术：HMAC（基于哈希的MAC）、CMAC（基于分组密码的MAC）。 密钥交换（Key Exchange） 目标：安全协商共享密钥 算法：Diffie-Hellman、ECDH（椭圆曲线Diffie-Hellman） 应用场景分类 网络通信安全 SSL/TLS：混合使用对称加密（AES）和非对称加密（RSA/ECC）。 VPN：IPsec协议中的ESP加密与AH认证。 区块链与数字货币 椭圆曲线签名：比特币的ECDSA。 零知识证明：Zcash的zk-SNARKs。 隐私保护技术 同态加密（Homomorphic Encryption）：允许在加密数据上直接运算（如医疗数据分析）。 安全多方计算（MPC）：多方协作计算数据，但各自隐私数据不泄露。 古典密码 link古典密码学主要关注信息的保密书写和传递，以及与其相对应的破译方法。\n理解密码学基础：揭示加密核心思想（混淆与扩散），为现代密码学（如AES的S盒设计）奠定基础。 掌握密码分析入门：频率分析、卡西斯基试验等攻击方法，是密码分析思维的起点。 替换密码 link原理：将明文中的字符替换为另一字符（或符号）。\n典型设计：\n凯撒密码（Caesar Cipher）： 明文每个字母在字母表中固定偏移（如右移3位，A→D，B→E）。 弱点：仅26种可能偏移，易被穷举或频率分析破解。 实践任务：编程实现加密与频率攻击（统计字母分布）。 维吉尼亚密码（Vigenère Cipher）： 使用关键词生成多表替换（如关键词“KEY”循环决定每字母的偏移量）。 优点：相比凯撒密码，多表替换抵抗频率分析。 弱点：关键词重复导致周期性漏洞，可用卡西斯基试验（Kasiski Examination）破解。 单表替换扩展：如仿射密码（Affine Cipher），通过线性变换加密：E(x)=(ax+b)mod 26E(x)=(ax+b)mod26。 置换密码（Transposition Cipher） link原理：改变明文字符的顺序，不替换字符本身。\n典型设计：\n栅栏密码（Rail Fence Cipher）： 将明文按“之”字形排列后按行读取（如明文“HELLOWORLD”排列为两行后加密为“HLOOL ELWRD”）。 弱点：排列规律易被猜测。 列置换密码（Columnar Transposition）： 将明文按固定列数排列，按密钥决定的列顺序重新组合（如密钥“3124”表示按第3、1、2、4列读取）。 安全性：相比栅栏密码更复杂，但密钥长度有限仍可能被破解。 密码器械（手工/机械密码） link 斯巴达密码棒（Scytale）： 古希腊用木棒缠绕羊皮纸书写，拆下后乱序，需相同粗细木棒还原。 恩尼格玛机（Enigma Machine）： 二战德军使用的转子机械密码机，虽属机械时代，但可视为古典密码的复杂延伸。 原理：通过多个转子电路实现动态多表替换，但因设计漏洞（如密钥重复）被图灵破解。 "
            }
        );
    index.add(
            {
                id:  7 ,
                href: "\/docs\/economy\/microeconomics_base\/",
                title: "微观经济学基础",
                description: "曼昆的《经济学原理》作为经济学领域的经典教材，以其清晰的逻辑框架和生动的现实案例，为无数经济学学习者打开了微观经济学的大门。本文将以曼昆的微观经济学分册为基础，系统梳理微观经济学的核心概念与原理，从经济学十大原理这一基础框架出发，逐步深入到市场运行机制、消费者与生产者行为分析、不同市场结构下的企业决策，以及市场失灵与政府干预等重要议题。每个部分都将结合现实案例进行阐释，帮助读者理解这些抽象理论如何解释我们日常生活中的经济现象。通过这篇总结，读者不仅能够掌握微观经济学的基础知识体系，还能学会像经济学家一样思考现实世界中的资源配置问题。\n经济学十大原理与基础概念 link经济学作为一门研究稀缺资源配置的社会科学，其核心问题源于一个基本事实：社会资源是有限的，而人类欲望是无限的。曼昆在《经济学原理》开篇即提出了贯穿全书的\"经济学十大原理\"，这些原理为我们理解个体决策、市场运行和整体经济提供了基本框架。稀缺性（scarcity）是经济学研究的出发点，它指社会拥有的资源有限，无法生产人们希望拥有的所有物品与劳务。正是这种稀缺性的存在，使得人们必须做出选择，从而产生了经济学研究的三个基本问题：生产什么、如何生产和为谁生产。\n曼昆将十大原理分为三组，分别对应个人决策、人们之间的交易以及整体经济运行。第一组原理关于个人如何做出决策：人们面临权衡取舍（原理一）；某种东西的成本是为了得到它所放弃的东西，即机会成本（原理二）；理性人考虑边际量（原理三）；人们会对激励做出反应（原理四）。以大学生选择学习时间为例，在考试前夕，学生需要在复习和娱乐之间做出权衡（原理一）；选择多玩一小时游戏的成本是少了一小时复习可能导致的成绩下降（原理二）；理性的学生会考虑多复习一小时带来的边际收益是否大于边际成本（原理三）；如果教授宣布考试难度降低，学生可能会减少复习时间，这就是对激励的反应（原理四）。\n第二组原理探讨人们之间的相互交易：贸易可以使每个人的状况都变得更好（原理五）；市场通常是组织经济活动的一种好方法（原理六）；政府有时可以改善市场结果（原理七）。国际贸易的例子生动说明了这些原理：中国生产服装有比较优势，美国生产飞机有比较优势，两国通过贸易都能以更低的成本获得对方的产品（原理五）；市场价格机制像一只\"看不见的手\"引导资源流向最有效率的用途（原理六）；但当存在污染等外部性时，政府通过环保法规可以改善市场结果（原理七）。\n第三组原理涉及整体经济运行：一国的生活水平取决于它生产物品与劳务的能力即生产率（原理八）；货币发行过多导致物价上涨（原理九）；社会面临通货膨胀与失业之间的短期权衡取舍（原理十）。二战后日本和德国的经济奇迹展示了生产率对生活水平的关键作用（原理八）；津巴布韦和委内瑞拉的恶性通货膨胀印证了货币超发的后果（原理九）；而各国央行在经济增长与物价稳定间的政策权衡则体现了菲利普斯曲线的短期交替关系（原理十）。\n理解这些经济学原理，有助于我们培养经济学思维方式。经济学家使用模型（如循环流向图、生产可能性边界）简化复杂现实，区分实证表述（描述\"是什么\"）与规范表述（主张\"应该是什么\"），并通过科学方法分析经济现象。例如，生产可能性边界展示了在资源和技术给定情况下，一个经济体能生产的两种产品的各种组合，以及机会成本随产量变化的关系。假设一个国家只能生产汽车和食品，多生产一辆汽车意味着必须放弃一定数量的食品生产，这种权衡取舍关系正是经济学研究的核心。\nmindmap root((经济学原理)) 个人决策 原理1: 权衡取舍 原理2: 机会成本 原理3: 边际决策 原理4: 激励反应 交互作用 原理5: 贸易增益 原理6: 市场效率 原理7: 政府职能 整体经济 原理8: 生产率 原理9: 通货膨胀 原理10: 失业通胀交替 市场运行机制：供给与需求 link供给与需求模型是微观经济学分析市场运行的核心工具，被称为\"经济学家的工具箱\"。这一模型解释了资源如何通过价格机制在市场经济中进行配置。市场需求指的是在一定时期内，消费者在各种价格水平下愿意且能够购买的商品或服务数量。根据需求定理，在其他条件不变的情况下，商品价格上升会导致需求量减少，反之亦然。这种反向关系可以用需求曲线直观表示：一条从左上方向右下方倾斜的曲线。例如，当智能手机价格从5000元降至3000元时，市场上愿意购买的消费者数量通常会增加。\n影响需求的因素远不止价格，还包括消费者偏好、收入水平、相关商品价格（替代品和互补品）以及消费者预期等。收入增加会提高对正常商品（如优质肉类、品牌服装）的需求，但减少对低档商品（如方便面、公共交通）的需求。替代品（如茶叶与咖啡）和互补品（如手机与流量套餐）的价格变动也会影响需求：咖啡价格上涨可能导致茶叶需求增加；而流量费下降可能提升智能手机销量。2020年疫情期间，居家办公导致笔记本电脑需求激增，就是一个现实案例。\n市场供给则指生产者在各种价格水平下愿意且能够提供的商品或服务数量。供给定理表明，价格与供给量之间存在正向关系，这体现为向右上方倾斜的供给曲线。影响供给的因素包括生产成本（原材料价格、工资水平等）、技术水平、生产者数量以及生产者对未来价格的预期。例如，芯片制造技术的进步降低了智能手机生产成本，使厂商在相同价格下愿意供应更多产品；而原油价格上涨预期可能导致石油公司减少当前供应，等待更高价格。\n当供给与需求力量相互作用时，市场会趋向于均衡状态——供给量与需求量相等时的价格和数量。均衡价格是市场自发调节的结果，此时既无短缺也无过剩。以房地产市场为例，当政府限制购房资格导致需求减少时，需求曲线左移，均衡价格和交易量都会下降；而建筑成本上升使供给曲线左移，将导致价格上升但交易量减少。2022年全球芯片短缺就是典型非均衡状态：疫情后需求激增而供给受限，导致芯片价格飙升，直至2023年供需逐渐恢复平衡。\n价格弹性衡量供需对价格变动的敏感程度，对企业和政策制定者至关重要。需求价格弹性取决于商品必要性、替代品可获得性、消费占收入比例以及时间跨度。生活必需品（如食盐、药品）通常缺乏弹性，而奢侈品（如高端旅游）弹性较大。企业利用弹性理论制定定价策略：弹性小的商品可适当提价增加收益，而弹性大的商品则可能通过降价扩大市场份额。政府征税时也会考虑弹性——对香烟等缺乏弹性的商品征税，既能增加财政收入又不会大幅减少销量。\n供给与需求模型的实际应用广泛存在于政府政策分析中。价格管制（如最高限价和最低限价）会干扰市场均衡，导致非效率。租金管制可能造成租房短缺，而农产品最低保护价则可能导致过剩库存。税收负担的实际分配也取决于供需弹性：弹性较小的一方承担更多税负。例如，烟草税主要由消费者承担，因为吸烟者对香烟的需求相对缺乏弹性；而针对旅游服务的税收则更多由供给方承担，因为消费者可以轻易选择不旅游或去其他地方。\n表：影响需求与供给的因素比较\n类别 需求影响因素 供给影响因素 价格因素 商品自身价格（需求定理） 商品自身价格（供给定理） 非价格因素 消费者收入、相关商品价格、偏好、预期、买家数量 生产成本、技术水平、卖家数量、生产者预期、自然条件 弹性决定因素 替代品可获得性、商品性质（必需品/奢侈品）、消费占比、时间跨度 生产能力调整难度、时间跨度、库存水平、生产要素流动性 graph TD subgraph 市场均衡 S[供给曲线] --\u003e|价格↑ 供给量↑| E(均衡点) D[需求曲线] --\u003e|价格↑ 需求量↓| E end E --\u003e P[均衡价格 P*] E --\u003e Q[均衡数量 Q*] P -.-\u003e|价格调节| 动态[市场调节机制] subgraph 动态[市场调节机制] 高价[价格过高] --\u003e 过剩[供过于求] --\u003e 降价[价格↓] --\u003e E 低价[价格过低] --\u003e 短缺[供不应求] --\u003e 涨价[价格↑] --\u003e E end class S,供给曲线 supply class D,需求曲线 demand class E,均衡点 equilibrium class P,Q keynode classDef supply fill:#f0f4ff,stroke:#4a90e2 classDef demand fill:#fff0f0,stroke:#eb4d4b classDef equilibrium fill:#f8f9fa,stroke:#2ecc71,stroke-width:2px classDef keynode fill:#eaf7ed,stroke:#27ae60 消费者行为理论 link消费者选择理论揭示了个人如何在有限收入的约束下做出最优购买决策，以实现满足感最大化。这一理论的核心假设是消费者是理性的，他们会系统性地选择能带来最大效用的商品组合。效用（Utility）是衡量消费者从商品或服务中获得满足程度的抽象概念，可分为基数效用（可计量）和序数效用（可排序）两种理论。虽然我们无法精确测量效用值，但这一概念帮助我们理解消费者偏好和选择行为。\n",
                content: "曼昆的《经济学原理》作为经济学领域的经典教材，以其清晰的逻辑框架和生动的现实案例，为无数经济学学习者打开了微观经济学的大门。本文将以曼昆的微观经济学分册为基础，系统梳理微观经济学的核心概念与原理，从经济学十大原理这一基础框架出发，逐步深入到市场运行机制、消费者与生产者行为分析、不同市场结构下的企业决策，以及市场失灵与政府干预等重要议题。每个部分都将结合现实案例进行阐释，帮助读者理解这些抽象理论如何解释我们日常生活中的经济现象。通过这篇总结，读者不仅能够掌握微观经济学的基础知识体系，还能学会像经济学家一样思考现实世界中的资源配置问题。\n经济学十大原理与基础概念 link经济学作为一门研究稀缺资源配置的社会科学，其核心问题源于一个基本事实：社会资源是有限的，而人类欲望是无限的。曼昆在《经济学原理》开篇即提出了贯穿全书的\"经济学十大原理\"，这些原理为我们理解个体决策、市场运行和整体经济提供了基本框架。稀缺性（scarcity）是经济学研究的出发点，它指社会拥有的资源有限，无法生产人们希望拥有的所有物品与劳务。正是这种稀缺性的存在，使得人们必须做出选择，从而产生了经济学研究的三个基本问题：生产什么、如何生产和为谁生产。\n曼昆将十大原理分为三组，分别对应个人决策、人们之间的交易以及整体经济运行。第一组原理关于个人如何做出决策：人们面临权衡取舍（原理一）；某种东西的成本是为了得到它所放弃的东西，即机会成本（原理二）；理性人考虑边际量（原理三）；人们会对激励做出反应（原理四）。以大学生选择学习时间为例，在考试前夕，学生需要在复习和娱乐之间做出权衡（原理一）；选择多玩一小时游戏的成本是少了一小时复习可能导致的成绩下降（原理二）；理性的学生会考虑多复习一小时带来的边际收益是否大于边际成本（原理三）；如果教授宣布考试难度降低，学生可能会减少复习时间，这就是对激励的反应（原理四）。\n第二组原理探讨人们之间的相互交易：贸易可以使每个人的状况都变得更好（原理五）；市场通常是组织经济活动的一种好方法（原理六）；政府有时可以改善市场结果（原理七）。国际贸易的例子生动说明了这些原理：中国生产服装有比较优势，美国生产飞机有比较优势，两国通过贸易都能以更低的成本获得对方的产品（原理五）；市场价格机制像一只\"看不见的手\"引导资源流向最有效率的用途（原理六）；但当存在污染等外部性时，政府通过环保法规可以改善市场结果（原理七）。\n第三组原理涉及整体经济运行：一国的生活水平取决于它生产物品与劳务的能力即生产率（原理八）；货币发行过多导致物价上涨（原理九）；社会面临通货膨胀与失业之间的短期权衡取舍（原理十）。二战后日本和德国的经济奇迹展示了生产率对生活水平的关键作用（原理八）；津巴布韦和委内瑞拉的恶性通货膨胀印证了货币超发的后果（原理九）；而各国央行在经济增长与物价稳定间的政策权衡则体现了菲利普斯曲线的短期交替关系（原理十）。\n理解这些经济学原理，有助于我们培养经济学思维方式。经济学家使用模型（如循环流向图、生产可能性边界）简化复杂现实，区分实证表述（描述\"是什么\"）与规范表述（主张\"应该是什么\"），并通过科学方法分析经济现象。例如，生产可能性边界展示了在资源和技术给定情况下，一个经济体能生产的两种产品的各种组合，以及机会成本随产量变化的关系。假设一个国家只能生产汽车和食品，多生产一辆汽车意味着必须放弃一定数量的食品生产，这种权衡取舍关系正是经济学研究的核心。\nmindmap root((经济学原理)) 个人决策 原理1: 权衡取舍 原理2: 机会成本 原理3: 边际决策 原理4: 激励反应 交互作用 原理5: 贸易增益 原理6: 市场效率 原理7: 政府职能 整体经济 原理8: 生产率 原理9: 通货膨胀 原理10: 失业通胀交替 市场运行机制：供给与需求 link供给与需求模型是微观经济学分析市场运行的核心工具，被称为\"经济学家的工具箱\"。这一模型解释了资源如何通过价格机制在市场经济中进行配置。市场需求指的是在一定时期内，消费者在各种价格水平下愿意且能够购买的商品或服务数量。根据需求定理，在其他条件不变的情况下，商品价格上升会导致需求量减少，反之亦然。这种反向关系可以用需求曲线直观表示：一条从左上方向右下方倾斜的曲线。例如，当智能手机价格从5000元降至3000元时，市场上愿意购买的消费者数量通常会增加。\n影响需求的因素远不止价格，还包括消费者偏好、收入水平、相关商品价格（替代品和互补品）以及消费者预期等。收入增加会提高对正常商品（如优质肉类、品牌服装）的需求，但减少对低档商品（如方便面、公共交通）的需求。替代品（如茶叶与咖啡）和互补品（如手机与流量套餐）的价格变动也会影响需求：咖啡价格上涨可能导致茶叶需求增加；而流量费下降可能提升智能手机销量。2020年疫情期间，居家办公导致笔记本电脑需求激增，就是一个现实案例。\n市场供给则指生产者在各种价格水平下愿意且能够提供的商品或服务数量。供给定理表明，价格与供给量之间存在正向关系，这体现为向右上方倾斜的供给曲线。影响供给的因素包括生产成本（原材料价格、工资水平等）、技术水平、生产者数量以及生产者对未来价格的预期。例如，芯片制造技术的进步降低了智能手机生产成本，使厂商在相同价格下愿意供应更多产品；而原油价格上涨预期可能导致石油公司减少当前供应，等待更高价格。\n当供给与需求力量相互作用时，市场会趋向于均衡状态——供给量与需求量相等时的价格和数量。均衡价格是市场自发调节的结果，此时既无短缺也无过剩。以房地产市场为例，当政府限制购房资格导致需求减少时，需求曲线左移，均衡价格和交易量都会下降；而建筑成本上升使供给曲线左移，将导致价格上升但交易量减少。2022年全球芯片短缺就是典型非均衡状态：疫情后需求激增而供给受限，导致芯片价格飙升，直至2023年供需逐渐恢复平衡。\n价格弹性衡量供需对价格变动的敏感程度，对企业和政策制定者至关重要。需求价格弹性取决于商品必要性、替代品可获得性、消费占收入比例以及时间跨度。生活必需品（如食盐、药品）通常缺乏弹性，而奢侈品（如高端旅游）弹性较大。企业利用弹性理论制定定价策略：弹性小的商品可适当提价增加收益，而弹性大的商品则可能通过降价扩大市场份额。政府征税时也会考虑弹性——对香烟等缺乏弹性的商品征税，既能增加财政收入又不会大幅减少销量。\n供给与需求模型的实际应用广泛存在于政府政策分析中。价格管制（如最高限价和最低限价）会干扰市场均衡，导致非效率。租金管制可能造成租房短缺，而农产品最低保护价则可能导致过剩库存。税收负担的实际分配也取决于供需弹性：弹性较小的一方承担更多税负。例如，烟草税主要由消费者承担，因为吸烟者对香烟的需求相对缺乏弹性；而针对旅游服务的税收则更多由供给方承担，因为消费者可以轻易选择不旅游或去其他地方。\n表：影响需求与供给的因素比较\n类别 需求影响因素 供给影响因素 价格因素 商品自身价格（需求定理） 商品自身价格（供给定理） 非价格因素 消费者收入、相关商品价格、偏好、预期、买家数量 生产成本、技术水平、卖家数量、生产者预期、自然条件 弹性决定因素 替代品可获得性、商品性质（必需品/奢侈品）、消费占比、时间跨度 生产能力调整难度、时间跨度、库存水平、生产要素流动性 graph TD subgraph 市场均衡 S[供给曲线] --\u003e|价格↑ 供给量↑| E(均衡点) D[需求曲线] --\u003e|价格↑ 需求量↓| E end E --\u003e P[均衡价格 P*] E --\u003e Q[均衡数量 Q*] P -.-\u003e|价格调节| 动态[市场调节机制] subgraph 动态[市场调节机制] 高价[价格过高] --\u003e 过剩[供过于求] --\u003e 降价[价格↓] --\u003e E 低价[价格过低] --\u003e 短缺[供不应求] --\u003e 涨价[价格↑] --\u003e E end class S,供给曲线 supply class D,需求曲线 demand class E,均衡点 equilibrium class P,Q keynode classDef supply fill:#f0f4ff,stroke:#4a90e2 classDef demand fill:#fff0f0,stroke:#eb4d4b classDef equilibrium fill:#f8f9fa,stroke:#2ecc71,stroke-width:2px classDef keynode fill:#eaf7ed,stroke:#27ae60 消费者行为理论 link消费者选择理论揭示了个人如何在有限收入的约束下做出最优购买决策，以实现满足感最大化。这一理论的核心假设是消费者是理性的，他们会系统性地选择能带来最大效用的商品组合。效用（Utility）是衡量消费者从商品或服务中获得满足程度的抽象概念，可分为基数效用（可计量）和序数效用（可排序）两种理论。虽然我们无法精确测量效用值，但这一概念帮助我们理解消费者偏好和选择行为。\n边际效用递减规律是消费者行为的重要基础，它指出随着对某种商品消费量的增加，每新增一单位消费带来的效用增量（边际效用）会逐渐减少。例如，炎炎夏日喝第一瓶冰镇饮料带来的满足感极大，第二瓶的满足感稍减，到第三瓶时可能已经没什么额外效用，甚至可能因过量而产生负效用。这一规律解释了为什么多样化消费通常比单一消费更优，也说明了需求曲线为何向下倾斜——只有价格下降，消费者才愿意购买更多单位商品。\n分析消费者选择的有力工具是无差异曲线，它表示给消费者带来相同满足程度的不同商品组合的轨迹。无差异曲线具有四个关键特征：向下倾斜（要保持效用不变，减少一种商品必须增加另一种商品）；凸向原点（反映边际替代率递减）；互不相交；离原点越远代表效用水平越高。假设一个消费者只购买食物和衣服两类商品，连接所有令他同样满意的食物与衣服组合的点，就形成了一条无差异曲线。边际替代率（MRS）则是消费者愿意用一种商品交换另一种商品的比率，等于无差异曲线斜率的绝对值。\n消费者的选择不仅取决于偏好，还受到预算约束的限制。预算线表示在给定收入和价格下，消费者能够购买的所有商品组合。预算线的斜率等于两种商品的价格比，其位置取决于收入水平——收入增加使预算线平行外移。消费者均衡发生在预算线与最高可达的无差异曲线相切之点，此时边际替代率等于商品价格比，实现了效用最大化。举例来说，大学生每月有2000元可支配收入，用于购买食物（每单位10元）和娱乐（每次100元），最优选择就是预算线与无差异曲线的切点组合。\n从消费者均衡理论可以推导出个人需求曲线。当一种商品价格变化时，预算线旋转，形成新的均衡点，连接这些点就得到价格-消费曲线，进而转化为需求曲线。需求曲线向下倾斜不仅反映了边际效用递减，也包含了替代效应和收入效应。当商品价格下降时，一方面它相对于其他商品变得更便宜（替代效应促使增加购买）；另一方面消费者的实际购买力提高（收入效应也可能增加购买，正常商品）或降低（低档商品）。\n消费者行为理论在实际生活中有广泛应用。企业利用消费者偏好分析进行产品设计和定价策略。例如，星巴克提供不同杯型选择，就是考虑消费者对咖啡消费的边际效用递减；而手机厂商推出多种配置版本，则旨在满足不同预算约束下的消费者最优选择。政府政策评估也需要考虑消费者行为，如燃油税的影响不仅取决于价格弹性，还与消费者能否找到合适替代品（如公共交通）密切相关。行为经济学进一步扩展了传统理论，发现消费者并非总是理性，会受心理账户、锚定效应等认知偏差影响。\n消费者选择理论还帮助我们理解生活决策中的机会成本。时间作为一种稀缺资源，其分配也遵循经济学原理。一个加班的白领面临的是工资收入与休闲时间的权衡；选择读研的学生实际上是在比较未来预期收入增加与当前学费及放弃的工作收入。甚至婚姻决策也可以从经济学角度分析——个人会选择能带来最大效用的伴侣，同时考虑寻找成本、替代选择等因素。这些应用展示了经济学思维的广泛适用性。\n$$ \\begin{align*} \\text{预算约束} \u0026:\\ p_xx + p_yy = I \\ \\text{最优解} \u0026:\\ MRS = \\frac{p_x}{p_y} \\ \\text{其中} \u0026:\\ \\begin{cases} p_x,p_y \u0026 \\text{商品价格} \\ x,y \u0026 \\text{消费数量} \\ I \u0026 \\text{收入水平} \\ MRS \u0026 \\text{边际替代率} \\end{cases} \\end{align*} $$\n表：消费者均衡条件的数学表示\n概念 数学表达 经济含义 预算约束 P₁X₁ + P₂X₂ = I 消费者支出不能超过收入 边际替代率(MRS) -ΔX₂/ΔX₁ = MU₁/MU₂ 消费者愿意交换两种商品的比率 消费者均衡条件 MRS = P₁/P₂ 或 MU₁/P₁ = MU₂/P₂ 最后一元钱花在各种商品上的边际效用相等 需求曲线推导 改变P₁，观察X₁变化，保持其他不变 反映价格与需求量之间的关系 %%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#ffdfd3', 'edgeLabelBackground':'#fff'}}}%% mindmap root((消费者选择理论)) 核心概念 效用理论 [\"基数效用(可测量)\"] [\"序数效用(可排序)\"] 理性人假设 边际效用递减 [\"第一单位\"] [\"第N单位\"] 分析工具 无差异曲线 |特征| 向下倾斜 凸向原点 互不相交 离原点越远效用越高 预算约束线 斜率=价格比(P₁/P₂) 收入变化→平行移动 均衡条件 切点条件 MRS = P₁/P₂ MU₁/P₁ = MU₂/P₂ 图形表现 预算线与无差异曲线相切 实际应用 企业决策 产品线设计 差别定价 政策评估 税收效应分析 补贴效果预测 生活决策 时间分配 教育投资 理论扩展 行为经济学 心理账户 锚定效应 显示偏好理论 通过选择反推偏好 生产者行为与成本分析 link生产者理论研究企业如何将投入转化为产出并做出最优生产决策，其核心目标是利润最大化。生产函数描述了在既定技术条件下，生产要素（如劳动、资本）投入量与最大产出量之间的关系。典型的短期生产函数会呈现先递增后递减的规律：随着可变要素（如劳动力）增加，总产出先快速上升，然后增速放缓，最终可能下降。例如，一家咖啡店在营业面积固定的情况下，雇佣更多服务员起初能显著提高服务效率，但人员过多时反而会造成拥挤，降低整体 productivity。\n边际产量递减规律是生产理论的重要基础，它指出在其他投入固定不变的情况下，随着某一可变投入的连续增加，其边际产量最终会递减。这一规律源于固定要素与可变要素比例的失衡。以农田为例，在土地面积固定时，持续增加劳动力投入，初期每新增一名工人带来的粮食增产显著，但当工人密度过高时，新增工人的贡献逐渐减少，甚至可能因过度拥挤而减产。这一规律解释了为什么单纯增加投入难以持续提升产出效率。\n生产成本是企业决策的另一关键因素。成本分类包括显性成本（实际货币支出，如工资、原材料）和隐性成本（自有资源的机会成本，如企业主时间）；固定成本（不随产量变化，如厂房租金）和可变成本（随产量变化，如原材料）。经济利润与会计利润的区别在于是否考虑隐性成本——经济利润=总收入-显性成本-隐性成本，而会计利润仅扣除显性成本。例如，一位自己经营网店的创业者可能账面盈利，但若考虑其放弃的工资收入，经济利润可能为负。\n成本曲线反映了生产成本与产量之间的关系。短期成本曲线包括：总成本（TC）=固定成本（FC）+可变成本（VC）；平均固定成本（AFC）随产量增加持续下降；平均可变成本（AVC）先降后升；平均总成本（ATC）呈U型；边际成本（MC）曲线也呈U型，且通过ATC和AVC的最低点。这些曲线的形状由边际产量递减规律决定。长期中，所有成本都是可变的，企业可以选择最优生产规模，长期平均成本（LRAC）曲线是所有短期平均成本曲线的包络线，可能呈现规模经济（递减）、规模不经济（递增）或规模报酬不变。\n利润最大化是企业决策的核心原则。在完全竞争市场中，企业是价格接受者，其利润最大化条件为边际收益（MR）等于边际成本（MC）。因为对竞争企业而言，MR等于市场价格P，所以条件简化为P=MC。这一条件决定了企业的供给曲线——在短期内，只要价格高于平均可变成本，企业就会继续生产；长期中，企业只有在价格不低于长期平均成本时才会留在市场。例如，当小麦市场价格为每吨2000元时，农场主会根据MC=2000元来决定最优产量，若价格长期低于生产成本，部分农场将退出市场。\n成本分析对企业战略决策至关重要。规模经济与范围经济影响企业规模和业务范围选择。规模经济指产量增加导致长期平均成本下降，可能源于专业化分工、大规模采购折扣或不可分性（如输油管道）。汽车制造业就是典型规模经济行业。范围经济则指同时生产多种产品比单独生产更节约成本，如航空公司同时提供客运和货运服务。企业还需要考虑学习曲线效应——随着生产经验积累，单位成本下降，这在飞机制造等高技术行业尤为显著。\n生产者行为理论也解释了市场供给曲线的形成。短期行业供给曲线是个别企业供给曲线的水平加总；长期供给曲线则考虑企业进入退出，完全竞争下可能是水平（成本不变行业）、向上倾斜（成本递增行业）或向下倾斜（成本递减行业）。投入品价格变化会移动成本曲线，如油价上涨提高运输成本，使供给曲线左移。技术进步则通常降低生产成本，使供给曲线右移，增加市场供给量。理解这些关系有助于预测政策变化（如环保标准提高）对行业供给和价格的影响。\n表：短期成本曲线之间的关系\n成本概念 计算公式 曲线特征 与其他成本的关系 总成本(TC) TC = FC + VC 从FC开始向右上方倾斜 TC曲线与VC曲线平行，垂直距离为FC 平均固定成本(AFC) AFC = FC/Q 持续下降的直角双曲线 随Q增加逐渐趋近于零 平均可变成本(AVC) AVC = VC/Q U形曲线 最低点对应MC与AVC的交点 平均总成本(ATC) ATC = TC/Q U形曲线，位于AVC上方 最低点对应MC与ATC的交点 边际成本(MC) MC = ΔTC/ΔQ U形曲线 通过AVC和ATC的最低点 市场结构与竞争策略 link市场结构是微观经济学分析企业行为和市场效率的核心框架，根据厂商数量、产品差异程度、进入壁垒等因素可分为完全竞争、垄断、垄断竞争和寡头四种类型。不同市场结构下，企业的定价策略、产量决策和经济利润存在显著差异。完全竞争和垄断是两种极端情况，现实中的市场大多介于两者之间。理解这些市场结构有助于分析行业动态和企业战略，也能为政府制定适当的竞争政策提供依据。\n完全竞争市场是最有效率的市场结构，其特征包括：大量小规模买者和卖者；同质产品；自由进入退出；完全信息。农产品市场接近完全竞争，单个农户无法影响市场价格。完全竞争企业的需求曲线是水平线（价格接受者），短期均衡条件为P=MC，可能获得正经济利润、零利润或亏损；长期均衡时所有企业仅获得正常利润（P=MC=ATC最低点），生产效率最高。完全竞争市场的优点在于资源配置效率（生产有效率和分配效率）和动态适应能力，但缺乏产品多样性和创新激励可能是其局限。\n垄断市场由一个厂商构成，存在高进入壁垒（如专利、规模经济、资源控制或政府特许），产品没有相近替代品。公用事业（如自来水、电网）和微软Windows操作系统是典型例子。垄断者面临向下倾斜的需求曲线，边际收益低于价格，利润最大化条件为MR=MC，此时价格高于边际成本，导致产量低于社会最优水平，产生无谓损失。垄断还可能通过价格歧视（如学生票、高峰定价）获取更多消费者剩余。垄断的成因包括：自然垄断（规模经济使单一厂商更有效率）；政府创造的垄断（如专利）；资源垄断（如De Beers钻石控制）。\n介于完全竞争和垄断之间的是垄断竞争市场，其特征为：较多厂商；产品差异化；自由进入退出。餐饮业、服装零售业属于此类。垄断竞争企业的需求曲线向下倾斜但弹性较大，短期可能盈利，长期因新进入者竞争而仅获正常利润（P=ATC），但不同于完全竞争，此时P\u003eMC且ATC未达到最低点，存在过剩产能。产品差异化促使企业通过广告、品牌建设等非价格竞争手段吸引顾客。虽然垄断竞争存在一定效率损失，但它提供了消费者重视的产品多样性选择。\n寡头市场由少数几家大厂商主导，产品可能同质（纯粹寡头，如钢铁）或差异（差异寡头，如汽车），存在显著进入壁垒。寡头企业的决策相互依赖，形成了丰富的策略行为，博弈论是分析寡头竞争的有力工具。寡头可能通过公开或 tacit collusion（如OPEC）限制产量抬高价格，也可能激烈竞争。囚徒困境模型解释了为什么即使合作对各方有利，寡头仍难以维持垄断产量。寡头市场的效率评价复杂，一方面可能因接近垄断而产生类似问题，另一方面大企业的规模经济和研发能力可能促进技术进步。\n不同市场结构下的企业策略差异显著。完全竞争企业只能被动接受价格，专注于成本最小化；垄断企业则需考虑整个市场需求，可能采取多级价格歧视（如软件的不同版本定价）。垄断竞争企业投资于产品差异化（如星巴克的\"第三空间\"概念）；寡头企业则需预测对手反应，可能采取先占策略、掠夺性定价或研发竞赛。例如，智能手机市场中苹果（差异化垄断竞争者）和安卓厂商（寡头竞争者）采取截然不同的策略组合。\n政府竞争政策旨在纠正市场结构导致的问题，尤其是针对垄断和寡头行为。常见措施包括：反垄断法禁止价格操纵和滥用支配地位（如欧盟对谷歌的反垄断处罚）；管制自然垄断企业的价格和服务质量；促进市场可竞争性（降低进入退出壁垒）；在某些情况下将垄断企业国有化或分拆。政府也通过专利制度平衡创新激励与垄断损失——授予临时垄断权以鼓励研发，但限制专利期限促进长期竞争。这些政策试图在静态效率与动态效率、规模经济与竞争活力之间寻求平衡。\n表：四种市场结构特征比较\n特征 完全竞争 垄断竞争 寡头垄断 完全垄断 厂商数量 非常多 较多 少数几家 唯一一家 产品性质 同质 有差异 同质或差异 无相近替代品 进入壁垒 无 较低 较高 非常高 价格控制力 无（价格接受者） 有限 相当程度 强大 需求曲线 水平线 向下倾斜较平坦 向下倾斜（受对手影响） 行业需求曲线 长期利润 零经济利润 零经济利润 可能有经济利润 可能有经济利润 典型行业 农产品 餐饮、服装 汽车、航空 公用事业、专利药品 要素市场与收入分配 link要素市场是微观经济学分析收入分配的核心环节，与产品市场不同，要素市场的需求是派生需求——源于对最终产品的需求。劳动力、资本、土地和企业家才能是四种基本生产要素，其价格分别表现为工资、利息、租金和利润。要素市场的供求关系决定了要素价格和收入分配格局，而要素价格又影响着社会财富分布和公平问题。理解要素市场运作有助于分析工资差异、资本回报率、土地价值变动等现实经济现象。\n劳动力市场是最重要的要素市场。劳动需求是派生需求，取决于劳动的边际产量价值（VMPL=MPL×P），企业雇佣劳动直到VMPL等于工资率。劳动供给曲线通常向上倾斜（工资越高供给量越大），但可能在高收入水平向后弯曲（收入效应超过替代效应）。均衡工资由劳动供求决定，但现实中工资差异巨大，原因包括：补偿性差异（危险工作工资更高）；人力资本差异（教育投资回报）；能力与努力差异；歧视；工会力量等。例如，程序员比普通文员工资高，部分因为技能培训成本高且技术更新快，边际产出价值大。\n资本市场调节资金配置，利率是资本的价格。资本需求来自企业的投资意愿，取决于资本的边际产量价值；供给来自家庭储蓄。利率影响投资决策和跨期选择——高利率鼓励储蓄而抑制投资。资本市场的不完全性（如信息不对称、风险差异）导致不同借款者面临不同利率。企业通过比较投资项目的预期回报率与资金成本（利率）来决定投资规模。2023年美联储加息抑制通胀，就是通过提高资金成本来减少企业和家庭借贷需求，从而冷却经济。\n土地市场有其特殊性，土地供给通常固定（缺乏弹性），地租完全由需求决定。城市中心商业区地价高昂，反映了该位置带来的高商业价值（如客流量）。经济租是指要素收入超过其机会成本的部分，明星运动员和顶级CEO的高收入中很大部分属于经济租——他们的才能稀缺且难以复制。亨利·乔治曾主张对土地征收单一税，因为地租是\"不劳而获\"的收入，不影响土地供给。\n收入分配既是经济问题也是社会问题。洛伦兹曲线和基尼系数是衡量收入不平等的主要工具。洛伦兹曲线离45度线越远，收入分配越不平等；基尼系数在0（完全平等）到1（完全不平等）之间，发达国家通常在0.3-0.4。收入不平等的原因包括：技能溢价（技术变革偏向高技能劳动者）；全球化（低技能工作外流）；超级明星现象（少数顶尖者获取绝大部分市场）；资本收入占比上升等。例如，信息技术革命大大提高了程序员和工程师的相对收入，而自动化则挤压了制造业工人工资。\n贫困问题与收入分配密切相关。贫困线通常设定为满足基本生活需要的收入水平，贫困率是人口中处于贫困线以下的比例。反贫困政策包括：负所得税（如美国的EITC）；最低工资（争议在于可能减少就业）；福利计划（食品券、医疗补助）；人力资本投资（教育扶贫）；以及机会平等措施。北欧国家的\"灵活安全\"模式（flexicurity）结合了宽松的雇佣解雇规则与强大的失业保障和再培训计划，试图平衡效率与公平。\n要素市场中的歧视经济学分析偏见如何影响工资和就业。歧视可能来自雇主、顾客或同事，表现为同工不同酬或职业隔离。贝克尔模型将歧视视为一种\"偏好\"，歧视者愿意为此支付代价（如拒绝雇佣合格少数族裔而接受生产率损失）。竞争市场理论上会惩罚歧视性雇主（因其效率较低），但现实中的不完全竞争和非市场力量（如制度性歧视）可能使歧视持续存在。平权法案等政策试图纠正历史歧视，但也面临\"逆向歧视\"争议。\n全球化对要素收入分配产生了深远影响。斯托尔珀-萨缪尔森定理预测，贸易开放会提高一国充裕要素的实际收入，降低稀缺要素收入。发达国家的高技能工人受益于全球化，而低技能工人面临来自发展中国家的竞争压力。这解释了为什么发达国家内部对贸易政策存在分歧——资本所有者和高技能劳动者更支持自由贸易，而低技能劳动者倾向保护主义。技术进步与全球化的交互作用进一步加剧了收入极化，形成所谓\"空心化\"的劳动力市场结构。\n表：生产要素及其报酬形式\n生产要素 市场特征 价格形式 收入决定因素 劳动力 派生需求，供给受人口、偏好影响 工资 边际产量价值、技能、制度因素 资本 跨期配置，供给取决于储蓄 利息 资本边际效率、风险、时间偏好 土地 供给固定，位置关键 地租 位置价值、用途需求 企业家才能 创新与风险承担 利润 创新回报、风险溢价、垄断租金 市场失灵与政府干预 link市场失灵是指市场机制无法有效配置资源的情况，为政府干预提供了理论基础。曼昆提出的第七大经济学原理指出\"政府有时可以改善市场结果\"，这正是因为市场并非总是完美运行。市场失灵的主要类型包括：外部性、公共物品、不完全竞争、信息不对称以及收入分配不平等。理解这些失灵现象及其解决方案，有助于平衡市场效率与社会福利，构建更合理的混合经济体制。\n外部性指经济活动对非直接参与的第三方产生的影响，分为正外部性（如疫苗接种减少疾病传播）和负外部性（如工厂污染）。外部性导致市场均衡偏离社会最优——负外部性活动过度供给（如污染），正外部性活动供给不足（如教育）。科斯定理认为如果产权明确且交易成本低，私人谈判可以解决外部性问题，但现实中往往存在高交易成本或多方参与问题。例如，空气污染涉及大量污染者和受污染者，难以通过双边谈判解决。\n政府纠正外部性的政策工具包括：庇古税（对负外部性征税，如碳税）；补贴（对正外部性活动，如研发税收抵免）；直接管制（如排放标准）；以及创建可交易许可证市场（如碳排放权交易）。中国2021年启动的全国碳排放权交易市场就是通过设定总量并允许企业交易配额，以市场机制实现减排目标。教育补贴是纠正正外部性的典型例子——个人可能低估教育的社会收益，导致教育投资不足，政府通过公立学校或学费补贴提高教育水平。\n公共物品是具有非排他性和非竞争性的物品，导致市场供给不足。国防是典型公共物品——无法排除任何人受益（非排他性），一个人享受保护不减少他人享受（非竞争性）。公共物品面临搭便车问题——个人有动机不付费而享受好处，导致私人供给无利可图。政府通过税收融资提供公共物品是常见解决方案。公共资源（如公海渔业）则面临过度使用问题（“公地悲剧”），解决方案包括私有化、管制或使用者协议。例如，国际渔业组织通过配额限制保护鱼类资源。\n信息不对称是市场失灵的又一重要原因，表现为逆向选择（交易前信息不对称，如次品市场）和道德风险（交易后行为不可观测，如保险后的冒险行为）。二手车市场中，卖家比买家更了解车况，可能导致只有低质量车成交（“柠檬市场”）。解决方案包括：信号发送（如教育文凭显示能力）；筛选（保险公司区分高风险低风险客户）；担保和声誉机制；以及政府监管（如食品质量标准）。2008年金融危机部分源于复杂的金融衍生品使买家难以评估风险，凸显信息透明的重要性。\n不完全竞争市场（垄断、寡头）也会导致市场失灵，表现为产量不足、价格过高和创新抑制。政府通过反垄断法（如阻止有害并购）、管制自然垄断企业价格、促进市场竞争来应对。美国拆分AT\u0026T和欧盟处罚谷歌滥用市场地位都是典型案例。但政府干预也需谨慎——过度管制可能抑制企业活力，专利制度就是在创新激励与垄断损失间的平衡。\n政府干预本身也可能失败，称为政府失灵，原因包括：信息不足（政府难以精确了解社会偏好和生产可能）；官僚主义低效；利益集团俘获；政策时滞等。例如，农产品价格支持政策可能最初旨在保护农民收入，但最终演变成代价高昂的补贴体系，同时扭曲生产决策。公共选择理论运用经济学方法分析政府决策，认为政治家和官员也追求自身利益（如选票、预算最大化），不一定以社会福利最大化为目标。\n福利经济学为评估市场结果和政府政策提供了框架。帕累托最优是指在不使任何人变差的情况下无法使某人变好的资源配置状态。完全竞争市场在理论上能达到帕累托效率，但现实中的各种市场失灵使这一理想难以实现。补偿原则（卡尔多-希克斯效率）认为如果获益者能补偿受损者而仍有剩余，就是效率改进，即使补偿并未实际发生。成本-收益分析是评估公共项目的重要工具，但量化生命价值、环境损失等非市场物品存在挑战。\n混合经济中市场与政府的边界是持续争议的话题。市场经济支持者强调分散决策、激励相容和动态效率；政府干预倡导者则关注市场失灵、公平目标和长期战略需求。东亚发展型国家（如日本、韩国）通过产业政策引导经济转型取得成功，但拉美国家的政府主导工业化却多告失败，表明政策设计和制度环境的关键作用。理想的经济体制可能因发展阶段、文化传统和全球环境而异，但普遍共识是需要市场活力与政府规制的适当结合。\n表：主要市场失灵类型及对策\n市场失灵类型 产生原因 导致结果 政府对策 案例 负外部性 私人成本\u003c社会成本 过度生产 征税、管制、许可证 碳税、污染排放标准 正外部性 私人收益\u003c社会收益 供给不足 补贴、政府提供 教育补贴、基础科研资助 公共物品 非排他性+非竞争性 市场不提供 政府直接提供 国防、公共公园 信息不对称 买卖方信息不均 逆向选择/道德风险 信息披露要求、标准制定 食品安全监管、金融产品透明度 市场权力 进入壁垒、规模经济 产量不足、价格过高 反垄断、价格管制、促进竞争 微软反垄断案、公用事业费率监管 "
            }
        );
    index.add(
            {
                id:  8 ,
                href: "\/docs\/develop\/",
                title: "成长",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  9 ,
                href: "\/docs\/mix\/list\/",
                title: "摩旅清单",
                description: "日常\n证件 充电器 充电宝 洗漱包 指甲刀 小刀 袜子 内裤 短裤 外套 帽子 卫生纸 湿巾 垃圾袋 纸笔 装备\n骑行服 头盔 手套 头套 雨衣 应急\n补胎 套筒 棘轮扳手 充气泵 锯子 锤子 钳子 扎带 尺子 汽油瓶 电工胶布 保险丝 打火机 打火石 抽油管 螺丝胶 纱布 碘伏 酒精 创可贴 角鲨烯 风油精 布洛芬 红霉素软膏 露营\n帐篷 垫子 睡袋 睡垫 枕头 眼罩 桌子 椅子 筷子 勺子 炉头 气罐 杯锅 水袋 灯 拍摄\n三脚架 八爪鱼 DJI Action DJI Pocket 飞行器 ",
                content: "日常\n证件 充电器 充电宝 洗漱包 指甲刀 小刀 袜子 内裤 短裤 外套 帽子 卫生纸 湿巾 垃圾袋 纸笔 装备\n骑行服 头盔 手套 头套 雨衣 应急\n补胎 套筒 棘轮扳手 充气泵 锯子 锤子 钳子 扎带 尺子 汽油瓶 电工胶布 保险丝 打火机 打火石 抽油管 螺丝胶 纱布 碘伏 酒精 创可贴 角鲨烯 风油精 布洛芬 红霉素软膏 露营\n帐篷 垫子 睡袋 睡垫 枕头 眼罩 桌子 椅子 筷子 勺子 炉头 气罐 杯锅 水袋 灯 拍摄\n三脚架 八爪鱼 DJI Action DJI Pocket 飞行器 "
            }
        );
    index.add(
            {
                id:  10 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/resources\/",
                title: "资源对象",
                description: "以下列举的内容都是 Kubernetes 中的对象（Object），这些对象都可以在 YAML 文件中作为一种 API 类型来配置。\nPod Node Namespace Service Volume PersistentVolume Deployment Secret StatefulSet DaemonSet ServiceAccount ReplicationController ReplicaSet Job CronJob SecurityContext ResourceQuota LimitRange HorizontalPodAutoscaling Ingress ConfigMap Label CustomResourceDefinition Role ClusterRole 我将它们简单的分类为以下几种资源对象：\n类别 名称 资源对象 Pod、ReplicaSet、ReplicationController、Deployment、StatefulSet、DaemonSet、Job、CronJob、HorizontalPodAutoscaling、Node、Namespace、Service、Ingress、Label、CustomResourceDefinition 存储对象 Volume、PersistentVolume、Secret、ConfigMap 策略对象 SecurityContext、ResourceQuota、LimitRange 身份对象 ServiceAccount、Role、ClusterRole 理解 Kubernetes 中的对象 link在 Kubernetes 系统中，Kubernetes 对象 是持久化的条目。Kubernetes 使用这些条目去表示整个集群的状态。特别地，它们描述了如下信息：\n什么容器化应用在运行（以及在哪个 Node 上） 可以被应用使用的资源 关于应用如何表现的策略，比如重启策略、升级策略，以及容错策略 Kubernetes 对象是 “目标性记录” —— 一旦创建对象，Kubernetes 系统将持续工作以确保对象存在。通过创建对象，可以有效地告知 Kubernetes 系统，所需要的集群工作负载看起来是什么样子的，这就是 Kubernetes 集群的 期望状态。\n与 Kubernetes 对象工作 —— 是否创建、修改，或者删除 —— 需要使用 Kubernetes API。当使用 kubectl 命令行接口时，比如，CLI 会使用必要的 Kubernetes API 调用，也可以在程序中直接使用 Kubernetes API。为了实现该目标，Kubernetes 当前提供了一个 golang 客户端库 ，其它语言库（例如Python）也正在开发中。\n",
                content: "以下列举的内容都是 Kubernetes 中的对象（Object），这些对象都可以在 YAML 文件中作为一种 API 类型来配置。\nPod Node Namespace Service Volume PersistentVolume Deployment Secret StatefulSet DaemonSet ServiceAccount ReplicationController ReplicaSet Job CronJob SecurityContext ResourceQuota LimitRange HorizontalPodAutoscaling Ingress ConfigMap Label CustomResourceDefinition Role ClusterRole 我将它们简单的分类为以下几种资源对象：\n类别 名称 资源对象 Pod、ReplicaSet、ReplicationController、Deployment、StatefulSet、DaemonSet、Job、CronJob、HorizontalPodAutoscaling、Node、Namespace、Service、Ingress、Label、CustomResourceDefinition 存储对象 Volume、PersistentVolume、Secret、ConfigMap 策略对象 SecurityContext、ResourceQuota、LimitRange 身份对象 ServiceAccount、Role、ClusterRole 理解 Kubernetes 中的对象 link在 Kubernetes 系统中，Kubernetes 对象 是持久化的条目。Kubernetes 使用这些条目去表示整个集群的状态。特别地，它们描述了如下信息：\n什么容器化应用在运行（以及在哪个 Node 上） 可以被应用使用的资源 关于应用如何表现的策略，比如重启策略、升级策略，以及容错策略 Kubernetes 对象是 “目标性记录” —— 一旦创建对象，Kubernetes 系统将持续工作以确保对象存在。通过创建对象，可以有效地告知 Kubernetes 系统，所需要的集群工作负载看起来是什么样子的，这就是 Kubernetes 集群的 期望状态。\n与 Kubernetes 对象工作 —— 是否创建、修改，或者删除 —— 需要使用 Kubernetes API。当使用 kubectl 命令行接口时，比如，CLI 会使用必要的 Kubernetes API 调用，也可以在程序中直接使用 Kubernetes API。为了实现该目标，Kubernetes 当前提供了一个 golang 客户端库 ，其它语言库（例如Python）也正在开发中。\n对象 Spec 与状态 link每个 Kubernetes 对象包含两个嵌套的对象字段，它们负责管理对象的配置：对象 spec 和 对象 status。spec 必须提供，它描述了对象的 期望状态—— 希望对象所具有的特征。status 描述了对象的 实际状态，它是由 Kubernetes 系统提供和更新。在任何时刻，Kubernetes 控制平面一直处于活跃状态，管理着对象的实际状态以与我们所期望的状态相匹配。\n例如，Kubernetes Deployment 对象能够表示运行在集群中的应用。当创建 Deployment 时，可能需要设置 Deployment 的 spec，以指定该应用需要有 3 个副本在运行。Kubernetes 系统读取 Deployment spec，启动我们所期望的该应用的 3 个实例 —— 更新状态以与 spec 相匹配。如果那些实例中有失败的（一种状态变更），Kubernetes 系统通过修正来响应 spec 和状态之间的不一致 —— 这种情况，启动一个新的实例来替换。\n关于对象 spec、status 和 metadata 更多信息，查看 Kubernetes API Conventions。\n描述 Kubernetes 对象 link当创建 Kubernetes 对象时，必须提供对象的 spec，用来描述该对象的期望状态，以及关于对象的一些基本信息（例如，名称）。当使用 Kubernetes API 创建对象时（或者直接创建，或者基于kubectl），API 请求必须在请求体中包含 JSON 格式的信息。更常用的是，需要在 .yaml 文件中为 kubectl 提供这些信息。 kubectl 在执行 API 请求时，将这些信息转换成 JSON 格式。\n这里有一个 .yaml 示例文件，展示了 Kubernetes Deployment 的必需字段和对象 spec：\napiVersion: apps/v1beta1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 3 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 一种创建 Deployment 的方式，类似上面使用 .yaml 文件，是使用 kubectl 命令行接口（CLI）中的 kubectl create 命令，传递 .yaml 作为参数。下面是一个示例：\n$ kubectl create -f docs/user-guide/nginx-deployment.yaml --record 输出类似如下这样：\ndeployment \"nginx-deployment\" created 必需字段 link在想要创建的 Kubernetes 对象对应的 .yaml 文件中，需要配置如下的字段：\napiVersion - 创建该对象所使用的 Kubernetes API 的版本 kind - 想要创建的对象的类型 metadata - 帮助识别对象唯一性的数据，包括一个 name 字符串、UID 和可选的 namespace 也需要提供对象的 spec 字段。对象 spec 的精确格式对每个 Kubernetes 对象来说是不同的，包含了特定于该对象的嵌套字段。Kubernetes API 参考能够帮助我们找到任何我们想创建的对象的 spec 格式。\n"
            }
        );
    index.add(
            {
                id:  11 ,
                href: "\/docs\/information\/software\/",
                title: "软件",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  12 ,
                href: "\/docs\/develop\/analysis\/",
                title: "问题分析：5W2H",
                description: "一、方法概述 link5W2H分析法是一种经典的问题分析与解决工具，通过7个维度（What、Why、Who、When、Where、How、How Much）对问题进行系统性拆解，帮助用户全面理解问题本质，制定有效行动方案。该方法最早由美国陆军在二战期间提出，后经管理学界优化推广，现被广泛应用于商业决策、项目管理、问题诊断等多个领域。\n二、核心要素解析 link What（何事）\n明确问题本质：“究竟发生了什么？需要解决的核心是什么？”\n例：某电商平台用户流失率上升至20%（明确现象）\nWhy（何因）\n追溯根源：“导致问题的根本原因是什么？”\n例：因物流时效延长导致用户满意度下降（因果关系分析）\nWho（何人）\n界定责任主体：“问题涉及哪些人？谁负责解决？”\n例：物流部门需牵头改进，客服团队配合处理投诉\nWhen（何时）\n时间维度管理：“问题何时发生？解决期限为何时？”\n例：物流延迟自3月起持续发生，需在2周内改善\nWhere（何地）\n空间定位：“问题发生的具体场景或区域？”\n例：华东地区仓储中心配送延误最严重\nHow（如何）\n解决方案设计：“通过什么方法解决问题？”\n例：优化仓储布局+引入智能调度系统\nHow Much（何量）\n量化评估：“需要多少资源投入？预期效果如何量化？”\n例：投入50万元系统升级，目标3周内时效提升30%\n三、应用价值 link 系统化思维：避免碎片化认知，7维度覆盖问题全貌 精准定位：通过分层追问直达问题核心（如丰田\"5个为什么\"的延伸） 执行导向：自然导出可落地的行动计划 沟通工具：结构化框架提升团队协作效率 四、实施步骤示范（以产品推广为例） link What：新产品市场渗透率未达预期 Why：目标用户认知度不足，竞品抢占先机 Who：市场部主导，销售部协同执行 When：Q2启动推广，8月底前完成首阶段 Where：重点突破一线城市KA渠道 How：KOL营销+体验店快闪活动 How Much：预算120万，目标触达50万潜在用户 五、使用建议 link 组合应用：可结合SWOT、鱼骨图等工具深化分析 动态调整：根据实施反馈循环优化各维度策略 避免误区：需区分客观事实与主观推测，确保数据支撑 效率优化：使用思维导图工具进行可视化呈现 结语 link5W2H作为结构化思维的经典框架，其价值在于将混沌的问题转化为可操作的行动蓝图。掌握这一方法，既能提升个人问题分析能力，也可作为团队建立系统性工作语言的通用工具。建议在初期使用时严格遵循7要素模板，熟练后可灵活调整维度组合，实现工具与场景的最佳适配。\n",
                content: "一、方法概述 link5W2H分析法是一种经典的问题分析与解决工具，通过7个维度（What、Why、Who、When、Where、How、How Much）对问题进行系统性拆解，帮助用户全面理解问题本质，制定有效行动方案。该方法最早由美国陆军在二战期间提出，后经管理学界优化推广，现被广泛应用于商业决策、项目管理、问题诊断等多个领域。\n二、核心要素解析 link What（何事）\n明确问题本质：“究竟发生了什么？需要解决的核心是什么？”\n例：某电商平台用户流失率上升至20%（明确现象）\nWhy（何因）\n追溯根源：“导致问题的根本原因是什么？”\n例：因物流时效延长导致用户满意度下降（因果关系分析）\nWho（何人）\n界定责任主体：“问题涉及哪些人？谁负责解决？”\n例：物流部门需牵头改进，客服团队配合处理投诉\nWhen（何时）\n时间维度管理：“问题何时发生？解决期限为何时？”\n例：物流延迟自3月起持续发生，需在2周内改善\nWhere（何地）\n空间定位：“问题发生的具体场景或区域？”\n例：华东地区仓储中心配送延误最严重\nHow（如何）\n解决方案设计：“通过什么方法解决问题？”\n例：优化仓储布局+引入智能调度系统\nHow Much（何量）\n量化评估：“需要多少资源投入？预期效果如何量化？”\n例：投入50万元系统升级，目标3周内时效提升30%\n三、应用价值 link 系统化思维：避免碎片化认知，7维度覆盖问题全貌 精准定位：通过分层追问直达问题核心（如丰田\"5个为什么\"的延伸） 执行导向：自然导出可落地的行动计划 沟通工具：结构化框架提升团队协作效率 四、实施步骤示范（以产品推广为例） link What：新产品市场渗透率未达预期 Why：目标用户认知度不足，竞品抢占先机 Who：市场部主导，销售部协同执行 When：Q2启动推广，8月底前完成首阶段 Where：重点突破一线城市KA渠道 How：KOL营销+体验店快闪活动 How Much：预算120万，目标触达50万潜在用户 五、使用建议 link 组合应用：可结合SWOT、鱼骨图等工具深化分析 动态调整：根据实施反馈循环优化各维度策略 避免误区：需区分客观事实与主观推测，确保数据支撑 效率优化：使用思维导图工具进行可视化呈现 结语 link5W2H作为结构化思维的经典框架，其价值在于将混沌的问题转化为可操作的行动蓝图。掌握这一方法，既能提升个人问题分析能力，也可作为团队建立系统性工作语言的通用工具。建议在初期使用时严格遵循7要素模板，熟练后可灵活调整维度组合，实现工具与场景的最佳适配。\n"
            }
        );
    index.add(
            {
                id:  13 ,
                href: "\/docs\/information\/software\/cloud\/storage\/configmap\/",
                title: "ConfigMap",
                description: "其实 ConfigMap 功能在 Kubernetes1.2 版本的时候就有了，许多应用程序会从配置文件、命令行参数或环境变量中读取配置信息。这些配置信息需要与 docker image 解耦，你总不能每修改一个配置就重做一个 image 吧？ConfigMap API 给我们提供了向容器中注入配置信息的机制，ConfigMap 可以被用来保存单个属性，也可以用来保存整个配置文件或者 JSON 二进制大对象。\nConfigMap 概览 linkConfigMap API 资源用来保存 key-value pair 配置数据，这个数据可以在 pods 里使用，或者被用来为像 controller 一样的系统组件存储配置数据。虽然 ConfigMap 跟 Secrets 类似，但是 ConfigMap 更方便的处理不含敏感信息的字符串。 注意：ConfigMaps 不是属性配置文件的替代品。ConfigMaps 只是作为多个 properties 文件的引用。你可以把它理解为 Linux 系统中的 /etc 目录，专门用来存储配置文件的目录。下面举个例子，使用 ConfigMap 配置来创建 Kubernetes Volumes，ConfigMap 中的每个 data 项都会成为一个新文件。\n",
                content: "其实 ConfigMap 功能在 Kubernetes1.2 版本的时候就有了，许多应用程序会从配置文件、命令行参数或环境变量中读取配置信息。这些配置信息需要与 docker image 解耦，你总不能每修改一个配置就重做一个 image 吧？ConfigMap API 给我们提供了向容器中注入配置信息的机制，ConfigMap 可以被用来保存单个属性，也可以用来保存整个配置文件或者 JSON 二进制大对象。\nConfigMap 概览 linkConfigMap API 资源用来保存 key-value pair 配置数据，这个数据可以在 pods 里使用，或者被用来为像 controller 一样的系统组件存储配置数据。虽然 ConfigMap 跟 Secrets 类似，但是 ConfigMap 更方便的处理不含敏感信息的字符串。 注意：ConfigMaps 不是属性配置文件的替代品。ConfigMaps 只是作为多个 properties 文件的引用。你可以把它理解为 Linux 系统中的 /etc 目录，专门用来存储配置文件的目录。下面举个例子，使用 ConfigMap 配置来创建 Kubernetes Volumes，ConfigMap 中的每个 data 项都会成为一个新文件。\nkind: ConfigMap apiVersion: v1 metadata: creationTimestamp: 2016-02-18T19:14:38Z name: example-config namespace: default data: example.property.1: hello example.property.2: world example.property.file: |- property.1=value-1 property.2=value-2 property.3=value-3 data 一栏包括了配置数据，ConfigMap 可以被用来保存单个属性，也可以用来保存一个配置文件。 配置数据可以通过很多种方式在 Pods 里被使用。ConfigMaps 可以被用来：\n设置环境变量的值 在容器里设置命令行参数 在数据卷里面创建 config 文件 用户和系统组件两者都可以在 ConfigMap 里面存储配置数据。\n其实不用看下面的文章，直接从 kubectl create configmap -h 的帮助信息中就可以对 ConfigMap 究竟如何创建略知一二了。\nExamples: # Create a new configmap named my-config based on folder bar kubectl create configmap my-config --from-file=path/to/bar # Create a new configmap named my-config with specified keys instead of file basenames on disk kubectl create configmap my-config --from-file=key1=/path/to/bar/file1.txt --from-file=key2=/path/to/bar/file2.txt # Create a new configmap named my-config with key1=config1 and key2=config2 kubectl create configmap my-config --from-literal=key1=config1 --from-literal=key2=config2 创建 ConfigMaps link可以使用该命令，用给定值、文件或目录来创建 ConfigMap。\nkubectl create configmap 使用目录创建 link比如我们已经有了一些配置文件，其中包含了我们想要设置的 ConfigMap 的值：\n$ ls docs/user-guide/configmap/kubectl/ game.properties ui.properties $ cat docs/user-guide/configmap/kubectl/game.properties enemies=aliens lives=3 enemies.cheat=true enemies.cheat.level=noGoodRotten secret.code.passphrase=UUDDLRLRBABAS secret.code.allowed=true secret.code.lives=30 $ cat docs/user-guide/configmap/kubectl/ui.properties color.good=purple color.bad=yellow allow.textmode=true how.nice.to.look=fairlyNice 使用下面的命令可以创建一个包含目录中所有文件的 ConfigMap。\n$ kubectl create configmap game-config --from-file=docs/user-guide/configmap/kubectl —from-file 指定在目录下的所有文件都会被用在 ConfigMap 里面创建一个键值对，键的名字就是文件名，值就是文件的内容。\n让我们来看一下这个命令创建的 ConfigMap：\n$ kubectl describe configmaps game-config Name: game-config Namespace: default Labels: Annotations: Data ==== game.properties: 158 bytes ui.properties: 83 bytes 我们可以看到那两个 key 是从 kubectl 指定的目录中的文件名。这些 key 的内容可能会很大，所以在 kubectl describe 的输出中，只能够看到键的名字和他们的大小。 如果想要看到键的值的话，可以使用 kubectl get：\n$ kubectl get configmaps game-config -o yaml 我们以 yaml 格式输出配置。\napiVersion: v1 data: game.properties: | enemies=aliens lives=3 enemies.cheat=true enemies.cheat.level=noGoodRotten secret.code.passphrase=UUDDLRLRBABAS secret.code.allowed=true secret.code.lives=30 ui.properties: | color.good=purple color.bad=yellow allow.textmode=true how.nice.to.look=fairlyNice kind: ConfigMap metadata: creationTimestamp: 2016-02-18T18:34:05Z name: game-config namespace: default resourceVersion: \"407\" selfLink: /api/v1/namespaces/default/configmaps/game-config uid: 30944725-d66e-11e5-8cd0-68f728db1985 使用文件创建 link刚才使用目录创建的时候我们 —from-file 指定的是一个目录，只要指定为一个文件就可以从单个文件中创建 ConfigMap。\n$ kubectl create configmap game-config-2 --from-file=docs/user-guide/configmap/kubectl/game.properties $ kubectl get configmaps game-config-2 -o yaml apiVersion: v1 data: game-special-key: | enemies=aliens lives=3 enemies.cheat=true enemies.cheat.level=noGoodRotten secret.code.passphrase=UUDDLRLRBABAS secret.code.allowed=true secret.code.lives=30 kind: ConfigMap metadata: creationTimestamp: 2016-02-18T18:54:22Z name: game-config-3 namespace: default resourceVersion: \"530\" selfLink: /api/v1/namespaces/default/configmaps/game-config-3 uid: 05f8da22-d671-11e5-8cd0-68f728db1985 —from-file 这个参数可以使用多次，你可以使用两次分别指定上个实例中的那两个配置文件，效果就跟指定整个目录是一样的。\n使用字面值创建 link使用文字值创建，利用 —from-literal 参数传递配置信息，该参数可以使用多次，格式如下；\n$ kubectl create configmap special-config --from-literal=special.how=very --from-literal=special.type=charm $ kubectl get configmaps special-config -o yaml apiVersion: v1 data: special.how: very special.type: charm kind: ConfigMap metadata: creationTimestamp: 2016-02-18T19:14:38Z name: special-config namespace: default resourceVersion: \"651\" selfLink: /api/v1/namespaces/default/configmaps/special-config uid: dadce046-d673-11e5-8cd0-68f728db1985 Pod 中使用 ConfigMap link使用 ConfigMap 来替代环境变量\nConfigMap 可以被用来填入环境变量。看下下面的 ConfigMap。\napiVersion: v1 kind: ConfigMap metadata: name: special-config namespace: default data: special.how: very special.type: charm apiVersion: v1 kind: ConfigMap metadata: name: env-config namespace: default data: log_level: INFO 我们可以在 Pod 中这样使用 ConfigMap：\napiVersion: v1 kind: Pod metadata: name: dapi-test-pod spec: containers: - name: test-container image: gcr.io/google_containers/busybox command: [ \"/bin/sh\", \"-c\", \"env\" ] env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type envFrom: - configMapRef: name: env-config restartPolicy: Never 这个 Pod 运行后会输出如下几行：\nSPECIAL_LEVEL_KEY=very SPECIAL_TYPE_KEY=charm log_level=INFO 用 ConfigMap 设置命令行参数\nConfigMap 也可以被使用来设置容器中的命令或者参数值。它使用的是 Kubernetes 的 $(VAR_NAME) 替换语法。我们看下下面这个 ConfigMap。\napiVersion: v1 kind: ConfigMap metadata: name: special-config namespace: default data: special.how: very special.type: charm 为了将 ConfigMap 中的值注入到命令行的参数里面，我们还要像前面那个例子一样使用环境变量替换语法 ${VAR_NAME)。（其实这个东西就是给 Docker 容器设置环境变量，以前我创建镜像的时候经常这么玩，通过 docker run 的时候指定 - e 参数修改镜像里的环境变量，然后 docker 的 CMD 命令再利用该 $(VAR_NAME) 通过 sed 来修改配置文件或者作为命令行启动参数。）\napiVersion: v1 kind: Pod metadata: name: dapi-test-pod spec: containers: - name: test-container image: gcr.io/google_containers/busybox command: [ \"/bin/sh\", \"-c\", \"echo $(SPECIAL_LEVEL_KEY) $(SPECIAL_TYPE_KEY)\" ] env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type restartPolicy: Never 运行这个 Pod 后会输出：\nvery charm 通过数据卷插件使用 ConfigMap\nConfigMap 也可以在数据卷里面被使用。还是这个 ConfigMap。\napiVersion: v1 kind: ConfigMap metadata: name: special-config namespace: default data: special.how: very special.type: charm 在数据卷里面使用这个 ConfigMap，有不同的选项。最基本的就是将文件填入数据卷，在这个文件中，键就是文件名，键值就是文件内容：\napiVersion: v1 kind: Pod metadata: name: dapi-test-pod spec: containers: - name: test-container image: gcr.io/google_containers/busybox command: [ \"/bin/sh\", \"-c\", \"cat /etc/config/special.how\" ] volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: special-config restartPolicy: Never 运行这个 Pod 的输出是 very。\n我们也可以在 ConfigMap 值被映射的数据卷里控制路径。\napiVersion: v1 kind: Pod metadata: name: dapi-test-pod spec: containers: - name: test-container image: gcr.io/google_containers/busybox command: [ \"/bin/sh\",\"-c\",\"cat /etc/config/path/to/special-key\" ] volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: special-config items: - key: special.how path: path/to/special-key restartPolicy: Never 运行这个 Pod 后的结果是 very。\n热更新 linkConfigMap是用来存储配置文件的kubernetes资源对象，所有的配置内容都存储在etcd中，下文主要是探究 ConfigMap 的创建和更新流程，以及对 ConfigMap 更新后容器内挂载的内容是否同步更新的测试。\n测试示例 link假设我们在 default namespace 下有一个名为 nginx-config 的 ConfigMap，可以使用 kubectl命令来获取：\n$ kubectl get configmap nginx-config NAME DATA AGE nginx-config 1 99d 获取该ConfigMap的内容。\nkubectl get configmap nginx-config -o yaml apiVersion: v1 data: nginx.conf: |- worker_processes 1; events { worker_connections 1024; } http { sendfile on; server { listen 80; # a test endpoint that returns http 200s location / { proxy_pass http://httpstat.us/200; proxy_set_header X-Real-IP $remote_addr; } } server { listen 80; server_name api.hello.world; location / { proxy_pass http://l5d.default.svc.cluster.local; proxy_set_header Host $host; proxy_set_header Connection \"\"; proxy_http_version 1.1; more_clear_input_headers 'l5d-ctx-*' 'l5d-dtab' 'l5d-sample'; } } server { listen 80; server_name www.hello.world; location / { # allow 'employees' to perform dtab overrides if ($cookie_special_employee_cookie != \"letmein\") { more_clear_input_headers 'l5d-ctx-*' 'l5d-dtab' 'l5d-sample'; } # add a dtab override to get people to our beta, world-v2 set $xheader \"\"; if ($cookie_special_employee_cookie ~* \"dogfood\") { set $xheader \"/host/world =\u003e /srv/world-v2;\"; } proxy_set_header 'l5d-dtab' $xheader; proxy_pass http://l5d.default.svc.cluster.local; proxy_set_header Host $host; proxy_set_header Connection \"\"; proxy_http_version 1.1; } } } kind: ConfigMap metadata: creationTimestamp: 2017-08-01T06:53:17Z name: nginx-config namespace: default resourceVersion: \"14925806\" selfLink: /api/v1/namespaces/default/configmaps/nginx-config uid: 18d70527-7686-11e7-bfbd-8af1e3a7c5bd ConfigMap中的内容是存储到etcd中的，然后查询etcd：\nETCDCTL_API=3 etcdctl get /registry/configmaps/default/nginx-config -w json|python -m json.tool 注意使用 v3 版本的 etcdctl API，下面是输出结果：\n{ \"count\": 1, \"header\": { \"cluster_id\": 12091028579527406772, \"member_id\": 16557816780141026208, \"raft_term\": 36, \"revision\": 29258723 }, \"kvs\": [ { \"create_revision\": 14925806, \"key\": \"L3JlZ2lzdHJ5L2NvbmZpZ21hcHMvZGVmYXVsdC9uZ2lueC1jb25maWc=\", \"mod_revision\": 14925806, \"value\": \"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\", \"version\": 1 } ] } 其中的value就是 nginx.conf 配置文件的内容。\n可以使用base64解码查看具体值，关于etcdctl的使用请参考使用etcdctl访问kuberentes数据。\n代码 linkConfigMap 结构体的定义：\n// ConfigMap holds configuration data for pods to consume. type ConfigMap struct { metav1.TypeMeta `json:\",inline\"` // Standard object's metadata. // More info: http://releases.k8s.io/HEAD/docs/devel/api-conventions.md#metadata // +optional metav1.ObjectMeta `json:\"metadata,omitempty\" protobuf:\"bytes,1,opt,name=metadata\"` // Data contains the configuration data. // Each key must be a valid DNS_SUBDOMAIN with an optional leading dot. // +optional Data map[string]string `json:\"data,omitempty\" protobuf:\"bytes,2,rep,name=data\"` } 在 staging/src/k8s.io/client-go/kubernetes/typed/core/v1/configmap.go 中ConfigMap 的接口定义：\n// ConfigMapInterface has methods to work with ConfigMap resources. type ConfigMapInterface interface { Create(*v1.ConfigMap) (*v1.ConfigMap, error) Update(*v1.ConfigMap) (*v1.ConfigMap, error) Delete(name string, options *meta_v1.DeleteOptions) error DeleteCollection(options *meta_v1.DeleteOptions, listOptions meta_v1.ListOptions) error Get(name string, options meta_v1.GetOptions) (*v1.ConfigMap, error) List(opts meta_v1.ListOptions) (*v1.ConfigMapList, error) Watch(opts meta_v1.ListOptions) (watch.Interface, error) Patch(name string, pt types.PatchType, data []byte, subresources ...string) (result *v1.ConfigMap, err error) ConfigMapExpansion } 在 staging/src/k8s.io/client-go/kubernetes/typed/core/v1/configmap.go 中创建 ConfigMap 的方法如下:\n// Create takes the representation of a configMap and creates it. Returns the server's representation of the configMap, and an error, if there is any. func (c *configMaps) Create(configMap *v1.ConfigMap) (result *v1.ConfigMap, err error) { result = \u0026v1.ConfigMap{} err = c.client.Post(). Namespace(c.ns). Resource(\"configmaps\"). Body(configMap). Do(). Into(result) return } 通过 RESTful 请求在 etcd 中存储 ConfigMap 的配置，该方法中设置了资源对象的 namespace 和 HTTP 请求中的 body，执行后将请求结果保存到 result 中返回给调用者。\n注意 Body 的结构\n// Body makes the request use obj as the body. Optional. // If obj is a string, try to read a file of that name. // If obj is a []byte, send it directly. // If obj is an io.Reader, use it directly. // If obj is a runtime.Object, marshal it correctly, and set Content-Type header. // If obj is a runtime.Object and nil, do nothing. // Otherwise, set an error. 创建 ConfigMap RESTful 请求中的的 Body 中包含 ObjectMeta 和 namespace。\nHTTP 请求中的结构体：\n// Request allows for building up a request to a server in a chained fashion. // Any errors are stored until the end of your call, so you only have to // check once. type Request struct { // required client HTTPClient verb string baseURL *url.URL content ContentConfig serializers Serializers // generic components accessible via method setters pathPrefix string subpath string params url.Values headers http.Header // structural elements of the request that are part of the Kubernetes API conventions namespace string namespaceSet bool resource string resourceName string subresource string timeout time.Duration // output err error body io.Reader // This is only used for per-request timeouts, deadlines, and cancellations. ctx context.Context backoffMgr BackoffManager throttle flowcontrol.RateLimiter } 测试 link分别测试使用 ConfigMap 挂载 Env 和 Volume 的情况。\n更新使用ConfigMap挂载的Env link使用下面的配置创建 nginx 容器测试更新 ConfigMap 后容器内的环境变量是否也跟着更新。\napiVersion: extensions/v1beta1 kind: Deployment metadata: name: my-nginx spec: replicas: 1 template: metadata: labels: run: my-nginx spec: containers: - name: my-nginx image: harbor-001.jimmysong.io/library/nginx:1.9 ports: - containerPort: 80 envFrom: - configMapRef: name: env-config --- apiVersion: v1 kind: ConfigMap metadata: name: env-config namespace: default data: log_level: INFO 获取环境变量的值\n$ kubectl exec `kubectl get pods -l run=my-nginx -o=name|cut -d \"/\" -f2` env|grep log_level log_level=INFO 修改 ConfigMap\n$ kubectl edit configmap env-config 修改 log_level 的值为 DEBUG。\n再次查看环境变量的值。\n$ kubectl exec `kubectl get pods -l run=my-nginx -o=name|cut -d \"/\" -f2` env|grep log_level log_level=INFO 实践证明修改 ConfigMap 无法更新容器中已注入的环境变量信息。\n更新使用ConfigMap挂载的Volume link使用下面的配置创建 nginx 容器测试更新 ConfigMap 后容器内挂载的文件是否也跟着更新。\napiVersion: extensions/v1beta1 kind: Deployment metadata: name: my-nginx spec: replicas: 1 template: metadata: labels: run: my-nginx spec: containers: - name: my-nginx image: harbor-001.jimmysong.io/library/nginx:1.9 ports: - containerPort: 80 volumeMounts: - name: config-volume mountPath: /etc/config volumes: - name: config-volume configMap: name: special-config --- apiVersion: v1 kind: ConfigMap metadata: name: special-config namespace: default data: log_level: INFO $ kubectl exec `kubectl get pods -l run=my-nginx -o=name|cut -d \"/\" -f2` cat /etc/config/log_level INFO 修改 ConfigMap\n$ kubectl edit configmap special-config 修改 log_level 的值为 DEBUG。\n等待大概10秒钟时间，再次查看环境变量的值。\n$ kubectl exec `kubectl get pods -l run=my-nginx -o=name|cut -d \"/\" -f2` cat /etc/config/log_level DEBUG 我们可以看到使用 ConfigMap 方式挂载的 Volume 的文件中的内容已经变成了 DEBUG。\nKnown Issue： 如果使用ConfigMap的subPath挂载为Container的Volume，Kubernetes不会做自动热更新: https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#mounted-configmaps-are-updated-automatically\nConfigMap 更新后滚动更新 Pod link更新 ConfigMap 目前并不会触发相关 Pod 的滚动更新，可以通过修改 pod annotations 的方式强制触发滚动更新。\n$ kubectl patch deployment my-nginx --patch '{\"spec\": {\"template\": {\"metadata\": {\"annotations\": {\"version/config\": \"20180411\" }}}}}' 这个例子里我们在 .spec.template.metadata.annotations 中添加 version/config，每次通过修改 version/config 来触发滚动更新。\n总结 link更新 ConfigMap 后：\n使用该 ConfigMap 挂载的 Env 不会同步更新 使用该 ConfigMap 挂载的 Volume 中的数据需要一段时间（实测大概10秒）才能同步更新 ENV 是在容器启动的时候注入的，启动之后 kubernetes 就不会再改变环境变量的值，且同一个 namespace 中的 pod 的环境变量是不断累加的，参考 Kubernetes中的服务发现与docker容器间的环境变量传递源码探究。为了更新容器中使用 ConfigMap 挂载的配置，需要通过滚动更新 pod 的方式来强制重新挂载 ConfigMap。\n参考 link Kubernetes 1.7 security in practice ConfigMap | kubernetes handbook - jimmysong.io 创建高可用ectd集群 | Kubernetes handbook - jimmysong.io Kubernetes中的服务发现与docker容器间的环境变量传递源码探究 "
            }
        );
    index.add(
            {
                id:  14 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/",
                title: "K8s集群控制",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  15 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/pod\/",
                title: "Pod",
                description: "概念 linkPod 是 Kubernetes 中最小的可部署单元，代表集群中运行的一个应用实例，由一个或多个紧密关联的容器组成。这些容器共享网络命名空间（同一 IP 和端口）、存储卷及其他资源，支持协同工作模式（如主容器与 sidecar 辅助容器配合）。通常情况下，每个 Pod 封装单个容器，但在需要耦合协作的场景（如日志收集、配置同步）中可包含多个容器。Pod 不直接管理，而是通过控制器（如 Deployment）进行复制扩展（运行多个相同 Pod 实现水平扩容），且支持 Docker 在内的多种容器运行时。\nPod 支持在同一节点上运行多个容器，这些容器共享网络命名空间（同一IP和端口）及存储卷，形成紧密协作的进程组。典型用例是主容器（如Web服务）与Sidecar容器（如日志收集、配置更新）协同工作：\n网络共享：容器通过 localhost 直接通信，对外暴露统一IP。 存储共享：多个容器可读写同一持久化Volume，避免数据丢失。 调度特性：容器始终被共同调度到同一节点，确保低延迟协作。 ⚠️ 适用场景：仅当容器需强耦合（如实时文件同步、依赖本地通信）时使用多容器Pod，否则优先采用单容器Pod+独立服务设计，以降低复杂度。\n在 Kubernetes 中，Pod 作为短暂且易失的实体，通常不直接单独创建，因其缺乏自愈能力且生命周期受节点故障、资源不足或进程终止等影响而无法持久。为确保高可用性和弹性，用户通过更高级的 Controller（如 Deployment、StatefulSet、DaemonSet）管理 Pod。Controller 基于 Pod 模板动态创建并维护 Pod 集群，提供副本控制、滚动升级及自愈能力，例如在节点故障时自动将 Pod 重新调度至健康节点，从而抽象化底层运维复杂度，保障应用持续稳定运行。\n动机 link 管理： Pod 是一个服务的多个进程的聚合单位，pod 提供这种模型能够简化应用部署管理，通过提供一个更高级别的抽象的方式。Pod 作为一个独立的部署单位，支持横向扩展和复制。共生（协同调度），命运共同体（例如被终结），协同复制，资源共享，依赖管理，pod 都会自动的为容器处理这些问题。 资源共享和通信： Pod 中的应用可以共享网络空间（IP 地址和端口），因此可以通过 localhost 互相发现。Pod 中的应用容器可以共享卷。持久化卷能够保证 pod 重启时使用的数据不丢失。 持久性 linkPod 在设计支持就不是作为持久化实体的。在调度失败、节点故障、缺少资源或者节点维护的状态下都会死掉会被驱逐。\n通常，用户不需要手动直接创建 Pod，而是应该使用 controller（例如 Deployments），即使是在创建单个 Pod 的情况下。Controller 可以提供集群级别的自愈功能、复制和升级管理。\n",
                content: "概念 linkPod 是 Kubernetes 中最小的可部署单元，代表集群中运行的一个应用实例，由一个或多个紧密关联的容器组成。这些容器共享网络命名空间（同一 IP 和端口）、存储卷及其他资源，支持协同工作模式（如主容器与 sidecar 辅助容器配合）。通常情况下，每个 Pod 封装单个容器，但在需要耦合协作的场景（如日志收集、配置同步）中可包含多个容器。Pod 不直接管理，而是通过控制器（如 Deployment）进行复制扩展（运行多个相同 Pod 实现水平扩容），且支持 Docker 在内的多种容器运行时。\nPod 支持在同一节点上运行多个容器，这些容器共享网络命名空间（同一IP和端口）及存储卷，形成紧密协作的进程组。典型用例是主容器（如Web服务）与Sidecar容器（如日志收集、配置更新）协同工作：\n网络共享：容器通过 localhost 直接通信，对外暴露统一IP。 存储共享：多个容器可读写同一持久化Volume，避免数据丢失。 调度特性：容器始终被共同调度到同一节点，确保低延迟协作。 ⚠️ 适用场景：仅当容器需强耦合（如实时文件同步、依赖本地通信）时使用多容器Pod，否则优先采用单容器Pod+独立服务设计，以降低复杂度。\n在 Kubernetes 中，Pod 作为短暂且易失的实体，通常不直接单独创建，因其缺乏自愈能力且生命周期受节点故障、资源不足或进程终止等影响而无法持久。为确保高可用性和弹性，用户通过更高级的 Controller（如 Deployment、StatefulSet、DaemonSet）管理 Pod。Controller 基于 Pod 模板动态创建并维护 Pod 集群，提供副本控制、滚动升级及自愈能力，例如在节点故障时自动将 Pod 重新调度至健康节点，从而抽象化底层运维复杂度，保障应用持续稳定运行。\n动机 link 管理： Pod 是一个服务的多个进程的聚合单位，pod 提供这种模型能够简化应用部署管理，通过提供一个更高级别的抽象的方式。Pod 作为一个独立的部署单位，支持横向扩展和复制。共生（协同调度），命运共同体（例如被终结），协同复制，资源共享，依赖管理，pod 都会自动的为容器处理这些问题。 资源共享和通信： Pod 中的应用可以共享网络空间（IP 地址和端口），因此可以通过 localhost 互相发现。Pod 中的应用容器可以共享卷。持久化卷能够保证 pod 重启时使用的数据不丢失。 持久性 linkPod 在设计支持就不是作为持久化实体的。在调度失败、节点故障、缺少资源或者节点维护的状态下都会死掉会被驱逐。\n通常，用户不需要手动直接创建 Pod，而是应该使用 controller（例如 Deployments），即使是在创建单个 Pod 的情况下。Controller 可以提供集群级别的自愈功能、复制和升级管理。\n终止 link用户需要能够发起一个删除 Pod 的请求，并且知道它们何时会被终止，是否被正确的删除。用户想终止程序时发送删除 pod 的请求，在 pod 可以被强制删除前会有一个宽限期，会发送一个 TERM 请求到每个容器的主进程。一旦超时，将向主进程发送 KILL 信号并从 API server 中删除。如果 kubelet 或者 container manager 在等待进程终止的过程中重启，在重启后仍然会重试完整的宽限期。\n删除宽限期默认是 30 秒。 kubectl delete 命令支持 —grace-period= 选项，允许用户设置自己的宽限期。如果设置为 0 将强制删除 pod。在 kubectl\u003e=1.5 版本的命令中，你必须同时使用 –force 和 –grace-period=0 来强制删除 pod。在 yaml 文件中可以通过 {{ .spec.spec.terminationGracePeriodSeconds }} 来修改此值。\n强制删除\nPod 的强制删除是通过在集群和 etcd 中将其定义为删除状态。当执行强制删除命令时，API server 不会等待该 pod 所运行在节点上的 kubelet 确认，就会立即将该 pod 从 API server 中移除，这时就可以创建跟原 pod 同名的 pod 了。这时，在节点上的 pod 会被立即设置为 terminating 状态，不过在被强制删除之前依然有一小段优雅删除周期。强制删除对于某些 pod 具有潜在危险性，请谨慎使用。\n特权模式 link从 Kubernetes1.1 版本开始，pod 中的容器就可以开启 privileged 模式，在容器定义文件的 SecurityContext 下使用 privileged flag。这在使用 Linux 的网络操作和访问设备的能力时是很有用的。容器内进程可获得近乎等同于容器外进程的权限。在不需要修改和重新编译 kubelet 的情况下就可以使用 pod 来开发节点的网络和存储插件。\nQA link为什么不直接在一个容器中运行多个应用程序呢？\n透明。让 pod 中的容器对基础设施可见，以便基础设施能够为这些容器提供服务，例如进程管理和资源监控。这可以为用户带来极大的便利。 解耦软件依赖。每个容器都可以进行版本管理，独立的编译和发布。未来 kubernetes 甚至可能支持单个容器的在线升级。 使用方便。用户不必运行自己的进程管理器，还要担心错误信号传播等。 效率。因为由基础架构提供更多的职责，所以容器可以变得更加轻量级。 为什么不支持容器的亲和性的协同调度？\n这种方法可以提供容器的协同定位，能够根据容器的亲和性进行调度，但是无法实现使用 pod 带来的大部分好处，例如资源共享，IPC，保持状态一致性和简化管理等。\nInit容器 link作为专用预处理容器，Init 容器在应用容器启动前顺序执行，常用于部署环境准备、依赖安装等场景，其设计特点包括：必须逐级成功运行（前一个完成后才会启动下一个）、失败时依据 Pod 的 restartPolicy 自动重试（Never 策略除外），且不支持就绪探针。尽管继承普通容器的资源限制、存储卷等特性，Init 容器对资源配额的处理逻辑存在差异，并在 Pod 状态中通过独立的 status.initContainerStatuses 字段追踪执行进度。当所有 Init 容器完成初始化后，Kubernetes 才会启动应用容器进入服务就绪状态。\nInit 容器是 Kubernetes 中用于执行预初始化任务的专用容器，其核心作用在于为应用容器提供独立、安全的初始化环境。由于 Init 容器与应用容器使用分离的镜像，它们能够在不污染应用镜像的前提下，运行安装脚本、安全工具（如 sed、dig）或定制化代码，实现环境预配置、依赖检查（如等待服务就绪、延迟启动）及资源初始化（如克隆代码仓库、动态生成配置文件）。通过 Linux Namespace 的文件系统隔离，Init 容器还可安全访问敏感信息（如 Secret），而应用容器无法直接获取。此外，Init 容器严格按顺序执行且必须全部成功，天然具备阻塞机制，确保应用容器仅在所需条件（如网络依赖、资源配置）就绪后启动，从而提升应用部署的可靠性和安全性，同时实现构建与部署的角色解耦。\napiVersion: v1 kind: Pod metadata: name: myapp-pod namespace: default labels: app: myapp spec: containers: - name: myapp-container image: busybox command: ['sh', '-c', 'echo The app is running! \u0026\u0026 sleep 3600'] initContainers: - name: init-myservice image: busybox command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2; done;'] - name: init-mydb image: busybox command: ['sh', '-c', 'until nslookup mydb; do echo waiting for mydb; sleep 2; done;'] 安全策略(PodSecurityPolicy v1.21+弃用) linkPod 安全策略 是集群级别的资源，它能够控制 Pod 运行的行为，以及它具有访问什么的能力。 PodSecurityPolicy对象定义了一组条件，指示 Pod 必须按系统所能接受的顺序运行。它们允许管理员控制如下方面：\n控制面 字段名称 已授权容器的运行 privileged 为容器添加默认的一组能力 defaultAddCapabilities 为容器去掉某些能力 requiredDropCapabilities 容器能够请求添加某些能力 allowedCapabilities 控制卷类型的使用 volumes 主机网络的使用 hostNetwork 主机端口的使用 hostPorts 主机 PID namespace 的使用 hostPID 主机 IPC namespace 的使用 hostIPC 主机路径的使用 allowedHostPaths 容器的 SELinux 上下文 seLinux 用户 ID runAsUser 配置允许的补充组 supplementalGroups 分配拥有 Pod 数据卷的 FSGroup fsGroup 必须使用一个只读的 root 文件系统 readOnlyRootFilesystem Pod 安全策略 由设置和策略组成，它们能够控制 Pod 访问的安全特征。这些设置分为如下三类：\n基于布尔值控制：这种类型的字段默认为最严格限制的值。 基于被允许的值集合控制：这种类型的字段会与这组值进行对比，以确认值被允许。 基于策略控制：设置项通过一种策略提供的机制来生成该值，这种机制能够确保指定的值落在被允许的这组值中。 RunAsUser link MustRunAs - 必须配置一个 range。使用该范围内的第一个值作为默认值。验证是否不在配置的该范围内。 MustRunAsNonRoot - 要求提交的 Pod 具有非零 runAsUser 值，或在镜像中定义了 USER 环境变量。不提供默认值。 RunAsAny - 没有提供默认值。允许指定任何 runAsUser 。 SELinux link MustRunAs - 如果没有使用预分配的值，必须配置 seLinuxOptions。默认使用 seLinuxOptions。验证 seLinuxOptions。 RunAsAny - 没有提供默认值。允许任意指定的 seLinuxOptions ID。 SupplementalGroups link MustRunAs - 至少需要指定一个范围。默认使用第一个范围的最小值。验证所有范围的值。 RunAsAny - 没有提供默认值。允许任意指定的 supplementalGroups ID。 FSGroup link MustRunAs - 至少需要指定一个范围。默认使用第一个范围的最小值。验证在第一个范围内的第一个 ID。 RunAsAny - 没有提供默认值。允许任意指定的 fsGroup ID。 控制卷 link通过设置 PSP 卷字段，能够控制具体卷类型的使用。当创建一个卷的时候，与该字段相关的已定义卷可以允许设置如下值：\nazureFile azureDisk flocker flexVolume hostPath emptyDir gcePersistentDisk awsElasticBlockStore gitRepo secret nfs iscsi glusterfs persistentVolumeClaim rbd cinder cephFS downwardAPI fc configMap vsphereVolume quobyte photonPersistentDisk projected portworxVolume scaleIO storageos *(allow all volumes) 对新的 PSP，推荐允许的卷的最小集合包括：configMap、downwardAPI、emptyDir、persistentVolumeClaim、secret 和 projected。\n主机网络 link HostPorts，默认为 empty。HostPortRange 列表通过 min(包含) and max(包含) 来定义，指定了被允许的主机端口。 允许的主机路径 link AllowedHostPaths 是一个被允许的主机路径前缀的白名单。空值表示所有的主机路径都可以使用。 许可 link包含 PodSecurityPolicy 的 许可控制，允许控制集群资源的创建和修改，基于这些资源在集群范围内被许可的能力。\n许可使用如下的方式为 Pod 创建最终的安全上下文：\n检索所有可用的 PSP。 生成在请求中没有指定的安全上下文设置的字段值。 基于可用的策略，验证最终的设置。 如果某个策略能够匹配上，该 Pod 就被接受。如果请求与 PSP 不匹配，则 Pod 被拒绝。\nPod 必须基于 PSP 验证每个字段。\n创建 Pod 安全策略 link下面是一个 Pod 安全策略的例子，所有字段的设置都被允许：\napiVersion: extensions/v1beta1 kind: PodSecurityPolicy metadata: name: permissive spec: seLinux: rule: RunAsAny supplementalGroups: rule: RunAsAny runAsUser: rule: RunAsAny fsGroup: rule: RunAsAny hostPorts: - min: 8000 max: 8080 volumes: - '*' 下载示例文件可以创建该策略，然后执行如下命令：\n$ kubectl create -f ./psp.yaml podsecuritypolicy \"permissive\" created 获取 Pod 安全策略列表 link获取已存在策略列表，使用 kubectl get：\n$ kubectl get psp NAME PRIV CAPS SELINUX RUNASUSER FSGROUP SUPGROUP READONLYROOTFS VOLUMES permissive false [] RunAsAny RunAsAny RunAsAny RunAsAny false [*] privileged true [] RunAsAny RunAsAny RunAsAny RunAsAny false [*] restricted false [] RunAsAny MustRunAsNonRoot RunAsAny RunAsAny false [emptyDir secret downwardAPI configMap persistentVolumeClaim projected] 修改 Pod 安全策略 link通过交互方式修改策略，使用 kubectl edit：\n$ kubectl edit psp permissive 删除 Pod 安全策略 link一旦不再需要一个策略，很容易通过 kubectl 删除它：\n$ kubectl delete psp permissive podsecuritypolicy \"permissive\" deleted 启用 Pod 安全策略 link为了能够在集群中使用 Pod 安全策略，必须确保如下：\n启用 API 类型 extensions/v1beta1/podsecuritypolicy（仅对 1.6 之前的版本） 启用许可控制器 PodSecurityPolicy 定义自己的策略 RBAC link在 Kubernetes 1.5 或更新版本，可以使用 PodSecurityPolicy 来控制，对基于用户角色和组的已授权容器的访问。访问不同的 PodSecurityPolicy 对象，可以基于认证来控制。基于 Deployment、ReplicaSet 等创建的 Pod，限制访问 PodSecurityPolicy 对象，Controller Manager 必须基于安全 API 端口运行，并且不能够具有超级用户权限。\nPodSecurityPolicy 认证使用所有可用的策略，包括创建 Pod 的用户，Pod 上指定的服务账户（service acount）。当 Pod 基于 Deployment、ReplicaSet 创建时，它是创建 Pod 的 Controller Manager，所以如果基于非安全 API 端口运行，允许所有的 PodSecurityPolicy 对象，并且不能够有效地实现细分权限。用户访问给定的 PSP 策略有效，仅当是直接部署 Pod 的情况。当直接部署 Pod 时，应用 PodSecurityPolicy 控制基于角色和组的已授权容器的访问。\n生命周期 link状态 linkPod 的 status 字段是一个 PodStatus 对象，PodStatus 中有一个 phase 字段。\nPod 的相位（phase）是 Pod 在其生命周期中的简单宏观概述。Pod 相位的数量和含义是严格指定的。\n下面是 phase 可能的值：\n挂起（Pending）：Pod 已被 Kubernetes 系统接受，但有一个或者多个容器镜像尚未创建。等待时间包括调度 Pod 的时间和通过网络下载镜像的时间，这可能需要花点时间。 运行中（Running）：该 Pod 已经绑定到了一个节点上，Pod 中所有的容器都已被创建。至少有一个容器正在运行，或者正处于启动或重启状态。 成功（Succeeded）：Pod 中的所有容器都被成功终止，并且不会再重启。 失败（Failed）：Pod 中的所有容器都已终止了，并且至少有一个容器是因为失败终止。也就是说，容器以非 0 状态退出或者被系统终止。 未知（Unknown）：因为某些原因无法取得 Pod 的状态，通常是因为与 Pod 所在主机通信失败。 Pod 有一个 PodStatus 对象，其中包含一个 PodCondition 数组。PodCondition 数组的每个元素都有一个 type 字段和一个 status 字段。type 字段是字符串，可能的值有 PodScheduled、Ready、Initialized、Unschedulable 和 ContainersReady。status 字段是一个字符串，可能的值有 True、False 和 Unknown。\ngraph LR classDef pending fill:#FFEB3B,stroke:#FBC02D; classDef running fill:#C8E6C9,stroke:#4CAF50; classDef terminal fill:#BBDEFB,stroke:#2196F3; classDef error fill:#FFCDD2,stroke:#F44336; Pending --\u003e|Init Containers完成| Running Pending --\u003e|镜像拉取失败| Failed Running --\u003e|所有容器正常退出| Succeeded Running --\u003e|容器异常退出| Failed Running --\u003e|API请求删除| Terminating Pending --\u003e|API请求删除| Terminating Terminating --\u003e|清理完成| End(( )) class Pending pending; class Running running; class Succeeded,Failed,End terminal; class Failed error; 容器探针 link探针是由 kubelet 对容器执行的定期诊断。要执行诊断，kubelet 调用由容器实现的 Handler。有三种类型的处理程序：\nExecAction：在容器内执行指定命令。如果命令退出时返回码为 0 则认为诊断成功。 TCPSocketAction：对指定端口上的容器的 IP 地址进行 TCP 检查。如果端口打开，则诊断被认为是成功的。 HTTPGetAction：对指定的端口和路径上的容器的 IP 地址执行 HTTP Get 请求。如果响应的状态码大于等于 200 且小于 400，则诊断被认为是成功的。 每次探测都将获得以下三种结果之一：\n成功：容器通过了诊断。 失败：容器未通过诊断。 未知：诊断失败，因此不会采取任何行动。 Kubelet 可以选择是否执行在容器上运行的两种探针执行和做出反应：\nlivenessProbe：指示容器是否正在运行。如果存活探测失败，则 kubelet 会杀死容器，并且容器将受到其 重启策略 的影响。如果容器不提供存活探针，则默认状态为 Success。 readinessProbe：指示容器是否准备好服务请求。如果就绪探测失败，端点控制器将从与 Pod 匹配的所有 Service 的端点中删除该 Pod 的 IP 地址。初始延迟之前的就绪状态默认为Failure。如果容器不提供就绪探针，则默认状态为 Success。 该什么时候使用存活（liveness）和就绪（readiness）探针？\n如果容器中的进程能够在遇到问题或不健康的情况下自行崩溃，则不一定需要存活探针; kubelet 将根据 Pod 的restartPolicy 自动执行正确的操作。\n如果你希望容器在探测失败时被杀死并重新启动，那么请指定一个存活探针，并指定restartPolicy 为 Always 或 OnFailure。\n如果要仅在探测成功时才开始向 Pod 发送流量，请指定就绪探针。在这种情况下，就绪探针可能与存活探针相同，但是 spec 中的就绪探针的存在意味着 Pod 将在没有接收到任何流量的情况下启动，并且只有在探针探测成功后才开始接收流量。\n如果你希望容器能够自行维护，你可以指定一个就绪探针，该探针检查与存活探针不同的端点。\n请注意，如果你只想在 Pod 被删除时能够排除请求，则不一定需要使用就绪探针；在删除 Pod 时，Pod 会自动将自身置于未完成状态，无论就绪探针是否存在。当等待 Pod 中的容器停止时，Pod 仍处于未完成状态。\n重启策略 linkPodSpec 中有一个 restartPolicy 字段，可能的值为 Always、OnFailure 和 Never。默认为 Always。 restartPolicy 适用于 Pod 中的所有容器。restartPolicy 仅指通过同一节点上的 kubelet 重新启动容器。失败的容器由 kubelet 以五分钟为上限的指数退避延迟（10 秒，20 秒，40 秒…）重新启动，并在成功执行十分钟后重置。如 Pod 文档 中所述，一旦绑定到一个节点，Pod 将永远不会重新绑定到另一个节点。\n的生命 link一般来说，Pod 不会消失，直到人为销毁他们。这可能是一个人或控制器。这个规则的唯一例外是成功或失败的 phase 超过一段时间（由 master 确定）的 Pod 将过期并被自动销毁。\n有三种可用的控制器：\n使用 Job 运行预期会终止的 Pod，例如批量计算。Job 仅适用于重启策略为 OnFailure 或 Never 的 Pod。\n对预期不会终止的 Pod 使用 ReplicationController、ReplicaSet 和 Deployment ，例如 Web 服务器。ReplicationController 仅适用于具有 restartPolicy 为 Always 的 Pod。\n提供特定于机器的系统服务，使用 DaemonSet 为每台机器运行一个 Pod。\n所有这三种类型的控制器都包含一个 PodTemplate。建议创建适当的控制器，让它们来创建 Pod，而不是直接自己创建 Pod。这是因为单独的 Pod 在机器故障的情况下没有办法自动复原，而控制器却可以。\n如果节点死亡或与集群的其余部分断开连接，则 Kubernetes 将应用一个策略将丢失节点上的所有 Pod 的 phase 设置为 Failed。\n示例 link高级 liveness 探针 link存活探针由 kubelet 来执行，因此所有的请求都在 kubelet 的网络命名空间中进行。\napiVersion: v1 kind: Pod metadata: labels: test: liveness name: liveness-http spec: containers: - args: - /server image: k8s.gcr.io/liveness livenessProbe: httpGet: # when \"host\" is not defined, \"PodIP\" will be used # host: my-host # when \"scheme\" is not defined, \"HTTP\" scheme will be used. Only \"HTTP\" and \"HTTPS\" are allowed # scheme: HTTPS path: /healthz port: 8080 httpHeaders: - name: X-Custom-Header value: Awesome initialDelaySeconds: 15 timeoutSeconds: 1 name: liveness 状态示例 link Pod 中只有一个容器并且正在运行。容器成功退出。 记录完成事件。 如果 restartPolicy 为： Always：重启容器；Pod phase 仍为 Running。 OnFailure：Pod phase 变成 Succeeded。 Never：Pod phase 变成 Succeeded。 Pod中只有一个容器并且正在运行。容器退出失败。 记录失败事件。 如果 restartPolicy 为： Always：重启容器；Pod phase 仍为 Running。 OnFailure：重启容器；Pod phase 仍为 Running。 Never：Pod phase 变成 Failed。 Pod 中有两个容器并且正在运行。容器 1 退出失败。 记录失败事件。 如果 restartPolicy 为： Always：重启容器；Pod phase 仍为 Running。 OnFailure：重启容器；Pod phase 仍为 Running。 Never：不重启容器；Pod phase 仍为 Running。 如果有容器 1 没有处于运行状态，并且容器 2 退出： 记录失败事件。 如果 restartPolicy 为： Always：重启容器；Pod phase 仍为 Running。 OnFailure：重启容器；Pod phase 仍为 Running。 Never：Pod phase 变成 Failed。 Pod 中只有一个容器并处于运行状态。容器运行时内存超出限制： 容器以失败状态终止。 记录 OOM 事件。 如果 restartPolicy 为： Always：重启容器；Pod phase 仍为 Running。 OnFailure：重启容器；Pod phase 仍为 Running。 Never: 记录失败事件；Pod phase 仍为 Failed。 Pod 正在运行，磁盘故障： 杀掉所有容器。 记录适当事件。 Pod phase 变成 Failed。 如果使用控制器来运行，Pod 将在别处重建。 Pod 正在运行，其节点被分段。 节点控制器等待直到超时。 节点控制器将 Pod phase 设置为 Failed。 如果是用控制器来运行，Pod 将在别处重建。 Hook linkPod Hook（钩子）是由 Kubernetes 管理的 kubelet 发起的，当容器中的进程启动前或者容器中的进程终止之前运行，这是包含在容器的生命周期之中。可以同时为 Pod 中的所有容器都配置 hook。\nHook 的类型包括两种：\nexec：执行一段命令 HTTP：发送 HTTP 请求。 apiVersion: v1 kind: Pod metadata: name: lifecycle-demo spec: containers: - name: lifecycle-demo-container image: nginx lifecycle: postStart: exec: command: [\"/bin/sh\", \"-c\", \"echo Hello from the postStart handler\u003e /usr/share/message\"] preStop: exec: command: [\"/usr/sbin/nginx\",\"-s\",\"quit\"] Kubernetes 在容器创建后立即发送 postStart 事件。但是，不能保证在调用容器的入口点之前调用 postStart 处理程序。postStart 处理程序相对于容器的代码异步运行，但 Kubernetes 对容器的管理将被阻止，直到 postStart 处理程序完成。在 postStart 处理程序完成之前，容器的状态不会设置为 RUNNING。\nPreStop 在容器终止之前被同步阻塞调用，常用于在容器结束前优雅的释放资源。\n如果 postStart 或者 preStop hook 失败，将会终止容器。\n中断预算 link自愿中断和非自愿中断 linkPod 不会消失，直到有人（人类或控制器）将其销毁，或者当出现不可避免的硬件或系统软件错误。\n我们把这些不可避免的情况称为应用的非自愿性中断。例如：\n后端节点物理机的硬件故障 集群管理员错误地删除虚拟机（实例） 云提供商或管理程序故障使虚拟机消失 内核恐慌（kernel panic） 节点由于集群网络分区而从集群中消失 由于节点资源不足而将容器逐出 除资源不足的情况外，大多数用户应该都熟悉以下这些情况；它们不是特定于 Kubernetes 的。\n我们称这些情况为”自愿中断“。包括由应用程序所有者发起的操作和由集群管理员发起的操作。典型的应用程序所有者操作包括：\n删除管理该 pod 的 Deployment 或其他控制器 更新了 Deployment 的 pod 模板导致 pod 重启 直接删除 pod（意外删除） 集群管理员操作包括：\n排空（drain）节点进行修复或升级。 从集群中排空节点以缩小集群。 从节点中移除一个 pod，以允许其他 pod 使用该节点。 这些操作可能由集群管理员直接执行，也可能由集群管理员或集群托管提供商自动执行。\n询问你的集群管理员或咨询你的云提供商或发行文档，以确定是否为你的集群启用了任何自动中断源。如果没有启用，你可以跳过创建 Pod Disruption Budget（Pod 中断预算）。\n处理中断 link以下是一些减轻非自愿性中断的方法：\n确保你的 pod 请求所需的资源。 如果你需要更高的可用性，请复制你的应用程序。 （了解有关运行复制的无状态和有状态应用程序的信息。） 为了在运行复制应用程序时获得更高的可用性，请跨机架（使用反亲和性）或跨区域（如果使用多区域集群）分布应用程序。 自愿中断的频率各不相同。在 Kubernetes 集群上，根本没有自愿的中断。但是，你的集群管理员或托管提供商可能会运行一些导致自愿中断的附加服务。例如，节点软件更新可能导致自愿更新。另外，集群（节点）自动缩放的某些实现可能会导致碎片整理和紧缩节点的自愿中断。你的集群管理员或主机提供商应该已经记录了期望的自愿中断级别（如果有的话）。\nKubernetes 提供的功能可以满足在频繁地自动中断的同时运行高可用的应用程序。我们称之为“中断预算”。\n中断预算的工作原理 link应用程序所有者可以为每个应用程序创建一个 PodDisruptionBudget 对象（PDB）。PDB 将限制在同一时间自愿中断的复制应用程序中宕机的 Pod 的数量。例如，基于定额的应用程序希望确保运行的副本数量永远不会低于仲裁所需的数量。Web 前端可能希望确保提供负载的副本的数量永远不会低于总数的某个百分比。\n集群管理器和托管提供商应使用遵循 Pod Disruption Budgets 的工具，方法是调用Eviction API而不是直接删除 Pod。例如 kubectl drain 命令和 Kubernetes-on-GCE 集群升级脚本（cluster/gce/upgrade.sh）。\n当集群管理员想要排空节点时，可以使用 kubectl drain 命令。该命令会试图驱逐机器上的所有 pod。驱逐请求可能会暂时被拒绝，并且该工具会定期重试所有失败的请求，直到所有的 pod 都被终止，或者直到达到配置的超时时间。\nPDB 指定应用程序可以容忍的副本的数量，相对于应该有多少副本。例如，具有 spec.replicas：5 的 Deployment 在任何给定的时间都应该有 5 个 Pod。如果其 PDB 允许在某一时刻有 4 个副本，那么驱逐 API 将只允许仅有一个而不是两个 Pod 自愿中断。\n使用标签选择器来指定应用程序的一组 pod，这与应用程序的控制器（Deployment、StatefulSet 等）使用的相同。\nPod 控制器的 .spec.replicas 计算“预期的”pod 数量。使用对象的 .metadata.ownerReferences 值从控制器获取。\nPDB 不能阻止非自愿中断的发生，但是它们确实会影响预算。\n由于应用程序的滚动升级而被删除或不可用的 Pod 确实会计入中断预算，但控制器（如 Deployment 和 StatefulSet）在进行滚动升级时不受 PDB 的限制——在应用程序更新期间的故障处理是在控制器的规格（spec）中配置（了解更新 Deployment）。\n使用驱逐 API 驱逐 pod 时，pod 会被优雅地终止（请参阅 PodSpec 中的 terminationGracePeriodSeconds）。\nPDB 示例 link假设集群有3个节点，node-1 到 node-3。集群中运行了一些应用，其中一个应用有3个副本，分别是 pod-a、pod-b 和 pod-c。另外，还有一个与它相关的不具有 PDB 的 pod，我们称为之为 pod-x。最初，所有 Pod 的分布如下：\nnode-1 node-2 node-3 pod-a available pod-b available pod-c available pod-x available 所有的3个 pod 都是 Deployment 中的一部分，并且它们共同拥有一个 PDB，要求至少有3个 pod 中的2个始终处于可用状态。\n例如，假设集群管理员想要重启系统，升级内核版本来修复内核中的错误。集群管理员首先使用 kubectl drain 命令尝试排除 node-1。该工具试图驱逐 pod-a 和 pod-x。这立即成功。两个 Pod 同时进入终止状态。这时的集群处于这种状态：\nnode-1 draining node-2 node-3 pod-a terminating pod-b available pod-c available pod-x terminating Deployment 注意到其中有一个 pod 处于正在终止，因此会创建了一个 pod-d 来替换。由于 node-1 被封锁（cordon），它落在另一个节点上。同时其它控制器也创建了 pod-y 作为 pod-x 的替代品。\n（注意：对于 StatefulSet，pod-a 将被称为 pod-1，需要在替换之前完全终止，替代它的也称为 pod-1，但是具有不同的 UID，可以创建。否则，示例也适用于 StatefulSet。）\n当前集群的状态如下：\nnode-1 draining node-2 node-3 pod-a terminating pod-b available pod-c available pod-x terminating pod-d starting pod-y 在某一时刻，pod 被终止，集群看起来像下面这样子：\nnode-1 drained node-2 node-3 pod-b available pod-c available pod-d starting pod-y 此时，如果一个急躁的集群管理员试图排空（drain）node-2 或 node-3，drain 命令将被阻塞，因为对于 Deployment 只有2个可用的 pod，并且其 PDB 至少需要2个。经过一段时间，pod-d 变得可用。\nnode-1 drained node-2 node-3 pod-b available pod-c available pod-d available pod-y 现在，集群管理员尝试排空 node-2。drain 命令将尝试按照某种顺序驱逐两个 pod，假设先是 pod-b，然后再 pod-d。它将成功驱逐 pod-b。但是，当它试图驱逐 pod-d 时，将被拒绝，因为这样对 Deployment 来说将只剩下一个可用的 pod。\nDeployment 将创建一个名为 pod-e 的 pod-b 的替代品。但是，集群中没有足够的资源来安排 pod-e。那么，drain 命令就会被阻塞。集群最终可能是这种状态：\nnode-1 drained node-2 drained node-3 no node pod-c available pod-e pending pod-d available pod-y 此时，集群管理员需要向集群中添加回一个节点以继续升级操作。\n您可以看到 Kubernetes 如何改变中断发生的速率，根据：\n应用程序需要多少副本 正常关闭实例需要多长时间 启动新实例需要多长时间 控制器的类型 集群的资源能力 分离集群所有者和应用程序所有者角色 link将集群管理者和应用程序所有者视为彼此知识有限的独立角色通常是很有用的。这种责任分离在这些情况下可能是有意义的：\n当有许多应用程序团队共享一个 Kubernetes 集群，并且有自然的专业角色 使用第三方工具或服务来自动化集群管理 Pod Disruption Budget（Pod 中断预算） 通过在角色之间提供接口来支持这种角色分离。\n如果您的组织中没有这样的职责分离，则可能不需要使用 Pod 中断预算。\n如何在集群上执行中断操作 link如果您是集群管理员，要对集群的所有节点执行中断操作，例如节点或系统软件升级，则可以使用以下选择：\n在升级期间接受停机时间。 故障转移到另一个完整的副本集群。 没有停机时间，但是对于重复的节点和人工协调成本可能是昂贵的。 编写可容忍中断的应用程序和使用 PDB。 没有停机时间。 最小的资源重复。 允许更多的集群管理自动化。 编写可容忍中断的应用程序是很棘手的，但对于可容忍自愿中断，和支持自动调整以容忍非自愿中断，两者在工作上有大量的重叠。 "
            }
        );
    index.add(
            {
                id:  16 ,
                href: "\/docs\/information\/software\/cloud\/auth\/rbac\/",
                title: "RBAC",
                description: "注意：本文基于 Kubernetes 1.6 撰写，当时 RBAC 模式处于 beta 版本。\n基于角色的访问控制（Role-Based Access Control，即”RBAC”）使用 rbac.authorization.k8s.io API Group 实现授权决策，允许管理员通过 Kubernetes API 动态配置策略。\n要启用 RBAC，请使用 --authorization-mode=RBAC 启动 API Server。\nAPI 概述 link本节将介绍 RBAC API 所定义的四种顶级类型。用户可以像使用其他 Kubernetes API 资源一样 （例如通过 kubectl、API 调用等）与这些资源进行交互。例如，命令 kubectl create -f (resource).yml 可以被用于以下所有的例子，当然，读者在尝试前可能需要先阅读以下相关章节的内容。\nRole 与 ClusterRole link在 RBAC API 中，一个角色包含了一套表示一组权限的规则。 权限以纯粹的累加形式累积（没有” 否定” 的规则）。 角色可以由命名空间（namespace）内的 Role 对象定义，而整个 Kubernetes 集群范围内有效的角色则通过 ClusterRole 对象实现。\n一个 Role 对象只能用于授予对某一单一命名空间中资源的访问权限。 以下示例描述了”default” 命名空间中的一个 Role 对象的定义，用于授予对 pod 的读访问权限：\nkind: Role apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: namespace: default name: pod-reader rules: - apiGroups: [\"\"] # 空字符串\"\" 表明使用 core API group resources: [\"pods\"] verbs: [\"get\", \"watch\", \"list\"] ClusterRole 对象可以授予与 Role 对象相同的权限，但由于它们属于集群范围对象， 也可以使用它们授予对以下几种资源的访问权限：\n",
                content: "注意：本文基于 Kubernetes 1.6 撰写，当时 RBAC 模式处于 beta 版本。\n基于角色的访问控制（Role-Based Access Control，即”RBAC”）使用 rbac.authorization.k8s.io API Group 实现授权决策，允许管理员通过 Kubernetes API 动态配置策略。\n要启用 RBAC，请使用 --authorization-mode=RBAC 启动 API Server。\nAPI 概述 link本节将介绍 RBAC API 所定义的四种顶级类型。用户可以像使用其他 Kubernetes API 资源一样 （例如通过 kubectl、API 调用等）与这些资源进行交互。例如，命令 kubectl create -f (resource).yml 可以被用于以下所有的例子，当然，读者在尝试前可能需要先阅读以下相关章节的内容。\nRole 与 ClusterRole link在 RBAC API 中，一个角色包含了一套表示一组权限的规则。 权限以纯粹的累加形式累积（没有” 否定” 的规则）。 角色可以由命名空间（namespace）内的 Role 对象定义，而整个 Kubernetes 集群范围内有效的角色则通过 ClusterRole 对象实现。\n一个 Role 对象只能用于授予对某一单一命名空间中资源的访问权限。 以下示例描述了”default” 命名空间中的一个 Role 对象的定义，用于授予对 pod 的读访问权限：\nkind: Role apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: namespace: default name: pod-reader rules: - apiGroups: [\"\"] # 空字符串\"\" 表明使用 core API group resources: [\"pods\"] verbs: [\"get\", \"watch\", \"list\"] ClusterRole 对象可以授予与 Role 对象相同的权限，但由于它们属于集群范围对象， 也可以使用它们授予对以下几种资源的访问权限：\n集群范围资源（例如节点，即 node） 非资源类型 endpoint（例如”/healthz”） 跨所有命名空间的命名空间范围资源（例如 pod，需要运行命令 kubectl get pods --all-namespaces 来查询集群中所有的 pod） 下面示例中的 ClusterRole 定义可用于授予用户对某一特定命名空间，或者所有命名空间中的 secret（取决于其 绑定 方式）的读访问权限：\nkind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: # 鉴于 ClusterRole 是集群范围对象，所以这里不需要定义 \"namespace\" 字段 name: secret-reader rules: - apiGroups: [\"\"] resources: [\"secrets\"] verbs: [\"get\", \"watch\", \"list\"] RoleBinding 与 ClusterRoleBinding link角色绑定将一个角色中定义的各种权限授予一个或者一组用户。 角色绑定包含了一组相关主体（即 subject, 包括用户 ——User、用户组 ——Group、或者服务账户 ——Service Account）以及对被授予角色的引用。 在命名空间中可以通过 RoleBinding 对象授予权限，而集群范围的权限授予则通过 ClusterRoleBinding 对象完成。\nRoleBinding 可以引用在同一命名空间内定义的 Role 对象。 下面示例中定义的 RoleBinding 对象在”default” 命名空间中将”pod-reader” 角色授予用户”jane”。 这一授权将允许用户”jane” 从”default” 命名空间中读取 pod。\n以下角色绑定定义将允许用户 “jane” 从 “default” 命名空间中读取 pod。\nkind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: read-pods namespace: default subjects: - kind: User name: jane apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: pod-reader apiGroup: rbac.authorization.k8s.io RoleBinding 对象也可以引用一个 ClusterRole 对象用于在 RoleBinding 所在的命名空间内授予用户对所引用的 ClusterRole 中 定义的命名空间资源的访问权限。这一点允许管理员在整个集群范围内首先定义一组通用的角色，然后再在不同的命名空间中复用这些角色。\n例如，尽管下面示例中的 RoleBinding 引用的是一个 ClusterRole 对象，但是用户”dave”（即角色绑定主体）还是只能读取”development” 命名空间中的 secret（即 RoleBinding 所在的命名空间）。\n# 以下角色绑定允许用户 \"dave\" 读取 \"development\" 命名空间中的 secret。 kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: read-secrets namespace: development # 这里表明仅授权读取 \"development\" 命名空间中的资源。 subjects: - kind: User name: dave apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole name: secret-reader apiGroup: rbac.authorization.k8s.io 最后，可以使用ClusterRoleBinding在集群级别和所有命名空间中授予权限。下面示例中所定义的ClusterRoleBinding允许在用户组”manager” 中的任何用户都可以读取集群中任何命名空间中的 secret。\n以下 ClusterRoleBinding 对象允许在用户组 “manager” 中的任何用户都可以读取集群中任何命名空间中的 secret。\nkind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: read-secrets-global subjects: - kind: Group name: manager apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole name: secret-reader apiGroup: rbac.authorization.k8s.io 对资源的引用 link大多数资源由代表其名字的字符串表示，例如”pods”，就像它们出现在相关 API endpoint 的 URL 中一样。然而，有一些 Kubernetes API 还 包含了” 子资源”，比如 pod 的 logs。在 Kubernetes 中，pod logs endpoint 的 URL 格式为：\nGET /api/v1/namespaces/{namespace}/pods/{name}/log\n在这种情况下，”pods” 是命名空间资源，而”log” 是 pods 的子资源。为了在 RBAC 角色中表示出这一点，我们需要使用斜线来划分资源 与子资源。如果需要角色绑定主体读取 pods 以及 pod log，您需要定义以下角色：\nkind: Role apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: namespace: default name: pod-and-pod-logs-reader rules: - apiGroups: [\"\"] resources: [\"pods\", \"pods/log\"] verbs: [\"get\", \"list\"] 通过resourceNames列表，角色可以针对不同种类的请求根据资源名引用资源实例。当指定了resourceNames列表时，不同动作 种类的请求的权限，如使用”get”、”delete”、”update” 以及”patch” 等动词的请求，将被限定到资源列表中所包含的资源实例上。 例如，如果需要限定一个角色绑定主体只能”get” 或者”update” 一个 configmap 时，您可以定义以下角色：\nkind: Role apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: namespace: default name: configmap-updater rules: - apiGroups: [\"\"] resources: [\"configmap\"] resourceNames: [\"my-configmap\"] verbs: [\"update\", \"get\"] 值得注意的是，如果设置了resourceNames，则请求所使用的动词不能是 list、watch、create 或者 deletecollection。 由于资源名不会出现在 create、list、watch 和 deletecollection 等 API 请求的 URL 中，所以这些请求动词不会被设置了resourceNames的规则所允许，因为规则中的resourceNames 部分不会匹配这些请求。\n一些角色定义的例子 link在以下示例中，我们仅截取展示了 rules 部分的定义。\n允许读取 core API Group 中定义的资源”pods”：\nrules: - apiGroups: [\"\"] resources: [\"pods\"] verbs: [\"get\", \"list\", \"watch\"] 允许读写在”extensions” 和”apps” API Group 中定义的”deployments”：\nrules: - apiGroups: [\"extensions\", \"apps\"] resources: [\"deployments\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"] 允许读取”pods” 以及读写”jobs”：\nrules: - apiGroups: [\"\"] resources: [\"pods\"] verbs: [\"get\", \"list\", \"watch\"] - apiGroups: [\"batch\", \"extensions\"] resources: [\"jobs\"] verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"] 允许读取一个名为”my-config” 的ConfigMap实例（需要将其通过RoleBinding绑定从而限制针对某一个命名空间中定义的一个ConfigMap实例的访问）：\nrules: - apiGroups: [\"\"] resources: [\"configmaps\"] resourceNames: [\"my-config\"] verbs: [\"get\"] 允许读取 core API Group 中的”nodes” 资源（由于Node是集群级别资源，所以此ClusterRole定义需要与一个ClusterRoleBinding绑定才能有效）：\nrules: - apiGroups: [\"\"] resources: [\"nodes\"] verbs: [\"get\", \"list\", \"watch\"] 允许对非资源 endpoint “/healthz” 及其所有子路径的”GET” 和”POST” 请求（此ClusterRole定义需要与一个ClusterRoleBinding绑定才能有效）：\nrules: - nonResourceURLs: [\"/healthz\", \"/healthz/*\"] # 在非资源 URL 中，'*' 代表后缀通配符 verbs: [\"get\", \"post\"] 对角色绑定主体（Subject）的引用RoleBinding或者ClusterRoleBinding 将角色绑定到 角色绑定主体（Subject）。 角色绑定主体可以是用户组（Group）、用户（User）或者服务账户（Service Accounts）。\n用户由字符串表示。可以是纯粹的用户名，例如”alice”、电子邮件风格的名字，如 “bob@example.com” 或者是用字符串表示的数字 id。由 Kubernetes 管理员配置 认证模块 以产生所需格式的用户名。对于用户名，RBAC 授权系统不要求任何特定的格式。然而，前缀 system: 是 为 Kubernetes 系统使用而保留的，所以管理员应该确保用户名不会意外地包含这个前缀。\nKubernetes 中的用户组信息由授权模块提供。用户组与用户一样由字符串表示。Kubernetes 对用户组 字符串没有格式要求，但前缀 system: 同样是被系统保留的。\n服务账户 拥有包含 system:serviceaccount: 前缀的用户名，并属于拥有 system:serviceaccounts: 前缀的用户组。\n角色绑定的一些例子 link以下示例中，仅截取展示了 RoleBinding 的 subjects 字段。\n一个名为”alice@example.com” 的用户：\nsubjects: - kind: User name: \"alice@example.com\" apiGroup: rbac.authorization.k8s.io 一个名为”frontend-admins” 的用户组：\nsubjects: - kind: Group name: \"frontend-admins\" apiGroup: rbac.authorization.k8s.io kube-system 命名空间中的默认服务账户：\nsubjects: - kind: ServiceAccount name: default namespace: kube-system 名为”qa” 命名空间中的所有服务账户：\nsubjects: - kind: Group name: system:serviceaccounts:qa apiGroup: rbac.authorization.k8s.io ​```在集群中的所有服务账户： ​```yaml subjects: - kind: Group name: system:serviceaccounts apiGroup: rbac.authorization.k8s.io 所有认证过的用户（version 1.5+）：\nsubjects: - kind: Group name: system:authenticated apiGroup: rbac.authorization.k8s.io ​```所有未认证的用户（version 1.5+）： ​```yaml subjects: - kind: Group name: system:unauthenticated apiGroup: rbac.authorization.k8s.io 所有用户（version 1.5+）：\nsubjects: - kind: Group name: system:authenticated apiGroup: rbac.authorization.k8s.io - kind: Group name: system:unauthenticated apiGroup: rbac.authorization.k8s.io 默认角色与默认角色绑定 linkAPI Server 会创建一组默认的 ClusterRole 和 ClusterRoleBinding 对象。 这些默认对象中有许多包含 system: 前缀，表明这些资源由 Kubernetes 基础组件” 拥有”。 对这些资源的修改可能导致非功能性集群（non-functional cluster）。一个例子是 system:node ClusterRole 对象。 这个角色定义了 kubelets 的权限。如果这个角色被修改，可能会导致 kubelets 无法正常工作。\n所有默认的 ClusterRole 和 ClusterRoleBinding 对象都会被标记为 kubernetes.io/bootstrapping=rbac-defaults。\n自动更新 link每次启动时，API Server 都会更新默认 ClusterRole 所缺乏的各种权限，并更新默认 ClusterRoleBinding 所缺乏的各个角色绑定主体。 这种自动更新机制允许集群修复一些意外的修改。由于权限和角色绑定主体在新的 Kubernetes 释出版本中可能变化，这也能够保证角色和角色 绑定始终保持是最新的。\n如果需要禁用自动更新，请将默认 ClusterRole 以及 ClusterRoleBinding 的 rbac.authorization.kubernetes.io/autoupdate 设置成为 false。 请注意，缺乏默认权限和角色绑定主体可能会导致非功能性集群问题。\n自 Kubernetes 1.6 + 起，当集群 RBAC 授权器（RBAC Authorizer）处于开启状态时，可以启用自动更新功能.\n发现类角色 link 默认 ClusterRole 默认 ClusterRoleBinding 描述 system:basic-user system:authenticated and system:unauthenticatedgroups 允许用户只读访问有关自己的基本信息。 system:discovery system:authenticated and system:unauthenticatedgroups 允许只读访问 API discovery endpoints, 用于在 API 级别进行发现和协商。 面向用户的角色 link一些默认角色并不包含 system: 前缀，它们是面向用户的角色。 这些角色包含超级用户角色（cluster-admin），即旨在利用 ClusterRoleBinding（cluster-status）在集群范围内授权的角色， 以及那些使用 RoleBinding（admin、edit 和 view）在特定命名空间中授权的角色。\n默认 ClusterRole 默认 ClusterRoleBinding 描述 cluster-admin system:masters group 超级用户权限，允许对任何资源执行任何操作。 在 ClusterRoleBinding 中使用时，可以完全控制集群和所有命名空间中的所有资源。 在 RoleBinding 中使用时，可以完全控制 RoleBinding 所在命名空间中的所有资源，包括命名空间自己。 admin None 管理员权限，利用 RoleBinding 在某一命名空间内部授予。 在 RoleBinding 中使用时，允许针对命名空间内大部分资源的读写访问， 包括在命名空间内创建角色与角色绑定的能力。 但不允许对资源配额（resource quota）或者命名空间本身的写访问。 edit None 允许对某一个命名空间内大部分对象的读写访问，但不允许查看或者修改角色或者角色绑定。 view None 允许对某一个命名空间内大部分对象的只读访问。 不允许查看角色或者角色绑定。 由于可扩散性等原因，不允许查看 secret 资源。 Core Component Roles link核心组件角色 link 默认 ClusterRole 默认 ClusterRoleBinding 描述 system:kube-scheduler system:kube-scheduler user 允许访问 kube-scheduler 组件所需要的资源。 system:kube-controller-manager system:kube-controller-manager user 允许访问 kube-controller-manager 组件所需要的资源。 单个控制循环所需要的权限请参阅 控制器（controller）角色. system:node system:nodes group (deprecated in 1.7) 允许对 kubelet 组件所需要的资源的访问，包括读取所有 secret 和对所有 pod 的写访问。 自 Kubernetes 1.7 开始，相比较于这个角色，更推荐使用 Node authorizer 以及 NodeRestriction admission plugin， 并允许根据调度运行在节点上的 pod 授予 kubelets API 访问的权限。 自 Kubernetes 1.7 开始，当启用 Node 授权模式时，对 system:nodes 用户组的绑定将不会被自动创建。 system:node-proxier system:kube-proxy user 允许对 kube-proxy 组件所需要资源的访问。 其它组件角色 link 默认 ClusterRole 默认 ClusterRoleBinding 描述 system:auth-delegator None 允许委托认证和授权检查。 通常由附加 API Server 用于统一认证和授权。 system:heapster None Heapster 组件的角色。 system:kube-aggregator None kube-aggregator 组件的角色。 system:kube-dns kube-dns service account in the kube-systemnamespace kube-dns 组件的角色。 system:node-bootstrapper None 允许对执行 Kubelet TLS 引导（Kubelet TLS bootstrapping） 所需要资源的访问. system:node-problem-detector None node-problem-detector 组件的角色。 system:persistent-volume-provisioner None 允许对大部分动态存储卷创建组件（dynamic volume provisioner）所需要资源的访问。 控制器（Controller）角色 linkKubernetes controller manager 负责运行核心控制循环。 当使用 --use-service-account-credentials 选项运行 controller manager 时，每个控制循环都将使用单独的服务账户启动。 而每个控制循环都存在对应的角色，前缀名为 system:controller:。 如果不使用 --use-service-account-credentials 选项时，controller manager 将会使用自己的凭证运行所有控制循环，而这些凭证必须被授予相关的角色。 这些角色包括：\nsystem:controller:attachdetach-controller system:controller:certificate-controller system:controller:cronjob-controller system:controller:daemon-set-controller system:controller:deployment-controller system:controller:disruption-controller system:controller:endpoint-controller system:controller:generic-garbage-collector system:controller:horizontal-pod-autoscaler system:controller:job-controller system:controller:namespace-controller system:controller:node-controller system:controller:persistent-volume-binder system:controller:pod-garbage-collector system:controller:replicaset-controller system:controller:replication-controller system:controller:resourcequota-controller system:controller:route-controller system:controller:service-account-controller system:controller:service-controller system:controller:statefulset-controller system:controller:ttl-controller 初始化与预防权限升级 linkRBAC API 会阻止用户通过编辑角色或者角色绑定来升级权限。 由于这一点是在 API 级别实现的，所以在 RBAC 授权器（RBAC authorizer）未启用的状态下依然可以正常工作。\n用户只有在拥有了角色所包含的所有权限的条件下才能创建／更新一个角色，这些操作还必须在角色所处的相同范围内进行（对于 ClusterRole 来说是集群范围，对于 Role 来说是在与角色相同的命名空间或者集群范围）。 例如，如果用户”user-1” 没有权限读取集群范围内的 secret 列表，那么他也不能创建包含这种权限的 ClusterRole。为了能够让用户创建／更新角色，需要：\n授予用户一个角色以允许他们根据需要创建／更新 Role 或者 ClusterRole 对象。 授予用户一个角色包含他们在 Role 或者 ClusterRole 中所能够设置的所有权限。如果用户尝试创建或者修改 Role 或者 ClusterRole 以设置那些他们未被授权的权限时，这些 API 请求将被禁止。 用户只有在拥有所引用的角色中包含的所有权限时才可以创建／更新角色绑定（这些操作也必须在角色绑定所处的相同范围内进行）* 或者 * 用户被明确授权可以在所引用的角色上执行绑定操作。 例如，如果用户”user-1” 没有权限读取集群范围内的 secret 列表，那么他将不能创建 ClusterRole 来引用那些授予了此项权限的角色。为了能够让用户创建／更新角色绑定，需要：\n授予用户一个角色以允许他们根据需要创建／更新 RoleBinding 或者 ClusterRoleBinding 对象。 授予用户绑定某一特定角色所需要的权限： 隐式地，通过授予用户所有所引用的角色中所包含的权限 显式地，通过授予用户在特定 Role（或者 ClusterRole）对象上执行 bind 操作的权限 例如，下面例子中的 ClusterRole 和 RoleBinding 将允许用户”user-1” 授予其它用户”user-1-namespace” 命名空间内的 admin、edit 和 view 等角色和角色绑定。\napiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRole metadata: name: role-grantor rules: - apiGroups: [\"rbac.authorization.k8s.io\"] resources: [\"rolebindings\"] verbs: [\"create\"] - apiGroups: [\"rbac.authorization.k8s.io\"] resources: [\"clusterroles\"] verbs: [\"bind\"] resourceNames: [\"admin\",\"edit\",\"view\"] --- apiVersion: rbac.authorization.k8s.io/v1beta1 kind: RoleBinding metadata: name: role-grantor-binding namespace: user-1-namespace roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: role-grantor subjects: - apiGroup: rbac.authorization.k8s.io kind: User name: user-1 当初始化第一个角色和角色绑定时，初始用户需要能够授予他们尚未拥有的权限。 初始化初始角色和角色绑定时需要：\n使用包含 system：masters 用户组的凭证，该用户组通过默认绑定绑定到 cluster-admin 超级用户角色。 如果您的 API Server 在运行时启用了非安全端口（--insecure-port），您也可以通过这个没有施行认证或者授权的端口发送角色或者角色绑定请求。 一些命令行工具 link有两个 kubectl 命令可以用于在命名空间内或者整个集群内授予角色。\nkubectl create rolebinding link在某一特定命名空间内授予 Role 或者 ClusterRole。示例如下：\n在名为”acme” 的命名空间中将 admin ClusterRole 授予用户”bob”：\nkubectl create rolebinding bob-admin-binding --clusterrole=admin --user=bob --namespace=acme\n在名为”acme” 的命名空间中将 view ClusterRole 授予服务账户”myapp”：\nkubectl create rolebinding myapp-view-binding --clusterrole=view --serviceaccount=acme:myapp --namespace=acme\nkubectl create clusterrolebinding link在整个集群中授予 ClusterRole，包括所有命名空间。示例如下：\n在整个集群范围内将 cluster-admin ClusterRole 授予用户”root”：\nkubectl create clusterrolebinding root-cluster-admin-binding --clusterrole=cluster-admin --user=root\n在整个集群范围内将 system:node ClusterRole 授予用户”kubelet”：\nkubectl create clusterrolebinding kubelet-node-binding --clusterrole=system:node --user=kubelet\n在整个集群范围内将 view ClusterRole 授予命名空间”acme” 内的服务账户”myapp”：\nkubectl create clusterrolebinding myapp-view-binding --clusterrole=view --serviceaccount=acme:myapp\n请参阅 CLI 帮助文档以获得上述命令的详细用法\n服务账户（Service Account）权限 link默认的 RBAC 策略将授予控制平面组件（control-plane component）、节点（node）和控制器（controller）一组范围受限的权限， 但对于”kube-system” 命名空间以外的服务账户，则 * 不授予任何权限 *（超出授予所有认证用户的发现权限）。\n这一点允许您根据需要向特定服务账号授予特定权限。 细粒度的角色绑定将提供更好的安全性，但需要更多精力管理。 更粗粒度的授权可能授予服务账号不需要的 API 访问权限（甚至导致潜在授权扩散），但更易于管理。\n从最安全到最不安全可以排序以下方法：\n对某一特定应用程序的服务账户授予角色（最佳实践）\n要求应用程序在其 pod 规范（pod spec）中指定 serviceAccountName 字段，并且要创建相应服务账户（例如通过 API、应用程序清单或者命令 kubectl create serviceaccount 等）。\n例如，在”my-namespace” 命名空间中授予服务账户”my-sa” 只读权限：\nkubectl create rolebinding my-sa-view \\ --clusterrole=view \\ --serviceaccount=my-namespace:my-sa \\ --namespace=my-namespace 在某一命名空间中授予”default” 服务账号一个角色\n如果一个应用程序没有在其 pod 规范中指定 serviceAccountName，它将默认使用”default” 服务账号。\n注意：授予”default” 服务账号的权限将可用于命名空间内任何没有指定 serviceAccountName 的 pod。\n下面的例子将在”my-namespace” 命名空间内授予”default” 服务账号只读权限：\nkubectl create rolebinding default-view \\ --clusterrole=view \\ --serviceaccount=my-namespace:default \\ --namespace=my-namespace 目前，许多 加载项（addon） 作为”kube-system” 命名空间中的”default” 服务帐户运行。 要允许这些加载项使用超级用户访问权限，请将 cluster-admin 权限授予”kube-system” 命名空间中的”default” 服务帐户。 注意：启用上述操作意味着”kube-system” 命名空间将包含允许超级用户访问 API 的秘钥。\nkubectl create clusterrolebinding add-on-cluster-admin \\ --clusterrole=cluster-admin \\ --serviceaccount=kube-system:default 为命名空间中所有的服务账号授予角色\n如果您希望命名空间内的所有应用程序都拥有同一个角色，无论它们使用什么服务账户，您可以为该命名空间的服务账户用户组授予角色。\n下面的例子将授予”my-namespace” 命名空间中的所有服务账户只读权限：\nkubectl create rolebinding serviceaccounts-view \\ --clusterrole=view \\ --group=system:serviceaccounts:my-namespace \\ --namespace=my-namespace 对集群范围内的所有服务账户授予一个受限角色（不鼓励）\n如果您不想管理每个命名空间的权限，则可以将集群范围角色授予所有服务帐户。\n下面的例子将所有命名空间中的只读权限授予集群中的所有服务账户：\nkubectl create clusterrolebinding serviceaccounts-view \\ --clusterrole=view \\ --group=system:serviceaccounts 授予超级用户访问权限给集群范围内的所有服务帐户（强烈不鼓励）\n如果您根本不关心权限分块，您可以对所有服务账户授予超级用户访问权限。\n警告：这种做法将允许任何具有读取权限的用户访问 secret 或者通过创建一个容器的方式来访问超级用户的凭据。\nkubectl create clusterrolebinding serviceaccounts-cluster-admin \\ --clusterrole=cluster-admin \\ --group=system:serviceaccounts 从版本 1.5 升级 link在 Kubernetes 1.6 之前，许多部署使用非常宽泛的 ABAC 策略，包括授予对所有服务帐户的完整 API 访问权限。\n默认的 RBAC 策略将授予控制平面组件（control-plane components）、节点（nodes）和控制器（controller）一组范围受限的权限， 但对于”kube-system” 命名空间以外的服务账户，则 不授予任何权限（超出授予所有认证用户的发现权限）。\n虽然安全性更高，但这可能会影响到期望自动接收 API 权限的现有工作负载。 以下是管理此转换的两种方法：\n并行授权器（authorizer） link同时运行 RBAC 和 ABAC 授权器，并包括旧版 ABAC 策略：\n--authorization-mode=RBAC,ABAC --authorization-policy-file=mypolicy.jsonl\nRBAC 授权器将尝试首先授权请求。如果 RBAC 授权器拒绝 API 请求，则 ABAC 授权器将被运行。这意味着 RBAC 策略 或者 ABAC 策略所允许的任何请求都是可通过的。\n当以日志级别为 2 或更高（--v = 2）运行时，您可以在 API Server 日志中看到 RBAC 拒绝请求信息（以 RBAC DENY: 为前缀）。 您可以使用该信息来确定哪些角色需要授予哪些用户，用户组或服务帐户。 一旦 授予服务帐户角色，并且服务器日志中没有 RBAC 拒绝消息的工作负载正在运行，您可以删除 ABAC 授权器。\n宽泛的 RBAC 权限 link您可以使用 RBAC 角色绑定来复制一个宽泛的策略。\n警告：以下政策略允许所有服务帐户作为集群管理员。 运行在容器中的任何应用程序都会自动接收服务帐户凭据，并且可以对 API 执行任何操作，包括查看 secret 和修改权限。 因此，并不推荐使用这种策略。\nkubectl create clusterrolebinding permissive-binding \\ --clusterrole=cluster-admin \\ --user=admin \\ --user=kubelet \\ --group=system:serviceaccounts 参考 link 使用 RBAC 鉴权 - kubernetes.io "
            }
        );
    index.add(
            {
                id:  17 ,
                href: "\/docs\/information\/",
                title: "信息技术",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  18 ,
                href: "\/docs\/economy\/macroeconomics_base\/",
                title: "宏观经济学基础",
                description: "宏观经济学作为理解整体经济运行规律的重要学科，奥利维尔·布兰查德的经典教材《宏观经济学》系统性地构建了从短期到长期的分析框架。本文将以布兰查德的宏观经济学体系为基础，详细梳理宏观经济学的核心概念、基础模型和政策应用，通过理论阐释与实例分析相结合的方式，帮助读者建立起完整的宏观经济学知识架构。文章将从宏观经济的基本度量开始，逐步深入到商品市场、金融市场分析，进而探讨劳动力市场与总供给总需求模型，最后延伸至经济增长理论和开放经济下的宏观经济学，每个部分都将配以现实经济案例和数据分析，使抽象理论具象化，复杂模型清晰化。\n宏观经济的基本概念与度量 link国内生产总值(GDP)作为宏观经济学最核心的度量指标，是指在一定时期内(通常为一个季度或一年)，一个国家或地区经济中所生产出的全部最终产品和服务的市场价值总和。理解GDP需要把握几个关键特征：它仅包括最终产品价值而排除中间产品以避免重复计算；它是一个市场价值概念，通过货币衡量；仅包含市场活动导致的价值，非市场活动如家务劳动不计入；它是一个流量而非存量概念。GDP的核算主要有三种方法：生产法(总产出减中间投入)、收入法(劳动者报酬+生产税净额+固定资产折旧+营业盈余)和支出法(消费+投资+政府购买+净出口)。\n通货膨胀与失业是宏观经济运行的两大核心问题。通货膨胀指一般物价水平持续上涨的现象，而通货紧缩则相反。布兰查德特别强调了滞胀这一特殊现象——即高通胀与高失业同时存在的困境，如1970年代石油危机期间西方国家经历的状况。失业率衡量的是劳动力中没有工作但正在积极寻找工作的人口比例，而参与率则是劳动年龄人口中实际参与劳动市场的比例。这些指标共同反映了经济体的健康状况，例如2008年金融危机后，美国失业率一度飙升至10%，反映了经济的严重衰退。\n价格指数是衡量通胀水平的重要工具。GDP平减指数反映了国内生产的所有最终产品价格变化，而消费者价格指数(CPI)则衡量典型消费者购买的一篮子商品和服务的成本变化。例如，若某年GDP平减指数从100上升至105，则表示总体价格水平上涨了5%。布兰查德还介绍了购买力平价(PPP)理论，该理论认为长期来看汇率会调整至使不同国家一篮子商品价格相等的水平，这解释了为什么人均GDP按市场汇率和按PPP计算会有显著差异，如中国的人均GDP按PPP计算约为美国的六分之一。\n宏观经济学的分析通常分为三个时间维度：短期关注经济波动和稳定性政策，主要工具是IS-LM模型；中期分析经济如何回归自然产出水平，核心是AS-AD模型；长期则聚焦经济增长的决定因素，索洛模型是基本分析框架。这种时间维度的划分为理解复杂经济现象提供了清晰思路，例如面对2020年新冠疫情冲击时，各国政府首先采取短期稳定措施(如美国的2万亿美元刺激计划)，随后逐步转向中期结构调整，而长期则需考虑疫情对潜在增长的影响。\n表：GDP核算的三种方法比较\n核算方法 基本公式 主要构成 适用场景 生产法 GDP=总产出-中间投入 各产业部门增加值之和 分析产业结构变化 收入法 GDP=劳动者报酬+生产税净额+固定资产折旧+营业盈余 生产要素获得的收入 研究收入分配格局 支出法 GDP=C+I+G+(X-M) 消费、投资、政府购买、净出口 观察需求结构变化 宏观经济政策的目标通常包括：稳定物价(低通胀)、充分就业、经济增长和国际收支平衡。这些目标之间可能存在冲突，例如短期内刺激就业可能导致通胀压力上升，这正体现了菲利普斯曲线所描述的失业与通胀之间的替代关系。政策制定者需要在多重目标间寻求平衡，例如美联储在制定货币政策时既考虑就业市场状况也关注通胀预期，采用\"对称性通胀目标\"框架允许通胀率暂时高于2%的目标以支持就业。\n商品市场与IS曲线分析 link凯恩斯交叉模型构成了理解商品市场均衡的基础框架。该模型的核心在于计划支出等于实际产出的均衡条件，其中计划支出(E)由消费(C)、投资(I)和政府支出(G)组成：E = C(Y-T) + I + G。消费函数C = c0 + c1(Y-T)表明消费取决于自主消费c0和边际消费倾向c1(通常0",
                content: "宏观经济学作为理解整体经济运行规律的重要学科，奥利维尔·布兰查德的经典教材《宏观经济学》系统性地构建了从短期到长期的分析框架。本文将以布兰查德的宏观经济学体系为基础，详细梳理宏观经济学的核心概念、基础模型和政策应用，通过理论阐释与实例分析相结合的方式，帮助读者建立起完整的宏观经济学知识架构。文章将从宏观经济的基本度量开始，逐步深入到商品市场、金融市场分析，进而探讨劳动力市场与总供给总需求模型，最后延伸至经济增长理论和开放经济下的宏观经济学，每个部分都将配以现实经济案例和数据分析，使抽象理论具象化，复杂模型清晰化。\n宏观经济的基本概念与度量 link国内生产总值(GDP)作为宏观经济学最核心的度量指标，是指在一定时期内(通常为一个季度或一年)，一个国家或地区经济中所生产出的全部最终产品和服务的市场价值总和。理解GDP需要把握几个关键特征：它仅包括最终产品价值而排除中间产品以避免重复计算；它是一个市场价值概念，通过货币衡量；仅包含市场活动导致的价值，非市场活动如家务劳动不计入；它是一个流量而非存量概念。GDP的核算主要有三种方法：生产法(总产出减中间投入)、收入法(劳动者报酬+生产税净额+固定资产折旧+营业盈余)和支出法(消费+投资+政府购买+净出口)。\n通货膨胀与失业是宏观经济运行的两大核心问题。通货膨胀指一般物价水平持续上涨的现象，而通货紧缩则相反。布兰查德特别强调了滞胀这一特殊现象——即高通胀与高失业同时存在的困境，如1970年代石油危机期间西方国家经历的状况。失业率衡量的是劳动力中没有工作但正在积极寻找工作的人口比例，而参与率则是劳动年龄人口中实际参与劳动市场的比例。这些指标共同反映了经济体的健康状况，例如2008年金融危机后，美国失业率一度飙升至10%，反映了经济的严重衰退。\n价格指数是衡量通胀水平的重要工具。GDP平减指数反映了国内生产的所有最终产品价格变化，而消费者价格指数(CPI)则衡量典型消费者购买的一篮子商品和服务的成本变化。例如，若某年GDP平减指数从100上升至105，则表示总体价格水平上涨了5%。布兰查德还介绍了购买力平价(PPP)理论，该理论认为长期来看汇率会调整至使不同国家一篮子商品价格相等的水平，这解释了为什么人均GDP按市场汇率和按PPP计算会有显著差异，如中国的人均GDP按PPP计算约为美国的六分之一。\n宏观经济学的分析通常分为三个时间维度：短期关注经济波动和稳定性政策，主要工具是IS-LM模型；中期分析经济如何回归自然产出水平，核心是AS-AD模型；长期则聚焦经济增长的决定因素，索洛模型是基本分析框架。这种时间维度的划分为理解复杂经济现象提供了清晰思路，例如面对2020年新冠疫情冲击时，各国政府首先采取短期稳定措施(如美国的2万亿美元刺激计划)，随后逐步转向中期结构调整，而长期则需考虑疫情对潜在增长的影响。\n表：GDP核算的三种方法比较\n核算方法 基本公式 主要构成 适用场景 生产法 GDP=总产出-中间投入 各产业部门增加值之和 分析产业结构变化 收入法 GDP=劳动者报酬+生产税净额+固定资产折旧+营业盈余 生产要素获得的收入 研究收入分配格局 支出法 GDP=C+I+G+(X-M) 消费、投资、政府购买、净出口 观察需求结构变化 宏观经济政策的目标通常包括：稳定物价(低通胀)、充分就业、经济增长和国际收支平衡。这些目标之间可能存在冲突，例如短期内刺激就业可能导致通胀压力上升，这正体现了菲利普斯曲线所描述的失业与通胀之间的替代关系。政策制定者需要在多重目标间寻求平衡，例如美联储在制定货币政策时既考虑就业市场状况也关注通胀预期，采用\"对称性通胀目标\"框架允许通胀率暂时高于2%的目标以支持就业。\n商品市场与IS曲线分析 link凯恩斯交叉模型构成了理解商品市场均衡的基础框架。该模型的核心在于计划支出等于实际产出的均衡条件，其中计划支出(E)由消费(C)、投资(I)和政府支出(G)组成：E = C(Y-T) + I + G。消费函数C = c0 + c1(Y-T)表明消费取决于自主消费c0和边际消费倾向c1(通常0"
            }
        );
    index.add(
            {
                id:  19 ,
                href: "\/docs\/information\/software\/cloud\/service-discovery\/topology-aware-routing\/",
                title: "拓扑感知路由",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  20 ,
                href: "\/docs\/information\/secure\/modern_cryptography\/",
                title: "现代密码学",
                description: "定义 link现代密码学是研究如何在数学理论基础上实现信息安全的学科，其核心目标包括：\n机密性（防止信息泄露） 完整性（防止数据篡改） 认证性（验证身份真实性） 不可否认性（防止事后抵赖） 分类与技术实现 link一、对称密码学 link1. 分组密码 link DES（Data Encryption Standard）\n设计：基于Feistel结构（64位分组，56位密钥），使用S盒实现非线性变换 缺点：密钥长度不足，易受暴力破解（已被AES取代） AES（Advanced Encryption Standard）\n设计：SPN结构（128位分组，支持128/192/256位密钥），通过字节代换、行移位、列混淆和轮密钥加实现加密 优点：抗差分/线性密码分析，硬件实现高效 缺点：可能遭受旁路攻击（如时序分析） 2. 流密码 link RC4\n原理：通过伪随机数生成器（PRGA）产生密钥流 缺陷：密钥调度算法存在偏差，已发现多组弱密钥 ChaCha20\n优势：基于ARX结构（Add-Rotate-XOR），抗时序攻击，移动端性能优异 二、非对称密码学 link1. 公钥密码 link RSA\n数学基础：大整数分解问题（n = p×q） 密钥生成：选择大素数p/q，计算n和φ(n)，选取e满足gcd(e,φ(n))=1 缺点：计算量大，密钥长度需≥2048位 ECC（椭圆曲线密码）\n核心：椭圆曲线离散对数问题（ECDLP） 优势：相同安全强度下密钥更短（256位ECC ≈ 3072位RSA） 2. 数字签名 link DSA\n流程：基于Schnorr签名改进，使用模p域运算 局限：签名长度固定320位，但计算效率低于ECDSA ECDSA\n优化：在椭圆曲线上实现数字签名，资源消耗减少50% 三、哈希函数与完整性 link1. 密码学哈希 link SHA-256\n结构：Merkle-Damgård结构，32位字运算 抗性：强抗碰撞性（2^128次操作） SHA-3\n",
                content: "定义 link现代密码学是研究如何在数学理论基础上实现信息安全的学科，其核心目标包括：\n机密性（防止信息泄露） 完整性（防止数据篡改） 认证性（验证身份真实性） 不可否认性（防止事后抵赖） 分类与技术实现 link一、对称密码学 link1. 分组密码 link DES（Data Encryption Standard）\n设计：基于Feistel结构（64位分组，56位密钥），使用S盒实现非线性变换 缺点：密钥长度不足，易受暴力破解（已被AES取代） AES（Advanced Encryption Standard）\n设计：SPN结构（128位分组，支持128/192/256位密钥），通过字节代换、行移位、列混淆和轮密钥加实现加密 优点：抗差分/线性密码分析，硬件实现高效 缺点：可能遭受旁路攻击（如时序分析） 2. 流密码 link RC4\n原理：通过伪随机数生成器（PRGA）产生密钥流 缺陷：密钥调度算法存在偏差，已发现多组弱密钥 ChaCha20\n优势：基于ARX结构（Add-Rotate-XOR），抗时序攻击，移动端性能优异 二、非对称密码学 link1. 公钥密码 link RSA\n数学基础：大整数分解问题（n = p×q） 密钥生成：选择大素数p/q，计算n和φ(n)，选取e满足gcd(e,φ(n))=1 缺点：计算量大，密钥长度需≥2048位 ECC（椭圆曲线密码）\n核心：椭圆曲线离散对数问题（ECDLP） 优势：相同安全强度下密钥更短（256位ECC ≈ 3072位RSA） 2. 数字签名 link DSA\n流程：基于Schnorr签名改进，使用模p域运算 局限：签名长度固定320位，但计算效率低于ECDSA ECDSA\n优化：在椭圆曲线上实现数字签名，资源消耗减少50% 三、哈希函数与完整性 link1. 密码学哈希 link SHA-256\n结构：Merkle-Damgård结构，32位字运算 抗性：强抗碰撞性（2^128次操作） SHA-3\n创新：海绵结构（Sponge Construction），抗长度扩展攻击 2. 消息认证码（MAC） link HMAC 公式：HMAC(K,m) = H((K⊕opad) || H((K⊕ipad)||m)) 优势：可结合任意哈希函数，保证消息来源可信 数学基础 link 领域 核心应用场景 数论 RSA密钥生成、离散对数问题 有限域理论 AES列混淆、ECC点运算 概率论 生日攻击分析（哈希碰撞概率） 组合数学 S盒设计优化（非线性度最大化） 算法对比与选型 link 类型 典型算法 优点 缺点 适用场景 对称加密 AES-GCM 高速、支持认证加密 密钥分发需安全通道 大数据量加密 非对称加密 ECC 密钥短、计算效率高 实现复杂度较高 密钥协商、证书 哈希函数 SHA3-512 抗量子攻击潜力 计算资源消耗较大 区块链、数字取证 数字签名 EdDSA 确定式随机数、抗侧信道 兼容性待提升 物联网设备认证 总结与展望 link现代密码学构建了三大支柱技术：\n对称加密解决高效加密问题 非对称加密突破密钥分发瓶颈 哈希函数保障数据完整性 未来发展方向：\n后量子密码（NTRU、Lattice-based） 同态加密（全同态算法优化） 多方安全计算（隐私保护升级） 数学理论的突破将继续推动密码学发展，而软硬件协同优化将成为工程实现的关键挑战。\n"
            }
        );
    index.add(
            {
                id:  21 ,
                href: "\/docs\/information\/communication\/",
                title: "通信",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  22 ,
                href: "\/docs\/information\/software\/cloud\/service-discovery\/ingress\/",
                title: "Ingress",
                description: "Ingress 是从 Kubernetes 集群外部访问集群内部服务的入口，这篇文章部分译自 Kubernetes 官方文档 Ingress Resource，后面的章节会讲到使用 Traefik 来做 Ingress controller，文章末尾给出了几个相关链接。\n",
                content: "Ingress 是从 Kubernetes 集群外部访问集群内部服务的入口，这篇文章部分译自 Kubernetes 官方文档 Ingress Resource，后面的章节会讲到使用 Traefik 来做 Ingress controller，文章末尾给出了几个相关链接。\n**术语 **\n在本篇文章中你将会看到一些在其他地方被交叉使用的术语，为了防止产生歧义，我们首先来澄清下。\n节点：Kubernetes 集群中的一台物理机或者虚拟机。 集群：位于 Internet 防火墙后的节点，这是 kubernetes 管理的主要计算资源。 边界路由器：为集群强制执行防火墙策略的路由器。 这可能是由云提供商或物理硬件管理的网关。 集群网络：一组逻辑或物理链接，可根据 Kubernetes 网络模型 实现群集内的通信。 集群网络的实现包括 Overlay 模型的 flannel 和基于 SDN 的 OVS。 服务：使用标签选择器标识一组 pod 成为的 Kubernetes 服务。 除非另有说明，否则服务假定在集群网络内仅可通过虚拟 IP 访问。 什么是 Ingress？ link通常情况下，service 和 pod 仅可在集群内部网络中通过 IP 地址访问。所有到达边界路由器的流量或被丢弃或被转发到其他地方。从概念上讲，可能像下面这样：\ninternet | ------------ [Services] Ingress 是授权入站连接到达集群服务的规则集合。\ninternet | [Ingress] --|-----|-- [Services] 你可以给 Ingress 配置提供外部可访问的 URL、负载均衡、SSL、基于名称的虚拟主机等。用户通过 POST Ingress 资源到 API server 的方式来请求 ingress。 Ingress controller 负责实现 Ingress，通常使用负载均衡器，它还可以配置边界路由和其他前端，这有助于以高可用的方式处理流量。\n先决条件 link在使用 Ingress 资源之前，有必要先了解下面几件事情。\nIngress 资源对象在 Kubernetes 1.1 之前还没有。 你需要一个 Ingress Controller 来实现 Ingress，单纯的创建一个 Ingress 没有任何意义。 GCE/GKE 会在 master 节点上部署一个 ingress controller。你可以在一个 pod 中部署任意个自定义的 ingress controller。你必须正确地注解每个 ingress，比如运行多个 ingress controller 和关闭 glbc。 在非 GCE/GKE 的环境中，你需要在 pod 中 部署一个 controller，例如 Nginx Ingress Controller。 Ingress 资源 link最简化的 Ingress 配置如下。\n1: apiVersion: extensions/v1beta1 2: kind: Ingress 3: metadata: 4: name: test-ingress 5: spec: 6: rules: 7: - http: 8: paths: 9: - path: /testpath 10: backend: 11: serviceName: test 12: servicePort: 80 如果你没有配置 Ingress controller 就将其 POST 到 API server 不会有任何用处。\n配置说明\n**1-4 行 **：跟 Kubernetes 的其他配置一样，ingress 的配置也需要 apiVersion，kind 和 metadata 字段。配置文件的详细说明请查看 部署应用，配置容器 和使用资源。\n**5-7 行 **: Ingress spec 中包含配置一个 loadbalancer 或 proxy server 的所有信息。最重要的是，它包含了一个匹配所有入站请求的规则列表。目前 ingress 只支持 http 规则。\n**8-9 行 **：每条 http 规则包含以下信息：一个 host 配置项（比如 for.bar.com，在这个例子中默认是 *），path 列表（比如：/testpath），每个 path 都关联一个 backend(比如 test:80)。在 loadbalancer 将流量转发到 backend 之前，所有的入站请求都要先匹配 host 和 path。\n**10-12 行 **：正如 services doc 中描述的那样，backend 是一个 service:port 的组合。Ingress 的流量被转发到它所匹配的 backend。\n全局参数：为了简单起见，Ingress 示例中没有全局参数，请参阅资源完整定义的 API 参考。 在所有请求都不能跟 spec 中的 path 匹配的情况下，请求被发送到 Ingress controller 的默认后端，可以指定全局缺省 backend。\nIngress controller link为了使 Ingress 正常工作，集群中必须运行 Ingress controller。 这与其他类型的控制器不同，其他类型的控制器通常作为 kube-controller-manager 二进制文件的一部分运行，在集群启动时自动启动。 你需要选择最适合自己集群的 Ingress controller 或者自己实现一个。\nKubernetes 当前支持并维护 GCE 和 nginx 两种 controller F5（公司）支持并维护 F5 BIG-IP Controller for Kubernetes Kong 同时支持并维护 社区版 与 企业版 的 Kong Ingress Controller for Kubernetes Traefik 是功能齐全的 ingress controller（Let’s Encrypt, secrets, http2, websocket…）, Containous 也对其提供商业支持。 Istio 使用 CRD Gateway 来 控制 Ingress 流量。 在你开始前 link以下文档描述了 Ingress 资源中公开的一组跨平台功能。 理想情况下，所有的 Ingress controller 都应该符合这个规范，但是我们还没有实现。 GCE 和 Nginx 控制器的文档分别在 这里 和 这里。如果您使用 F5 BIG-IP controller，请参看 这里。\n确保您查看控制器特定的文档，以便您了解每个文档的注意事项。\nIngress 类型 link单 Service Ingress linkKubernetes 中已经存在一些概念可以暴露单个 service（查看 替代方案），但是你仍然可以通过 Ingress 来实现，通过指定一个没有 rule 的默认 backend 的方式。\ningress.yaml 定义文件：\napiVersion: extensions/v1beta1 kind: Ingress metadata: name: test-ingress spec: backend: serviceName: testsvc servicePort: 80 使用kubectl create -f命令创建，然后查看 ingress：\n$ kubectl get ing NAME RULE BACKEND ADDRESS test-ingress - testsvc:80 107.178.254.228 107.178.254.228 就是 Ingress controller 为了实现 Ingress 而分配的 IP 地址。RULE 列表示所有发送给该 IP 的流量都被转发到了 BACKEND 所列的 Kubernetes service 上。\n简单展开 link如前面描述的那样，kubernetes pod 中的 IP 只在集群网络内部可见，我们需要在边界设置一个东西，让它能够接收 ingress 的流量并将它们转发到正确的端点上。这个东西一般是高可用的 loadbalancer。使用 Ingress 能够允许你将 loadbalancer 的个数降低到最少，例如，假如你想要创建这样的一个设置：\nfoo.bar.com -\u003e 178.91.123.132 -\u003e /foo s1:80 /bar s2:80 你需要一个这样的 ingress：\napiVersion: extensions/v1beta1 kind: Ingress metadata: name: test spec: rules: - host: foo.bar.com http: paths: - path: /foo backend: serviceName: s1 servicePort: 80 - path: /bar backend: serviceName: s2 servicePort: 80 使用 kubectl create -f 创建完 ingress 后：\n$ kubectl get ing NAME RULE BACKEND ADDRESS test - foo.bar.com /foo s1:80 /bar s2:80 只要服务（s1，s2）存在，Ingress controller 就会将提供一个满足该 Ingress 的特定 loadbalancer 实现。 这一步完成后，您将在 Ingress 的最后一列看到 loadbalancer 的地址。\n基于名称的虚拟主机 linkName-based 的虚拟主机在同一个 IP 地址下拥有多个主机名。\nfoo.bar.com --| |-\u003e foo.bar.com s1:80 | 178.91.123.132 | bar.foo.com --| |-\u003e bar.foo.com s2:80 下面这个 ingress 说明基于 Host header 的后端 loadbalancer 的路由请求：\napiVersion: extensions/v1beta1 kind: Ingress metadata: name: test spec: rules: - host: foo.bar.com http: paths: - backend: serviceName: s1 servicePort: 80 - host: bar.foo.com http: paths: - backend: serviceName: s2 servicePort: 80 默认 backend：一个没有 rule 的 ingress，如前面章节中所示，所有流量都将发送到一个默认 backend。你可以用该技巧通知 loadbalancer 如何找到你网站的 404 页面，通过制定一些列 rule 和一个默认 backend 的方式。如果请求 header 中的 host 不能跟 ingress 中的 host 匹配，并且 / 或请求的 URL 不能与任何一个 path 匹配，则流量将路由到你的默认 backend。\nTLS link你可以通过指定包含 TLS 私钥和证书的 secret 来加密 Ingress。 目前，Ingress 仅支持单个 TLS 端口 443，并假定 TLS termination。 如果 Ingress 中的 TLS 配置部分指定了不同的主机，则它们将根据通过 SNI TLS 扩展指定的主机名（假如 Ingress controller 支持 SNI）在多个相同端口上进行复用。 TLS secret 中必须包含名为 tls.crt 和 tls.key 的密钥，这里面包含了用于 TLS 的证书和私钥，例如：\napiVersion: v1 data: tls.crt: base64 encoded cert tls.key: base64 encoded key kind: Secret metadata: name: testsecret namespace: default type: Opaque 在 Ingress 中引用这个 secret 将通知 Ingress controller 使用 TLS 加密从将客户端到 loadbalancer 的 channel：\napiVersion: extensions/v1beta1 kind: Ingress metadata: name: no-rules-map spec: tls: - secretName: testsecret backend: serviceName: s1 servicePort: 80 请注意，各种 Ingress controller 支持的 TLS 功能之间存在差距。 请参阅有关 nginx，GCE 或任何其他平台特定 Ingress controller 的文档，以了解 TLS 在你的环境中的工作原理。\nIngress controller 启动时附带一些适用于所有 Ingress 的负载平衡策略设置，例如负载均衡算法，后端权重方案等。更高级的负载平衡概念（例如持久会话，动态权重）尚未在 Ingress 中公开。 你仍然可以通过 service loadbalancer 获取这些功能。 随着时间的推移，我们计划将适用于跨平台的负载平衡模式加入到 Ingress 资源中。\n还值得注意的是，尽管健康检查不直接通过 Ingress 公开，但 Kubernetes 中存在并行概念，例如 准备探查，可以使你达成相同的最终结果。 请查看特定控制器的文档，以了解他们如何处理健康检查（nginx，GCE）。\n更新 Ingress link假如你想要向已有的 ingress 中增加一个新的 Host，你可以编辑和更新该 ingress：\n$ kubectl get ing NAME RULE BACKEND ADDRESS test - 178.91.123.132 foo.bar.com /foo s1:80 $ kubectl edit ing test 这会弹出一个包含已有的 yaml 文件的编辑器，修改它，增加新的 Host 配置。\nspec: rules: - host: foo.bar.com http: paths: - backend: serviceName: s1 servicePort: 80 path: /foo - host: bar.baz.com http: paths: - backend: serviceName: s2 servicePort: 80 path: /foo .. 保存它会更新 API server 中的资源，这会触发 ingress controller 重新配置 loadbalancer。\n$ kubectl get ing NAME RULE BACKEND ADDRESS test - 178.91.123.132 foo.bar.com /foo s1:80 bar.baz.com /foo s2:80 在一个修改过的 ingress yaml 文件上调用kubectl replace -f 命令一样可以达到同样的效果。\n跨可用域故障 link在不同云供应商之间，跨故障域的流量传播技术有所不同。 有关详细信息，请查看相关 Ingress controller 的文档。 有关在 federation 集群中部署 Ingress 的详细信息，请参阅 federation 文档。\n未来计划 link 多样化的 HTTPS/TLS 模型支持（如 SNI，re-encryption） 通过声明来请求 IP 或者主机名 结合 L4 和 L7 Ingress 更多的 Ingress controller 请跟踪 L7 和 Ingress 的 proposal，了解有关资源演进的更多细节，以及 Ingress repository，了解有关各种 Ingress controller 演进的更多详细信息。\n替代方案 link你可以通过很多种方式暴露 service 而不必直接使用 ingress：\n使用 Service.Type=LoadBalancer 使用 Service.Type=NodePort 使用 Port Proxy 部署一个 Service loadbalancer 这允许你在多个 service 之间共享单个 IP，并通过 Service Annotations 实现更高级的负载平衡。 参考 link Kubernetes Ingress Resource - kubernetes.io 使用 NGINX Plus 负载均衡 Kubernetes 服务 - dockone.io 使用 NGINX 和 NGINX Plus 的 Ingress Controller 进行 Kubernetes 的负载均衡 - cnblogs.com "
            }
        );
    index.add(
            {
                id:  23 ,
                href: "\/docs\/information\/software\/cloud\/auth\/networkpolicy\/",
                title: "NetworkPolicy",
                description: "网络策略说明一组 Pod 之间是如何被允许互相通信，以及如何与其它网络 Endpoint 进行通信。 NetworkPolicy 资源使用标签来选择 Pod，并定义了一些规则，这些规则指明允许什么流量进入到选中的 Pod 上。关于 Network Policy 的详细用法请参考 Kubernetes 官网。\nNetwork Policy 的作用对象是 Pod，也可以应用到 Namespace 和集群的 Ingress、Egress 流量。Network Policy 是作用在 L3/4 层的，即限制的是对 IP 地址和端口的访问，如果需要对应用层做访问限制需要使用如 Istio 这类 Service Mesh。\n",
                content: "网络策略说明一组 Pod 之间是如何被允许互相通信，以及如何与其它网络 Endpoint 进行通信。 NetworkPolicy 资源使用标签来选择 Pod，并定义了一些规则，这些规则指明允许什么流量进入到选中的 Pod 上。关于 Network Policy 的详细用法请参考 Kubernetes 官网。\nNetwork Policy 的作用对象是 Pod，也可以应用到 Namespace 和集群的 Ingress、Egress 流量。Network Policy 是作用在 L3/4 层的，即限制的是对 IP 地址和端口的访问，如果需要对应用层做访问限制需要使用如 Istio 这类 Service Mesh。\n前提条件 link网络策略通过网络插件来实现，所以必须使用一种支持 NetworkPolicy 的网络方案（如 calico）—— 非 Controller 创建的资源，是不起作用的。\n隔离的与未隔离的 Pod link默认 Pod 是未隔离的，它们可以从任何的源接收请求。 具有一个可以选择 Pod 的网络策略后，Pod 就会变成隔离的。 一旦 Namespace 中配置的网络策略能够选择一个特定的 Pod，这个 Pod 将拒绝任何该网络策略不允许的连接。（Namespace 中其它未被网络策略选中的 Pod 将继续接收所有流量）\nNetworkPolicy 资源 link下面是一个 NetworkPolicy 的例子：\napiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: test-network-policy namespace: default spec: podSelector: matchLabels: role: db policyTypes: - Ingress - Egress ingress: - from: - ipBlock: cidr: 172.17.0.0/16 except: - 172.17.1.0/24 - namespaceSelector: matchLabels: project: myproject - podSelector: matchLabels: role: frontend ports: - protocol: TCP port: 6379 egress: - to: - ipBlock: cidr: 10.0.0.0/24 ports: - protocol: TCP port: 5978 将上面配置 POST 到 API Server 将不起任何作用，除非选择的网络方案支持网络策略。\n必选字段：像所有其它 Kubernetes 配置一样， NetworkPolicy 需要 apiVersion、kind 和 metadata 这三个字段，关于如何使用配置文件的基本信息，可以查看 这里。\nspec：NetworkPolicy spec 具有在给定 Namespace 中定义特定网络的全部信息。\npodSelector：每个 NetworkPolicy 包含一个 podSelector，它可以选择一组应用了网络策略的 Pod。由于 NetworkPolicy 当前只支持定义 ingress 规则，这个 podSelector 实际上为该策略定义了一组 “目标Pod”。示例中的策略选择了标签为 “role=db” 的 Pod。一个空的 podSelector 选择了该 Namespace 中的所有 Pod。\ningress：每个NetworkPolicy 包含了一个白名单 ingress 规则列表。每个规则只允许能够匹配上 from 和 ports配置段的流量。示例策略包含了单个规则，它从这两个源中匹配在单个端口上的流量，第一个是通过namespaceSelector 指定的，第二个是通过 podSelector 指定的。\negress：每个NetworkPolicy 包含了一个白名单 ingress 规则列表。每个规则只允许能够匹配上 to 和 ports配置段的流量。示例策略包含了单个规则，它匹配目的地 10.0.0.0/24 单个端口的流量。\n因此，上面示例的 NetworkPolicy：\n在 “default” Namespace中 隔离了标签 “role=db” 的 Pod（如果他们还没有被隔离） 在 “default” Namespace中，允许任何具有 “role=frontend” 的 Pod，IP 范围在 172.17.0.0–172.17.0.255 和 172.17.2.0–172.17.255.255（整个 172.17.0.0/16 段， 172.17.1.0/24 除外）连接到标签为 “role=db” 的 Pod 的 TCP 端口 6379 允许在 Namespace 中任何具有标签 “project=myproject” ，IP范围在10.0.0.0/24段的 Pod，连接到 “default” Namespace 中标签为 “role=db” 的 Pod 的 TCP 端口 5978 查看 NetworkPolicy 入门指南给出的更进一步的例子。\n默认策略 link通过创建一个可以选择所有 Pod 但不允许任何流量的 NetworkPolicy，你可以为一个 Namespace 创建一个 “默认的” 隔离策略，如下所示：\napiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: default-deny spec: podSelector: 这确保了即使是没有被任何 NetworkPolicy 选中的 Pod，将仍然是被隔离的。\n可选地，在 Namespace 中，如果你想允许所有的流量进入到所有的 Pod（即使已经添加了某些策略，使一些 Pod 被处理为 “隔离的”），你可以通过创建一个策略来显式地指定允许所有流量：\napiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: allow-all spec: podSelector: ingress: - {} 参考 link Network Policies - kubernetes.io "
            }
        );
    index.add(
            {
                id:  24 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/node\/",
                title: "Node",
                description: "Node 是 Kubernetes 集群的工作节点，可以是物理机也可以是虚拟机。\nNode 的状态 linkNode 包括如下状态信息：\nAddress HostName：可以被 kubelet 中的 --hostname-override 参数替代。 ExternalIP：可以被集群外部路由到的 IP 地址。 InternalIP：集群内部使用的 IP，集群外部无法访问。 Condition OutOfDisk：磁盘空间不足时为 True Ready：Node controller 40 秒内没有收到 node 的状态报告为 Unknown，健康为 True，否则为 False。 MemoryPressure：当 node 有内存压力时为 True，否则为 False。 DiskPressure：当 node 有磁盘压力时为 True，否则为 False。 Capacity CPU 内存 可运行的最大 Pod 个数 Info：节点的一些版本信息，如 OS、kubernetes、docker 等 Node 管理 link禁止 Pod 调度到该节点上。\nkubectl cordon 驱逐该节点上的所有 Pod。\nkubectl drain 该命令会删除该节点上的所有 Pod（DaemonSet 除外），在其他 node 上重新启动它们，通常该节点需要维护时使用该命令。直接使用该命令会自动调用kubectl cordon 命令。当该节点维护完成，启动了 kubelet 后，再使用kubectl uncordon 即可将该节点添加到 kubernetes 集群中。\n",
                content: "Node 是 Kubernetes 集群的工作节点，可以是物理机也可以是虚拟机。\nNode 的状态 linkNode 包括如下状态信息：\nAddress HostName：可以被 kubelet 中的 --hostname-override 参数替代。 ExternalIP：可以被集群外部路由到的 IP 地址。 InternalIP：集群内部使用的 IP，集群外部无法访问。 Condition OutOfDisk：磁盘空间不足时为 True Ready：Node controller 40 秒内没有收到 node 的状态报告为 Unknown，健康为 True，否则为 False。 MemoryPressure：当 node 有内存压力时为 True，否则为 False。 DiskPressure：当 node 有磁盘压力时为 True，否则为 False。 Capacity CPU 内存 可运行的最大 Pod 个数 Info：节点的一些版本信息，如 OS、kubernetes、docker 等 Node 管理 link禁止 Pod 调度到该节点上。\nkubectl cordon 驱逐该节点上的所有 Pod。\nkubectl drain 该命令会删除该节点上的所有 Pod（DaemonSet 除外），在其他 node 上重新启动它们，通常该节点需要维护时使用该命令。直接使用该命令会自动调用kubectl cordon 命令。当该节点维护完成，启动了 kubelet 后，再使用kubectl uncordon 即可将该节点添加到 kubernetes 集群中。\n"
            }
        );
    index.add(
            {
                id:  25 ,
                href: "\/docs\/information\/software\/cloud\/storage\/volume\/",
                title: "Volume",
                description: "容器磁盘上的文件的生命周期是短暂的，这就使得在容器中运行重要应用时会出现一些问题。首先，当容器崩溃时，kubelet 会重启它，但是容器中的文件将丢失——容器以干净的状态（镜像最初的状态）重新启动。其次，在 Pod 中同时运行多个容器时，这些容器之间通常需要共享文件。Kubernetes 中的 Volume 抽象就很好的解决了这些问题。\n建议先熟悉 pod。\n背景 linkDocker 中也有一个 volume 的概念，尽管它稍微宽松一些，管理也很少。在 Docker 中，卷就像是磁盘或是另一个容器中的一个目录。它的生命周期不受管理，直到最近才有了 local-disk-backed 卷。Docker 现在提供了卷驱动程序，但是功能还非常有限（例如Docker1.7只允许每个容器使用一个卷驱动，并且无法给卷传递参数）。\n",
                content: "容器磁盘上的文件的生命周期是短暂的，这就使得在容器中运行重要应用时会出现一些问题。首先，当容器崩溃时，kubelet 会重启它，但是容器中的文件将丢失——容器以干净的状态（镜像最初的状态）重新启动。其次，在 Pod 中同时运行多个容器时，这些容器之间通常需要共享文件。Kubernetes 中的 Volume 抽象就很好的解决了这些问题。\n建议先熟悉 pod。\n背景 linkDocker 中也有一个 volume 的概念，尽管它稍微宽松一些，管理也很少。在 Docker 中，卷就像是磁盘或是另一个容器中的一个目录。它的生命周期不受管理，直到最近才有了 local-disk-backed 卷。Docker 现在提供了卷驱动程序，但是功能还非常有限（例如Docker1.7只允许每个容器使用一个卷驱动，并且无法给卷传递参数）。\n另一方面，Kubernetes 中的卷有明确的寿命——与封装它的 Pod 相同。所以，卷的生命比 Pod 中的所有容器都长，当这个容器重启时数据仍然得以保存。当然，当 Pod 不再存在时，卷也将不复存在。也许更重要的是，Kubernetes 支持多种类型的卷，Pod 可以同时使用任意数量的卷。\n卷的核心是目录，可能还包含了一些数据，可以通过 pod 中的容器来访问。该目录是如何形成的、支持该目录的介质以及其内容取决于所使用的特定卷类型。\n要使用卷，需要为 pod 指定为卷（spec.volumes 字段）以及将它挂载到容器的位置（spec.containers.volumeMounts 字段）。\n容器中的进程看到的是由其 Docker 镜像和卷组成的文件系统视图。Docker 镜像位于文件系统层次结构的根目录，任何卷都被挂载在镜像的指定路径中。卷无法挂载到其他卷上或与其他卷有硬连接。Pod 中的每个容器都必须独立指定每个卷的挂载位置。\n卷的类型 linkKubernetes 支持以下类型的卷：\nawsElasticBlockStore azureDisk azureFile cephfs csi downwardAPI emptyDir fc (fibre channel) flocker gcePersistentDisk gitRepo glusterfs hostPath iscsi local nfs persistentVolumeClaim projected portworxVolume quobyte rbd scaleIO secret storageos vsphereVolume 我们欢迎额外贡献。\nawsElasticBlockStore linkawsElasticBlockStore 卷将Amazon Web Services（AWS）EBS Volume 挂载到您的容器中。与 emptyDir 类型会在删除 Pod 时被清除不同，EBS 卷的的内容会保留下来，仅仅是被卸载。这意味着 EBS 卷可以预先填充数据，并且可以在数据包之间“切换”数据。\n重要提示：您必须使用 aws ec2 create-volume 或 AWS API 创建 EBS 卷，才能使用它。\n使用 awsElasticBlockStore 卷时有一些限制：\n运行 Pod 的节点必须是 AWS EC2 实例 这些实例需要与 EBS 卷位于相同的区域和可用区域 EBS 仅支持卷和 EC2 实例的一对一的挂载 创建 EBS 卷 link在 pod 中使用的 EBS 卷之前，您需要先创建它。\naws ec2 create-volume --availability-zone=eu-west-1a --size=10 --volume-type=gp2 确保区域与您启动集群的区域相匹配（并且检查大小和 EBS 卷类型是否适合您的使用！）\nAWS EBS 示例配置 link apiVersion: v1 kind: Pod metadata: name: test-ebs spec: containers: - image: k8s.gcr.io/test-webserver name: test-container volumeMounts: - mountPath: /test-ebs name: test-volume volumes: - name: test-volume # This AWS EBS volume must already exist. awsElasticBlockStore: volumeID: fsType: ext4 azureDisk linkAzureDisk 用于将 Microsoft Azure Data Disk 挂载到 Pod 中。\nazureFile linkazureFile 用于将 Microsoft Azure File Volume（SMB 2.1 和 3.0）挂载到 Pod 中。\ncephfs linkcephfs 卷允许将现有的 CephFS 卷挂载到您的容器中。不像 emptyDir，当删除 Pod 时被删除，cephfs 卷的内容将被保留，卷仅仅是被卸载。这意味着 CephFS 卷可以预先填充数据，并且可以在数据包之间“切换”数据。 CephFS 可以被多个写设备同时挂载。\n重要提示：您必须先拥有自己的 Ceph 服务器，然后才能使用它。\ncsi linkCSI 代表容器存储接口，CSI 试图建立一个行业标准接口的规范，借助 CSI 容器编排系统（CO）可以将任意存储系统暴露给自己的容器工作负载。有关详细信息，请查看设计方案。\ncsi 卷类型是一种 in-tree 的 CSI 卷插件，用于 Pod 与在同一节点上运行的外部 CSI 卷驱动程序交互。部署 CSI 兼容卷驱动后，用户可以使用 csi 作为卷类型来挂载驱动提供的存储。\nCSI 持久化卷支持是在 Kubernetes v1.9 中引入的，作为一个 alpha 特性，必须由集群管理员明确启用。换句话说，集群管理员需要在 apiserver、controller-manager 和 kubelet 组件的 “--feature-gates =” 标志中加上 “CSIPersistentVolume = true”。\nCSI 持久化卷具有以下字段可供用户指定：\ndriver：一个字符串值，指定要使用的卷驱动程序的名称。必须少于 63 个字符，并以一个字符开头。驱动程序名称可以包含 “.”、“- ”、“_” 或数字。 volumeHandle：一个字符串值，唯一标识从 CSI 卷插件的 CreateVolume 调用返回的卷名。随后在卷驱动程序的所有后续调用中使用卷句柄来引用该卷。 readOnly：一个可选的布尔值，指示卷是否被发布为只读。默认是 false。 downwardAPI linkdownwardAPI 卷用于使向下 API 数据（downward API data）对应用程序可用。它挂载一个目录，并将请求的数据写入纯文本文件。\n参考 downwardAPI 卷示例查看详细信息。\nemptyDir link当 Pod 被分配给节点时，首先创建 emptyDir 卷，并且只要该 Pod 在该节点上运行，该卷就会存在。正如卷的名字所述，它最初是空的。Pod 中的容器可以读取和写入 emptyDir 卷中的相同文件，尽管该卷可以挂载到每个容器中的相同或不同路径上。当出于任何原因从节点中删除 Pod 时，emptyDir 中的数据将被永久删除。\n注意：容器崩溃不会从节点中移除 pod，因此 emptyDir 卷中的数据在容器崩溃时是安全的。\nemptyDir 的用法有：\n暂存空间，例如用于基于磁盘的合并排序 用作长时间计算崩溃恢复时的检查点 Web服务器容器提供数据时，保存内容管理器容器提取的文件 Pod 示例 link apiVersion: v1 kind: Pod metadata: name: test-pd spec: containers: - image: k8s.gcr.io/test-webserver name: test-container volumeMounts: - mountPath: /cache name: cache-volume volumes: - name: cache-volume emptyDir: {} fc (fibre channel) linkfc 卷允许将现有的 fc 卷挂载到 pod 中。您可以使用卷配置中的 targetWWN 参数指定单个或多个目标全球通用名称（World Wide Name）。如果指定了多个 WWN，则 targetWWN 期望这些 WWN 来自多路径连接。\n重要提示：您必须配置 FC SAN 区域划分，并预先将这些 LUN（卷）分配并屏蔽到目标 WWN，以便 Kubernetes 主机可以访问它们。\n参考 FC 示例获取详细信息。\nflocker linkFlocker 是一款开源的集群容器数据卷管理器。它提供了由各种存储后端支持的数据卷的管理和编排。\nflocker 允许将 Flocker 数据集挂载到 pod 中。如果数据集在 Flocker 中不存在，则需要先使用 Flocker CLI 或使用 Flocker API 创建数据集。如果数据集已经存在，它将被 Flocker 重新连接到 pod 被调度的节点上。这意味着数据可以根据需要在数据包之间“切换”。\n重要提示：您必须先运行自己的 Flocker 安装程序才能使用它。\n参考 Flocker 示例获取更多详细信息。\ngcePersistentDisk linkgcePersistentDisk 卷将 Google Compute Engine（GCE）Persistent Disk 挂载到您的容器中。与删除 Pod 时删除的 emptyDir 不同，PD 的内容被保留，只是卸载了卷。这意味着 PD 可以预先填充数据，并且数据可以在 Pod 之间“切换”。\n重要提示：您必须先使用 gcloud 或 GCE API 或 UI 创建一个 PD，然后才能使用它。\n使用 gcePersistentDisk 时有一些限制：\n运行 Pod 的节点必须是 GCE 虚拟机 那些虚拟机需要在与 PD 一样在 GCE 项目和区域中 PD 的一个特点是它们可以同时被多个用户以只读方式挂载。这意味着您可以预先使用您的数据集填充 PD，然后根据需要给多个 Pod 中并行提供。不幸的是，只能由单个消费者以读写模式挂载 PD，而不允许同时写入。 在由 ReplicationController 控制的 pod 上使用 PD 将会失败，除非 PD 是只读的或者副本数是 0 或 1。\n创建 PD link在您在 pod 中使用 GCE PD 之前，需要先创建它。\ngcloud compute disks create --size=500GB --zone=us-central1-a my-data-disk Pod 示例 link apiVersion: v1 kind: Pod metadata: name: test-pd spec: containers: - image: k8s.gcr.io/test-webserver name: test-container volumeMounts: - mountPath: /test-pd name: test-volume volumes: - name: test-volume # This GCE PD must already exist. gcePersistentDisk: pdName: my-data-disk fsType: ext4 gitRepo linkgitRepo 卷是一个可以演示卷插件功能的示例。它会挂载一个空目录并将 git 存储库克隆到您的容器中。将来，这样的卷可能会转移到一个更加分离的模型，而不是为每个这样的用例扩展 Kubernetes API。\n下面是 gitRepo 卷示例：\napiVersion: v1 kind: Pod metadata: name: server spec: containers: - image: nginx name: nginx volumeMounts: - mountPath: /mypath name: git-volume volumes: - name: git-volume gitRepo: repository: \"git@somewhere:me/my-git-repository.git\" revision: \"22f1d8406d464b0c0874075539c1f2e96c253775\" glusterfs linkglusterfs 卷允许将 Glusterfs（一个开放源代码的网络文件系统）卷挂载到您的集群中。与删除 Pod 时删除的 emptyDir 不同，glusterfs 卷的内容将被保留，而卷仅仅被卸载。这意味着 glusterfs 卷可以预先填充数据，并且可以在数据包之间“切换”数据。 GlusterFS 可以同时由多个写入挂载。\n重要提示：您必须先自行安装 GlusterFS，才能使用它。\nhostPath linkhostPath 卷将主机节点的文件系统中的文件或目录挂载到集群中。该功能大多数 Pod 都用不到，但它为某些应用程序提供了一个强大的解决方法。\n例如，hostPath 的用途如下：\n运行需要访问 Docker 内部的容器；使用 /var/lib/docker 的 hostPath 在容器中运行 cAdvisor；使用 /dev/cgroups 的 hostPath 允许 pod 指定给定的 hostPath 是否应该在 pod 运行之前存在，是否应该创建，以及它应该以什么形式存在 除了所需的 path 属性之外，用户还可以为 hostPath 卷指定 type。\ntype 字段支持以下值：\n值 行为 空字符串（默认）用于向后兼容，这意味着在挂载 hostPath 卷之前不会执行任何检查。 DirectoryOrCreate 如果在给定的路径上没有任何东西存在，那么将根据需要在那里创建一个空目录，权限设置为 0755，与 Kubelet 具有相同的组和所有权。 Directory 给定的路径下必须存在目录 FileOrCreate 如果在给定的路径上没有任何东西存在，那么会根据需要创建一个空文件，权限设置为 0644，与 Kubelet 具有相同的组和所有权。 File 给定的路径下必须存在文件 Socket 给定的路径下必须存在 UNIX 套接字 CharDevice 给定的路径下必须存在字符设备 BlockDevice 给定的路径下必须存在块设备 使用这种卷类型是请注意，因为：\n由于每个节点上的文件都不同，具有相同配置（例如从 podTemplate 创建的）的 pod 在不同节点上的行为可能会有所不同 当 Kubernetes 按照计划添加资源感知调度时，将无法考虑 hostPath 使用的资源 在底层主机上创建的文件或目录只能由 root 写入。您需要在特权容器中以 root 身份运行进程，或修改主机上的文件权限以便写入 hostPath 卷 Pod 示例 link apiVersion: v1 kind: Pod metadata: name: test-pd spec: containers: - image: k8s.gcr.io/test-webserver name: test-container volumeMounts: - mountPath: /test-pd name: test-volume volumes: - name: test-volume hostPath: # directory location on host path: /data # this field is optional type: Directory iscsi linkiscsi 卷允许将现有的 iSCSI（SCSI over IP）卷挂载到容器中。不像 emptyDir，删除 Pod 时 iscsi 卷的内容将被保留，卷仅仅是被卸载。这意味着 iscsi 卷可以预先填充数据，并且这些数据可以在 pod 之间“切换”。\n重要提示：必须先创建自己的 iSCSI 服务器，然后才能使用它。\niSCSI 的一个特点是它可以同时被多个用户以只读方式安装。这意味着您可以预先使用您的数据集填充卷，然后根据需要向多个额 pod 同时提供。不幸的是，iSCSI 卷只能由单个使用者以读写模式挂载——不允许同时写入。\nlocal link这个 alpha 功能要求启用 PersistentLocalVolumes feature gate。\n注意：从 1.9 开始，VolumeScheduling feature gate 也必须启用。\nlocal 卷表示挂载的本地存储设备，如磁盘、分区或目录。\n本地卷只能用作静态创建的 PersistentVolume。\n与 HostPath 卷相比，local 卷可以以持久的方式使用，而无需手动将 pod 调度到节点上，因为系统会通过查看 PersistentVolume 上的节点关联性来了解卷的节点约束。\n但是，local 卷仍然受底层节点的可用性影响，并不适用于所有应用程序。\n以下是使用 local 卷的示例 PersistentVolume 规范：\napiVersion: v1 kind: PersistentVolume metadata: name: example-pv annotations: \"volume.alpha.kubernetes.io/node-affinity\": '{ \"requiredDuringSchedulingIgnoredDuringExecution\": { \"nodeSelectorTerms\": [ { \"matchExpressions\": [ { \"key\": \"kubernetes.io/hostname\", \"operator\": \"In\", \"values\": [\"example-node\"] } ]} ]} }' spec: capacity: storage: 100Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Delete storageClassName: local-storage local: path: /mnt/disks/ssd1 注意：本地 PersistentVolume 清理和删除需要手动干预，无外部提供程序。\n从 1.9 开始，本地卷绑定可以被延迟，直到通过具有 StorageClass 中的 WaitForFirstConsumer 设置为volumeBindingMode 的 pod 开始调度。请参阅示例。延迟卷绑定可确保卷绑定决策也可以使用任何其他节点约束（例如节点资源需求，节点选择器，pod 亲和性和 pod 反亲和性）进行评估。\n有关 local 卷类型的详细信息，请参见本地持久化存储用户指南。\nnfs linknfs 卷允许将现有的 NFS（网络文件系统）共享挂载到您的容器中。不像 emptyDir，当删除 Pod 时，nfs 卷的内容被保留，卷仅仅是被卸载。这意味着 NFS 卷可以预填充数据，并且可以在 pod 之间“切换”数据。 NFS 可以被多个写入者同时挂载。\n重要提示：您必须先拥有自己的 NFS 服务器才能使用它，然后才能使用它。\n有关更多详细信息，请参见 NFS 示例。\npersistentVolumeClaim linkpersistentVolumeClaim 卷用于将 PersistentVolume 挂载到容器中。PersistentVolumes 是在用户不知道特定云环境的细节的情况下“声明”持久化存储（例如 GCE PersistentDisk 或 iSCSI 卷）的一种方式。\n有关更多详细信息，请参阅 PersistentVolumes 示例。\nprojected linkprojected 卷将几个现有的卷源映射到同一个目录中。\n目前，可以映射以下类型的卷来源：\nsecret downwardAPI configMap 所有来源都必须在与 pod 相同的命名空间中。\n带有 secret、downward API 和 configmap 的 pod link apiVersion: v1 kind: Pod metadata: name: volume-test spec: containers: - name: container-test image: busybox volumeMounts: - name: all-in-one mountPath: \"/projected-volume\" readOnly: true volumes: - name: all-in-one projected: sources: - secret: name: mysecret items: - key: username path: my-group/my-username - downwardAPI: items: - path: \"labels\" fieldRef: fieldPath: metadata.labels - path: \"cpu_limit\" resourceFieldRef: containerName: container-test resource: limits.cpu - configMap: name: myconfigmap items: - key: config path: my-group/my-config 使用非默认权限模式设置多个 secret 的示例 pod link apiVersion: v1 kind: Pod metadata: name: volume-test spec: containers: - name: container-test image: busybox volumeMounts: - name: all-in-one mountPath: \"/projected-volume\" readOnly: true volumes: - name: all-in-one projected: sources: - secret: name: mysecret items: - key: username path: my-group/my-username - secret: name: mysecret2 items: - key: password path: my-group/my-password mode: 511 每个映射的卷来源在 sources 下的规格中列出。除了以下两个例外，参数几乎相同：\n对于 secret，secretName 字段已经被更改为 name 以与 ConfigMap 命名一致。 defaultMode 只能在映射级别指定，而不能针对每个卷源指定。但是，如上所述，您可以明确设置每个映射的 mode。 portworxVolume linkportworxVolume 是一个与 Kubernetes 一起，以超融合模式运行的弹性块存储层。Portwork 指纹存储在服务器中，基于功能的分层，以及跨多个服务器聚合容量。 Portworx 在虚拟机或裸机 Linux 节点上运行。\nportworxVolume 可以通过 Kubernetes 动态创建，也可以在 Kubernetes pod 中预先设置和引用。\n以下是一个引用预先配置的 PortworxVolume 的示例 pod：\napiVersion: v1 kind: Pod metadata: name: test-portworx-volume-pod spec: containers: - image: k8s.gcr.io/test-webserver name: test-container volumeMounts: - mountPath: /mnt name: pxvol volumes: - name: pxvol # This Portworx volume must already exist. portworxVolume: volumeID: \"pxvol\" fsType: \"\" 重要提示：在 pod 中使用之前，请确保您有一个名为 pxvol 的现有 PortworxVolume。\nquobyte linkquobyte 卷允许将现有的 Quobyte 卷挂载到容器中。\n重要提示：您必须先创建自己的 Quobyte 安装程序，然后才能使用它。\nrbd linkrbd 卷允许将 Rados Block Device 卷挂载到容器中。不像 emptyDir，删除 Pod 时 rbd 卷的内容被保留，卷仅仅被卸载。这意味着 RBD 卷可以预先填充数据，并且可以在 pod 之间“切换”数据。\n重要提示：您必须先自行安装 Ceph，然后才能使用 RBD。\nRBD 的一个特点是它可以同时为多个用户以只读方式挂载。这意味着可以预先使用您的数据集填充卷，然后根据需要同时为多个 pod 并行提供。不幸的是，RBD 卷只能由单个用户以读写模式安装——不允许同时写入。\nscaleIO linkScaleIO 是一个基于软件的存储平台，可以使用现有的硬件来创建可扩展的共享块网络存储集群。scaleIO 卷插件允许已部署的 pod 访问现有的 ScaleIO 卷（或者它可以为持久性卷声明动态调配新卷，请参阅 ScaleIO 持久卷）。\n重要提示：您必须有一个已经配置好的 ScaleIO 集群，并和创建的卷一同运行，然后才能使用它们。\n以下是使用 ScaleIO 的示例 pod 配置：\napiVersion: v1 kind: Pod metadata: name: pod-0 spec: containers: - image: k8s.gcr.io/test-webserver name: pod-0 volumeMounts: - mountPath: /test-pd name: vol-0 volumes: - name: vol-0 scaleIO: gateway: https://localhost:443/api system: scaleio protectionDomain: sd0 storagePool: sp1 volumeName: vol-0 secretRef: name: sio-secret fsType: xfs 有关更多详细信息，请参阅 ScaleIO 示例。\nsecret linksecret 卷用于将敏感信息（如密码）传递到 pod。您可以将 secret 存储在 Kubernetes API 中，并将它们挂载为文件，以供 Pod 使用，而无需直接连接到 Kubernetes。 secret 卷由 tmpfs（一个 RAM 支持的文件系统）支持，所以它们永远不会写入非易失性存储器。\n重要提示：您必须先在 Kubernetes API 中创建一个 secret，然后才能使用它。\nstorageOS linkstorageos 卷允许将现有的 StorageOS 卷挂载到容器中。\nStorageOS 在 Kubernetes 环境中以容器方式运行，使本地或附加存储可以从 Kubernetes 集群中的任何节点访问。可以复制数据以防止节点故障。精简配置和压缩可以提高利用率并降低成本。\nStorageOS 的核心是为容器提供块存储，可以通过文件系统访问。\nStorageOS 容器需要 64 位 Linux，没有额外的依赖关系。可以使用免费的开发者许可证。\n重要提示：您必须在每个要访问 StorageOS 卷的节点上运行 StorageOS 容器，或者为该池提供存储容量。相关的安装说明，请参阅 StorageOS文档。\napiVersion: v1 kind: Pod metadata: labels: name: redis role: master name: test-storageos-redis spec: containers: - name: master image: kubernetes/redis:v1 env: - name: MASTER value: \"true\" ports: - containerPort: 6379 volumeMounts: - mountPath: /redis-master-data name: redis-data volumes: - name: redis-data storageos: # The `redis-vol01` volume must already exist within StorageOS in the `default` namespace. volumeName: redis-vol01 fsType: ext4 vsphereVolume link先决条件：配置了 vSphere Cloud Provider 的 Kubernetes。\nvsphereVolume 用于将 vSphere VMDK 卷挂载到 Pod 中。卷的内容在卸载时会被保留。支持 VMFS 和 VSAN 数据存储。\n重要提示：在 Pod 中使用它之前，您必须使用以下一种方法创建 VMDK。\n创建 VMDK 卷 link选择以下方法之一来创建 VMDK。\n首先进入 ESX，然后使用以下命令创建一个 VMDK：\nvmkfstools -c 2G /vmfs/volumes/DatastoreName/volumes/myDisk.vmdk 使用下列命令创建一个 VMDK：\nvmware-vdiskmanager -c -t 0 -s 40GB -a lsilogic myDisk.vmdk vSphere VMDK 示例配置 link apiVersion: v1 kind: Pod metadata: name: test-vmdk spec: containers: - image: k8s.gcr.io/test-webserver name: test-container volumeMounts: - mountPath: /test-vmdk name: test-volume volumes: - name: test-volume # This VMDK volume must already exist. vsphereVolume: volumePath: \"[DatastoreName] volumes/myDisk\" fsType: ext4 更多的例子可以在这里找到。\n使用 subPath link有时，在单个容器中共享一个卷用于多个用途是有用的。volumeMounts.subPath 属性可用于在引用的卷内而不是其根目录中指定子路径。\n下面是一个使用单个共享卷的 LAMP 堆栈（Linux Apache Mysql PHP）的示例。 HTML 内容被映射到它的 html 目录，数据库将被存储在它的 mysql 目录中：\napiVersion: v1 kind: Pod metadata: name: my-lamp-site spec: containers: - name: mysql image: mysql env: - name: MYSQL_ROOT_PASSWORD value: \"rootpasswd\" volumeMounts: - mountPath: /var/lib/mysql name: site-data subPath: mysql - name: php image: php:7.0-apache volumeMounts: - mountPath: /var/www/html name: site-data subPath: html volumes: - name: site-data persistentVolumeClaim: claimName: my-lamp-site-data 资源 linkemptyDir 卷的存储介质（磁盘、SSD 等）由保存在 kubelet 根目录的文件系统的介质（通常是 /var/lib/kubelet）决定。 emptyDir 或 hostPath 卷可占用多少空间并没有限制，容器之间或 Pod 之间也没有隔离。\n在将来，我们预计 emptyDir 和 hostPath 卷将能够使用 resource 规范请求一定的空间，并选择要使用的介质，适用于具有多种媒体类型的集群。\nOut-of-Tree 卷插件 link除了之前列出的卷类型之外，存储供应商可以创建自定义插件而不将其添加到 Kubernetes 存储库中。可以通过使用 FlexVolume 插件来实现。\nFlexVolume使用户能够将供应商卷挂载到容器中。供应商插件是使用驱动程序实现的，该驱动程序支持由 FlexVolume API定义的一系列卷命令。驱动程序必须安装在每个节点的预定义卷插件路径中。\n挂载传播 link注意：挂载传播是 Kubernetes 1.8 中的一个 alpha 特性，在将来的版本中可能会重新设计甚至删除。\n挂载传播允许将由容器挂载的卷共享到同一个 Pod 中的其他容器上，甚至是同一节点上的其他 Pod。\n如果禁用 MountPropagation 功能，则不会传播 pod 中的卷挂载。也就是说，容器按照 Linux内核文档中所述的 private 挂载传播运行。\n要启用此功能，请在 --feature-gates 命令行选项中指定 MountPropagation = true。启用时，容器的 volumeMounts 字段有一个新的 mountPropagation 子字段。它的值为：\nHostToContainer：此卷挂载将接收所有后续挂载到此卷或其任何子目录的挂载。这是 MountPropagation 功能启用时的默认模式。\n同样的，如果任何带有 Bidirectional 挂载传播的 pod 挂载到同一个卷上，带有 HostToContainer 挂载传播的容器将会看到它。\n该模式等同于Linux内核文档中描述的 rslave 挂载传播。\nBidirectional 卷挂载与 HostToContainer 挂载相同。另外，由容器创建的所有卷挂载将被传播回主机和所有使用相同卷的容器的所有容器。\n此模式的一个典型用例是带有 Flex 卷驱动器或需要使用 HostPath 卷在主机上挂载某些内容的 pod。\n该模式等同于 Linux内核文档中所述的 rshared 挂载传播。\n小心：双向挂载传播可能是危险的。它可能会损坏主机操作系统，因此只能在特权容器中使用。强烈建议熟悉 Linux 内核行为。另外，容器在 Pod 中创建的任何卷挂载必须在容器终止时销毁（卸载）。\n参考 link Volumes - kubernetes.io\n使用持久化卷来部署 WordPress 和 MySQL - kubernetes.io\n"
            }
        );
    index.add(
            {
                id:  26 ,
                href: "\/docs\/develop\/demand\/",
                title: "个人需求：马斯洛理论",
                description: "马斯洛需求层次理论（Maslow’s Hierarchy of Needs）由美国心理学家亚伯拉罕·马斯洛（Abraham Maslow）于1943年提出，是心理学、管理学和教育学领域的经典理论。该理论将人类需求划分为五个层次，揭示了从基本生存需求到自我实现的心理发展路径。其核心观点是：人类行为由内在需求驱动，需求的满足遵循从低级到高级的递进规律。\n一、需求层次的结构 link马斯洛将需求分为五个层次，形似金字塔（后扩展为七层，但五层模型最广为人知）：\n生理需求（Physiological Needs）\n最底层是维持生存的基本需求，包括食物、水、空气、睡眠和性等。这些需求未满足时，人的行为会优先围绕其展开，例如饥饿时觅食是唯一目标。\n安全需求（Safety Needs）\n生理需求满足后，人开始追求安全与稳定，例如人身安全、健康保障、财产安全、工作稳定等。儿童对秩序的需求、成年人对储蓄的偏好均与此相关。\n归属与爱的需求（Love and Belonging Needs）\n社会性需求开始显现，表现为对友谊、家庭、亲密关系和社群归属的渴望。孤独感或社交排斥会引发心理问题。\n尊重需求（Esteem Needs）\n包括内在尊重（自信、成就感）和外在尊重（他人的认可、地位）。此阶段人希望展现能力、获得价值认同，需求未被满足可能导致自卑或无助感。\n自我实现需求（Self-Actualization）\n最高层次的需求，指个体追求潜能的最大化发挥，实现理想、创造价值。例如艺术家追求创作、科学家探索真理。马斯洛认为，只有少数人能够完全达到这一阶段。\n二、理论的核心观点 link 需求层级递进性：低级需求满足后，高级需求才会成为主导动机，但并非严格“全有或全无”。 动态性与灵活性：需求层次可能因突发事件（如灾难、失业）而倒退，不同文化中需求优先级可能变化。 超越性需求：后期马斯洛提出“自我超越”作为更高层次，即超越个人利益，追求宇宙意义或帮助他人成长。 三、理论的应用与批评 link应用领域：\n企业管理：通过满足员工安全、归属和尊重需求提升积极性。 教育：为学生提供安全环境以激发学习动力。 个人发展：帮助个体明确当前需求阶段，制定成长目标。 争议与批评：\n文化局限性：集体主义文化中，归属需求可能优先于个人成就。 实证支持不足：需求层次缺乏严格的科学验证，现实中人可能同时追求多层级需求。 过度理想化：贫困、战争等极端环境下，自我实现需求难以成为普遍目标。 四、现代意义 link尽管存在争议，马斯洛理论为理解人类动机提供了简洁框架。在当代社会，其启示在于：\n个人成长需兼顾物质与精神需求； 组织设计应关注成员的多层次需求； 幸福感源于需求的动态平衡，而非单一目标的实现。 结语\n马斯洛需求层次理论并非完美，但它像一盏明灯，指引我们探索人类复杂行为背后的深层动力。无论是个人追求幸福，还是社会构建和谐，这一模型都提醒我们：真正的满足，始于对“人”的全面理解。\n",
                content: "马斯洛需求层次理论（Maslow’s Hierarchy of Needs）由美国心理学家亚伯拉罕·马斯洛（Abraham Maslow）于1943年提出，是心理学、管理学和教育学领域的经典理论。该理论将人类需求划分为五个层次，揭示了从基本生存需求到自我实现的心理发展路径。其核心观点是：人类行为由内在需求驱动，需求的满足遵循从低级到高级的递进规律。\n一、需求层次的结构 link马斯洛将需求分为五个层次，形似金字塔（后扩展为七层，但五层模型最广为人知）：\n生理需求（Physiological Needs）\n最底层是维持生存的基本需求，包括食物、水、空气、睡眠和性等。这些需求未满足时，人的行为会优先围绕其展开，例如饥饿时觅食是唯一目标。\n安全需求（Safety Needs）\n生理需求满足后，人开始追求安全与稳定，例如人身安全、健康保障、财产安全、工作稳定等。儿童对秩序的需求、成年人对储蓄的偏好均与此相关。\n归属与爱的需求（Love and Belonging Needs）\n社会性需求开始显现，表现为对友谊、家庭、亲密关系和社群归属的渴望。孤独感或社交排斥会引发心理问题。\n尊重需求（Esteem Needs）\n包括内在尊重（自信、成就感）和外在尊重（他人的认可、地位）。此阶段人希望展现能力、获得价值认同，需求未被满足可能导致自卑或无助感。\n自我实现需求（Self-Actualization）\n最高层次的需求，指个体追求潜能的最大化发挥，实现理想、创造价值。例如艺术家追求创作、科学家探索真理。马斯洛认为，只有少数人能够完全达到这一阶段。\n二、理论的核心观点 link 需求层级递进性：低级需求满足后，高级需求才会成为主导动机，但并非严格“全有或全无”。 动态性与灵活性：需求层次可能因突发事件（如灾难、失业）而倒退，不同文化中需求优先级可能变化。 超越性需求：后期马斯洛提出“自我超越”作为更高层次，即超越个人利益，追求宇宙意义或帮助他人成长。 三、理论的应用与批评 link应用领域：\n企业管理：通过满足员工安全、归属和尊重需求提升积极性。 教育：为学生提供安全环境以激发学习动力。 个人发展：帮助个体明确当前需求阶段，制定成长目标。 争议与批评：\n文化局限性：集体主义文化中，归属需求可能优先于个人成就。 实证支持不足：需求层次缺乏严格的科学验证，现实中人可能同时追求多层级需求。 过度理想化：贫困、战争等极端环境下，自我实现需求难以成为普遍目标。 四、现代意义 link尽管存在争议，马斯洛理论为理解人类动机提供了简洁框架。在当代社会，其启示在于：\n个人成长需兼顾物质与精神需求； 组织设计应关注成员的多层次需求； 幸福感源于需求的动态平衡，而非单一目标的实现。 结语\n马斯洛需求层次理论并非完美，但它像一盏明灯，指引我们探索人类复杂行为背后的深层动力。无论是个人追求幸福，还是社会构建和谐，这一模型都提醒我们：真正的满足，始于对“人”的全面理解。\n"
            }
        );
    index.add(
            {
                id:  27 ,
                href: "\/docs\/information\/secure\/cryptographic_protocol\/",
                title: "密码协议",
                description: "一、密码协议：信任传递的规则体系 link1.1 认证协议 link挑战-响应协议\n# 典型挑战-响应流程 1. 客户端发送认证请求 2. 服务器生成随机数N（挑战） 3. 客户端用预共享密钥加密N生成响应R=H(K||N) 4. 服务器验证R的正确性 通过动态挑战值防止重放攻击，广泛应用于智能卡认证、双因素认证等场景。\n零知识证明\n基本原理：证明者在不透露秘密信息的前提下验证声明真实性 实用案例：ZK-SNARKs在区块链隐私交易中的应用 实现要素： 完备性（Valid proofs verify） 可靠性（False statements fail） 零知识性（No extra信息泄露） 1.2 安全通信协议 linkTLS 1.3握手流程革新\nsequenceDiagram Client-\u003e\u003eServer: ClientHello (支持算法列表) Server-\u003e\u003eClient: ServerHello (选定的算法) Server-\u003e\u003eClient: 数字证书 + 公钥 Client-\u003e\u003eServer: 预主密钥加密传输 双方-\u003e\u003e安全通道: 生成会话密钥 相比TLS 1.2的关键改进：\n消除不安全算法（如RSA密钥交换） 1-RTT快速握手 强制前向安全性 IPsec协议栈\n协议层 AH协议 ESP协议 功能 完整性验证 加密+完整性 头部位置 IP层 IP层 保护范围 完整数据包 仅载荷 二、密钥管理：安全体系的命脉 link2.1 PKI体系架构 linkX.509证书核心字段\n",
                content: "一、密码协议：信任传递的规则体系 link1.1 认证协议 link挑战-响应协议\n# 典型挑战-响应流程 1. 客户端发送认证请求 2. 服务器生成随机数N（挑战） 3. 客户端用预共享密钥加密N生成响应R=H(K||N) 4. 服务器验证R的正确性 通过动态挑战值防止重放攻击，广泛应用于智能卡认证、双因素认证等场景。\n零知识证明\n基本原理：证明者在不透露秘密信息的前提下验证声明真实性 实用案例：ZK-SNARKs在区块链隐私交易中的应用 实现要素： 完备性（Valid proofs verify） 可靠性（False statements fail） 零知识性（No extra信息泄露） 1.2 安全通信协议 linkTLS 1.3握手流程革新\nsequenceDiagram Client-\u003e\u003eServer: ClientHello (支持算法列表) Server-\u003e\u003eClient: ServerHello (选定的算法) Server-\u003e\u003eClient: 数字证书 + 公钥 Client-\u003e\u003eServer: 预主密钥加密传输 双方-\u003e\u003e安全通道: 生成会话密钥 相比TLS 1.2的关键改进：\n消除不安全算法（如RSA密钥交换） 1-RTT快速握手 强制前向安全性 IPsec协议栈\n协议层 AH协议 ESP协议 功能 完整性验证 加密+完整性 头部位置 IP层 IP层 保护范围 完整数据包 仅载荷 二、密钥管理：安全体系的命脉 link2.1 PKI体系架构 linkX.509证书核心字段\nCertificate: Version: v3 Serial Number: 0x0a:01:...:ff Signature Algorithm: ecdsa-with-SHA256 Issuer: C=CN, O=Example CA Validity: Not Before: 20240101 Not After: 20261231 Subject: CN=server.example.com Public Key: 04:9a:...:c2 Extensions: Key Usage: digitalSignature Subject Alternative Name: DNS:*.example.com 2.2 密钥生命周期管理 link全周期保护机制：\n生成：使用FIPS 140-2认证的HSM设备 分发：基于量子安全的KYBER算法 存储：TEE可信执行环境保护 轮换：定期更换策略（如TLS会话密钥每小时更新） 撤销：OCSP实时验证机制 三、安全性分析：攻防实战视角 link3.1 密码算法评估矩阵 link 攻击类型 AES-256 RSA-4096 ECC-384 穷举攻击 2^256次 因子分解 ECDLP问题 侧信道防护 缓存屏蔽 时间恒定 随机化标量 量子威胁 Grover算法 Shor算法 同受Shor威胁 3.2 经典漏洞案例分析 link心脏出血漏洞(Heartbleed)\n成因：OpenSSL 1.0.1-1.0.1f的心跳扩展未验证长度字段 漏洞利用： // 恶意构造心跳请求 struct heartbeat_packet { uint16_t payload_length; // 声明为65535 char payload[1]; // 实际仅1字节 } 后果：服务器返回64KB内存数据（可能包含私钥等敏感信息） 修复方案： 增加内存边界检查 使用带内存保护的实现（如Rust重写关键模块） 强制证书吊销与重新签发 四、前沿发展 link 后量子密码迁移：\nNIST标准化进展（CRYSTALS-Kyber等算法） 混合密钥交换方案（PQC + ECC） 隐私增强技术：\n同态加密在云计算中的应用 安全多方计算协议优化 硬件安全演进：\nTPM 2.0可信平台模块 Intel SGX/TDX机密计算 结语 link构建安全的密码系统需要协议设计、算法实现、密钥管理、安全审计的多维度协同。随着量子计算、AI攻防等新挑战的出现，密码协议与系统安全将持续演进，在保障数字世界可信交互的道路上发挥关键作用。\n"
            }
        );
    index.add(
            {
                id:  28 ,
                href: "\/docs\/math\/",
                title: "数学",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  29 ,
                href: "\/docs\/information\/data\/",
                title: "数据",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  30 ,
                href: "\/docs\/information\/data\/data_classification\/",
                title: "数据存储类型及特点",
                description: "数据存储技术根据不同的维度可划分为多种类型，每种类型针对特定场景和需求设计。以下是数据存储的主要分类及其核心特点：\n一、按存储介质分类 link1. 磁性存储 link 机械硬盘（HDD）\n特点：成本低、容量大，适合冷数据存储。 磁带\n特点：超低成本、长期归档，但读写速度慢。 2. 固态存储 link SSD\n特点：高性能、低延迟，适合热数据或实时处理场景。 3. 光存储 link 光盘/蓝光\n特点：长期保存、防篡改，适合归档（如医疗影像、法律文件）。 4. 内存存储 link RAM/缓存（如Redis）\n特点：超高速读写，用于临时数据或缓存层。 二、按数据格式和模型分类 link1. 结构化数据存储 link 关系型数据库（RDBMS）\n代表：MySQL、PostgreSQL\n场景：支持 ACID 事务，适合订单、用户信息等结构化数据。 2. 非结构化数据存储 link NoSQL 数据库 键值存储：Redis、DynamoDB（适合缓存或会话数据） 文档存储：MongoDB、Couchbase（存储 JSON/XML 文档） 列族存储：Cassandra、HBase（适合海量时序数据或日志） 图数据库：Neo4j、Amazon Neptune（高效处理关联关系） 对象存储\n代表：AWS S3、MinIO\n场景：存储文件、图片、视频等非结构化数据。 3. 半结构化数据存储 link 搜索引擎数据库\n代表：Elasticsearch\n特点：支持全文检索和复杂分析。 三、按使用场景分类 link1. 在线事务处理（OLTP） link 场景：高并发、低延迟的实时事务处理（如银行交易、电商订单）。 2. 在线分析处理（OLAP） link 代表：Snowflake、Redshift 场景：大数据分析，如数据仓库、实时数仓（ClickHouse、Druid）。 3. 时序数据存储 link 代表：InfluxDB、TimescaleDB 场景：物联网、监控数据等时间序列场景。 4. 日志存储 link 代表：Elasticsearch、Loki 特点：支持快速检索与分析。 5. 地理空间数据存储 link 代表：PostGIS（基于 PostgreSQL） 场景：处理地图、位置数据。 四、按架构类型分类 link1. 集中式存储 link NAS（网络附加存储）\n特点：文件级共享存储（如企业文件服务器）。 SAN（存储区域网络）\n特点：块级存储，高性能（如数据库存储）。 2. 分布式存储 link 分布式文件系统\n代表：HDFS、Ceph\n场景：大数据场景的横向扩展。 分布式数据库\n代表：CockroachDB、TiDB\n特点：高可用、全球部署能力。 3. 云存储 link 对象存储：AWS S3、Azure Blob Storage（适合海量非结构化数据） 块存储：AWS EBS（为云服务器提供持久化磁盘） 4. 边缘存储 link 场景：IoT 设备、CDN 边缘节点本地化存储。 五、按数据访问频率分类 link1. 热存储（Hot Storage） link 特点：频繁访问，使用 SSD 或内存存储（如 Redis）。 2. 温存储（Warm Storage） link 特点：中等访问频率，成本与性能平衡（如标准云存储）。 3. 冷存储（Cold Storage） link 代表：AWS Glacier、磁带库 特点：极少访问，低成本长期保存。 六、其他特殊类型 link1. 区块链存储 link 代表：IPFS、Arweave 特点：去中心化、不可篡改。 2. 内存数据库 link 代表：SAP HANA、VoltDB 特点：全量数据驻留内存，追求极致性能。 3. 多模型数据库 link 代表：ArangoDB 特点：同时支持键值、文档、图等多种数据模型。 总结与选型建议 link选择数据存储技术时需综合考虑以下因素：\n",
                content: "数据存储技术根据不同的维度可划分为多种类型，每种类型针对特定场景和需求设计。以下是数据存储的主要分类及其核心特点：\n一、按存储介质分类 link1. 磁性存储 link 机械硬盘（HDD）\n特点：成本低、容量大，适合冷数据存储。 磁带\n特点：超低成本、长期归档，但读写速度慢。 2. 固态存储 link SSD\n特点：高性能、低延迟，适合热数据或实时处理场景。 3. 光存储 link 光盘/蓝光\n特点：长期保存、防篡改，适合归档（如医疗影像、法律文件）。 4. 内存存储 link RAM/缓存（如Redis）\n特点：超高速读写，用于临时数据或缓存层。 二、按数据格式和模型分类 link1. 结构化数据存储 link 关系型数据库（RDBMS）\n代表：MySQL、PostgreSQL\n场景：支持 ACID 事务，适合订单、用户信息等结构化数据。 2. 非结构化数据存储 link NoSQL 数据库 键值存储：Redis、DynamoDB（适合缓存或会话数据） 文档存储：MongoDB、Couchbase（存储 JSON/XML 文档） 列族存储：Cassandra、HBase（适合海量时序数据或日志） 图数据库：Neo4j、Amazon Neptune（高效处理关联关系） 对象存储\n代表：AWS S3、MinIO\n场景：存储文件、图片、视频等非结构化数据。 3. 半结构化数据存储 link 搜索引擎数据库\n代表：Elasticsearch\n特点：支持全文检索和复杂分析。 三、按使用场景分类 link1. 在线事务处理（OLTP） link 场景：高并发、低延迟的实时事务处理（如银行交易、电商订单）。 2. 在线分析处理（OLAP） link 代表：Snowflake、Redshift 场景：大数据分析，如数据仓库、实时数仓（ClickHouse、Druid）。 3. 时序数据存储 link 代表：InfluxDB、TimescaleDB 场景：物联网、监控数据等时间序列场景。 4. 日志存储 link 代表：Elasticsearch、Loki 特点：支持快速检索与分析。 5. 地理空间数据存储 link 代表：PostGIS（基于 PostgreSQL） 场景：处理地图、位置数据。 四、按架构类型分类 link1. 集中式存储 link NAS（网络附加存储）\n特点：文件级共享存储（如企业文件服务器）。 SAN（存储区域网络）\n特点：块级存储，高性能（如数据库存储）。 2. 分布式存储 link 分布式文件系统\n代表：HDFS、Ceph\n场景：大数据场景的横向扩展。 分布式数据库\n代表：CockroachDB、TiDB\n特点：高可用、全球部署能力。 3. 云存储 link 对象存储：AWS S3、Azure Blob Storage（适合海量非结构化数据） 块存储：AWS EBS（为云服务器提供持久化磁盘） 4. 边缘存储 link 场景：IoT 设备、CDN 边缘节点本地化存储。 五、按数据访问频率分类 link1. 热存储（Hot Storage） link 特点：频繁访问，使用 SSD 或内存存储（如 Redis）。 2. 温存储（Warm Storage） link 特点：中等访问频率，成本与性能平衡（如标准云存储）。 3. 冷存储（Cold Storage） link 代表：AWS Glacier、磁带库 特点：极少访问，低成本长期保存。 六、其他特殊类型 link1. 区块链存储 link 代表：IPFS、Arweave 特点：去中心化、不可篡改。 2. 内存数据库 link 代表：SAP HANA、VoltDB 特点：全量数据驻留内存，追求极致性能。 3. 多模型数据库 link 代表：ArangoDB 特点：同时支持键值、文档、图等多种数据模型。 总结与选型建议 link选择数据存储技术时需综合考虑以下因素：\n数据模型：结构化（RDBMS） vs 非结构化（NoSQL/对象存储） 性能需求：延迟敏感（SSD/内存） vs 吞吐量优先（分布式存储） 扩展性：水平扩展（Cassandra/HDFS） vs 垂直扩展（传统数据库） 成本：热存储成本 \u003e 冷存储成本 场景特性：事务（OLTP） vs 分析（OLAP） 典型混合架构示例：\n热数据：Redis 缓存 核心业务数据：MySQL/PostgreSQL 日志数据：Elasticsearch 非结构化文件：对象存储（如 S3） 历史归档：冷存储（如 Glacier） "
            }
        );
    index.add(
            {
                id:  31 ,
                href: "\/docs\/information\/software\/cloud\/service-discovery\/",
                title: "服务发现",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  32 ,
                href: "\/docs\/economy\/financial_market_base\/",
                title: "金融市场基础",
                description: "一、金融市场的核心资产类别 link1. 股票（Equities） link定义与本质： 股票代表公司所有权的份额，持有者（股东）对公司资产和收益拥有剩余索取权。股票市场是企业直接融资的重要渠道，也是投资者参与企业成长的主要方式。\n关键特征：\n永久性资本：无到期日，除非公司回购或私有化 收益构成：资本增值（股价上涨）+股息收入 投票权：普通股通常享有公司治理权（特殊类别股除外） 有限责任：股东损失不超过投资金额 主要类型：\n普通股：基本所有权形式，具有投票权和分红权 优先股：固定股息优先权，通常无投票权，清算时优先受偿 存托凭证（如ADR/GDR）：跨境上市的变通形式 估值要素：\n基本面分析：PE比率、PB比率、股息率、自由现金流 市场情绪：投资者预期、行业轮动、宏观经济环境 风险维度：\n系统性风险（市场整体波动） 非系统性风险（公司特定风险，可通过分散化降低） 2. 债券（Fixed Income Securities） link定义与本质： 债券是发行人（政府/企业）与投资者之间的债权债务契约，承诺按期支付利息并到期偿还本金。债券市场是债务融资的核心场所。\n核心要素：\n票面利率：固定或浮动利息支付率 到期期限：短期（1年内）、中期（1-10年）、长期（10年以上） 信用质量：由评级机构（穆迪、标普等）评估的违约风险 主要品种：\n国债：国家信用背书，视为无风险利率基准 市政债券：地方政府发行，常具税收优惠 公司债：企业发行，收益率反映信用风险 资产证券化产品：MBS、ABS等基于底层资产的结构化债券 定价机制：\n与市场利率反向变动：Price = ∑(C/(1+r)^t) + FV/(1+r)^n 收益率曲线：反映不同期限利率结构的关键指标 风险类型：\n利率风险（久期衡量） 信用风险（违约可能性） 流动性风险（市场深度不足） 再投资风险（现金流再投资收益率下降） 3. 期货（Futures） link定义与本质： 标准化合约，约定未来特定时间以确定价格买卖标的资产。期货市场最初为对冲商品价格风险而生，现已扩展到金融资产。\n核心机制：\n标准化合约：交易所统一规定合约规模、交割品质等 保证金交易：杠杆效应（通常5-15%保证金比例） 每日无负债结算：Mark-to-Market制度 交割方式：实物交割或现金结算 主要类别：\n商品期货：原油、黄金、农产品等 金融期货：股指期货、国债期货、外汇期货 市场功能：\n价格发现：反映市场对未来价格的集体预期 风险管理：套期保值对冲现货风险 投机交易：利用杠杆获取价差收益 定价基础：\n持有成本模型：F = S × e^(r-q)T 基差风险：现货与期货价格之差 4. 期权（Options） link定义与本质： 赋予持有者在特定日期或之前以约定价格买卖标的资产权利的合约。期权买方支付权利金获取选择权，卖方收取权利金承担义务。\n",
                content: "一、金融市场的核心资产类别 link1. 股票（Equities） link定义与本质： 股票代表公司所有权的份额，持有者（股东）对公司资产和收益拥有剩余索取权。股票市场是企业直接融资的重要渠道，也是投资者参与企业成长的主要方式。\n关键特征：\n永久性资本：无到期日，除非公司回购或私有化 收益构成：资本增值（股价上涨）+股息收入 投票权：普通股通常享有公司治理权（特殊类别股除外） 有限责任：股东损失不超过投资金额 主要类型：\n普通股：基本所有权形式，具有投票权和分红权 优先股：固定股息优先权，通常无投票权，清算时优先受偿 存托凭证（如ADR/GDR）：跨境上市的变通形式 估值要素：\n基本面分析：PE比率、PB比率、股息率、自由现金流 市场情绪：投资者预期、行业轮动、宏观经济环境 风险维度：\n系统性风险（市场整体波动） 非系统性风险（公司特定风险，可通过分散化降低） 2. 债券（Fixed Income Securities） link定义与本质： 债券是发行人（政府/企业）与投资者之间的债权债务契约，承诺按期支付利息并到期偿还本金。债券市场是债务融资的核心场所。\n核心要素：\n票面利率：固定或浮动利息支付率 到期期限：短期（1年内）、中期（1-10年）、长期（10年以上） 信用质量：由评级机构（穆迪、标普等）评估的违约风险 主要品种：\n国债：国家信用背书，视为无风险利率基准 市政债券：地方政府发行，常具税收优惠 公司债：企业发行，收益率反映信用风险 资产证券化产品：MBS、ABS等基于底层资产的结构化债券 定价机制：\n与市场利率反向变动：Price = ∑(C/(1+r)^t) + FV/(1+r)^n 收益率曲线：反映不同期限利率结构的关键指标 风险类型：\n利率风险（久期衡量） 信用风险（违约可能性） 流动性风险（市场深度不足） 再投资风险（现金流再投资收益率下降） 3. 期货（Futures） link定义与本质： 标准化合约，约定未来特定时间以确定价格买卖标的资产。期货市场最初为对冲商品价格风险而生，现已扩展到金融资产。\n核心机制：\n标准化合约：交易所统一规定合约规模、交割品质等 保证金交易：杠杆效应（通常5-15%保证金比例） 每日无负债结算：Mark-to-Market制度 交割方式：实物交割或现金结算 主要类别：\n商品期货：原油、黄金、农产品等 金融期货：股指期货、国债期货、外汇期货 市场功能：\n价格发现：反映市场对未来价格的集体预期 风险管理：套期保值对冲现货风险 投机交易：利用杠杆获取价差收益 定价基础：\n持有成本模型：F = S × e^(r-q)T 基差风险：现货与期货价格之差 4. 期权（Options） link定义与本质： 赋予持有者在特定日期或之前以约定价格买卖标的资产权利的合约。期权买方支付权利金获取选择权，卖方收取权利金承担义务。\n基本类型：\n看涨期权（Call）：买入标的资产的权利 看跌期权（Put）：卖出标的资产的权利 美式期权：可在到期前任何时间行权 欧式期权：仅能在到期日行权 价值构成：\n内在价值：立即行权可获收益（标的现价与行权价之差） 时间价值：合约剩余时间带来的潜在价值 定价模型：\nBlack-Scholes模型：考虑标的价、行权价、剩余时间、波动率、无风险利率 二叉树模型：离散时间框架下的定价方法 交易策略：\n保护性策略（如买入看跌期权对冲持股风险） 收益增强策略（如备兑看涨期权） 价差策略（垂直/水平/对角价差） 组合策略（跨式/宽跨式组合） 风险指标（希腊字母）：\nDelta：期权价格对标的资产价格变化的敏感度 Gamma：Delta的变化率 Vega：对波动率变化的敏感度 Theta：时间衰减的影响 Rho：对利率变化的敏感度 二、金融市场运行机制 link1. 交易规则体系 link市场类型：\n交易所市场（如NYSE、NASDAQ）：集中竞价，透明度高 场外市场（OTC）：双边协商，灵活性大 交易时段：\n常规交易时段（如美股9:30-16:00） 盘前/盘后交易（流动性较低） 集合竞价（开盘/收盘价格形成机制） 价格形成机制：\n连续竞价：订单实时匹配 做市商制度：提供买卖双向报价 拍卖机制：特定时点的集中撮合 交易限制：\n涨跌停板（部分市场设置每日价格波动上限） 熔断机制（市场剧烈波动时的暂停交易） 卖空限制（如uptick rule） 2. 订单类型详解 link基本订单类型：\n市价订单（Market Order）：立即以最优可用价格执行\n优点：执行确定性高 风险：滑点（实际成交价与预期偏差） 限价订单（Limit Order）：指定可接受的最差价格\n买入限价≤当前卖价方可立即成交 提供流动性（挂单等待对手方） 止损订单（Stop Order）：触发条件后转为市价单\n买入止损\u003e当前市价，卖出止损\u003c当前市价 常用于风险控制 高级订单类型：\n止损限价单（Stop-Limit）：触发后转为限价单 冰山订单（Iceberg）：仅显示部分订单规模 全或无（AON）：要求全部数量同时成交 立即成交否则取消（IOC）：部分成交后剩余自动撤销 有效至取消（GTC）：持续有效直至手动撤销 算法订单策略：\nTWAP（时间加权平均价格） VWAP（成交量加权平均价格） 狙击算法（捕捉流动性机会） 暗池寻单（寻找隐藏流动性） 3. 市场微观结构 link流动性维度：\n宽度（买卖价差）：Bid-Ask Spread反映即时交易成本 深度（订单簿厚度）：各价格档位的挂单数量 弹性：价格偏离后恢复的速度 市场参与者：\n流动性提供者：\n做市商：承担存货风险，赚取买卖价差 高频交易：通过快速报价获取微小价差 流动性消耗者：\n机构投资者：大额订单需分拆执行 零售投资者：通常为价格接受者 订单簿动态：\n价格优先/时间优先的撮合规则 隐藏订单与显示订单的相互作用 大额订单对市场情绪的冲击效应 交易成本构成：\n显性成本：佣金、税费 隐性成本：滑点、市场冲击成本 机会成本：未完成交易带来的潜在损失 市场质量评估指标：\n买卖价差比率（Spread/ Mid Price） 价格波动率（短期价格变化幅度） 订单执行率（订单完成比例） 信息效率（价格反映信息的速度） 三、市场间的相互作用 link跨市场联动：\n股债跷跷板效应（风险偏好变化） 大宗商品与通胀预期的关联 汇率变动对跨国资产的影响 套利机制：\n现货-期货套利（Cash-and-Carry） 跨市场套利（同一资产在不同市场的价差） ETF套利（净值与市价之间的折溢价） 流动性传导：\n主要市场的价格波动如何影响相关市场 危机时期的流动性枯竭与资产抛售螺旋 中央银行的流动性注入渠道 理解这些金融市场基础要素，是构建有效投资策略、实施风险管理以及把握市场机会的必要前提。不同资产类别各有特性，市场机制则构成了价格发现和交易执行的制度框架，二者共同塑造了金融市场的运行规律。\n"
            }
        );
    index.add(
            {
                id:  33 ,
                href: "\/docs\/information\/software\/cloud\/service-discovery\/gateway\/",
                title: "GatewayAPI",
                description: "除了直接使用 Service 和 Ingress 之外，Kubernetes 社区还发起了 Gateway API 项目，这是一个 CRD，可以帮助我们将 Kubernetes 中的服务暴露到集群外。\nGateway API 是一个由 SIG-NETWORK 管理的开源项目。该项目的目标是在 Kubernetes 生态系统中发展服务网络 API。Gateway API 提供了暴露 Kubernetes 应用的接口 ——Service、Ingress 等。\n",
                content: "除了直接使用 Service 和 Ingress 之外，Kubernetes 社区还发起了 Gateway API 项目，这是一个 CRD，可以帮助我们将 Kubernetes 中的服务暴露到集群外。\nGateway API 是一个由 SIG-NETWORK 管理的开源项目。该项目的目标是在 Kubernetes 生态系统中发展服务网络 API。Gateway API 提供了暴露 Kubernetes 应用的接口 ——Service、Ingress 等。\n该 API 在 Istio 中也被应用，用于将 Kubernetes 中的服务暴露到服务网格之外。\n目标 linkGateway API 旨在通过提供表现性的、可扩展的、面向角色的接口来改善服务网络，这些接口由许多厂商实现，并得到了业界的广泛支持。\nGateway API 是一个 API 资源的集合 —— Service、GatewayClass、Gateway、HTTPRoute、TCPRoute 等。使用这些资源共同为各种网络用例建模。\n下图中展示的是 Kubernetes 集群中四层和七层的网络配置。从图中可以看到通过将这些资源对象分离，可以实现配置上的解耦，由不同角色的人员来管理。\nflowchart TD subgraph 平台提供 GatewayClass end subgraph 平台运维提供 Gateway end subgraph 服务运维提供 HTTPRouter1 HTTPRouter2 end GatewayClass --\u003e Gateway Gateway --\u003e HTTPRouter1 Gateway --\u003e HTTPRouter2 HTTPRouter1 --\u003e Service1 HTTPRouter1 --\u003e Service2 HTTPRouter2 --\u003e Service3 HTTPRouter2 --\u003e Service4 Gateway 相较于 Ingress 做了哪些改进？ link更具表现力\nGateway 表达了更多的核心功能，比如基于头的匹配、流量加权和其他功能，而这些功能在 Ingress 中只能通过自定义方式实现。\n更具扩展性\nGateway API 允许在 API 的各个层次上链接自定义资源。这就允许在 API 结构的适当位置进行更精细的定制。\n面向角色\n它们被分离成不同的 API 资源，这些资源映射到 Kubernetes 上运行应用程序的常见角色。\n通用性\n这不是一种改进，而是应该保持不变。正如 Ingress 是一个具有众多实现的通用规范一样，Gateway API 被设计成一个由许多实现支持的可移植规范。\n共享网关\n它们允许独立的路由资源绑定到同一个网关，从而实现负载均衡器和 VIP 的共享。这允许团队安全地共享基础设施，而不需要直接协调。\n类型化后端引用\n通过类型化后端引用，Routes 可以引用 Kubernetes 服务，也可以引用任何一种被设计为 Gateway 后端的 Kubernetes 资源。\n跨命名空间引用\n跨越不同 Namespaces 的路由可以绑定到网关。这样，尽管对工作负载进行了命名空间划分，但仍可共享网络基础设施。\n类\nGatewayClasses 将负载均衡实现的类型形式化。这些类使用户可以很容易和明确地了解资源模型本身有什么样的能力。\n在了解了 Gateway API 的目的后，接下来我们再看下它的资源模型、请求流程、TLS 配置及扩展点等。\n角色 linkGateway API 开发者为其使用场景定义四类角色：\n基础设施提供方：如 AWS、GKE 等 集群运维：管理整个集群的计算、存储、网络、安全等 应用程序开发者：为自己开发的应用负责，管理应用的健壮性 应用管理员：不是所有的公司都有，通常在一些复杂系统中会有专门的应用管理员 资源模型 link注意：资源最初将作为 CRD 存在于 networking.x-k8s.io API 组中。未限定的资源名称将隐含在该 API 组中。\nGateway API 的资源模型中，主要有三种类型的对象：\nGatewayClass：定义了一组具有共同配置和行为的网关。 Gateway：请求一个点，在这个点上，流量可以被翻译到集群内的服务。 Route：描述了通过 Gateway 而来的流量如何映射到服务。 GatewayClass linkGatewayClass 定义了一组共享共同配置和行为的 Gateway，每个 GatewayClass 由一个控制器处理，但控制器可以处理多个 GatewayClass。\nGatewayClass 是一个集群范围的资源。必须至少定义一个 GatewayClass，Gateway 才能够生效。实现 Gateway API 的控制器通过关联的 GatewayClass 资源来实现，用户可以在自己的 Gateway 中引用该资源。\n这类似于 Ingress 的 IngressClass 和 PersistentVolumes 的 StorageClass。在 Ingress v1beta1 中，最接近 GatewayClass 的是 ingress-class 注解，而在 IngressV1 中，最接近的类似物是 IngressClass 对象。\nGateway linkGateway 描述了如何将流量翻译到集群内的服务。也就是说，它定义了一个方法，将流量从不了解 Kubernetes 的地方翻译到了解 Kubernetes 的地方。例如，由云负载均衡器、集群内代理或外部硬件负载均衡器发送到 Kubernetes 服务的流量。虽然许多用例的客户端流量源自集群的 “外部”，但这并不强求。\nGateway 定义了对实现 GatewayClass 配置和行为合同的特定负载均衡器配置的请求。该资源可以由运维人员直接创建，也可以由处理 GatewayClass 的控制器创建。\n由于 Gateway 规范捕获了用户意图，它可能不包含规范中所有属性的完整规范。例如，用户可以省略地址、端口、TLS 设置等字段。这使得管理 GatewayClass 的控制器可以为用户提供这些设置，从而使规范更加可移植。这种行为将通过 GatewayClass 状态对象来明确。\n一个 Gateway 可以包含一个或多个 Route 引用，这些 Route 引用的作用是将一个子集的流量引导到一个特定的服务上。\n{HTTP,TCP,Foo} Route linkRoute 对象定义了特定协议的规则，用于将请求从 Gateway 映射到 Kubernetes 服务。\nHTTPRoute 和 TCPRoute 是目前唯一已定义的 Route 对象。未来可能会添加其他特定协议的 Route 对象。\nBackendPolicy linkBackendPolicy 提供了一种配置 Gateway 和后端之间连接的方法。在这个 API 中，后端是指路由可以转发流量的任何资源。后端的一个常见例子是 Service。这个级别的配置目前仅限于 TLS，但将来会扩展到支持更高级的策略，如健康检查。\n一些后端配置可能会根据针对后端的 Route 而有所不同。在这些情况下，配置字段将放在 Route 上，而不是 BackendPolicy 上。有关该资源未来可能配置的更多信息，请参考相关的 GitHub issue。\n路由绑定 link当 Route 绑定到 Gateway 时，代表应用在 Gateway 上的配置，配置了底层的负载均衡器或代理。哪些 Route 如何绑定到 Gateway 是由资源本身控制的。Route 和 Gateway 资源具有内置的控制，以允许或限制它们之间如何相互选择。这对于强制执行组织政策以确定 Route 如何暴露以及在哪些 Gateway 上暴露非常有用。看下下面的例子。\n一个 Kubernetes 集群管理员在 Infra 命名空间中部署了一个名为 shared-gw 的 Gateway，供不同的应用团队使用，以便将其应用暴露在集群之外。团队 A 和团队 B（分别在命名空间 “A” 和 “B” 中）将他们的 Route 绑定到这个 Gateway。它们互不相识，只要它们的 Route 规则互不冲突，就可以继续隔离运行。团队 C 有特殊的网络需求（可能是性能、安全或关键性），他们需要一个专门的 Gateway 来代理他们的应用到集群外。团队 C 在 “C” 命名空间中部署了自己的 Gateway specialive-gw，该 Gateway 只能由 “C” 命名空间中的应用使用。\n不同命名空间及 Gateway 与 Route 的绑定关系如下图所示。\nflowchart TD subgraph infraNamespace SharedGW end subgraph namespace1 HTTPRouter1 end subgraph namespace2 HTTPRouter2 end subgraph namespace3 HTTPRouter3 end SharedGW --\u003e HTTPRouter1 SharedGW --\u003e HTTPRouter2 dedicatedGW --\u003e HTTPRouter3 在如何将路由与网关绑定以实现不同的组织政策和责任范围方面，有很大的灵活性。下面是网关和路由之间可能的对应关系：\n一对一：网关和路由可以由一个所有者部署和使用，并具有一对一的关系。团队 C 就是一个例子。 一对多：一个网关可以有许多路由与之绑定，这些路由由来自不同命名空间的不同团队所拥有。团队 A 和 B 就是这样的一个例子。 多对一：路由也可以绑定到多个网关，允许一个路由同时控制不同 IP、负载均衡器或网络上的应用暴露。 总之，网关选择路由，路由控制它们的暴露。当网关选择一个允许自己暴露的路由时，那么该路由将与网关绑定。当路由与网关绑定时，意味着它们的集体路由规则被配置在了由该网关管理的底层负载均衡器或代理服务器上。因此，网关是一个网络数据平面的逻辑表示，可以通过路由进行配置。\n路由选择 linkGateway 根据 Route 元数据，特别是 Route 资源的种类、命名空间和标签来选择 Route。Route 实际上被绑定到 Gateway 中的特定监听器上，因此每个监听器都有一个 listener.routes 字段，它通过以下一个或多个标准来选择 Route。\nLabel：Gateway 可以通过资源上存在的标签来选择 Route（类似于 Service 通过 Pod 标签选择 Pod 的方式）。 Kind：网关监听器只能选择单一类型的路由资源。可以是 HTTPRoute、TCPRoute 或自定义 Route 类型。 Namespace：Gateway 还可以通过 namespaces.from 字段控制可以从哪些 Namespace、 Route 中选择。它支持三种可能的值。 SameNamespace 是默认选项。只有与该网关相同的命名空间中的路由才会被选择。 All 将选择来自所有命名空间的 Route。 Selector 意味着该网关将选择由 Namespace 标签选择器选择的 Namespace 子集的 Route。当使用 Selector 时，那么 listeners.route.namespaces.selector 字段可用于指定标签选择器。All 或 SameNamespace 不支持该字段。 下面的 Gateway 将在集群中的所有 Namespace 中选择 expose: prod-web-gw 的所有 HTTPRoute 资源。\nkind: Gateway ... spec: listeners: - routes: kind: HTTPRoute selector: matchLabels: expose: prod-web-gw namespaces: from: All 路由暴露 link路由可以决定它们如何通过网关暴露。gateways.allow 字段支持三个值。\nAll：如果没有指定，则是默认值。这使得所有的 Route 标签和 Namespace 选择器都绑定在网关上。 SameNamespace 只允许该路由与来自同一 Namespace 的网关绑定。 FromList 允许指定一个明确的网关列表，以便路由与之绑定。 下面的 my-route Route 只选择 foo-namespace 中的 foo-gateway，而不能与其他 Gateway 绑定。注意，foo-gateway 与 my-route 在不同的 Namespace 中。如果 foo-gateway 允许跨 Namespace 绑定，并且也选择了这个 Route，那么 my-route 就会与之绑定。\nkind: HTTPRoute metadata: name: my-route namespace: bar-namespace spec: gateways: allow: FromList gatewayRefs: - name: foo-gateway namespace: foo-namespace 请注意，网关和路由的绑定是双向的。这意味着两个资源必须相互选择才能绑定。如果一个Gateway的Route标签选择器不匹配任何现有的Route，那么即使Route的spec.gateways.allow = All，也不会有任何东西与之绑定。同样，如果一个Route引用了一个特定的Gateway，但该Gateway没有选择Route的Namespace，那么它们也不会绑定。只有当两个资源相互选择时，才会发生绑定。\n从资源规范中可能并不总是能明显看出哪些网关和路由是绑定的，但可以通过资源状态来确定绑定。路由状态将列出路由所绑定的所有网关以及绑定的任何相关条件。\n组合类型 linkGatewayClass、Gateway、xRoute 和 Service 的组合将定义一个可实现的负载均衡器。下图说明了不同资源之间的关系。\nflowchart TD Gateway --\u003e GatewayClass Gateway --m~n--- *Route *Route --\u003e Service 请求流程 link使用反向代理实现的网关的一个典型的客户端 / 网关 API 请求流程是：\n客户端向 http://foo.example.com 发出请求。 DNS 将该名称解析为网关地址。 反向代理在 Listener 上接收请求，并使用 Host 头 来匹配 HTTPRoute。 可选地，反向代理可以根据 HTTPRoute 的匹配规则执行请求头和 / 或路径匹配。 可选地，反向代理可以根据 HTTPRoute 的过滤规则修改请求，即添加 / 删除头。 最后，反向代理可以根据 HTTPRoute 的 forwardTo 规则，将请求转发到集群中的一个或多个对象，即 Service。 TLS 配置 linkTLS 配置在 Gateway 监听器上。此外，对于某些自助服务用例，TLS 证书可以配置在路由对象上。\n扩展点 linkAPI 中提供了一些扩展点，以灵活处理大量通用 API 无法处理的用例。\n以下是 API 中扩展点的摘要。\nXRouteMatch.ExtensionRef：这个扩展点应该用来扩展特定核心 Route 的匹配语义。这是一个实验性的扩展点，未来会根据反馈进行迭代。 XForwardTo.BackendRef：这个扩展点应该用于将流量转发到核心 Kubernetes 服务资源以外的网络端点。例如 S3 bucket、Lambda 函数、文件服务器等。 HTTPRouteFilter：HTTPRoute 为这一 API 类型提供了一种方法，可以钩入 HTTP 请求的请求 / 响应生命周期。 自定义路由：如果上述扩展点都不能满足用例的需求，实现者可以选择为目前 API 中不支持的协议创建自定义路由资源。 参考 link kuberentes-sigs/gateway-api - github.com "
            }
        );
    index.add(
            {
                id:  34 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/namespace\/",
                title: "Namespace",
                description: "在一个 Kubernetes 集群中可以使用 namespace 创建多个 “虚拟集群”，这些 namespace 之间可以完全隔离，也可以通过某种方式，让一个 namespace 中的 service 可以访问到其他的 namespace 中的服务，比如 Traefik ingress 和 kube-systemnamespace 下的 service 就可以为整个集群提供服务，这些都需要通过 RBAC 定义集群级别的角色来实现。\n哪些情况下适合使用多个 namespace link因为 namespace 可以提供独立的命名空间，因此可以实现部分的环境隔离。当你的项目和人员众多的时候可以考虑根据项目属性，例如生产、测试、开发划分不同的 namespace。\nNamespace 使用 link**获取集群中有哪些 namespace **\nkubectl get ns\n集群中默认会有 default 和 kube-system 这两个 namespace。\n在执行 kubectl 命令时可以使用 -n 指定操作的 namespace。\n用户的普通应用默认是在 default 下，与集群管理相关的为整个集群提供服务的应用一般部署在 kube-system 的 namespace 下，例如我们在安装 kubernetes 集群时部署的 kubedns、heapseter、EFK 等都是在这个 namespace 下面。\n另外，并不是所有的资源对象都会对应 namespace，node 和 persistentVolume 就不属于任何 namespace。\n",
                content: "在一个 Kubernetes 集群中可以使用 namespace 创建多个 “虚拟集群”，这些 namespace 之间可以完全隔离，也可以通过某种方式，让一个 namespace 中的 service 可以访问到其他的 namespace 中的服务，比如 Traefik ingress 和 kube-systemnamespace 下的 service 就可以为整个集群提供服务，这些都需要通过 RBAC 定义集群级别的角色来实现。\n哪些情况下适合使用多个 namespace link因为 namespace 可以提供独立的命名空间，因此可以实现部分的环境隔离。当你的项目和人员众多的时候可以考虑根据项目属性，例如生产、测试、开发划分不同的 namespace。\nNamespace 使用 link**获取集群中有哪些 namespace **\nkubectl get ns\n集群中默认会有 default 和 kube-system 这两个 namespace。\n在执行 kubectl 命令时可以使用 -n 指定操作的 namespace。\n用户的普通应用默认是在 default 下，与集群管理相关的为整个集群提供服务的应用一般部署在 kube-system 的 namespace 下，例如我们在安装 kubernetes 集群时部署的 kubedns、heapseter、EFK 等都是在这个 namespace 下面。\n另外，并不是所有的资源对象都会对应 namespace，node 和 persistentVolume 就不属于任何 namespace。\n"
            }
        );
    index.add(
            {
                id:  35 ,
                href: "\/docs\/information\/software\/cloud\/auth\/spiffe\/",
                title: "SPIFFE",
                description: "SPIFFE，即每个人的安全生产身份框架（Secure Production Identity Framework for Everyone），是一套开源标准，用于在动态和异构环境中安全地进行身份识别。采用 SPIFFE 的系统无论在哪里运行，都可以轻松可靠地相互认证。\nSPIFFE 开源规范的核心是——通过简单 API 定义了一个短期的加密身份文件 SVID。然后，工作负载进行认证时可以使用该身份文件，例如建立 TLS 连接或签署和验证 JWT 令牌等。\nSPIFFE 已经在云原生应用中得到了大量的应用，尤其是在 Istio 和 Envoy 中。下面将向你介绍 SPIFFE 的一些基本概念。\n工作负载 link工作负载是个单一的软件，以特定的配置部署，用于单一目的；它可能包括软件的多个运行实例，所有这些实例执行相同的任务。工作负载这个术语可以包含一系列不同的软件系统定义，包括：\n一个运行 Python 网络应用程序的网络服务器，在一个虚拟机集群上运行，前面有一个负载均衡器。\n一个 MySQL 数据库的实例。\n一个处理队列中项目的 worker 程序。\n独立部署的系统的集合，它们一起工作，例如一个使用数据库服务的网络应用程序。网络应用程序和数据库也可以单独被视为工作负载。\n就 SPIFFE 而言，工作负载往往比物理或虚拟节点更加细化——通常细化到节点上的单个进程。这对工作负载来说至关重要，例如，在容器编排器中托管的工作负载，几个工作负载可能在同一个节点上（但彼此隔离）。\n就 SPIFFE 而言，一个工作负载也可能跨越许多节点。例如，一个可弹性扩展的网络服务器可能同时运行在许多机器上。\n虽然工作负载的粒度会因环境而异，但就 SPIFFE 而言，我们假设工作负载之间有足够好的隔离，这样恶意的工作负载就不能窃取他人的凭证。这种隔离的稳健性和实现的机制超出了 SPIFFE 的范围。\nSPIFFE ID linkSPIFFE ID 是一个字符串，可以唯一地、具体地标识一个工作负载。SPIFFE ID 也可以分配给工作负载所运行的中间系统（如一组虚拟机）。例如，spiffe://acme.com/billing/payments 是一个有效的SPIFFE ID。\nSPIFFE ID 是一个统一资源标识符（URI），其格式如下：spiffe://信任域/工作负载标识符。\n",
                content: "SPIFFE，即每个人的安全生产身份框架（Secure Production Identity Framework for Everyone），是一套开源标准，用于在动态和异构环境中安全地进行身份识别。采用 SPIFFE 的系统无论在哪里运行，都可以轻松可靠地相互认证。\nSPIFFE 开源规范的核心是——通过简单 API 定义了一个短期的加密身份文件 SVID。然后，工作负载进行认证时可以使用该身份文件，例如建立 TLS 连接或签署和验证 JWT 令牌等。\nSPIFFE 已经在云原生应用中得到了大量的应用，尤其是在 Istio 和 Envoy 中。下面将向你介绍 SPIFFE 的一些基本概念。\n工作负载 link工作负载是个单一的软件，以特定的配置部署，用于单一目的；它可能包括软件的多个运行实例，所有这些实例执行相同的任务。工作负载这个术语可以包含一系列不同的软件系统定义，包括：\n一个运行 Python 网络应用程序的网络服务器，在一个虚拟机集群上运行，前面有一个负载均衡器。\n一个 MySQL 数据库的实例。\n一个处理队列中项目的 worker 程序。\n独立部署的系统的集合，它们一起工作，例如一个使用数据库服务的网络应用程序。网络应用程序和数据库也可以单独被视为工作负载。\n就 SPIFFE 而言，工作负载往往比物理或虚拟节点更加细化——通常细化到节点上的单个进程。这对工作负载来说至关重要，例如，在容器编排器中托管的工作负载，几个工作负载可能在同一个节点上（但彼此隔离）。\n就 SPIFFE 而言，一个工作负载也可能跨越许多节点。例如，一个可弹性扩展的网络服务器可能同时运行在许多机器上。\n虽然工作负载的粒度会因环境而异，但就 SPIFFE 而言，我们假设工作负载之间有足够好的隔离，这样恶意的工作负载就不能窃取他人的凭证。这种隔离的稳健性和实现的机制超出了 SPIFFE 的范围。\nSPIFFE ID linkSPIFFE ID 是一个字符串，可以唯一地、具体地标识一个工作负载。SPIFFE ID 也可以分配给工作负载所运行的中间系统（如一组虚拟机）。例如，spiffe://acme.com/billing/payments 是一个有效的SPIFFE ID。\nSPIFFE ID 是一个统一资源标识符（URI），其格式如下：spiffe://信任域/工作负载标识符。\n工作负载标识符是一个信任域内的特定工作负载的唯一标识。\nSPIFFE 规范详细描述了 SPIFFE ID 的格式和使用。\n信任域 link信任域对应于系统的信任根。信任域可以代表个人、组织、环境或部门，运行他们自己独立的 SPIFFE 基础设施。在同一信任域中确定的所有工作负载都会被颁发身份文件，它们可以根据信任域的根密钥进行验证。\n通常建议将处于不同物理位置（如不同的数据中心或云区域）或应用不同安全实践的环境（如与生产环境相比的暂存或实验环境）的工作负载放在不同的信任域中。\nSPIFFE 可验证的身份文件（SVID） linkSVID（SPIFFE Verifiable Identity Document） 是工作负载向资源或调用者证明其身份的文件。如果 SVID 是由 SPIFFE ID 的信任域内的机构签发的，则被认为是有效的。\nSVID 包含一个 SPIFFE ID，代表了服务的身份。它将 SPIFFE ID 编码在一个可加密验证的文件中，目前支持两种格式：X.509 证书或 JWT 令牌。\n由于令牌容易受到重放攻击（replay attack），即在传输过程中获得令牌的攻击者可以使用它来冒充工作负载，因此建议尽可能使用 X.509-SVID。然而，在某些情况下，JWT令牌格式是唯一的选择，例如，当你的架构在两个工作负载之间有一个L7代理或负载均衡器。\n关于 SVID 的详细信息，请参阅 SVID 规范。\nSPIFFE 工作负载 API link工作负载 API 提供以下内容。\n对于X.509格式的身份文件（X.509-SVID）:\n其身份，描述为 SPIFFE ID。\n一个与该 ID 绑定的私钥，可用于代表工作负载签署数据。一个相应的短期 X.509 证书也将被创建，即 X509-SVID。这可以用来建立 TLS 或以其他方式对其他工作负载进行认证。\n一组证书——被称为信任包。一个工作负载用来验证另一个工作负载提出的X.509-SVID。\n对于 JWT 格式的身份文件（JWT-SVID）：\n其身份，描述为 SPIFFE ID\nJWT 令牌\n一组证书——被称为信任包，一个工作负载用来验证其他工作负载的身份。\n与 AWS EC2 实例元数据 API和 Google GCE 实例元数据 API 类似，工作负载 API 不要求调用的工作负载对自己的身份有任何了解，也不要求调用 API 时拥有任何认证令牌。这意味着你的应用程序不需要与工作负载共同部署任何认证密钥。\n然而，与这些其他 API 不同的是，Workload API 与平台无关，可以在进程级和内核级识别正在运行的服务，这使得它适合与 Kubernetes 等容器调度器一起使用。\n为了最大限度地减少密钥泄露的风险，所有私钥（和相应的证书）都是短期的，经常自动轮换。工作负载可以在相应的密钥过期前从工作负载API请求新的密钥和信任包。\n信任包 link当使用 X.509-SVID 时，目标工作负载使用信任包（Trust Bundle）来验证源工作负载的身份。信任包是一个或多个证书机构（CA）根证书的集合，工作负载认为这些证书是可信的。信任包包含 X.509 和 JWT SVID 的公钥材料。\n用来验证 X.509 SVID 的公钥材料是一组证书。用于验证 JWT 的公钥材料是一个原始公钥。信任包的内容是经常轮换的。工作负载在调用工作负载 API 时检索信任包。\n参考 link SPIFFE 官网 - spiffe.io "
            }
        );
    index.add(
            {
                id:  36 ,
                href: "\/docs\/develop\/value\/",
                title: "个人价值：冰山模型",
                description: "一、模型缘起与核心逻辑 link冰山理论最早由弗洛伊德提出，经美国心理学家麦克利兰发展为能力素质模型。个人价值冰山模型在此基础上演化而来，将人的综合价值比作海上冰山：\n可见部分（20%）：知识储备、技能证书、行为表现等显性要素 潜在部分（80%）：价值观、思维模式、情绪能力、内在动机等隐性特质 该模型揭示：决定个人发展上限的往往不是水面上的\"硬实力\"，而是深藏于意识底层的\"软素质\"。\n二、冰山分层解析 link 表层价值（冰山之上）\n知识体系：学历背景、专业资质 技能储备：语言能力、技术认证 行为输出：工作成果、社交表现 深层价值（冰山之下）\n自我认知：对自身优势/局限的清醒判断 价值取向：是非判断标准和人生优先级 思维模式：分析问题的角度与逻辑结构 情绪能力：压力管理、同理心、自我激励 底层动机：成就欲望、好奇心、利他精神 三、隐性特质的关键作用 link 决策质量：面对职业选择时，价值观决定方向取舍 逆境突破：成长型思维帮助突破能力天花板 关系构建：情绪智力影响团队协作效能 持续发展：内在动机驱动终身学习 典型案例：乔布斯对完美主义的执着（隐性价值）推动苹果突破性创新，远超其编程能力（显性价值）带来的影响。\n四、价值提升路径 link 显性层迭代：建立T型知识结构，保持技能更新 隐性层修炼： 通过反思日记强化自我认知 用正念冥想提升情绪觉察 构建多元思维模型（如芒格跨学科思维） 系统整合：将内在特质转化为可展示的行为成果 五、应用场景 link 职业规划：匹配深层价值观的工作带来持续动力 人才选拔：企业更关注冰山下的文化适应性 教育培养：家庭教育应侧重品格塑造而非单纯知识灌输 结语 link个人价值冰山模型提醒我们：在人工智能替代显性技能的时代，塑造强大的底层操作系统（价值观×思维×动机）才是核心竞争力。正如管理学家彼得·德鲁克所言：“预测未来的最好方式，就是创造它。“而创造未来的密钥，正藏在每个人的冰山之下。\n",
                content: "一、模型缘起与核心逻辑 link冰山理论最早由弗洛伊德提出，经美国心理学家麦克利兰发展为能力素质模型。个人价值冰山模型在此基础上演化而来，将人的综合价值比作海上冰山：\n可见部分（20%）：知识储备、技能证书、行为表现等显性要素 潜在部分（80%）：价值观、思维模式、情绪能力、内在动机等隐性特质 该模型揭示：决定个人发展上限的往往不是水面上的\"硬实力\"，而是深藏于意识底层的\"软素质\"。\n二、冰山分层解析 link 表层价值（冰山之上）\n知识体系：学历背景、专业资质 技能储备：语言能力、技术认证 行为输出：工作成果、社交表现 深层价值（冰山之下）\n自我认知：对自身优势/局限的清醒判断 价值取向：是非判断标准和人生优先级 思维模式：分析问题的角度与逻辑结构 情绪能力：压力管理、同理心、自我激励 底层动机：成就欲望、好奇心、利他精神 三、隐性特质的关键作用 link 决策质量：面对职业选择时，价值观决定方向取舍 逆境突破：成长型思维帮助突破能力天花板 关系构建：情绪智力影响团队协作效能 持续发展：内在动机驱动终身学习 典型案例：乔布斯对完美主义的执着（隐性价值）推动苹果突破性创新，远超其编程能力（显性价值）带来的影响。\n四、价值提升路径 link 显性层迭代：建立T型知识结构，保持技能更新 隐性层修炼： 通过反思日记强化自我认知 用正念冥想提升情绪觉察 构建多元思维模型（如芒格跨学科思维） 系统整合：将内在特质转化为可展示的行为成果 五、应用场景 link 职业规划：匹配深层价值观的工作带来持续动力 人才选拔：企业更关注冰山下的文化适应性 教育培养：家庭教育应侧重品格塑造而非单纯知识灌输 结语 link个人价值冰山模型提醒我们：在人工智能替代显性技能的时代，塑造强大的底层操作系统（价值观×思维×动机）才是核心竞争力。正如管理学家彼得·德鲁克所言：“预测未来的最好方式，就是创造它。“而创造未来的密钥，正藏在每个人的冰山之下。\n"
            }
        );
    index.add(
            {
                id:  37 ,
                href: "\/docs\/information\/secure\/",
                title: "安全",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  38 ,
                href: "\/docs\/information\/software\/cloud\/storage\/pv\/",
                title: "持久化卷（Persistent Volume）",
                description: "本文档介绍了 Kubernetes 中 PersistentVolume 的当前状态。建议您在阅读本文档前先熟悉 volume。\n介绍 link对于管理计算资源来说，管理存储资源明显是另一个问题。PersistentVolume 子系统为用户和管理员提供了一个 API，该 API 将如何提供存储的细节抽象了出来。为此，我们引入两个新的 API 资源：PersistentVolume 和 PersistentVolumeClaim。\nPersistentVolume（PV）是由管理员设置的存储，它是群集的一部分。就像节点是集群中的资源一样，PV 也是集群中的资源。 PV 是 Volume 之类的卷插件，但具有独立于使用 PV 的 Pod 的生命周期。此 API 对象包含存储实现的细节，即 NFS、iSCSI 或特定于云供应商的存储系统。\n",
                content: "本文档介绍了 Kubernetes 中 PersistentVolume 的当前状态。建议您在阅读本文档前先熟悉 volume。\n介绍 link对于管理计算资源来说，管理存储资源明显是另一个问题。PersistentVolume 子系统为用户和管理员提供了一个 API，该 API 将如何提供存储的细节抽象了出来。为此，我们引入两个新的 API 资源：PersistentVolume 和 PersistentVolumeClaim。\nPersistentVolume（PV）是由管理员设置的存储，它是群集的一部分。就像节点是集群中的资源一样，PV 也是集群中的资源。 PV 是 Volume 之类的卷插件，但具有独立于使用 PV 的 Pod 的生命周期。此 API 对象包含存储实现的细节，即 NFS、iSCSI 或特定于云供应商的存储系统。\nPersistentVolumeClaim（PVC）是用户存储的请求。它与 Pod 相似。Pod 消耗节点资源，PVC 消耗 PV 资源。Pod 可以请求特定级别的资源（CPU 和内存）。声明可以请求特定的大小和访问模式（例如，可以以读/写一次或 只读多次模式挂载）。\n虽然 PersistentVolumeClaims 允许用户使用抽象存储资源，但用户需要具有不同性质（例如性能）的 PersistentVolume 来解决不同的问题。集群管理员需要能够提供各种各样的 PersistentVolume，这些PersistentVolume 的大小和访问模式可以各有不同，但不需要向用户公开实现这些卷的细节。对于这些需求，StorageClass 资源可以实现。\n请参阅工作示例的详细过程。\n卷和声明的生命周期 linkPV 属于集群中的资源。PVC 是对这些资源的请求，也作为对资源的请求的检查。 PV 和 PVC 之间的相互作用遵循这样的生命周期：\n配置（Provision） link有两种方式来配置 PV：静态或动态。\n静态 link集群管理员创建一些 PV。它们带有可供群集用户使用的实际存储的细节。它们存在于 Kubernetes API 中，可用于消费。\n动态 link根据 StorageClasses，当管理员创建的静态 PV 都不匹配用户的 PersistentVolumeClaim 时，集群可能会尝试动态地为 PVC 创建卷。\n绑定 link在动态配置的情况下，用户创建或已经创建了具有特定存储量的 PersistentVolumeClaim 以及某些访问模式。master 中的控制环路监视新的 PVC，寻找匹配的 PV（如果可能），并将它们绑定在一起。如果为新的 PVC 动态调配 PV，则该环路将始终将该 PV 绑定到 PVC。否则，用户总会得到他们所请求的存储，但是容量可能超出要求的数量。一旦 PV 和 PVC 绑定后，PersistentVolumeClaim 绑定是排他性的，不管它们是如何绑定的。 PVC 跟 PV 绑定是一对一的映射。\n如果没有匹配的卷，声明将无限期地保持未绑定状态。随着匹配卷的可用，声明将被绑定。例如，配置了许多 50Gi PV的集群将不会匹配请求 100Gi 的PVC。将100Gi PV 添加到群集时，可以绑定 PVC。\n使用 linkPod 使用声明作为卷。集群检查声明以查找绑定的卷并为集群挂载该卷。对于支持多种访问模式的卷，用户指定在使用声明作为容器中的卷时所需的模式。\n用户进行了声明，并且该声明是绑定的，则只要用户需要，绑定的 PV 就属于该用户。用户通过在 Pod 的 volume 配置中包含 persistentVolumeClaim 来调度 Pod 并访问用户声明的 PV。\n持久化卷声明的保护 linkPVC 保护的目的是确保由 pod 正在使用的 PVC 不会从系统中移除，因为如果被移除的话可能会导致数据丢失。\n注意：当 pod 状态为 Pending 并且 pod 已经分配给节点或 pod 为 Running 状态时，PVC 处于活动状态。\n当启用PVC 保护 alpha 功能时，如果用户删除了一个 pod 正在使用的 PVC，则该 PVC 不会被立即删除。PVC 的删除将被推迟，直到 PVC 不再被任何 pod 使用。\n您可以看到，当 PVC 的状态为 Teminatiing 时，PVC 受到保护，Finalizers 列表中包含 kubernetes.io/pvc-protection：\nkubectl described pvc hostpath Name: hostpath Namespace: default StorageClass: example-hostpath Status: Terminating Volume: Labels: Annotations: volume.beta.kubernetes.io/storage-class=example-hostpath volume.beta.kubernetes.io/storage-provisioner=example.com/hostpath Finalizers: [kubernetes.io/pvc-protection] ... 回收 link用户用完 volume 后，可以从允许回收资源的 API 中删除 PVC 对象。PersistentVolume 的回收策略告诉集群在存储卷声明释放后应如何处理该卷。目前，volume 的处理策略有保留、回收或删除。\n保留 link保留回收策略允许手动回收资源。当 PersistentVolumeClaim 被删除时，PersistentVolume 仍然存在，volume 被视为“已释放”。但是由于前一个声明人的数据仍然存在，所以还不能马上进行其他声明。管理员可以通过以下步骤手动回收卷。\n删除 PersistentVolume。在删除 PV 后，外部基础架构中的关联存储资产（如 AWS EBS、GCE PD、Azure Disk 或 Cinder 卷）仍然存在。 手动清理相关存储资产上的数据。 手动删除关联的存储资产，或者如果要重新使用相同的存储资产，请使用存储资产定义创建新的 PersistentVolume。 回收 link如果存储卷插件支持，回收策略会在 volume上执行基本擦除（rm -rf / thevolume / *），可被再次声明使用。\n但是，管理员可以使用如此处所述的 Kubernetes controller manager 命令行参数来配置自定义回收站 pod 模板。自定义回收站 pod 模板必须包含 volumes 规范，如下面的示例所示：\napiVersion: v1 kind: Pod metadata: name: pv-recycler namespace: default spec: restartPolicy: Never volumes: - name: vol hostPath: path: /any/path/it/will/be/replaced containers: - name: pv-recycler image: \"k8s.gcr.io/busybox\" command: [\"/bin/sh\", \"-c\", \"test -e /scrub \u0026\u0026 rm -rf /scrub/..?* /scrub/.[!.]* /scrub/* \u0026\u0026 test -z \\\"$(ls -A /scrub)\\\" || exit 1\"] volumeMounts: - name: vol mountPath: /scrub 但是，volumes 部分的自定义回收站模块中指定的特定路径将被替换为正在回收的卷的特定路径。\n删除 link对于支持删除回收策略的卷插件，删除操作将从 Kubernetes 中删除 PersistentVolume 对象，并删除外部基础架构（如 AWS EBS、GCE PD、Azure Disk 或 Cinder 卷）中的关联存储资产。动态配置的卷继承其 StorageClass，默认为 Delete。管理员应该根据用户的期望来配置 StorageClass，否则就必须要在 PV 创建后进行编辑或修补。请参阅更改 PersistentVolume 的回收策略。\n扩展持久化卷声明 linkKubernetes 1.8 增加了对扩展持久化存储卷的 Alpha 支持。在 v1.9 中，以下持久化卷支持扩展持久化卷声明：\ngcePersistentDisk awsElasticBlockStore Cinder glusterfs rbd 管理员可以通过将 ExpandPersistentVolumes 特性门设置为true来允许扩展持久卷声明。管理员还应该启用PersistentVolumeClaimResize 准入控制插件来执行对可调整大小的卷的其他验证。\n一旦 PersistentVolumeClaimResize 准入插件已打开，将只允许其 allowVolumeExpansion 字段设置为 true 的存储类进行大小调整。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: gluster-vol-default provisioner: kubernetes.io/glusterfs parameters: resturl: \"http://192.168.10.100:8080\" restuser: \"\" secretNamespace: \"\" secretName: \"\" allowVolumeExpansion: true 一旦功能门和前述准入插件打开后，用户就可以通过简单地编辑声明以请求更大的 PersistentVolumeClaim 卷。这反过来将触发 PersistentVolume 后端的卷扩展。\n在任何情况下都不会创建新的 PersistentVolume 来满足声明。 Kubernetes 将尝试调整现有 volume 来满足声明的要求。\n对于扩展包含文件系统的卷，只有在 ReadWrite 模式下使用 PersistentVolumeClaim 启动新的 Pod 时，才会执行文件系统调整大小。换句话说，如果正在扩展的卷在 pod 或部署中使用，则需要删除并重新创建要进行文件系统调整大小的pod。此外，文件系统调整大小仅适用于以下文件系统类型：\nXFS Ext3、Ext4 注意：扩展 EBS 卷是一个耗时的操作。另外，每6个小时有一个修改卷的配额。\n持久化卷类型 linkPersistentVolume 类型以插件形式实现。Kubernetes 目前支持以下插件类型：\nGCEPersistentDisk AWSElasticBlockStore AzureFile AzureDisk FC (Fibre Channel) FlexVolume Flocker NFS iSCSI RBD (Ceph Block Device) CephFS Cinder (OpenStack block storage) Glusterfs VsphereVolume Quobyte Volumes HostPath （仅限于但节点测试—— 不会以任何方式支持本地存储，也无法在多节点集群中工作） VMware Photon Portworx Volumes ScaleIO Volumes StorageOS 原始块支持仅适用于以上这些插件。\n持久化卷 link每个 PV 配置中都包含一个 sepc 规格字段和一个 status 卷状态字段。\napiVersion: v1 kind: PersistentVolume metadata: name: pv0003 spec: capacity: storage: 5Gi volumeMode: Filesystem accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle storageClassName: slow mountOptions: - hard - nfsvers=4.1 nfs: path: /tmp server: 172.17.0.2 容量 link通常，PV 将具有特定的存储容量。这是使用 PV 的容量属性设置的。查看 Kubernetes 资源模型 以了解 capacity 预期。\n目前，存储大小是可以设置或请求的唯一资源。未来的属性可能包括 IOPS、吞吐量等。\n卷模式 link在 v1.9 之前，所有卷插件的默认行为是在持久卷上创建一个文件系统。在 v1.9 中，用户可以指定一个 volumeMode，除了文件系统之外，它现在将支持原始块设备。 volumeMode 的有效值可以是“Filesystem”或“Block”。如果未指定，volumeMode 将默认为“Filesystem”。这是一个可选的 API 参数。\n注意：该功能在 V1.9 中是 alpha的，未来可能会更改。\n访问模式 linkPersistentVolume 可以以资源提供者支持的任何方式挂载到主机上。如下表所示，供应商具有不同的功能，每个 PV 的访问模式都将被设置为该卷支持的特定模式。例如，NFS 可以支持多个读/写客户端，但特定的 NFS PV 可能以只读方式导出到服务器上。每个 PV 都有一套自己的用来描述特定功能的访问模式。\n存储模式包括：\nReadWriteOnce——该卷可以被单个节点以读/写模式挂载 ReadOnlyMany——该卷可以被多个节点以只读模式挂载 ReadWriteMany——该卷可以被多个节点以读/写模式挂载 在命令行中，访问模式缩写为：\nRWO - ReadWriteOnce ROX - ReadOnlyMany RWX - ReadWriteMany 重要！一个卷一次只能使用一种访问模式挂载，即使它支持很多访问模式。例如，GCEPersistentDisk 可以由单个节点作为 ReadWriteOnce 模式挂载，或由多个节点以 ReadOnlyMany 模式挂载，但不能同时挂载。\nVolume 插件 ReadWriteOnce ReadOnlyMany ReadWriteMany AWSElasticBlockStore ✓ - - AzureFile ✓ ✓ ✓ AzureDisk ✓ - - CephFS ✓ ✓ ✓ Cinder ✓ - - FC ✓ ✓ - FlexVolume ✓ ✓ - Flocker ✓ - - GCEPersistentDisk ✓ ✓ - Glusterfs ✓ ✓ ✓ HostPath ✓ - - iSCSI ✓ ✓ - PhotonPersistentDisk ✓ - - Quobyte ✓ ✓ ✓ NFS ✓ ✓ ✓ RBD ✓ ✓ - VsphereVolume ✓ - - （当 pod 并列时有效） PortworxVolume ✓ - ✓ ScaleIO ✓ ✓ - StorageOS ✓ - - 类 linkPV 可以具有一个类，通过将 storageClassName 属性设置为 StorageClass 的名称来指定该类。一个特定类别的 PV 只能绑定到请求该类别的 PVC。没有 storageClassName 的 PV 就没有类，它只能绑定到不需要特定类的 PVC。\n过去，使用的是 volume.beta.kubernetes.io/storage-class 注解而不是 storageClassName 属性。这个注解仍然有效，但是将来的 Kubernetes 版本中将会完全弃用它。\n回收策略 link当前的回收策略包括：\nRetain（保留）——手动回收 Recycle（回收）——基本擦除（rm -rf /thevolume/*） Delete（删除）——关联的存储资产（例如 AWS EBS、GCE PD、Azure Disk 和 OpenStack Cinder 卷）将被删除 当前，只有 NFS 和 HostPath 支持回收策略。AWS EBS、GCE PD、Azure Disk 和 Cinder 卷支持删除策略。\n挂载选项 linkKubernetes 管理员可以指定在节点上为挂载持久卷指定挂载选项。\n注意：不是所有的持久化卷类型都支持挂载选项。\n以下卷类型支持挂载选项：\nGCEPersistentDisk AWSElasticBlockStore AzureFile AzureDisk NFS iSCSI RBD （Ceph Block Device） CephFS Cinder （OpenStack 卷存储） Glusterfs VsphereVolume Quobyte Volumes VMware Photon 挂载选项没有校验，如果挂载选项无效则挂载失败。\n过去，使用 volume.beta.kubernetes.io/mount-options 注解而不是 mountOptions 属性。这个注解仍然有效，但在将来的 Kubernetes 版本中它将会被完全弃用。\n状态 link卷可以处于以下的某种状态：\nAvailable（可用）——一块空闲资源还没有被任何声明绑定 Bound（已绑定）——卷已经被声明绑定 Released（已释放）——声明被删除，但是资源还未被集群重新声明 Failed（失败）——该卷的自动回收失败 命令行会显示绑定到 PV 的 PVC 的名称。\nPersistentVolumeClaim link每个 PVC 中都包含一个 spec 规格字段和一个 status 声明状态字段。\nkind: PersistentVolumeClaim apiVersion: v1 metadata: name: myclaim spec: accessModes: - ReadWriteOnce volumeMode: Filesystem resources: requests: storage: 8Gi storageClassName: slow selector: matchLabels: release: \"stable\" matchExpressions: - {key: environment, operator: In, values: [dev]} 访问模式 link在请求具有特定访问模式的存储时，声明使用与卷相同的约定。\n卷模式 link声明使用与卷相同的约定，指示将卷作为文件系统或块设备使用。\n资源 link像 pod 一样，声明可以请求特定数量的资源。在这种情况下，请求是用于存储的。相同的资源模型适用于卷和声明。\n选择器 link声明可以指定一个标签选择器来进一步过滤该组卷。只有标签与选择器匹配的卷可以绑定到声明。选择器由两个字段组成：\nmatchLabels：volume 必须有具有该值的标签 matchExpressions：这是一个要求列表，通过指定关键字，值列表以及与关键字和值相关的运算符组成。有效的运算符包括 In、NotIn、Exists 和 DoesNotExist。 所有来自 matchLabels 和 matchExpressions 的要求都被“与”在一起——它们必须全部满足才能匹配。\n类 link声明可以通过使用属性 storageClassName 指定 StorageClass 的名称来请求特定的类。只有所请求的类与 PVC 具有相同 storageClassName 的 PV 才能绑定到 PVC。\nPVC 不一定要请求类。其 storageClassName 设置为 \"\" 的 PVC 始终被解释为没有请求类的 PV，因此只能绑定到没有类的 PV（没有注解或 \"\"）。没有 storageClassName 的 PVC 根据是否打开DefaultStorageClass 准入控制插件，集群对其进行不同处理。\n如果打开了准入控制插件，管理员可以指定一个默认的 StorageClass。所有没有 StorageClassName 的 PVC 将被绑定到该默认的 PV。通过在 StorageClass 对象中将注解 storageclass.kubernetes.io/is-default-class 设置为 “true” 来指定默认的 StorageClass。如果管理员没有指定缺省值，那么集群会响应 PVC 创建，就好像关闭了准入控制插件一样。如果指定了多个默认值，则准入控制插件将禁止所有 PVC 创建。 如果准入控制插件被关闭，则没有默认 StorageClass 的概念。所有没有 storageClassName 的 PVC 只能绑定到没有类的 PV。在这种情况下，没有 storageClassName 的 PVC 的处理方式与 storageClassName 设置为 \"\" 的 PVC 的处理方式相同。 根据安装方法的不同，默认的 StorageClass 可以在安装过程中通过插件管理器部署到 Kubernetes 集群。\n当 PVC 指定了 selector，除了请求一个 StorageClass 之外，这些需求被“与”在一起：只有被请求的类的 PV 具有和被请求的标签才可以被绑定到 PVC。\n注意：目前，具有非空 selector 的 PVC 不能为其动态配置 PV。\n过去，使用注解 volume.beta.kubernetes.io/storage-class 而不是 storageClassName 属性。这个注解仍然有效，但是在未来的 Kubernetes 版本中不会支持。\n声明作为卷 link通过将声明用作卷来访问存储。声明必须与使用声明的 pod 存在于相同的命名空间中。集群在 pod 的命名空间中查找声明，并使用它来获取支持声明的 PersistentVolume。该卷然后被挂载到主机的 pod 上。\nkind: Pod apiVersion: v1 metadata: name: mypod spec: containers: - name: myfrontend image: dockerfile/nginx volumeMounts: - mountPath: \"/var/www/html\" name: mypd volumes: - name: mypd persistentVolumeClaim: claimName: myclaim 命名空间注意点 linkPersistentVolumes 绑定是唯一的，并且由于 PersistentVolumeClaims 是命名空间对象，因此只能在一个命名空间内挂载具有“多个”模式（ROX、RWX）的声明。\n原始块卷支持 link原始块卷的静态配置在 v1.9 中作为 alpha 功能引入。由于这个改变，需要一些新的 API 字段来使用该功能。目前，Fibre Channl 是支持该功能的唯一插件。\n使用原始块卷作为持久化卷 link apiVersion: v1 kind: PersistentVolume metadata: name: block-pv spec: capacity: storage: 10Gi accessModes: - ReadWriteOnce volumeMode: Block persistentVolumeReclaimPolicy: Retain fc: targetWWNs: [\"50060e801049cfd1\"] lun: 0 readOnly: false 持久化卷声明请求原始块卷 link apiVersion: v1 kind: PersistentVolumeClaim metadata: name: block-pvc spec: accessModes: - ReadWriteOnce volumeMode: Block resources: requests: storage: 10Gi 在 Pod 规格配置中为容器添加原始块设备 link apiVersion: v1 kind: Pod metadata: name: pod-with-block-volume spec: containers: - name: fc-container image: fedora:26 command: [\"/bin/sh\", \"-c\"] args: [ \"tail -f /dev/null\" ] volumeDevices: - name: data devicePath: /dev/xvda volumes: - name: data persistentVolumeClaim: claimName: block-pvc 注意：当为 Pod 增加原始块设备时，我们在容器中指定设备路径而不是挂载路径。\n绑定块卷 link如果用户通过使用 PersistentVolumeClaim 规范中的 volumeMode 字段指示此请求来请求原始块卷，则绑定规则与以前不认为该模式为规范一部分的版本略有不同。\n下面是用户和管理员指定请求原始块设备的可能组合的表格。该表指示卷是否将被绑定或未给定组合。静态设置的卷的卷绑定矩阵：\nPV volumeMode PVC volumeMode 结果 unspecified unspecified 绑定 unspecified Block 不绑定 unspecified Filesystem 绑定 Block unspecified 不绑定 Block Block 绑定 Block Filesystem 不绑定 Filesystem Filesystem 绑定 Filesystem Block 不绑定 Filesystem unspecified 绑定 注意：alpha 版本只支持静态配置卷。使用原始块设备时，管理员应该注意考虑这些值。\n编写可移植配置 link如果您正在编写在多种集群上运行并需要持久存储的配置模板或示例，我们建议您使用以下模式：\n要在您的在配置组合中包含 PersistentVolumeClaim 对象（与 Deployment、ConfigMap等一起）。 不要在配置中包含 PersistentVolume 对象，因为用户实例化配置可能没有创建 PersistentVolume 的权限。 给用户在实例化模板时提供存储类名称的选项。 如果用户提供存储类名称，则将该值放入 persistentVolumeClaim.storageClassName 字段中。如果集群具有由管理员启用的 StorageClass，这将导致 PVC 匹配正确的存储类别。 如果用户未提供存储类名称，则将 persistentVolumeClaim.storageClassName 字段保留为 nil。 这将导致使用集群中默认的 StorageClass 为用户自动配置 PV。许多集群环境都有默认的 StorageClass，或者管理员可以创建自己的默认 StorageClass。 在您的工具中，请注意一段时间之后仍未绑定的 PVC，并向用户展示它们，因为这表示集群可能没有动态存储支持（在这种情况下用户应创建匹配的 PV），或集群没有存储系统（在这种情况下用户不能部署需要 PVC 的配置）。 原文地址：https://kubernetes.io/docs/concepts/storage/persistent-volumes/\n译者：rootsongjc\n"
            }
        );
    index.add(
            {
                id:  39 ,
                href: "\/docs\/economy\/",
                title: "经济",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  40 ,
                href: "\/docs\/information\/software\/cloud\/auth\/",
                title: "认证",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  41 ,
                href: "\/docs\/information\/aigc\/",
                title: "AIGC",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  42 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/label\/",
                title: "Label",
                description: "Label 是附着到 object 上（例如 Pod）的键值对。可以在创建 object 的时候指定，也可以在 object 创建后随时指定。Labels 的值对系统本身并没有什么含义，只是对用户才有意义。\n\"labels\": { \"key1\" : \"value1\", \"key2\" : \"value2\" } Kubernetes 最终将对 labels 最终索引和反向索引用来优化查询和 watch，在 UI 和命令行中会对它们排序。不要在 label 中使用大型、非标识的结构化数据，记录这样的数据应该用 annotation。\n动机 linkLabel 能够将组织架构映射到系统架构上（就像是康威定律），这样能够更便于微服务的管理，你可以给 object 打上如下类型的 label：\n\"release\" : \"stable\", \"release\" : \"canary\" \"environment\" : \"dev\", \"environment\" : \"qa\", \"environment\" : \"production\" \"tier\" : \"frontend\", \"tier\" : \"backend\", \"tier\" : \"cache\" \"partition\" : \"customerA\", \"partition\" : \"customerB\" \"track\" : \"daily\", \"track\" : \"weekly\" \"team\" : \"teamA\",\"team:\" : \"teamB\" 语法和字符集 linkLabel key 的组成：\n",
                content: "Label 是附着到 object 上（例如 Pod）的键值对。可以在创建 object 的时候指定，也可以在 object 创建后随时指定。Labels 的值对系统本身并没有什么含义，只是对用户才有意义。\n\"labels\": { \"key1\" : \"value1\", \"key2\" : \"value2\" } Kubernetes 最终将对 labels 最终索引和反向索引用来优化查询和 watch，在 UI 和命令行中会对它们排序。不要在 label 中使用大型、非标识的结构化数据，记录这样的数据应该用 annotation。\n动机 linkLabel 能够将组织架构映射到系统架构上（就像是康威定律），这样能够更便于微服务的管理，你可以给 object 打上如下类型的 label：\n\"release\" : \"stable\", \"release\" : \"canary\" \"environment\" : \"dev\", \"environment\" : \"qa\", \"environment\" : \"production\" \"tier\" : \"frontend\", \"tier\" : \"backend\", \"tier\" : \"cache\" \"partition\" : \"customerA\", \"partition\" : \"customerB\" \"track\" : \"daily\", \"track\" : \"weekly\" \"team\" : \"teamA\",\"team:\" : \"teamB\" 语法和字符集 linkLabel key 的组成：\n不得超过 63 个字符 可以使用前缀，使用 / 分隔，前缀必须是 DNS 子域，不得超过 253 个字符，系统中的自动化组件创建的 label 必须指定前缀，kubernetes.io/ 由 kubernetes 保留 起始必须是字母（大小写都可以）或数字，中间可以有连字符、下划线和点 Label value 的组成：\n不得超过 63 个字符 起始必须是字母（大小写都可以）或数字，中间可以有连字符、下划线和点 Label selector linkLabel 不是唯一的，很多 object 可能有相同的 label。\n通过 label selector，客户端／用户可以指定一个 object 集合，通过 label selector 对 object 的集合进行操作。\nLabel selector 有两种类型：\nequality-based ：可以使用 =、==、!= 操作符，可以使用逗号分隔多个表达式 set-based ：可以使用 in、notin、! 操作符，另外还可以没有操作符，直接写出某个 label 的 key，表示过滤有某个 key 的 object 而不管该 key 的 value 是何值，! 表示没有该 label 的 object 示例 link $ kubectl get pods -l environment=production,tier=frontend $ kubectl get pods -l 'environment in (production),tier in (frontend)' $ kubectl get pods -l 'environment in (production, qa)' $ kubectl get pods -l 'environment,environment notin (frontend)' 在 API object 中设置 label selector link在 service、replicationcontroller 等 object 中有对 pod 的 label selector，使用方法只能使用等于操作，例如：\nselector: component: redis 在 Job、Deployment、ReplicaSet 和 DaemonSet 这些 object 中，支持 set-based 的过滤，例如：\nselector: matchLabels: component: redis matchExpressions: - {key: tier, operator: In, values: [cache]} - {key: environment, operator: NotIn, values: [dev]} 如 Service 通过 label selector 将同一类型的 pod 作为一个服务 expose 出来。\n另外在 node affinity 和 pod affinity 中的 label selector 的语法又有些许不同，示例如下：\naffinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/e2e-az-name operator: In values: - e2e-az1 - e2e-az2 preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - key: another-node-label-key operator: In values: - another-node-label-value "
            }
        );
    index.add(
            {
                id:  43 ,
                href: "\/docs\/information\/software\/cloud\/storage\/storageclass\/",
                title: "StorageClass",
                description: "本文介绍了 Kubernetes 中 StorageClass 的概念。在阅读本文之前建议先熟悉 卷 和 Persistent Volume（持久卷）。\n",
                content: "本文介绍了 Kubernetes 中 StorageClass 的概念。在阅读本文之前建议先熟悉 卷 和 Persistent Volume（持久卷）。\n介绍 linkStorageClass 为管理员提供了描述存储 “class（类）” 的方法。 不同的 class 可能会映射到不同的服务质量等级或备份策略，或由群集管理员确定的任意策略。 Kubernetes 本身不清楚各种 class 代表的什么。这个概念在其他存储系统中有时被称为“配置文件”。\nStorageClass 资源 linkStorageClass 中包含 provisioner、parameters 和 reclaimPolicy 字段，当 class 需要动态分配 PersistentVolume 时会使用到。\nStorageClass 对象的名称很重要，用户使用该类来请求一个特定的方法。 当创建 StorageClass 对象时，管理员设置名称和其他参数，一旦创建了对象就不能再对其更新。\n管理员可以为没有申请绑定到特定 class 的 PVC 指定一个默认的 StorageClass ： 更多详情请参阅 PersistentVolumeClaim 章节。\nkind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: standard provisioner: kubernetes.io/aws-ebs parameters: type: gp2 reclaimPolicy: Retain mountOptions: - debug Provisioner（存储分配器） linkStorage class 有一个分配器，用来决定使用哪个卷插件分配 PV。该字段必须指定。\nVolume Plugin Internal Provisioner Config Example AWSElasticBlockStore ✓ AWS AzureFile ✓ Azure File AzureDisk ✓ Azure Disk CephFS - - Cinder ✓ OpenStack Cinder FC - - FlexVolume - - Flocker ✓ - GCEPersistentDisk ✓ GCE Glusterfs ✓ Glusterfs iSCSI - - PhotonPersistentDisk ✓ - Quobyte ✓ Quobyte NFS - - RBD ✓ Ceph RBD VsphereVolume ✓ vSphere PortworxVolume ✓ Portworx Volume ScaleIO ✓ ScaleIO StorageOS ✓ StorageOS 您不限于指定此处列出的\"内置\"分配器（其名称前缀为 kubernetes.io 并打包在 Kubernetes 中）。 您还可以运行和指定外部分配器，这些独立的程序遵循由 Kubernetes 定义的 规范。 外部供应商的作者完全可以自由决定他们的代码保存于何处、打包方式、运行方式、使用的插件（包括Flex）等。 代码仓库 kubernetes-incubator/external-storage 包含一个用于为外部分配器编写功能实现的类库，以及各种社区维护的外部分配器。\n例如，NFS 没有内部分配器，但可以使用外部分配器。一些外部分配器在代码仓库 kubernetes-incubator/external-storage 中。 也有第三方存储供应商提供自己的外部分配器。\n关于内置的 StorageClass 的配置请参考 Storage Classes。\n回收策略 link由 storage class 动态创建的 Persistent Volume 会在的 reclaimPolicy 字段中指定回收策略，可以是 Delete 或者 Retain。如果 StorageClass 对象被创建时没有指定 reclaimPolicy ，它将默认为 Delete。\n通过 storage class 手动创建并管理的 Persistent Volume 会使用它们被创建时指定的回收政策。\n挂载选项 link由 storage class 动态创建的 Persistent Volume 将使用 class 中 mountOptions 字段指定的挂载选项。\n如果卷插件不支持挂载选项，却指定了该选项，则分配操作失败。 安装选项在 class 和 PV 上都不会做验证，所以如果挂载选项无效，那么这个 PV 就会失败。\n参数 linkStorage class 具有描述属于 storage class 卷的参数。取决于分配器，可以接受不同的参数。 例如，参数 type 的值 io1 和参数 iopsPerGB 特定于 EBS PV。当参数被省略时，会使用默认值。\n参考 link https://kubernetes.io/docs/concepts/storage/storage-classes/ "
            }
        );
    index.add(
            {
                id:  44 ,
                href: "\/docs\/history\/",
                title: "历史",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  45 ,
                href: "\/docs\/information\/software\/cloud\/storage\/",
                title: "存储",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  46 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/annotation\/",
                title: "Annotation",
                description: "Annotation，顾名思义，就是注解。Annotation 可以将 Kubernetes 资源对象关联到任意的非标识性元数据。使用客户端（如工具和库）可以检索到这些元数据。\n关联元数据到对象 linkLabel 和 Annotation 都可以将元数据关联到 Kubernetes 资源对象。Label 主要用于选择对象，可以挑选出满足特定条件的对象。相比之下，annotation 不能用于标识及选择对象。annotation 中的元数据可多可少，可以是结构化的或非结构化的，也可以包含 label 中不允许出现的字符。\nAnnotation 和 label 一样都是 key/value 键值对映射结构：\njson\"annotations\": {\"key1\":\"value1\",\"key2\":\"value2\"}\n以下列出了一些可以记录在 annotation 中的对象信息：\n声明配置层管理的字段。使用 annotation 关联这类字段可以用于区分以下几种配置来源：客户端或服务器设置的默认值，自动生成的字段或自动生成的 auto-scaling 和 auto-sizing 系统配置的字段。\n创建信息、版本信息或镜像信息。例如时间戳、版本号、git 分支、PR 序号、镜像哈希值以及仓库地址。\n记录日志、监控、分析或审计存储仓库的指针\n可以用于 debug 的客户端（库或工具）信息，例如名称、版本和创建信息。\n用户信息，以及工具或系统来源信息、例如来自非 Kubernetes 生态的相关对象的 URL 信息。\n轻量级部署工具元数据，例如配置或检查点。\n负责人的电话或联系方式，或能找到相关信息的目录条目信息，例如团队网站。\n如果不使用 annotation，您也可以将以上类型的信息存放在外部数据库或目录中，但这样做不利于创建用于部署、管理、内部检查的共享工具和客户端库。\n示例 link如 Istio 的 Deployment 配置中就使用到了 annotation：\napiVersion: extensions/v1beta1 kind: Deployment metadata: name: istio-manager spec: replicas: 1 template: metadata: annotations: alpha.istio.io/sidecar: ignore labels: istio: manager spec: serviceAccountName: istio-manager-service-account containers: - name: discovery image: harbor-001.jimmysong.io/library/manager:0.1.5 imagePullPolicy: Always args: [\"discovery\", \"-v\", \"2\"] ports: - containerPort: 8080 env: - name: POD_NAMESPACE valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.namespace - name: apiserver image: harbor-001.jimmysong.io/library/manager:0.1.5 imagePullPolicy: Always args: [\"apiserver\", \"-v\", \"2\"] ports: - containerPort: 8081 env: - name: POD_NAMESPACE valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.namespace alpha.istio.io/sidecar 注解就是用来控制是否自动向 pod 中注入 sidecar 的。\n",
                content: "Annotation，顾名思义，就是注解。Annotation 可以将 Kubernetes 资源对象关联到任意的非标识性元数据。使用客户端（如工具和库）可以检索到这些元数据。\n关联元数据到对象 linkLabel 和 Annotation 都可以将元数据关联到 Kubernetes 资源对象。Label 主要用于选择对象，可以挑选出满足特定条件的对象。相比之下，annotation 不能用于标识及选择对象。annotation 中的元数据可多可少，可以是结构化的或非结构化的，也可以包含 label 中不允许出现的字符。\nAnnotation 和 label 一样都是 key/value 键值对映射结构：\njson\"annotations\": {\"key1\":\"value1\",\"key2\":\"value2\"}\n以下列出了一些可以记录在 annotation 中的对象信息：\n声明配置层管理的字段。使用 annotation 关联这类字段可以用于区分以下几种配置来源：客户端或服务器设置的默认值，自动生成的字段或自动生成的 auto-scaling 和 auto-sizing 系统配置的字段。\n创建信息、版本信息或镜像信息。例如时间戳、版本号、git 分支、PR 序号、镜像哈希值以及仓库地址。\n记录日志、监控、分析或审计存储仓库的指针\n可以用于 debug 的客户端（库或工具）信息，例如名称、版本和创建信息。\n用户信息，以及工具或系统来源信息、例如来自非 Kubernetes 生态的相关对象的 URL 信息。\n轻量级部署工具元数据，例如配置或检查点。\n负责人的电话或联系方式，或能找到相关信息的目录条目信息，例如团队网站。\n如果不使用 annotation，您也可以将以上类型的信息存放在外部数据库或目录中，但这样做不利于创建用于部署、管理、内部检查的共享工具和客户端库。\n示例 link如 Istio 的 Deployment 配置中就使用到了 annotation：\napiVersion: extensions/v1beta1 kind: Deployment metadata: name: istio-manager spec: replicas: 1 template: metadata: annotations: alpha.istio.io/sidecar: ignore labels: istio: manager spec: serviceAccountName: istio-manager-service-account containers: - name: discovery image: harbor-001.jimmysong.io/library/manager:0.1.5 imagePullPolicy: Always args: [\"discovery\", \"-v\", \"2\"] ports: - containerPort: 8080 env: - name: POD_NAMESPACE valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.namespace - name: apiserver image: harbor-001.jimmysong.io/library/manager:0.1.5 imagePullPolicy: Always args: [\"apiserver\", \"-v\", \"2\"] ports: - containerPort: 8081 env: - name: POD_NAMESPACE valueFrom: fieldRef: apiVersion: v1 fieldPath: metadata.namespace alpha.istio.io/sidecar 注解就是用来控制是否自动向 pod 中注入 sidecar 的。\n"
            }
        );
    index.add(
            {
                id:  47 ,
                href: "\/docs\/information\/software\/cloud\/storage\/local-persistent-storage\/",
                title: "本地持久化存储",
                description: "本地持久化卷允许用户通过标准 PVC 接口以简单便携的方式访问本地存储。PV 中包含系统用于将 Pod 安排到正确节点的节点亲和性信息。\n一旦配置了本地卷，外部静态配置器（provisioner）可用于帮助简化本地存储管理。请注意，本地存储配置器与大多数配置器不同，并且尚不支持动态配置。相反，它要求管理员预先配置每个节点上的本地卷，并且这些卷应该是：\nFilesystem volumeMode（默认）PV—— 将它们挂载到发现目录下。 Block volumeMode PV——在发现目录下为节点上的块设备创建一个符号链接。 配置器将通过为每个卷创建和清除 PersistentVolumes 来管理发现目录下的卷。\n配置要求 link 本地卷插件希望路径稳定，包括在重新启动时和添加或删除磁盘时。 静态配置器仅发现挂载点（对于文件系统模式卷）或符号链接（对于块模式卷）。对于基于目录的本地卷必须绑定到发现目录中。 版本兼容性 link推荐配置器版本与Kubernetes版本\nProvisioner version K8s version Reason 2.1.0 1.10 Beta API default, block 2.0.0 1.8, 1.9 Mount propagation 1.0.1 1.7 K8s功能状态 link另请参阅已知问题和 CHANGELOG。\n",
                content: "本地持久化卷允许用户通过标准 PVC 接口以简单便携的方式访问本地存储。PV 中包含系统用于将 Pod 安排到正确节点的节点亲和性信息。\n一旦配置了本地卷，外部静态配置器（provisioner）可用于帮助简化本地存储管理。请注意，本地存储配置器与大多数配置器不同，并且尚不支持动态配置。相反，它要求管理员预先配置每个节点上的本地卷，并且这些卷应该是：\nFilesystem volumeMode（默认）PV—— 将它们挂载到发现目录下。 Block volumeMode PV——在发现目录下为节点上的块设备创建一个符号链接。 配置器将通过为每个卷创建和清除 PersistentVolumes 来管理发现目录下的卷。\n配置要求 link 本地卷插件希望路径稳定，包括在重新启动时和添加或删除磁盘时。 静态配置器仅发现挂载点（对于文件系统模式卷）或符号链接（对于块模式卷）。对于基于目录的本地卷必须绑定到发现目录中。 版本兼容性 link推荐配置器版本与Kubernetes版本\nProvisioner version K8s version Reason 2.1.0 1.10 Beta API default, block 2.0.0 1.8, 1.9 Mount propagation 1.0.1 1.7 K8s功能状态 link另请参阅已知问题和 CHANGELOG。\n1.10：Beta link 添加了新的 PV.NodeAffinity 字段。 重要： Alpha PV NodeAffinity annotation 已弃用。用户必须手动更新其 PV 以使用新的 NodeAffinity字段或运行一次性更新作业。 Alpha：添加了对 raw block 的支持。 1.9：Alpha link 新的 StorageClass volumeBindingMode 参数将延迟PVC绑定，直到 pod 被调度。 1.7：Alpha link 新的local PersistentVolume 源，允许指定具有 node affinity 的目录或挂载点。 使用绑定到该 PV 的 PVC 的 Pod 将始终调度到该节点。 未来的功能 link 本地块设备作为卷源，具有分区和 fs 格式化 共享本地持久化存储的动态资源调配 当地 PV 健康监测、污点和容忍 内联 PV（使用专用本地磁盘作为临时存储） 用户指南 link这些说明反映了最新版本的代码库。有关旧版本的说明，请参阅版本兼容性下的版本链接。\n步骤1：使用本地磁盘启动集群 link启用alpha feature gate link1.10+ link如果需要原始的本地块功能，\nexport KUBE_FEATURE_GATES =\"BlockVolume = true\" 注意：1.10 之前的 Kubernetes 版本需要几个附加 feature gate，因为持久的本地卷和其他功能处于 alpha 版本。\n选项1：裸金属环境 link 根据应用程序的要求对每个节点上的磁盘进行分区和格式化。 根据 StorageClass 将所有文件系统挂载到同一个目录下。目录在 configmap 中指定，见下文。 使用 KUBE_FEATURE_GATES 配置 Kubernetes API server、controller manager、scheduler 和所有kubelet，如上所述。 如果不使用默认 Kubernetes 调度程序策略，则必须启用以下谓词： 1.9之前：NoVolumeBindConflict 1.9+：VolumeBindingChecker 选项2：本地测试集群 link 创建 /mnt/disks 目录并将多个卷挂载到其子目录。下面的示例使用三个 ram 磁盘来模拟真实的本地卷：\nmkdir/mnt/disks vol for vol1 vol2 vol3;do mkdir/mnt/disks/$vol mount -t tmpfs $vol/mnt/disks/$vol DONE 运行本地集群。\n$ALLOW_PRIVILEGED = true LOG_LEVEL = 5 FEATURE_GATES = $KUBE_FEATURE_GATES hack/local-up-cluster.sh 步骤2：创建StorageClass（1.9+） link要延迟卷绑定，直到 pod 被调度，并在单个 pod 中处理多个本地 PV，必须使用设置为 WaitForFirstConsumer 的 volumeBindingMode 创建 StorageClass。\n$kubectl create -f provisioner/deployment/kubernetes/example/default_example_storageclass.yaml 步骤3：创建本地持久卷 link选项1：使用本地卷静态配置器 link 生成 Provisioner 的 ServiceAccount、Role、DaemonSet 和 ConfigMap 规范，并对其进行自定义。\n这一步使用 helm 模板来生成规格。有关安装说明，请参阅helm readme。要使用默认值生成配置器的规格，请运行：\nhelm template ./helm/provisioner \u003e ./provisioner/deployment/kubernetes/provisioner_generated.yaml 您也可以提供一个自定义值文件：\nhelm template ./helm/provisioner --values custom-values.yaml \u003e ./provisioner/deployment/kubernetes/provisioner_generated.yaml 部署配置程序\n如果用户对 Provisioner 的 yaml 文件的内容感到满意，可以用 kubectl 创建 Provisioner 的 DaemonSet 和 ConfigMap。\n$kubectl create -f ./provisioner/deployment/kubernetes/provisioner_generated.yaml 检查发现的本地卷\n一旦启动，外部静态配置器将发现并创建本地 PV。\n例如，如果目录 /mnt/disks/ 包含一个目录 /mnt/disks/vol1，则静态配置器会创建以下本地卷 PV：\n$ kubectl get pv NAME CAPACITY ACCESSMODES RECLAIMPOLICY STATUS CLAIM STORAGECLASS REASON AGE local-pv-ce05be60 1024220Ki RWO Delete Available local-storage 26s $ kubectl describe pv local-pv-ce05be60 Name:\tlocal-pv-ce05be60 Labels:\tAnnotations:\tpv.kubernetes.io/provisioned-by=local-volume-provisioner-minikube-18f57fb2-a186-11e7-b543-080027d51893 StorageClass:\tlocal-fast Status:\tAvailable Claim:\tReclaim Policy:\tDelete Access Modes:\tRWO Capacity:\t1024220Ki NodeAffinity: Required Terms: Term 0: kubernetes.io/hostname in [my-node] Message:\tSource: Type:\tLocalVolume (a persistent volume backed by local storage on a node) Path:\t/mnt/disks/vol1 Events:\t上面描述的 PV 可以通过引用 local-fast storageClassName 声明和绑定到 PVC。\n选项2：手动创建本地持久化卷 link有关示例 PersistentVolume 规范，请参阅Kubernetes文档。\n步骤4：创建本地持久卷声明 link kind: PersistentVolumeClaim apiVersion: v1 metadata: name: example-local-claim spec: accessModes: - ReadWriteOnce resources: requests: storage: 5Gi storageClassName: local-storage 请替换以下元素以反映您的配置：\n卷所需的存储容量“5Gi” “local-storage”，与本地 PV 关联的存储类名称应该用于满足此 PVC 对于试图声明 “Block” PV 的 “Block” volumeMode PVC，可以使用以下示例：\nkind: PersistentVolumeClaim apiVersion: v1 metadata: name: example-local-claim spec: accessModes: - ReadWriteOnce resources: requests: storage: 5Gi volumeMode: Block storageClassName: local-storage 请注意，此处唯一需要注意的字段是 volumeMode，它已被设置为“Block”。\n最佳实践 link 对于IO隔离，建议每个卷使用整个磁盘 对于容量隔离，建议使用单个分区 避免重新创建具有相同节点名称的节点，而仍然存在指定了该节点亲和性的旧 PV。否则，系统可能认为新节点包含旧的 PV。 对于带有文件系统的卷，建议在 fstab 条目和该挂载点的目录名称中使用它们的 UUID（例如 ls -l/dev/disk/by-uuid 的输出）。这种做法可确保即使设备路径发生变化（例如，如果 /dev/sda1 在添加新磁盘时变为 /dev/sdb1），也不会错误地挂在本地卷。此外，这种做法将确保如果创建具有相同名称的另一个节点，则该节点上的任何卷都是唯一的，而不会误认为是具有相同名称的另一个节点上的卷。 对于没有文件系统的 raw block 卷，使用唯一的 ID 作为符号链接名称。根据您的环境，/dev/disk/by-id/ 中的卷 ID 可能包含唯一的硬件序列号。否则，应该生成一个唯一的 ID。符号链接名称的唯一性将确保如果创建具有相同名称的另一个节点，则该节点上的任何卷都是唯一的，而不会误认为是具有相同名称的另一个节点上的卷。 删除/清理底层卷 link当您想要停用本地卷时，以下是可能的工作流程。\n停止使用卷的 pod 从节点中删除本地卷（即卸载、拔出磁盘等） 删除 PVC 供应商将尝试清理卷，但由于卷不再存在而会失败 手动删除 PV 对象 参考 link Local Persistent Storage User Guide "
            }
        );
    index.add(
            {
                id:  48 ,
                href: "\/docs\/information\/mix\/",
                title: "杂",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  49 ,
                href: "\/docs\/information\/software\/cloud\/resource_oversold\/",
                title: "资源超卖",
                description: "背景 linkWhat link资源超卖（Oversubscription） 是指在计算资源（如CPU、内存）的分配过程中，系统承诺给用户或工作负载的资源总量 超过实际可用的物理资源。这一概念类似于航空公司的机票超售：飞机座位是有限的，但通过统计分析和历史数据预测，航空公司可以卖出略多于实际容量的机票，因为通常会有部分乘客改签或取消行程。\n在Kubernetes（k8s）中，超卖通常表现为：\n资源请求（Requests）总和 \u003c 节点实际资源\n例如：一个节点有16核CPU，但所有Pod的CPU请求总和为20核。 资源限制（Limits）总和 » 节点实际资源\n例如：节点内存为64GB，但所有Pod的内存限制总和达到80GB。 为什么能实现超卖？\n资源使用具有波动性 大多数应用不会始终满负荷运行（如Web服务在夜间流量低谷时CPU利用率可能低于10%）。 时间片复用（CPU） CPU是时分复用资源，超卖的Pod通过分时共享物理核心。 内存超卖的投机性 依赖“并非所有Pod会同时满负荷使用内存”的假设，但风险较高（可能触发OOM Kill）。 超卖 vs 资源过度分配（Overcommitment）\n超卖 是主动行为，目的是提高资源利用率，通常伴随监控和兜底机制。 过度分配 可能是无意识的配置错误，容易导致系统不稳定。 # 一个超卖CPU的Pod配置示例： resources: requests: cpu: \"0.5\" # 调度器按此值分配 limits: cpu: \"2\" # 实际可突发使用2核（如果节点有空闲） Why link1. 提升集群资源利用率\n现实问题：大多数Kubernetes集群的平均资源利用率不足50%（尤其是CPU），大量资源因“预留”而闲置。 超卖的作用： 允许更多Pod运行在相同节点上，充分利用资源空闲时段。 例如：一个16核的节点，若所有Pod的requests总和为10核，超卖后实际运行20核的负载（利用时间片复用）。 2. 降低成本\n云环境成本优化：减少为“峰值负载”预留的节点数量，直接降低云厂商计费（如AWS EC2实例费用）。 裸金属服务器场景：通过超卖推迟硬件扩容，降低CAPEX（资本支出）。 3. 支持弹性业务需求\n突发流量处理：互联网服务的流量具有潮汐特征（如电商大促），超卖允许Pod临时突破requests限制，快速响应请求。 批处理任务：AI训练、日志分析等短时高负载任务，可通过超卖“见缝插针”式调度，避免排队等待。 4. 开发/测试环境效率\n低优先级负载容忍超卖：开发环境的Pod通常不需要严格SLA，超卖可让单节点运行更多测试容器，加速CI/CD流程。 背后的经济学原理\n超卖本质是通过风险交换效率，其可行性依赖两个统计规律：\n负载不重合性：不同业务的峰值时间错开（如白天在线服务、夜间批处理任务）。 局部性原理：多数应用的实际资源使用量长期低于其requests（如某服务声明需要4核，但实际平均使用1核）。 典型案例\n",
                content: "背景 linkWhat link资源超卖（Oversubscription） 是指在计算资源（如CPU、内存）的分配过程中，系统承诺给用户或工作负载的资源总量 超过实际可用的物理资源。这一概念类似于航空公司的机票超售：飞机座位是有限的，但通过统计分析和历史数据预测，航空公司可以卖出略多于实际容量的机票，因为通常会有部分乘客改签或取消行程。\n在Kubernetes（k8s）中，超卖通常表现为：\n资源请求（Requests）总和 \u003c 节点实际资源\n例如：一个节点有16核CPU，但所有Pod的CPU请求总和为20核。 资源限制（Limits）总和 » 节点实际资源\n例如：节点内存为64GB，但所有Pod的内存限制总和达到80GB。 为什么能实现超卖？\n资源使用具有波动性 大多数应用不会始终满负荷运行（如Web服务在夜间流量低谷时CPU利用率可能低于10%）。 时间片复用（CPU） CPU是时分复用资源，超卖的Pod通过分时共享物理核心。 内存超卖的投机性 依赖“并非所有Pod会同时满负荷使用内存”的假设，但风险较高（可能触发OOM Kill）。 超卖 vs 资源过度分配（Overcommitment）\n超卖 是主动行为，目的是提高资源利用率，通常伴随监控和兜底机制。 过度分配 可能是无意识的配置错误，容易导致系统不稳定。 # 一个超卖CPU的Pod配置示例： resources: requests: cpu: \"0.5\" # 调度器按此值分配 limits: cpu: \"2\" # 实际可突发使用2核（如果节点有空闲） Why link1. 提升集群资源利用率\n现实问题：大多数Kubernetes集群的平均资源利用率不足50%（尤其是CPU），大量资源因“预留”而闲置。 超卖的作用： 允许更多Pod运行在相同节点上，充分利用资源空闲时段。 例如：一个16核的节点，若所有Pod的requests总和为10核，超卖后实际运行20核的负载（利用时间片复用）。 2. 降低成本\n云环境成本优化：减少为“峰值负载”预留的节点数量，直接降低云厂商计费（如AWS EC2实例费用）。 裸金属服务器场景：通过超卖推迟硬件扩容，降低CAPEX（资本支出）。 3. 支持弹性业务需求\n突发流量处理：互联网服务的流量具有潮汐特征（如电商大促），超卖允许Pod临时突破requests限制，快速响应请求。 批处理任务：AI训练、日志分析等短时高负载任务，可通过超卖“见缝插针”式调度，避免排队等待。 4. 开发/测试环境效率\n低优先级负载容忍超卖：开发环境的Pod通常不需要严格SLA，超卖可让单节点运行更多测试容器，加速CI/CD流程。 背后的经济学原理\n超卖本质是通过风险交换效率，其可行性依赖两个统计规律：\n负载不重合性：不同业务的峰值时间错开（如白天在线服务、夜间批处理任务）。 局部性原理：多数应用的实际资源使用量长期低于其requests（如某服务声明需要4核，但实际平均使用1核）。 典型案例\n某视频网站：通过CPU超卖将直播转码任务的集群成本降低40%，仅在大规模直播事件时短暂启用备用节点。 机器学习平台：超卖GPU节点的显存，允许多个推理任务共享同一张GPU卡（需显存隔离工具配合）。 风险与挑战 linkKubernetes资源超卖虽然能提高资源利用率，但同时也引入了潜在风险。如果不加以控制，可能导致集群不稳定、应用性能下降，甚至服务中断。以下是超卖的主要风险和应对思路：\n1. 资源竞争导致的性能下降\n（1）CPU Throttling（CPU限流）\n问题：当多个Pod竞争CPU时，Kubernetes会对超出requests的Pod进行CPU限流，导致应用响应变慢。 表现：Pod的cpu_throttling指标升高，请求延迟增加。 解决方案： 使用Horizontal Pod Autoscaler (HPA)动态调整副本数，减少单Pod负载。 监控CPU Throttling指标，优化requests和limits的比值（如requests: 1, limits: 2）。 （2）内存争抢（OOM Kill）\n问题：内存超卖后，如果多个Pod同时占用高内存，Kubernetes的kubelet会触发OOM Killer，强制终止Pod。 表现：Pod被意外终止，日志显示OOMKilled。 解决方案： 避免超卖关键业务Pod，仅对低优先级任务（如批处理Job）超卖内存。 设置合理的limits，并监控memory.usage，接近阈值时告警。 2. 节点资源耗尽（Noisy Neighbor Problem）\n（1）磁盘I/O、网络带宽争抢\n问题：超卖通常只关注CPU/内存，但磁盘I/O、网络带宽也可能成为瓶颈。 例如：某个Pod疯狂写日志，导致节点磁盘IOPS饱和，影响其他Pod。 解决方案： 使用ResourceQuota限制每个Namespace的存储/网络资源。 对高I/O负载的Pod使用Local SSD或独立网络QoS策略。 （2）节点压力驱逐（Node Pressure Eviction）\n问题：当节点资源（内存、磁盘）耗尽时，kubelet会按优先级驱逐Pod，可能导致服务中断。 解决方案： 配置kubelet的--eviction-hard参数，提前触发驱逐（如memory.available\u003c10%时）。 使用Pod PriorityClass，确保关键服务不被优先驱逐。 3. 监控与运维复杂度增加\n（1）资源使用难以预测\n问题：超卖后，实际资源使用量可能远超requests，导致容量规划困难。 解决方案： 使用Prometheus + Grafana监控实际资源利用率，建立超卖比例模型（如超卖率=Σlimits/节点容量）。 定期进行压力测试，模拟峰值负载下的集群行为。 （2）故障排查难度上升\n问题：超卖环境下，问题可能由资源竞争引起，而非应用本身。 解决方案： 记录kubelet日志，关注OOMKilled和CPUThrottling事件。 使用kubectl describe node查看节点资源分配情况。 4. 不适合超卖的场景\n场景 风险 建议 金融交易类服务 延迟敏感，OOM可能导致交易失败 禁用超卖，使用Guaranteed QoS 数据库（MySQL/Redis） 内存竞争可能导致缓存失效或查询超时 独立节点部署，不超卖内存 实时音视频处理 CPU限流会导致卡顿、音画不同步 预留专用资源 总结：如何安全超卖？\n分层超卖：核心业务不超卖，非核心业务适度超卖。 动态调整：结合VPA/HPA自动优化资源分配。 严格监控：关注OOM Kill、CPU Throttling、节点压力指标。 渐进式验证：先在Dev/Test环境测试，再逐步推广到生产。 实现原理 linkCPU虚拟化与隔离 linkLinux Cgroups（控制组） linkKubernetes通过cgroups（特别是cpu和cpuacct子系统）限制容器的CPU使用：\ncpu.cfs_quota_us \u0026 cpu.cfs_period_us\n用于实现CPU时间片分配（CFS调度器）。 例如：设置cpu.cfs_quota_us=100000（100ms）和cpu.cfs_period_us=100000（100ms），表示容器最多使用1个CPU核心。 如果quota=200000，则允许使用2个CPU核心（即limits.cpu: \"2\"）。 cpu.shares\n用于设置CPU权重（影响requests.cpu）。 默认值：1024（相当于1个CPU核心的权重）。 例如：Pod A的requests.cpu: 2 → cpu.shares=2048；Pod B的requests.cpu: 1 → cpu.shares=1024。 当CPU资源紧张时，Pod A获得的CPU时间是Pod B的2倍。 CPU Throttling（限流） link 当容器尝试使用超过limits.cpu时，内核会限制其CPU时间片，导致性能下降（throttled_cpu_time增加）。 查看容器的CPU限流情况： cat /sys/fs/cgroup/cpu/kubepods/pod-/cpu.stat 输出示例： nr_periods 1000 nr_throttled 200 throttled_time 50000000 # 被限流的时间（纳秒） 多核与超线程（SMT）的影响 link 物理核心（Core） vs 逻辑核心（vCPU）： 超线程（Hyper-Threading）会让1个物理核心表现为2个逻辑核心（vCPU）。 Kubernetes的limits.cpu对应的是逻辑核心，因此超卖时需注意物理核心的争抢。 CPU亲和性（Affinity）： 可通过cpuAffinity将Pod绑定到特定核心，减少上下文切换开销（但对超卖灵活性有影响）。 内存虚拟化与隔离 linkCgroups内存控制 linkKubernetes通过memory子系统限制容器内存：\nmemory.limit_in_bytes\n对应limits.memory，例如设置4Gi → memory.limit_in_bytes=4294967296。 当容器内存使用超过该值，会触发OOM Kill（除非配置了swap，但Kubernetes默认禁用）。 memory.soft_limit_in_bytes\n对应requests.memory，内核会尽量保障该值，但不强制限制。 memory.oom_control\n可禁用OOM Killer（不推荐，可能导致节点不稳定）。 内存超卖的风险 link OOM Kill机制： 当节点内存不足时，内核根据oom_score（受QoS影响）选择牺牲者。 查看Pod的OOM分数： cat /proc//oom_score BestEffort Pod的分数通常最高（最先被杀）。 Swap的争议： Kubernetes默认禁用swap，因为磁盘交换会大幅降低性能。 如果启用swap，超卖内存的Pod可能不会立即OOM Kill，但会导致严重性能下降。 Kernel内存与透明大页（THP） link Kernel内存： 包括Slab、Page Tables等，不计入limits.memory，但可能影响节点稳定性。 透明大页（Transparent Huge Pages, THP）： 大内存页（2MB/1GB）可提高性能，但可能导致内存碎片化。 建议在kubelet中禁用THP： --feature-gates=DynamicKubeletConfig=true --kube-reserved=\"memory=1Gi\" --kernel-memcg-notify=true 资源请求（Requests）与限制（Limits） linkRequests（请求） link 定义：Pod向Kubernetes声明的最小资源需求，调度器（Scheduler）依据该值决定Pod应该运行在哪个节点上。 示例： resources: requests: cpu: \"1\" # 申请1核CPU memory: \"2Gi\" # 申请2GB内存 作用： 调度依据：如果一个节点的剩余可分配CPU \u003c 1核，则Pod不会被调度到该节点。 资源预留：kubelet会为Pod预留这部分资源，即使Pod未完全使用。 Limits（限制） link 定义：Pod可以使用的最大资源上限，超过该值会被限制（CPU）或终止（内存）。 示例： resources: limits: cpu: \"2\" # 最多使用2核CPU memory: \"4Gi\" # 最多使用4GB内存 作用： CPU限流（Throttling）：如果Pod尝试使用超过limits.cpu，Linux内核的CFS（完全公平调度器）会限制其CPU时间片。 OOM Kill：如果Pod的内存使用超过limits.memory，kubelet会强制终止该Pod（OOMKilled）。 Requests vs Limits 关系 link 场景 表现 requests \u003c limits 可超卖：Pod可以临时使用超出requests的资源（超卖的基础）。 requests == limits 不可超卖：Pod只能使用固定量的资源（Guaranteed QoS，适合关键业务）。 未设置requests/limits 最低优先级：Pod可能被随意调度，并面临资源竞争（BestEffort QoS）。 QoS（服务质量） linkKubernetes根据requests和limits的配置，将Pod分为3种QoS等级，直接影响资源竞争时的优先级：\nGuaranteed（最高优先级） link 条件：所有容器的requests == limits（CPU和内存均需设置）。 特点： 资源完全保障，不会被超卖影响。 最后被OOM Kill，适合数据库、核心服务。 Burstable（中等优先级） link 条件：至少一个容器设置了requests，但requests \u003c limits。 特点： 可以超卖，但受limits约束。 OOM Kill优先级低于BestEffort，适合普通业务Pod。 BestEffort（最低优先级） link 条件：未设置任何requests和limits。 特点： 资源无保障，完全依赖节点剩余资源。 最先被OOM Kill，适合临时任务、测试环境。 QoS优先级总结 link OOM Kill顺序：BestEffort → Burstable → Guaranteed 调度器如何基于资源请求分配Pod？ linkKubernetes调度器（kube-scheduler）在调度Pod时，仅考虑requests，而limits不影响调度决策。流程如下：\n筛选（Filtering）\n检查节点剩余可分配资源（Allocatable）是否 ≥ Pod的requests。 排除不满足条件的节点（如CPU不足、内存不足）。 评分（Scoring）\n对剩余节点打分（如选择资源剩余最多的节点，避免热点）。 绑定（Binding）\n将Pod绑定到最佳节点，kubelet负责后续资源分配。 关键点\n超卖的本质：多个Pod的requests总和可以超过节点实际资源，只要它们的limits总和也允许。 调度器不检查limits：即使limits总和远超节点容量，只要requests满足，Pod仍会被调度。 示例：超卖调度场景\n假设一个节点有 4核CPU / 8GB内存：\nPod CPU Requests CPU Limits 内存 Requests 内存 Limits Pod A 1核 2核 2GB 4GB Pod B 1核 2核 2GB 4GB Pod C 1核 2核 2GB 4GB 调度结果： requests总和 = 3核CPU / 6GB内存 ≤ 节点容量（4核/8GB）→ 允许调度。 limits总和 = 6核CPU / 12GB内存 \u003e 节点容量 → 实际运行依赖资源争抢。 实现方案 link静态超卖 link核心思想：通过手动设置Pod的requests和limits差值，允许其临时占用超额资源。\nCPU静态超卖\n适用场景：突发流量、批处理任务等短期高负载需求。 配置示例： resources: requests: cpu: \"1\" # 调度器按1核分配 limits: cpu: \"4\" # 实际允许使用4核（超卖3核） 效果： 调度器保证至少有1核可用，但Pod可突发使用至4核（若节点有空闲资源）。 若多个Pod同时爆发，则触发CPU Throttling。 内存静态超卖\n适用场景：内存使用波动大的服务（如缓存服务）。 配置示例： resources: requests: memory: \"1Gi\" # 调度器预留1GB limits: memory: \"3Gi\" # 允许使用3GB（超卖2GB） 风险： 若多个Pod同时占用高内存，可能触发OOM Kill。 静态超卖的优缺点\n优点 缺点 配置简单，无需额外组件 超卖比例固定，无法适应动态负载 适合已知规律的负载 内存超卖风险较高 动态超卖 link核心思想：通过自动化工具实时调整requests，基于实际负载动态控制超卖比例。\nVertical Pod Autoscaler（VPA） link 作用：自动调整Pod的requests和limits，避免资源浪费。 配置示例： apiVersion: autoscaling.k8s.io/v1 kind: VerticalPodAutoscaler metadata: name: my-app-vpa spec: targetRef: apiVersion: \"apps/v1\" kind: Deployment name: my-app updatePolicy: updateMode: \"Auto\" # 自动更新Pod资源 动态超卖逻辑： VPA监控Pod的历史资源使用量，降低requests（如从2核→1核），腾出资源供其他Pod超卖使用。 注意：VPA的Auto模式会重建Pod，可能引发短暂服务中断。 基于Prometheus的自适应超卖 link架构：\ngraph LR Prometheus --\u003e|指标数据| Custom-Controller Custom-Controller --\u003e|调整requests| Kubernetes-API 实现步骤：\n使用Prometheus采集节点和Pod的实时资源使用率（如container_cpu_usage_seconds_total）。 自定义控制器计算安全超卖比例（例如：超卖系数 = 当前空闲资源 / 总资源）。 动态修改Pod的requests（需配合kubectl patch或API调用）。 动态超卖的优缺点\n优点 缺点 适应负载变化，资源利用率最大化 实现复杂度高，需维护监控和控制器 降低OOM风险（通过动态调整） VPA的Auto模式可能导致Pod重建 节点级超卖 link核心思想：在节点层面全局控制资源分配，而非单个Pod。\nkubelet资源预留参数 link --system-reserved：为系统进程（如sshd、docker）预留资源。 --kube-reserved：为Kubernetes组件（如kubelet、CNI插件）预留资源。 --eviction-hard：设置资源驱逐阈值（如内存不足时触发Pod驱逐）。 示例：允许节点超卖CPU 20%\nkubelet \\ --system-reserved=cpu=1,memory=1Gi \\ --kube-reserved=cpu=0.5,memory=512Mi \\ --eviction-hard=memory.available\u003c500Mi 节点资源分配策略 link --cpu-manager-policy=static： 将CPU核心独占分配给关键Pod（如Guaranteed QoS的Pod），其余核心用于超卖。 --memory-manager-policy=None： 默认策略，允许内存超卖（若需严格隔离，可切换为Static或Dynamic）。 节点级超卖的优缺点 link 优点 缺点 全局控制，避免单个Pod配置遗漏 调整需重启kubelet，影响节点可用性 适合混合部署（关键+非关键业务） 内存超卖仍需谨慎 超卖控制器 link为了实现动态资源超卖，我们可以设计一个超卖控制系统，包含以下核心组件：\n超卖Server（Oversell Server）：负责计算超卖策略，生成/更新OversellRule CR。 超卖Operator（Oversell Operator）：监听OversellRule CR，动态调整Pod的requests/limits。 监控系统（Prometheus + Metrics Server）：提供实时资源利用率数据。 graph TB subgraph 超卖控制系统 OversellServer --\u003e|生成/更新| OversellRuleCR OversellOperator --\u003e|监听| OversellRuleCR OversellOperator --\u003e|修改Pod资源| KubernetesAPI Prometheus --\u003e|资源指标| OversellServer end 超卖的关键技术考量 link资源类型差异：CPU vs 内存超卖 linkCPU超卖：时间片复用 link 技术原理： CPU是时分复用资源，通过Linux CFS调度器分配时间片。 超卖后，多个Pod分时共享物理核心（如10个Pod的limits.cpu总和为20核，但节点只有16核）。 优势： 即使超卖，Pod仅会因Throttling导致性能下降，通常不会崩溃。 风险控制： 监控CPU Throttling比例（超过5%需告警）。 为关键Pod设置cpuAffinity，减少上下文切换开销。 指标参考：\n# 查询容器的CPU限流时间占比 sum(rate(container_cpu_cfs_throttled_seconds_total{container!=\"\"}[5m])) by (pod) / sum(rate(container_cpu_usage_seconds_total{container!=\"\"}[5m])) by (pod) 内存超卖：OOM Kill风险 link 技术原理： 内存是独占式资源，超卖依赖“并非所有Pod同时满负荷”的假设。 一旦节点内存耗尽，内核根据oom_score强制终止Pod（OOMKilled）。 优势： 可显著提高内存利用率（尤其对稀疏使用的服务）。 风险控制： 避免超卖关键Pod（如数据库），仅对无状态服务超卖。 设置limits.memory ≤ 节点可用内存的70%（预留缓冲）。 指标参考：\n# 查询OOM Kill事件 kube_pod_container_status_last_terminated_reason{reason=\"OOMKilled\"} CPU与内存超卖对比\n维度 CPU超卖 内存超卖 隔离机制 时间片分时共享 硬性上限（OOM Kill） 超卖安全性 高（仅限流） 低（可能崩溃） 适合场景 计算密集型、批处理任务 内存使用波动大的无状态服务 监控与告警策略 link核心监控指标 link 指标 说明 超卖健康阈值 node_memory_MemAvailable_bytes 节点可用内存量 \u003c20%总内存时告警 container_cpu_cfs_throttled_seconds_total CPU限流时间 \u003e5%时告警 container_memory_working_set_bytes Pod内存使用量（常驻集） 接近limits.memory时告警 kube_pod_status_phase{phase=\"Failed\"} 因OOM Kill失败的Pod 任意出现即告警 Grafana看板示例：\nCPU超卖看板：展示各节点的CPU Allocatable vs CPU Requests vs CPU Usage。 内存超卖看板：监控Memory Limits总和与节点物理内存的比例。 告警规则示例（Prometheus） link # 内存超卖告警：节点可用内存不足 - alert: NodeMemoryUnderPressure expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes \u003c 0.2 for: 5m labels: severity: warning annotations: summary: \"{{ $labels.instance }} 可用内存低于20%\" # CPU限流告警 - alert: HighCPUThrottling expr: rate(container_cpu_cfs_throttled_seconds_total[5m]) / rate(container_cpu_usage_seconds_total[5m]) \u003e 0.05 for: 10m labels: severity: warning 优先级与抢占机制 linkPod PriorityClass link通过定义优先级，确保关键业务在资源竞争时优先存活：\napiVersion: scheduling.k8s.io/v1 kind: PriorityClass metadata: name: high-priority value: 1000000 # 优先级数值（越高越优先） preemptionPolicy: Never # 是否允许抢占其他Pod 使用场景：\n关键业务：设置为high-priority，避免被OOM Kill或驱逐。 批处理任务：设置为low-priority，允许超卖且可被抢占。 调度抢占（Preemption） link 触发条件：\n当高优先级Pod因资源不足无法调度时，Kubernetes会尝试驱逐低优先级Pod腾出资源。 限制： 仅驱逐Burstable/BestEffort Pod，不驱逐Guaranteed Pod。 需配合PodDisruptionBudget（PDB）防止大规模中断。 示例：\napiVersion: policy/v1 kind: PodDisruptionBudget metadata: name: zk-pdb spec: minAvailable: 2 # 保证至少2个Pod可用 selector: matchLabels: app: zookeeper 超卖场景下的优化技巧 linkCPU绑核（CPU Pinning） link 问题：超卖可能导致CPU缓存频繁失效，降低性能。 方案：对延迟敏感型Pod绑定特定核心： resources: limits: cpu: \"2\" affinity: nodeAffinity: {...} podAntiAffinity: {...} 内存大页（HugePages） link 问题：常规4KB内存页在超卖时可能引发TLB抖动。 方案：为数据库等应用分配大页内存： resources: limits: memory: \"2Gi\" hugepages-2Mi: \"1Gi\" cgroup v2增强隔离 link 特性： CPU权重：替代cpu.shares，更精确控制资源分配。 内存QoS：限制内存回收优先级，减少OOM概率。 启用方式： kubelet --cgroup-driver=systemd --cgroups-per-qos=true --enforce-node-allocatable=pods 超卖的最佳实践 link资源超卖是一把双刃剑，用得好可以显著提升集群效率，用不好则可能导致稳定性问题。本章将结合生产经验，总结适合超卖的场景、避免超卖陷阱的方法，以及混合部署策略，帮助你在安全边界内最大化资源利用率。\n适合超卖的场景 link非关键业务 link 业务类型 超卖建议 开发/测试环境 允许CPU/内存超卖，即使发生OOM Kill影响也有限 CI/CD流水线 构建任务可超卖CPU，加速任务完成（配合BestEffort QoS） 批处理作业 日志分析、数据清洗等短时任务，适合动态超卖（突发资源需求后释放） 配置示例（低优先级批处理Job）：\napiVersion: batch/v1 kind: Job metadata: name: data-processor spec: template: spec: priorityClassName: low-priority # 设置为低优先级 containers: - name: processor resources: requests: cpu: \"0.5\" memory: \"512Mi\" limits: cpu: \"2\" memory: \"2Gi\" 弹性业务负载 link 业务类型 超卖策略 Web服务 根据流量规律超卖CPU（日间高峰时突发，夜间自动缩容） 缓存服务 超卖内存（如Redis实例内存limits设为物理内存的120%，依赖监控及时扩容） 消息队列消费者 消费队列积压时临时超卖CPU，快速消费后释放资源 流量自适应超卖架构：\ngraph LR HPA(Horizontal Pod Autoscaler) --\u003e|扩缩容| Pod VPA(Vertical Pod Autoscaler) --\u003e|调整requests/limits| Pod Prometheus --\u003e|监控指标| HPA Prometheus --\u003e|历史数据| VPA 避免超卖陷阱的硬性规则 link内存超卖的禁区 link 禁止超卖的场景：\n数据库（MySQL/PostgreSQL等）—— OOM可能导致数据损坏。 有状态服务（如Etcd、ZooKeeper）—— 内存不足破坏集群一致性。 实时音视频处理—— 内存抖动引发卡顿或中断。 安全替代方案：\n# 数据库Pod的配置示例（禁止超卖） resources: requests: memory: \"8Gi\" limits: memory: \"8Gi\" # requests == limits → Guaranteed QoS CPU超卖的缓冲策略 link 设置Throttling告警阈值： # 当CPU限流时间占比超过10%时告警 sum(rate(container_cpu_cfs_throttled_seconds_total[5m])) by (pod) / sum(rate(container_cpu_usage_seconds_total[5m])) by (pod) \u003e 0.1 关键Pod的CPU绑定： affinity: nodeAffinity: {...} resources: limits: cpu: \"2\" requests: cpu: \"2\" 全局资源配额（ResourceQuota） link通过ResourceQuota限制Namespace级别的超卖总量，避免单个团队过度占用资源：\napiVersion: v1 kind: ResourceQuota metadata: name: oversell-quota spec: hard: requests.cpu: \"100\" # 所有Pod的requests总和不超过100核 limits.cpu: \"200\" # 所有Pod的limits总和不超过200核（超卖比例2:1） requests.memory: 200Gi limits.memory: 300Gi # 内存超卖比例1.5:1 混合部署策略 link节点分组管理 link 节点池 超卖策略 标签选择器示例 critical-nodes 禁止超卖（Guaranteed QoS专用） node-role.kubernetes.io/critical=true oversell-nodes 允许CPU/内存超卖（运行非关键业务） node-role.kubernetes.io/oversell=true 调度示例：\napiVersion: apps/v1 kind: Deployment metadata: name: nginx spec: template: spec: nodeSelector: node-role.kubernetes.io/oversell: \"true\" # 指定调度到超卖节点 优先级与驱逐协同 link 关键业务： 设置priorityClassName: system-cluster-critical（Kubernetes内置最高优先级）。 配置podAntiAffinity避免与其他高负载Pod同节点。 低优先级任务： 允许被驱逐（priorityClassName: low-priority）。 设置restartPolicy: OnFailure应对OOM Kill。 完整示例：\napiVersion: apps/v1 kind: Deployment metadata: name: web-service spec: template: spec: priorityClassName: high-priority affinity: podAntiAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: app operator: In values: [\"redis\"] topologyKey: kubernetes.io/hostname containers: - name: nginx resources: requests: cpu: \"2\" memory: \"4Gi\" limits: cpu: \"2\" memory: \"4Gi\" 超卖实施的渐进式验证 link四阶段上线流程 link 观察期（1周）： 采集现有业务的真实资源使用曲线（尤其关注波谷时段）。 小规模测试（2周）： 在dev命名空间对非关键Pod启用超卖，监控Throttling/OOM事件。 滚动推广（1个月）： 按业务优先级分批调整requests/limits，优先处理批处理任务。 全局优化： 结合VPA动态调整超卖比例，定期审查监控数据。 验收指标：\nCPU平均利用率从30%提升至60%+，且Throttling率\u003c5%。 内存OOM Kill事件每周≤1次（仅发生在低优先级Pod）。 总结：超卖的安全边界 link ✅ 可以做： 对无状态、可中断的业务超卖CPU。 在监控完备的情况下超卖内存（预留20%缓冲）。 ❌ 不要做： 超卖数据库、有状态服务的内存。 在未设置PriorityClass和ResourceQuota时全局超卖。 "
            }
        );
    index.add(
            {
                id:  50 ,
                href: "\/docs\/information\/software\/cloud\/autoscale\/",
                title: "Cluster Autoscaler",
                description: "1. 什么是 Cluster Autoscaler？ linkKubernetes Cluster Autoscaler（CA） 是一个开源的 Kubernetes 组件，用于 自动调整集群的节点数量，以确保 Pod 能够被高效调度，同时优化资源利用率，降低成本。\n核心功能 link 自动扩容：当 Pod 因资源不足无法调度时，自动增加节点。 自动缩容：当节点利用率过低时，安全移除空闲节点。 多云支持：兼容 AWS、GCP、Azure、阿里云、腾讯云等主流云平台。 2. 为什么需要 Cluster Autoscaler？ link在 Kubernetes 集群中，Pod 的负载通常是动态变化的：\n突发流量：业务高峰时，需要快速扩容节点以承载更多 Pod。 资源浪费：低峰期时，部分节点可能闲置，但仍需支付费用。 手动管理节点的问题：\n响应慢：人工调整节点数量无法应对突发流量。 成本高：固定节点数量可能导致资源浪费或不足。 Cluster Autoscaler 的解决方案：\n自动化：根据 Pod 需求动态调整节点数量。 成本优化：减少闲置节点，节省云资源费用。 3. Cluster Autoscaler 的工作原理 link（1）触发扩容的条件 link 当 Kubernetes 调度器（Scheduler）发现 Pending Pod（因资源不足无法调度的 Pod）时，Cluster Autoscaler 会检查： 是否有合适的节点池（Node Pool）可以扩容。 扩容后是否能满足 Pod 的资源需求（CPU、内存等）。 （2）触发缩容的条件 link 当节点 长时间利用率过低（默认低于 50%）时，Cluster Autoscaler 会尝试缩容： 检查节点上的 Pod 是否可以被安全迁移（如使用 PodDisruptionBudget 保护关键应用）。 确保缩容不会导致其他节点过载。 （3）与云厂商的交互 linkCluster Autoscaler 通过调用 云厂商的 API（如 AWS ASG、Azure VMSS、GCP MIG）调整节点数量：\n",
                content: "1. 什么是 Cluster Autoscaler？ linkKubernetes Cluster Autoscaler（CA） 是一个开源的 Kubernetes 组件，用于 自动调整集群的节点数量，以确保 Pod 能够被高效调度，同时优化资源利用率，降低成本。\n核心功能 link 自动扩容：当 Pod 因资源不足无法调度时，自动增加节点。 自动缩容：当节点利用率过低时，安全移除空闲节点。 多云支持：兼容 AWS、GCP、Azure、阿里云、腾讯云等主流云平台。 2. 为什么需要 Cluster Autoscaler？ link在 Kubernetes 集群中，Pod 的负载通常是动态变化的：\n突发流量：业务高峰时，需要快速扩容节点以承载更多 Pod。 资源浪费：低峰期时，部分节点可能闲置，但仍需支付费用。 手动管理节点的问题：\n响应慢：人工调整节点数量无法应对突发流量。 成本高：固定节点数量可能导致资源浪费或不足。 Cluster Autoscaler 的解决方案：\n自动化：根据 Pod 需求动态调整节点数量。 成本优化：减少闲置节点，节省云资源费用。 3. Cluster Autoscaler 的工作原理 link（1）触发扩容的条件 link 当 Kubernetes 调度器（Scheduler）发现 Pending Pod（因资源不足无法调度的 Pod）时，Cluster Autoscaler 会检查： 是否有合适的节点池（Node Pool）可以扩容。 扩容后是否能满足 Pod 的资源需求（CPU、内存等）。 （2）触发缩容的条件 link 当节点 长时间利用率过低（默认低于 50%）时，Cluster Autoscaler 会尝试缩容： 检查节点上的 Pod 是否可以被安全迁移（如使用 PodDisruptionBudget 保护关键应用）。 确保缩容不会导致其他节点过载。 （3）与云厂商的交互 linkCluster Autoscaler 通过调用 云厂商的 API（如 AWS ASG、Azure VMSS、GCP MIG）调整节点数量：\n扩容：增加节点池中的实例数量。 缩容：选择最空闲的节点进行移除。 4. 支持的云平台 link 云平台 依赖组件 备注 AWS EC2 Auto Scaling Groups (ASG) 支持 Spot 实例 GCP Managed Instance Groups (MIG) 内置 GKE 支持 Azure VM Scale Sets (VMSS) 适用于 AKS 阿里云 弹性伸缩组 (ESS) 需配置 RAM 权限 腾讯云 弹性伸缩 (AS) 需适配 本地/裸金属 需自定义实现 较少使用 5. 如何部署 Cluster Autoscaler？ link（1）前置条件 link Kubernetes 集群（版本 ≥ 1.14）。 配置好 节点组/自动伸缩组（如 AWS ASG）。 确保节点有足够的 IAM 权限（如 autoscaling:SetDesiredCapacity）。 （2）安装方式（以 AWS EKS 为例） link方式 1：Helm 安装 link helm repo add autoscaler https://kubernetes.github.io/autoscaler helm install cluster-autoscaler autoscaler/cluster-autoscaler \\ --namespace kube-system \\ --set \"autoDiscovery.clusterName=\" \\ --set \"awsRegion=\" \\ --set \"rbac.create=true\" 方式 2：直接部署 YAML link apiVersion: apps/v1 kind: Deployment metadata: name: cluster-autoscaler namespace: kube-system spec: replicas: 1 selector: matchLabels: app: cluster-autoscaler template: metadata: labels: app: cluster-autoscaler spec: containers: - name: cluster-autoscaler image: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.25.0 command: - ./cluster-autoscaler - --cloud-provider=aws - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled, - --balance-similar-node-groups - --skip-nodes-with-system-pods=false serviceAccountName: cluster-autoscaler （3）关键参数配置 link 参数 说明 --scale-down-utilization-threshold 缩容阈值（默认 0.5，即 50% 利用率） --expander 扩容策略（least-waste / random / priority） --skip-nodes-with-system-pods 是否跳过含系统 Pod 的节点（默认 true） 6. 最佳实践 link（1）合理设置 Pod 资源请求 link resources: requests: cpu: \"500m\" memory: \"512Mi\" 避免未设置 requests，否则 CA 无法正确计算资源需求。 （2）使用 PodDisruptionBudget (PDB) 保护关键应用 link apiVersion: policy/v1 kind: PodDisruptionBudget metadata: name: myapp-pdb spec: minAvailable: 1 # 确保至少 1 个 Pod 可用 selector: matchLabels: app: myapp （3）结合 HPA（Horizontal Pod Autoscaler） link HPA 负责 Pod 横向扩缩，CA 负责节点扩缩，两者配合实现全自动弹性伸缩。 （4）监控与告警 link 使用 Prometheus + Grafana 监控： kube_pod_status_unschedulable（Pending Pod 数量）。 cluster_autoscaler_nodes_count（节点变化趋势）。 7. 常见问题 linkQ1：Cluster Autoscaler 和 HPA 有什么区别？ link HPA：调整 Pod 副本数量（水平扩缩容）。 CA：调整节点数量（垂直扩缩容）。 Q2：为什么节点没有自动缩容？ link 可能原因： 节点上有 不可迁移的 Pod（如 kube-system 组件）。 未满足 scale-down-utilization-threshold。 PDB 阻止 Pod 被驱逐。 Q3：如何防止频繁扩缩容？ link 调整 --scale-down-delay-after-add（默认 10m）和 --scale-down-unneeded-time（默认 10m）。 8. 总结 linkKubernetes Cluster Autoscaler 是构建弹性、高可用集群的关键组件，能够： ✅ 自动优化节点数量，提高资源利用率。\n✅ 降低成本，减少闲置节点开销。\n✅ 支持多云环境，与主流云平台无缝集成。\n适用于 突发流量、CI/CD、大数据计算 等动态负载场景。建议结合 HPA 和 PDB 实现更完善的自动扩缩策略。\n参考链接 link 官方 GitHub AWS EKS 最佳实践 GKE 自动扩缩文档 "
            }
        );
    index.add(
            {
                id:  51 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/taint_toleration\/",
                title: "Taint \u0026 Toleration",
                description: "Taint（污点）和 Toleration（容忍）可以作用于 node 和 pod 上，其目的是优化 pod 在集群间的调度，这跟节点亲和性类似，只不过它们作用的方式相反，具有 taint 的 node 和 pod 是互斥关系，而具有节点亲和性关系的 node 和 pod 是相吸的。另外还有可以给 node 节点设置 label，通过给 pod 设置 nodeSelector 将 pod 调度到具有匹配标签的节点上。\nTaint 和 toleration 相互配合，可以用来避免 pod 被分配到不合适的节点上。每个节点上都可以应用一个或多个 taint ，这表示对于那些不能容忍这些 taint 的 pod，是不会被该节点接受的。如果将 toleration 应用于 pod 上，则表示这些 pod 可以（但不要求）被调度到具有相应 taint 的节点上。\n示例 link以下分别以为 node 设置 taint 和为 pod 设置 toleration 为例。\n为 node 设置 taint link为 node1 设置 taint：\nkubectl taint nodes node1 key1=value1:NoSchedule kubectl taint nodes node1 key1=value1:NoExecute kubectl taint nodes node1 key2=value2:NoSchedule 删除上面的 taint：\n",
                content: "Taint（污点）和 Toleration（容忍）可以作用于 node 和 pod 上，其目的是优化 pod 在集群间的调度，这跟节点亲和性类似，只不过它们作用的方式相反，具有 taint 的 node 和 pod 是互斥关系，而具有节点亲和性关系的 node 和 pod 是相吸的。另外还有可以给 node 节点设置 label，通过给 pod 设置 nodeSelector 将 pod 调度到具有匹配标签的节点上。\nTaint 和 toleration 相互配合，可以用来避免 pod 被分配到不合适的节点上。每个节点上都可以应用一个或多个 taint ，这表示对于那些不能容忍这些 taint 的 pod，是不会被该节点接受的。如果将 toleration 应用于 pod 上，则表示这些 pod 可以（但不要求）被调度到具有相应 taint 的节点上。\n示例 link以下分别以为 node 设置 taint 和为 pod 设置 toleration 为例。\n为 node 设置 taint link为 node1 设置 taint：\nkubectl taint nodes node1 key1=value1:NoSchedule kubectl taint nodes node1 key1=value1:NoExecute kubectl taint nodes node1 key2=value2:NoSchedule 删除上面的 taint：\nkubectl taint nodes node1 key1:NoSchedule- kubectl taint nodes node1 key1:NoExecute- kubectl taint nodes node1 key2:NoSchedule- 查看 node1 上的 taint：\nkubectl describe nodes node1 为 pod 设置 toleration link只要在 pod 的 spec 中设置 tolerations 字段即可，可以有多个 key，如下所示：\ntolerations: - key: \"key1\" operator: \"Equal\" value: \"value1\" effect: \"NoSchedule\" - key: \"key1\" operator: \"Equal\" value: \"value1\" effect: \"NoExecute\" - key: \"node.alpha.kubernetes.io/unreachable\" operator: \"Exists\" effect: \"NoExecute\" tolerationSeconds: 6000 value 的值可以为 NoSchedule、 PreferNoSchedule 或 NoExecute。 tolerationSeconds 是当 pod 需要被驱逐时，可以继续在 node 上运行的时间。 详细使用方法请参考官方文档。\n参考 link Taints and Tolerations - kuberentes.io "
            }
        );
    index.add(
            {
                id:  52 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/garbage-collection\/",
                title: "垃圾回收",
                description: "Kubernetes 垃圾收集器的角色是删除指定的对象，这些对象曾经有但以后不再拥有 Owner 了。\n注意：垃圾收集是 beta 特性，在 Kubernetes 1.4 及以上版本默认启用。\nOwner 和 Dependent link一些 Kubernetes 对象是其它一些的 Owner。例如，一个 ReplicaSet 是一组 Pod 的 Owner。具有 Owner 的对象被称为是 Owner 的 Dependent。每个 Dependent 对象具有一个指向其所属对象的 metadata.ownerReferences 字段。\n有时，Kubernetes 会自动设置 ownerReference 的值。例如，当创建一个 ReplicaSet 时，Kubernetes 自动设置 ReplicaSet 中每个 Pod 的 ownerReference 字段值。在 1.6 版本，Kubernetes 会自动为一些对象设置 ownerReference 的值，这些对象是由 ReplicationController、ReplicaSet、StatefulSet、DaemonSet 和 Deployment 所创建或管理。\n也可以通过手动设置 ownerReference 的值，来指定 Owner 和 Dependent 之间的关系。\n这有一个配置文件my-repset.yaml，表示一个具有 3 个 Pod 的 ReplicaSet：\n# k8s \u003e= 1.16 使用下面注释 https://stackoverflow.com/questions/64412740/no-matches-for-kind-replicaset-in-version-extensions-v1beta1/64412990#64412990 # apiVersion: apps/v1 # k8s \u003c 1.16 使用下面配置 apiVersion: extensions/v1beta1 kind: ReplicaSet metadata: name: my-repset spec: replicas: 3 selector: matchLabels: pod-is-for: garbage-collection-example template: metadata: labels: pod-is-for: garbage-collection-example spec: containers: - name: nginx image: nginx 如果创建该 ReplicaSet，然后查看 Pod 的 metadata 字段，能够看到 OwnerReferences 字段：\n",
                content: "Kubernetes 垃圾收集器的角色是删除指定的对象，这些对象曾经有但以后不再拥有 Owner 了。\n注意：垃圾收集是 beta 特性，在 Kubernetes 1.4 及以上版本默认启用。\nOwner 和 Dependent link一些 Kubernetes 对象是其它一些的 Owner。例如，一个 ReplicaSet 是一组 Pod 的 Owner。具有 Owner 的对象被称为是 Owner 的 Dependent。每个 Dependent 对象具有一个指向其所属对象的 metadata.ownerReferences 字段。\n有时，Kubernetes 会自动设置 ownerReference 的值。例如，当创建一个 ReplicaSet 时，Kubernetes 自动设置 ReplicaSet 中每个 Pod 的 ownerReference 字段值。在 1.6 版本，Kubernetes 会自动为一些对象设置 ownerReference 的值，这些对象是由 ReplicationController、ReplicaSet、StatefulSet、DaemonSet 和 Deployment 所创建或管理。\n也可以通过手动设置 ownerReference 的值，来指定 Owner 和 Dependent 之间的关系。\n这有一个配置文件my-repset.yaml，表示一个具有 3 个 Pod 的 ReplicaSet：\n# k8s \u003e= 1.16 使用下面注释 https://stackoverflow.com/questions/64412740/no-matches-for-kind-replicaset-in-version-extensions-v1beta1/64412990#64412990 # apiVersion: apps/v1 # k8s \u003c 1.16 使用下面配置 apiVersion: extensions/v1beta1 kind: ReplicaSet metadata: name: my-repset spec: replicas: 3 selector: matchLabels: pod-is-for: garbage-collection-example template: metadata: labels: pod-is-for: garbage-collection-example spec: containers: - name: nginx image: nginx 如果创建该 ReplicaSet，然后查看 Pod 的 metadata 字段，能够看到 OwnerReferences 字段：\nkubectl create -f my-repset.yaml kubectl get pods --output=yaml 输出显示了 Pod 的 Owner 是名为 my-repset 的 ReplicaSet：\napiVersion: v1 kind: Pod metadata: ... ownerReferences: - apiVersion: extensions/v1beta1 controller: true blockOwnerDeletion: true kind: ReplicaSet name: my-repset uid: d9607e19-f88f-11e6-a518-42010a800195 ... 控制垃圾收集器删除 Dependent link当删除对象时，可以指定是否该对象的 Dependent 也自动删除掉。自动删除 Dependent 也称为 级联删除。Kubernetes 中有两种 级联删除 的模式：background 模式和 foreground 模式。\n如果删除对象时，不自动删除它的 Dependent，这些 Dependent 被称作是原对象的 孤儿。\nBackground 级联删除 link在 background 级联删除 模式下，Kubernetes 会立即删除 Owner 对象，然后垃圾收集器会在后台删除这些 Dependent。\nForeground 级联删除 link在 foreground 级联删除 模式下，根对象首先进入 “删除中” 状态。在 “删除中” 状态会有如下的情况：\n对象仍然可以通过 REST API 可见 会设置对象的 deletionTimestamp 字段 对象的 metadata.finalizers 字段包含了值 “foregroundDeletion” 一旦被设置为 “删除中” 状态，垃圾收集器会删除对象的所有 Dependent。垃圾收集器删除了所有 “Blocking” 的 Dependent（对象的 ownerReference.blockOwnerDeletion=true）之后，它会删除 Owner 对象。\n注意，在 “foreground 删除” 模式下，Dependent 只有通过 ownerReference.blockOwnerDeletion 才能阻止删除 Owner 对象。在 Kubernetes 1.7 版本中将增加 admission controller，基于 Owner 对象上的删除权限来控制用户去设置 blockOwnerDeletion 的值为 true，所以未授权的 Dependent 不能够延迟 Owner 对象的删除。\n如果一个对象的ownerReferences 字段被一个 Controller（例如 Deployment 或 ReplicaSet）设置，blockOwnerDeletion 会被自动设置，没必要手动修改这个字段。\n设置级联删除策略 link通过为 Owner 对象设置 deleteOptions.propagationPolicy 字段，可以控制级联删除策略。可能的取值包括：“orphan”、“Foreground” 或 “Background”。\n对很多 Controller 资源，包括 ReplicationController、ReplicaSet、StatefulSet、DaemonSet 和 Deployment，默认的垃圾收集策略是 orphan。因此，除非指定其它的垃圾收集策略，否则所有 Dependent 对象使用的都是 orphan 策略。\n注意：本段所指的默认值是指 REST API 的默认值，并非 kubectl 命令的默认值，kubectl 默认为级联删除，后面会讲到。\n下面是一个在后台删除 Dependent 对象的例子：\nkubectl proxy --port=8080 curl -X DELETE localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/my-repset \\ -d '{\"kind\":\"DeleteOptions\",\"apiVersion\":\"v1\",\"propagationPolicy\":\"Background\"}' \\ -H \"Content-Type: application/json\" 下面是一个在前台删除 Dependent 对象的例子：\nkubectl proxy --port=8080 curl -X DELETE localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/my-repset \\ -d '{\"kind\":\"DeleteOptions\",\"apiVersion\":\"v1\",\"propagationPolicy\":\"Foreground\"}' \\ -H \"Content-Type: application/json\" 下面是一个孤儿 Dependent 的例子：\nkubectl proxy --port=8080 curl -X DELETE localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/my-repset \\ -d '{\"kind\":\"DeleteOptions\",\"apiVersion\":\"v1\",\"propagationPolicy\":\"Orphan\"}' \\ -H \"Content-Type: application/json\" kubectl 也支持级联删除。 通过设置 --cascade 为 true，可以使用 kubectl 自动删除 Dependent 对象。设置 --cascade 为 false，会使 Dependent 对象成为孤儿 Dependent 对象。--cascade 的默认值是 true。\n下面是一个例子，使一个 ReplicaSet 的 Dependent 对象成为孤儿 Dependent：\nkubectl delete replicaset my-repset --cascade=false 已知的问题 link 1.7 版本，垃圾收集不支持 自定义资源，比如那些通过 CustomResourceDefinition 新增，或者通过 API server 聚集而成的资源对象。 其它已知的问题。 "
            }
        );
    index.add(
            {
                id:  53 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/scheduling\/",
                title: "资源调度",
                description: "Kubernetes 作为一个容器编排调度引擎，资源调度是它的最基本也是最重要的功能，这一节中我们将着重讲解 Kubernetes 中是如何做资源调度的。\nKubernetes 中有一个叫做 kube-scheduler 的组件，该组件就是专门监听 kube-apiserver 中是否有还未调度到 node 上的 pod，再通过特定的算法为 pod 指定分派 node 运行。\nKubernetes 中的众多资源类型，例如 Deployment、DaemonSet、StatefulSet 等都已经定义了 Pod 运行的一些默认调度策略，但是如果我们细心的根据 node 或者 pod 的不同属性，分别为它们打上标签之后，我们将发现 Kubernetes 中的高级调度策略是多么强大。当然如果要实现动态的资源调度，即 pod 已经调度到某些节点上后，因为一些其它原因，想要让 pod 重新调度到其它节点。\n考虑以下两种情况：\n集群中有新增节点，想要让集群中的节点的资源利用率比较均衡一些，想要将一些高负载的节点上的 pod 驱逐到新增节点上，这是 kuberentes 的 scheduler 所不支持的，需要使用如 descheduler 这样的插件来实现。 想要运行一些大数据应用，设计到资源分片，pod 需要与数据分布达到一致均衡，避免个别节点处理大量数据，而其它节点闲置导致整个作业延迟，这时候可以考虑使用 kube-batch。 ",
                content: "Kubernetes 作为一个容器编排调度引擎，资源调度是它的最基本也是最重要的功能，这一节中我们将着重讲解 Kubernetes 中是如何做资源调度的。\nKubernetes 中有一个叫做 kube-scheduler 的组件，该组件就是专门监听 kube-apiserver 中是否有还未调度到 node 上的 pod，再通过特定的算法为 pod 指定分派 node 运行。\nKubernetes 中的众多资源类型，例如 Deployment、DaemonSet、StatefulSet 等都已经定义了 Pod 运行的一些默认调度策略，但是如果我们细心的根据 node 或者 pod 的不同属性，分别为它们打上标签之后，我们将发现 Kubernetes 中的高级调度策略是多么强大。当然如果要实现动态的资源调度，即 pod 已经调度到某些节点上后，因为一些其它原因，想要让 pod 重新调度到其它节点。\n考虑以下两种情况：\n集群中有新增节点，想要让集群中的节点的资源利用率比较均衡一些，想要将一些高负载的节点上的 pod 驱逐到新增节点上，这是 kuberentes 的 scheduler 所不支持的，需要使用如 descheduler 这样的插件来实现。 想要运行一些大数据应用，设计到资源分片，pod 需要与数据分布达到一致均衡，避免个别节点处理大量数据，而其它节点闲置导致整个作业延迟，这时候可以考虑使用 kube-batch。 "
            }
        );
    index.add(
            {
                id:  54 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/qos\/",
                title: "Qos 服务质量等级",
                description: "QoS（Quality of Service），大部分译为“服务质量等级”，又译作“服务质量保证”，是作用在 Pod 上的一个配置，当 Kubernetes 创建一个 Pod 时，它就会给这个 Pod 分配一个 QoS 等级，可以是以下等级之一：\nGuaranteed：Pod 里的每个容器都必须有内存/CPU 限制和请求，而且值必须相等。 Burstable：Pod 里至少有一个容器有内存或者 CPU 请求且不满足 Guarantee 等级的要求，即内存/CPU 的值设置的不同。 BestEffort：容器必须没有任何内存或者 CPU 的限制或请求。 该配置不是通过一个配置项来配置的，而是通过配置 CPU/内存的 limits 与 requests 值的大小来确认服务质量等级的。使用 kubectl get pod -o yaml 可以看到 pod 的配置输出中有 qosClass 一项。该配置的作用是为了给资源调度提供策略支持，Kubernetes 依赖这种分类来决定当 Node 上没有足够可用资源时要驱逐哪些 Pod。\n例如，下面这个 YAML 配置中的 Pod 资源配置部分设置的服务质量等级就是 Guarantee。\nspec: containers: ... resources: limits: cpu: 100m memory: 128Mi requests: cpu: 100m memory: 128Mi 下面的 YAML 配置的 Pod 的服务质量等级是 Burstable。\n",
                content: "QoS（Quality of Service），大部分译为“服务质量等级”，又译作“服务质量保证”，是作用在 Pod 上的一个配置，当 Kubernetes 创建一个 Pod 时，它就会给这个 Pod 分配一个 QoS 等级，可以是以下等级之一：\nGuaranteed：Pod 里的每个容器都必须有内存/CPU 限制和请求，而且值必须相等。 Burstable：Pod 里至少有一个容器有内存或者 CPU 请求且不满足 Guarantee 等级的要求，即内存/CPU 的值设置的不同。 BestEffort：容器必须没有任何内存或者 CPU 的限制或请求。 该配置不是通过一个配置项来配置的，而是通过配置 CPU/内存的 limits 与 requests 值的大小来确认服务质量等级的。使用 kubectl get pod -o yaml 可以看到 pod 的配置输出中有 qosClass 一项。该配置的作用是为了给资源调度提供策略支持，Kubernetes 依赖这种分类来决定当 Node 上没有足够可用资源时要驱逐哪些 Pod。\n例如，下面这个 YAML 配置中的 Pod 资源配置部分设置的服务质量等级就是 Guarantee。\nspec: containers: ... resources: limits: cpu: 100m memory: 128Mi requests: cpu: 100m memory: 128Mi 下面的 YAML 配置的 Pod 的服务质量等级是 Burstable。\nspec: containers: ... resources: limits: memory: \"180Mi\" requests: memory: \"100Mi\" 参考 link 配置 Pod 的服务质量 - kubernetes.io "
            }
        );
    index.add(
            {
                id:  55 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/deployment\/",
                title: "Deployment",
                description: "Deployment 为 Pod 和 ReplicaSet 提供了一个声明式定义（declarative）方法，用来替代以前的 ReplicationController 来方便的管理应用。典型的应用场景包括：\n定义 Deployment 来创建 Pod 和 ReplicaSet 滚动升级和回滚应用 扩容和缩容 暂停和继续 Deployment 比如一个简单的 nginx 应用可以定义为：\napiVersion: extensions/v1beta1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 3 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 扩容：\nkubectl scale deployment nginx-deployment --replicas 10 如果集群支持 horizontal pod autoscaling 的话，还可以为 Deployment 设置自动扩展：\nkubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80 更新镜像也比较简单：\n",
                content: "Deployment 为 Pod 和 ReplicaSet 提供了一个声明式定义（declarative）方法，用来替代以前的 ReplicationController 来方便的管理应用。典型的应用场景包括：\n定义 Deployment 来创建 Pod 和 ReplicaSet 滚动升级和回滚应用 扩容和缩容 暂停和继续 Deployment 比如一个简单的 nginx 应用可以定义为：\napiVersion: extensions/v1beta1 kind: Deployment metadata: name: nginx-deployment spec: replicas: 3 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 扩容：\nkubectl scale deployment nginx-deployment --replicas 10 如果集群支持 horizontal pod autoscaling 的话，还可以为 Deployment 设置自动扩展：\nkubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80 更新镜像也比较简单：\nkubectl set image deployment/nginx-deployment nginx=nginx:1.9.1 回滚：\nkubectl rollout undo deployment/nginx-deployment Deployment 概念详细解析 link本文翻译自 kubernetes 官方文档：https://kubernetes.io/docs/concepts/workloads/controllers/deployment\n根据 2017 年 5 月 10 日的 Commit 8481c02 翻译。\nDeployment 是什么？ linkDeployment 为 Pod 和 Replica Set（下一代 Replication Controller）提供声明式更新。\n您只需要在 Deployment 中描述您想要的目标状态是什么，Deployment controller 就会帮您将 Pod 和 ReplicaSet 的实际状态改变到您的目标状态。您可以定义一个全新的 Deployment 来创建 ReplicaSet 或者删除已有的 Deployment 并创建一个新的来替换。\n注意：您不该手动管理由 Deployment 创建的 ReplicaSet，否则您就篡越了 Deployment controller 的职责！下文罗列了 Deployment 对象中已经覆盖了所有的用例。如果未有覆盖您所有需要的用例，请直接在 Kubernetes 的代码库中提 issue。\n典型的用例如下：\n使用 Deployment 来创建 ReplicaSet。ReplicaSet 在后台创建 pod。检查启动状态，看它是成功还是失败。 然后，通过更新 Deployment 的 PodTemplateSpec 字段来声明 Pod 的新状态。这会创建一个新的 ReplicaSet，Deployment 会按照控制的速率将 pod 从旧的 ReplicaSet 移动到新的 ReplicaSet 中。 如果当前状态不稳定，回滚到之前的 Deployment revision。每次回滚都会更新 Deployment 的 revision。 扩容 Deployment 以满足更高的负载。 暂停 Deployment 来应用 PodTemplateSpec 的多个修复，然后恢复上线。 根据 Deployment 的状态判断上线是否 hang 住了。 清除旧的不必要的 ReplicaSet。 创建 Deployment link下面是一个 Deployment 示例，它创建了一个 ReplicaSet 来启动 3 个 nginx pod。\n下载示例文件并执行命令：\n$ kubectl create -f https://kubernetes.io/docs/user-guide/nginx-deployment.yaml --record deployment \"nginx-deployment\" created 将 kubectl 的--record的 flag 设置为true 可以在 annotation 中记录当前命令创建或者升级了该资源。这在未来会很有用，例如，查看在每个 Deployment revision 中执行了哪些命令。\n然后立即执行 get 将获得如下结果：\n$ kubectl get deployments NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx-deployment 3 0 0 0 1s 输出结果表明我们希望的 repalica 数是 3（根据 deployment 中的.spec.replicas配置）当前 replica 数（.status.replicas）是 0, 最新的 replica 数（.status.updatedReplicas）是 0，可用的 replica 数（.status.availableReplicas）是 0。\n过几秒后再执行 get 命令，将获得如下输出：\n$ kubectl get deployments NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx-deployment 3 3 3 3 18s 我们可以看到 Deployment 已经创建了 3 个 replica，所有的 replica 都已经是最新的了（包含最新的 pod template），可用的（根据 Deployment 中的.spec.minReadySeconds声明，处于已就绪状态的 pod 的最少个数）。执行kubectl get rs和kubectl get pods会显示 Replica Set（RS）和 Pod 已创建。\n$ kubectl get rs NAME DESIRED CURRENT READY AGE nginx-deployment-2035384211 3 3 0 18s 您可能会注意到 ReplicaSet 的名字总是-。\n$ kubectl get pods --show-labels NAME READY STATUS RESTARTS AGE LABELS nginx-deployment-2035384211-7ci7o 1/1 Running 0 18s app=nginx,pod-template-hash=2035384211 nginx-deployment-2035384211-kzszj 1/1 Running 0 18s app=nginx,pod-template-hash=2035384211 nginx-deployment-2035384211-qqcnn 1/1 Running 0 18s app=nginx,pod-template-hash=2035384211 刚创建的 Replica Set 将保证总是有 3 个 nginx 的 pod 存在。\n注意： 您必须在 Deployment 中的 selector 指定正确的 pod template label（在该示例中是 app = nginx），不要跟其他的 controller 的 selector 中指定的 pod template label 搞混了（包括 Deployment、Replica Set、Replication Controller 等）。Kubernetes 本身并不会阻止您任意指定 pod template label，但是如果您真的这么做了，这些 controller 之间会相互打架，并可能导致不正确的行为。\nPod-template-hash label link注意：这个 label 不是用户指定的！\n注意上面示例输出中的 pod label 里的 pod-template-hash label。当 Deployment 创建或者接管 ReplicaSet 时，Deployment controller 会自动为 Pod 添加 pod-template-hash label。这样做的目的是防止 Deployment 的子 ReplicaSet 的 pod 名字重复。通过将 ReplicaSet 的 PodTemplate 进行哈希散列，使用生成的哈希值作为 label 的值，并添加到 ReplicaSet selector 里、 pod template label 和 ReplicaSet 管理中的 Pod 上。\n更新 Deployment link**注意：**Deployment 的 rollout 当且仅当 Deployment 的 pod template（例如 .spec.template）中的 label 更新或者镜像更改时被触发。其他更新，例如扩容 Deployment 不会触发 rollout。\n假如我们现在想要让 nginx pod 使用 nginx:1.9.1 的镜像来代替原来的 nginx:1.7.9 的镜像。\n$ kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1 deployment \"nginx-deployment\" image updated 我们可以使用edit命令来编辑 Deployment，修改.spec.template.spec.containers [0].image，将nginx:1.7.9改写成nginx:1.9.1。\n$ kubectl edit deployment/nginx-deployment deployment \"nginx-deployment\" edited 查看 rollout 的状态，只要执行：\n$ kubectl rollout status deployment/nginx-deployment Waiting for rollout to finish: 2 out of 3 new replicas have been updated... deployment \"nginx-deployment\" successfully rolled out Rollout 成功后，getDeployment：\n$ kubectl get deployments NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx-deployment 3 3 3 3 36s UP-TO-DATE 的 replica 的数目已经达到了配置中要求的数目。\nCURRENT 的 replica 数表示 Deployment 管理的 replica 数量，AVAILABLE 的 replica 数是当前可用的 replica 数量。\n我们通过执行 kubectl get rs 可以看到 Deployment 更新了 Pod，通过创建一个新的 ReplicaSet 并扩容了 3 个 replica，同时将原来的 ReplicaSet 缩容到了 0 个 replica。\n$ kubectl get rs NAME DESIRED CURRENT READY AGE nginx-deployment-1564180365 3 3 0 6s nginx-deployment-2035384211 0 0 0 36s 执行get pods只会看到当前的新的 pod：\n$ kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-1564180365-khku8 1/1 Running 0 14s nginx-deployment-1564180365-nacti 1/1 Running 0 14s nginx-deployment-1564180365-z9gth 1/1 Running 0 14s 下次更新这些 pod 的时候，只需要更新 Deployment 中的 pod 的 template 即可。\nDeployment 可以保证在升级时只有一定数量的 Pod 是 down 的。默认的，它会确保至少有比期望的 Pod 数量少一个是 up 状态（最多一个不可用）。\nDeployment 同时也可以确保只创建出超过期望数量的一定数量的 Pod。默认的，它会确保最多比期望的 Pod 数量多一个的 Pod 是 up 的（最多 1 个 surge ）。\n在未来的 Kuberentes 版本中，将从 1-1 变成 25%-25%。\n例如，如果您自己看下上面的 Deployment，您会发现，开始创建一个新的 Pod，然后删除一些旧的 Pod 再创建一个新的。当新的 Pod 创建出来之前不会杀掉旧的 Pod。这样能够确保可用的 Pod 数量至少有 2 个，Pod 的总数最多 4 个。\n$ kubectl describe deployments Name: nginx-deployment Namespace: default CreationTimestamp: Tue, 15 Mar 2016 12:01:06 -0700 Labels: app=nginx Selector: app=nginx Replicas: 3 updated | 3 total | 3 available | 0 unavailable StrategyType: RollingUpdate MinReadySeconds: 0 RollingUpdateStrategy: 1 max unavailable, 1 max surge OldReplicaSets: NewReplicaSet: nginx-deployment-1564180365 (3/3 replicas created) Events: FirstSeen LastSeen Count From SubobjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 36s 36s 1 {deployment-controller} Normal ScalingReplicaSet Scaled up replica set nginx-deployment-2035384211 to 3 23s 23s 1 {deployment-controller} Normal ScalingReplicaSet Scaled up replica set nginx-deployment-1564180365 to 1 23s 23s 1 {deployment-controller} Normal ScalingReplicaSet Scaled down replica set nginx-deployment-2035384211 to 2 23s 23s 1 {deployment-controller} Normal ScalingReplicaSet Scaled up replica set nginx-deployment-1564180365 to 2 21s 21s 1 {deployment-controller} Normal ScalingReplicaSet Scaled down replica set nginx-deployment-2035384211 to 0 21s 21s 1 {deployment-controller} Normal ScalingReplicaSet Scaled up replica set nginx-deployment-1564180365 to 3 我们可以看到当我们刚开始创建这个 Deployment 的时候，创建了一个 ReplicaSet（nginx-deployment-2035384211），并直接扩容到了 3 个 replica。\n当我们更新这个 Deployment 的时候，它会创建一个新的 ReplicaSet（nginx-deployment-1564180365），将它扩容到 1 个 replica，然后缩容原先的 ReplicaSet 到 2 个 replica，此时满足至少 2 个 Pod 是可用状态，同一时刻最多有 4 个 Pod 处于创建的状态。\n接着继续使用相同的 rolling update 策略扩容新的 ReplicaSet 和缩容旧的 ReplicaSet。最终，将会在新的 ReplicaSet 中有 3 个可用的 replica，旧的 ReplicaSet 的 replica 数目变成 0。\nRollover（多个 rollout 并行） link每当 Deployment controller 观测到有新的 deployment 被创建时，如果没有已存在的 ReplicaSet 来创建期望个数的 Pod 的话，就会创建出一个新的 ReplicaSet 来做这件事。已存在的 ReplicaSet 控制 label 与 .spec.selector 匹配但是 template 跟 .spec.template 不匹配的 Pod 缩容。最终，新的 ReplicaSet 将会扩容出 .spec.replicas 指定数目的 Pod，旧的 ReplicaSet 会缩容到 0。\n如果您更新了一个的已存在并正在进行中的 Deployment，每次更新 Deployment 都会创建一个新的 ReplicaSet 并扩容它，同时回滚之前扩容的 ReplicaSet —— 将它添加到旧的 ReplicaSet 列表中，开始缩容。\n例如，假如您创建了一个有 5 个 niginx:1.7.9 replica 的 Deployment，但是当还只有 3 个 nginx:1.7.9 的 replica 创建出来的时候您就开始更新含有 5 个 nginx:1.9.1 replica 的 Deployment。在这种情况下，Deployment 会立即杀掉已创建的 3 个 nginx:1.7.9 的 Pod，并开始创建 nginx:1.9.1 的 Pod。它不会等到所有的 5 个 nginx:1.7.9 的 Pod 都创建完成后才开始改变航道。\nLabel selector 更新 link我们通常不鼓励更新 label selector，我们建议事先规划好您的 selector。\n任何情况下，只要您想要执行 label selector 的更新，请一定要谨慎并确认您已经预料到所有可能因此导致的后果。\n增添 selector 需要同时在 Deployment 的 spec 中更新新的 label，否则将返回校验错误。此更改是不可覆盖的，这意味着新的 selector 不会选择使用旧 selector 创建的 ReplicaSet 和 Pod，从而导致所有旧版本的 ReplicaSet 都被丢弃，并创建新的 ReplicaSet。 更新 selector，即更改 selector key 的当前值，将导致跟增添 selector 同样的后果。 删除 selector，即删除 Deployment selector 中的已有的 key，不需要对 Pod template label 做任何更改，现有的 ReplicaSet 也不会成为孤儿，但是请注意，删除的 label 仍然存在于现有的 Pod 和 ReplicaSet 中。 回退 Deployment link有时候您可能想回退一个 Deployment，例如，当 Deployment 不稳定时，比如一直 crash looping。\n默认情况下，kubernetes 会在系统中保存前两次的 Deployment 的 rollout 历史记录，以便您可以随时回退（您可以修改 revision history limit 来更改保存的 revision 数）。\n**注意：**只要 Deployment 的 rollout 被触发就会创建一个 revision。也就是说当且仅当 Deployment 的 Pod template（如 .spec.template）被更改，例如更新 template 中的 label 和容器镜像时，就会创建出一个新的 revision。\n其他的更新，比如扩容 Deployment 不会创建 revision—— 因此我们可以很方便的手动或者自动扩容。这意味着当您回退到历史 revision 时，只有 Deployment 中的 Pod template 部分才会回退。\n假设我们在更新 Deployment 的时候犯了一个拼写错误，将镜像的名字写成了 nginx:1.91，而正确的名字应该是 nginx:1.9.1：\n$ kubectl set image deployment/nginx-deployment nginx=nginx:1.91 deployment \"nginx-deployment\" image updated Rollout 将会卡住。\n$ kubectl rollout status deployments nginx-deployment Waiting for rollout to finish: 2 out of 3 new replicas have been updated... 按住 Ctrl-C 停止上面的 rollout 状态监控。\n您会看到旧的 replica（nginx-deployment-1564180365 和 nginx-deployment-2035384211）和新的 replica （nginx-deployment-3066724191）数目都是 2 个。\n$ kubectl get rs NAME DESIRED CURRENT READY AGE nginx-deployment-1564180365 2 2 0 25s nginx-deployment-2035384211 0 0 0 36s nginx-deployment-3066724191 2 2 2 6s 看下创建 Pod，您会看到有两个新的 ReplicaSet 创建的 Pod 处于 ImagePullBackOff 状态，循环拉取镜像。\n$ kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-1564180365-70iae 1/1 Running 0 25s nginx-deployment-1564180365-jbqqo 1/1 Running 0 25s nginx-deployment-3066724191-08mng 0/1 ImagePullBackOff 0 6s nginx-deployment-3066724191-eocby 0/1 ImagePullBackOff 0 6s 注意，Deployment controller 会自动停止坏的 rollout，并停止扩容新的 ReplicaSet。\n$ kubectl describe deployment Name: nginx-deployment Namespace: default CreationTimestamp: Tue, 15 Mar 2016 14:48:04 -0700 Labels: app=nginx Selector: app=nginx Replicas: 2 updated | 3 total | 2 available | 2 unavailable StrategyType: RollingUpdate MinReadySeconds: 0 RollingUpdateStrategy: 1 max unavailable, 1 max surge OldReplicaSets: nginx-deployment-1564180365 (2/2 replicas created) NewReplicaSet: nginx-deployment-3066724191 (2/2 replicas created) Events: FirstSeen LastSeen Count From SubobjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 1m 1m 1 {deployment-controller} Normal ScalingReplicaSet Scaled up replica set nginx-deployment-2035384211 to 3 22s 22s 1 {deployment-controller} Normal ScalingReplicaSet Scaled up replica set nginx-deployment-1564180365 to 1 22s 22s 1 {deployment-controller} Normal ScalingReplicaSet Scaled down replica set nginx-deployment-2035384211 to 2 22s 22s 1 {deployment-controller} Normal ScalingReplicaSet Scaled up replica set nginx-deployment-1564180365 to 2 21s 21s 1 {deployment-controller} Normal ScalingReplicaSet Scaled down replica set nginx-deployment-2035384211 to 0 21s 21s 1 {deployment-controller} Normal ScalingReplicaSet Scaled up replica set nginx-deployment-1564180365 to 3 13s 13s 1 {deployment-controller} Normal ScalingReplicaSet Scaled up replica set nginx-deployment-3066724191 to 1 13s 13s 1 {deployment-controller} Normal ScalingReplicaSet Scaled down replica set nginx-deployment-1564180365 to 2 13s 13s 1 {deployment-controller} Normal ScalingReplicaSet Scaled up replica set nginx-deployment-3066724191 to 2 为了修复这个问题，我们需要回退到稳定的 Deployment revision。\n检查 Deployment 升级的历史记录 link首先，检查下 Deployment 的 revision：\n$ kubectl rollout history deployment/nginx-deployment deployments \"nginx-deployment\": REVISION CHANGE-CAUSE 1 kubectl create -f https://kubernetes.io/docs/user-guide/nginx-deployment.yaml--record 2 kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1 3 kubectl set image deployment/nginx-deployment nginx=nginx:1.91 因为我们创建 Deployment 的时候使用了--record 参数可以记录命令，我们可以很方便的查看每次 revision 的变化。\n查看单个 revision 的详细信息：\n$ kubectl rollout history deployment/nginx-deployment --revision=2 deployments \"nginx-deployment\" revision 2 Labels: app=nginx pod-template-hash=1159050644 Annotations: kubernetes.io/change-cause=kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1 Containers: nginx: Image: nginx:1.9.1 Port: 80/TCP QoS Tier: cpu: BestEffort memory: BestEffort Environment Variables: No volumes. 回退到历史版本 link现在，我们可以决定回退当前的 rollout 到之前的版本：\n$ kubectl rollout undo deployment/nginx-deployment deployment \"nginx-deployment\" rolled back 也可以使用--revision参数指定某个历史版本：\n$ kubectl rollout undo deployment/nginx-deployment --to-revision=2 deployment \"nginx-deployment\" rolled back 该 Deployment 现在已经回退到了先前的稳定版本。如您所见，Deployment controller 产生了一个回退到 revison 2 的DeploymentRollback的 event。\n$ kubectl get deployment NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx-deployment 3 3 3 3 30m $ kubectl describe deployment Name: nginx-deployment Namespace: default CreationTimestamp: Tue, 15 Mar 2016 14:48:04 -0700 Labels: app=nginx Selector: app=nginx Replicas: 3 updated | 3 total | 3 available | 0 unavailable StrategyType: RollingUpdate MinReadySeconds: 0 RollingUpdateStrategy: 1 max unavailable, 1 max surge OldReplicaSets: NewReplicaSet: nginx-deployment-1564180365 (3/3 replicas created) Events: FirstSeen LastSeen Count From SubobjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 30m 30m 1 {deployment-controller} Normal ScalingReplicaSet Scaled up replica set nginx-deployment-2035384211 to 3 29m 29m 1 {deployment-controller} Normal ScalingReplicaSet Scaled up replica set nginx-deployment-1564180365 to 1 29m 29m 1 {deployment-controller} Normal ScalingReplicaSet Scaled down replica set nginx-deployment-2035384211 to 2 29m 29m 1 {deployment-controller} Normal ScalingReplicaSet Scaled up replica set nginx-deployment-1564180365 to 2 29m 29m 1 {deployment-controller} Normal ScalingReplicaSet Scaled down replica set nginx-deployment-2035384211 to 0 29m 29m 1 {deployment-controller} Normal ScalingReplicaSet Scaled up replica set nginx-deployment-3066724191 to 2 29m 29m 1 {deployment-controller} Normal ScalingReplicaSet Scaled up replica set nginx-deployment-3066724191 to 1 29m 29m 1 {deployment-controller} Normal ScalingReplicaSet Scaled down replica set nginx-deployment-1564180365 to 2 2m 2m 1 {deployment-controller} Normal ScalingReplicaSet Scaled down replica set nginx-deployment-3066724191 to 0 2m 2m 1 {deployment-controller} Normal DeploymentRollback Rolled back deployment \"nginx-deployment\" to revision 2 29m 2m 2 {deployment-controller} Normal ScalingReplicaSet Scaled up replica set nginx-deployment-1564180365 to 3 清理 Policy link您可以通过设置 .spec.revisonHistoryLimit 项来指定 deployment 最多保留多少 revision 历史记录。默认的会保留所有的 revision；如果将该项设置为 0，Deployment 就不允许回退了。\nDeployment 扩容 link您可以使用以下命令扩容 Deployment：\n$ kubectl scale deployment nginx-deployment --replicas 10 deployment \"nginx-deployment\" scaled 假设您的集群中启用了 horizontal pod autoscaling，您可以给 Deployment 设置一个 autoscaler，基于当前 Pod 的 CPU 利用率选择最少和最多的 Pod 数。\n$ kubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80 deployment \"nginx-deployment\" autoscaled 比例扩容 linkRollingUpdate Deployment 支持同时运行一个应用的多个版本。或者 autoscaler 扩 容 RollingUpdate Deployment 的时候，正在中途的 rollout（进行中或者已经暂停的），为了降低风险，Deployment controller 将会平衡已存在的活动中的 ReplicaSet（有 Pod 的 ReplicaSet）和新加入的 replica。这被称为比例扩容。\n例如，您正在运行中含有 10 个 replica 的 Deployment。maxSurge=3，maxUnavailable=2。\n$ kubectl get deploy NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx-deployment 10 10 10 10 50s 您更新了一个镜像，而在集群内部无法解析。\n$ kubectl set image deploy/nginx-deployment nginx=nginx:sometag deployment \"nginx-deployment\" image updated 镜像更新启动了一个包含 ReplicaSet nginx-deployment-1989198191 的新的 rollout，但是它被阻塞了，因为我们上面提到的 maxUnavailable。\n$ kubectl get rs NAME DESIRED CURRENT READY AGE nginx-deployment-1989198191 5 5 0 9s nginx-deployment-618515232 8 8 8 1m 然后发起了一个新的 Deployment 扩容请求。autoscaler 将 Deployment 的 repllica 数目增加到了 15 个。Deployment controller 需要判断在哪里增加这 5 个新的 replica。如果我们没有谁用比例扩容，所有的 5 个 replica 都会加到一个新的 ReplicaSet 中。如果使用比例扩容，新添加的 replica 将传播到所有的 ReplicaSet 中。大的部分加入 replica 数最多的 ReplicaSet 中，小的部分加入到 replica 数少的 ReplciaSet 中。0 个 replica 的 ReplicaSet 不会被扩容。\n在我们上面的例子中，3 个 replica 将添加到旧的 ReplicaSet 中，2 个 replica 将添加到新的 ReplicaSet 中。rollout 进程最终会将所有的 replica 移动到新的 ReplicaSet 中，假设新的 replica 成为健康状态。\n$ kubectl get deploy NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx-deployment 15 18 7 8 7m $ kubectl get rs NAME DESIRED CURRENT READY AGE nginx-deployment-1989198191 7 7 0 7m nginx-deployment-618515232 11 11 11 7m 删除 autoscale link kubectl get hpa kubectl delete hpa ${name of hpa} 暂停和恢复 Deployment link您可以在发出一次或多次更新前暂停一个 Deployment，然后再恢复它。这样您就能在 Deployment 暂停期间进行多次修复工作，而不会发出不必要的 rollout。\n例如使用刚刚创建 Deployment：\n$ kubectl get deploy NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE nginx 3 3 3 3 1m [mkargaki@dhcp129-211 kubernetes]$ kubectl get rs NAME DESIRED CURRENT READY AGE nginx-2142116321 3 3 3 1m 使用以下命令暂停 Deployment：\n$ kubectl rollout pause deployment/nginx-deployment deployment \"nginx-deployment\" paused 然后更新 Deplyment 中的镜像：\n$ kubectl set image deploy/nginx nginx=nginx:1.9.1 deployment \"nginx-deployment\" image updated 注意新的 rollout 启动了：\n$ kubectl rollout history deploy/nginx deployments \"nginx\" REVISION CHANGE-CAUSE 1 $ kubectl get rs NAME DESIRED CURRENT READY AGE nginx-2142116321 3 3 3 2m 您可以进行任意多次更新，例如更新使用的资源：\n$ kubectl set resources deployment nginx -c=nginx --limits=cpu=200m,memory=512Mi deployment \"nginx\" resource requirements updated Deployment 暂停前的初始状态将继续它的功能，而不会对 Deployment 的更新产生任何影响，只要 Deployment 是暂停的。\n最后，恢复这个 Deployment，观察完成更新的 ReplicaSet 已经创建出来了：\n$ kubectl rollout resume deploy nginx deployment \"nginx\" resumed $ KUBECTL get rs -w NAME DESIRED CURRENT READY AGE nginx-2142116321 2 2 2 2m nginx-3926361531 2 2 0 6s nginx-3926361531 2 2 1 18s nginx-2142116321 1 2 2 2m nginx-2142116321 1 2 2 2m nginx-3926361531 3 2 1 18s nginx-3926361531 3 2 1 18s nginx-2142116321 1 1 1 2m nginx-3926361531 3 3 1 18s nginx-3926361531 3 3 2 19s nginx-2142116321 0 1 1 2m nginx-2142116321 0 1 1 2m nginx-2142116321 0 0 0 2m nginx-3926361531 3 3 3 20s ^C $ KUBECTL get rs NAME DESIRED CURRENT READY AGE nginx-2142116321 0 0 0 2m nginx-3926361531 3 3 3 28s **注意：**在恢复 Deployment 之前您无法回退一个已经暂停的 Deployment。\nDeployment 状态 linkDeployment 在生命周期中有多种状态。在创建一个新的 ReplicaSet 的时候它可以是 progressing 状态， complete 状态，或者 fail to progress 状态。\n进行中的 Deployment linkKubernetes 将执行过下列任务之一的 Deployment 标记为 progressing 状态：\nDeployment 正在创建新的 ReplicaSet 过程中。 Deployment 正在扩容一个已有的 ReplicaSet。 Deployment 正在缩容一个已有的 ReplicaSet。 有新的可用的 pod 出现。 您可以使用 kubectl rollout status 命令监控 Deployment 的进度。\n完成的 Deployment linkKubernetes 将包括以下特性的 Deployment 标记为 complete 状态：\nDeployment 最小可用。最小可用意味着 Deployment 的可用 replica 个数等于或者超过 Deployment 策略中的期望个数。 所有与该 Deployment 相关的 replica 都被更新到了您指定版本，也就说更新完成。 该 Deployment 中没有旧的 Pod 存在。 您可以用 kubectl rollout status 命令查看 Deployment 是否完成。如果 rollout 成功完成，kubectl rollout status 将返回一个 0 值的 Exit Code。\n$ kubectl rollout status deploy/nginx Waiting for rollout to finish: 2 of 3 updated replicas are available... deployment \"nginx\" successfully rolled out $ echo $? 0 失败的 Deployment link您的 Deployment 在尝试部署新的 ReplicaSet 的时候可能卡住，永远也不会完成。这可能是因为以下几个因素引起的：\n无效的引用 不可读的 probe failure 镜像拉取错误 权限不够 范围限制 程序运行时配置错误 探测这种情况的一种方式是，在您的 Deployment spec 中指定 spec.progressDeadlineSeconds。spec.progressDeadlineSeconds 表示 Deployment controller 等待多少秒才能确定（通过 Deployment status）Deployment 进程是卡住的。\n下面的 kubectl 命令设置 progressDeadlineSeconds 使 controller 在 Deployment 在进度卡住 10 分钟后报告：\n$ kubectl patch deployment/nginx-deployment -p '{\"spec\":{\"progressDeadlineSeconds\":600}}' \"nginx-deployment\" patched 当超过截止时间后，Deployment controller 会在 Deployment 的status.conditions 中增加一条 DeploymentCondition，它包括如下属性：\nType=Progressing Status=False Reason=ProgressDeadlineExceeded **注意：**kubernetes 除了报告 Reason=ProgressDeadlineExceeded 状态信息外不会对卡住的 Deployment 做任何操作。更高层次的协调器可以利用它并采取相应行动，例如，回滚 Deployment 到之前的版本。\n**注意：**如果您暂停了一个 Deployment，在暂停的这段时间内 kubernetnes 不会检查您指定的 deadline。您可以在 Deployment 的 rollout 途中安全的暂停它，然后再恢复它，这不会触发超过 deadline 的状态。\n您可能在使用 Deployment 的时候遇到一些短暂的错误，这些可能是由于您设置了太短的 timeout，也有可能是因为各种其他错误导致的短暂错误。例如，假设您使用了无效的引用。当您 Describe Deployment 的时候可能会注意到如下信息：\n$ kubectl describe deployment nginx-deployment \u003c...\u003e Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True ReplicaSetUpdated ReplicaFailure True FailedCreate \u003c...\u003e 执行kubectl get deployment nginx-deployment -o yaml，Deployement 的状态可能看起来像这个样子：\nstatus: availableReplicas: 2 conditions: - lastTransitionTime: 2016-10-04T12:25:39Z lastUpdateTime: 2016-10-04T12:25:39Z message: Replica set \"nginx-deployment-4262182780\" is progressing. reason: ReplicaSetUpdated status: \"True\" type: Progressing - lastTransitionTime: 2016-10-04T12:25:42Z lastUpdateTime: 2016-10-04T12:25:42Z message: Deployment has minimum availability. reason: MinimumReplicasAvailable status: \"True\" type: Available - lastTransitionTime: 2016-10-04T12:25:39Z lastUpdateTime: 2016-10-04T12:25:39Z message: 'Error creating: pods \"nginx-deployment-4262182780-\" is forbidden: exceeded quota: object-counts, requested: pods=1, used: pods=3, limited: pods=2' reason: FailedCreate status: \"True\" type: ReplicaFailure observedGeneration: 3 replicas: 2 unavailableReplicas: 2 最终，一旦超过 Deployment 进程的 deadline，kubernetes 会更新状态和导致 Progressing 状态的原因：\nConditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing False ProgressDeadlineExceeded ReplicaFailure True FailedCreate 您可以通过缩容 Deployment 的方式解决配额不足的问题，或者增加您的 namespace 的配额。如果您满足了配额条件后，Deployment controller 就会完成您的 Deployment rollout，您将看到 Deployment 的状态更新为成功状态（Status=True并且Reason=NewReplicaSetAvailable）。\nConditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailable Type=Available、 Status=True 意味着您的 Deployment 有最小可用性。 最小可用性是在 Deployment 策略中指定的参数。Type=Progressing 、 Status=True 意味着您的 Deployment 或者在部署过程中，或者已经成功部署，达到了期望的最少的可用 replica 数量（查看特定状态的 Reason—— 在我们的例子中 Reason=NewReplicaSetAvailable 意味着 Deployment 已经完成）。\n您可以使用 kubectl rollout status 命令查看 Deployment 进程是否失败。当 Deployment 过程超过了 deadline，kubectl rollout status 将返回非 0 的 exit code。\n$ kubectl rollout status deploy/nginx Waiting for rollout to finish: 2 out of 3 new replicas have been updated... error: deployment \"nginx\" exceeded its progress deadline $ echo $? 1 操作失败的 Deployment link所有对完成的 Deployment 的操作都适用于失败的 Deployment。您可以对它扩 / 缩容，回退到历史版本，您甚至可以多次暂停它来应用 Deployment pod template。\n清理 Policy link您可以设置 Deployment 中的 .spec.revisionHistoryLimit 项来指定保留多少旧的 ReplicaSet。 余下的将在后台被当作垃圾收集。默认的，所有的 revision 历史就都会被保留。在未来的版本中，将会更改为 2。\n**注意：**将该值设置为 0，将导致所有的 Deployment 历史记录都会被清除，该 Deployment 就无法再回退了。\n用例 link金丝雀 Deployment link如果您想要使用 Deployment 对部分用户或服务器发布 release，您可以创建多个 Deployment，每个 Deployment 对应一个 release，参照 managing resources 中对金丝雀模式的描述。\n编写 Deployment Spec link在所有的 Kubernetes 配置中，Deployment 也需要 apiVersion，kind 和 metadata 这些配置项。配置文件的通用使用说明查看 部署应用，配置容器，和使用 kubectl 管理资源文档。\nPod Template link.spec.template 是 .spec 中唯一要求的字段。\n.spec.template 是 pod template. 它跟 Pod 有一模一样的 schema，除了它是嵌套的并且不需要 apiVersion 和 kind 字段。\n另外为了划分 Pod 的范围，Deployment 中的 pod template 必须指定适当的 label（不要跟其他 controller 重复了，参考 selector）和适当的重启策略。\n.spec.template.spec.restartPolicy 可以设置为 Always , 如果不指定的话这就是默认配置。\nReplicas link.spec.replicas 是可以选字段，指定期望的 pod 数量，默认是 1。\nSelector link.spec.selector 是可选字段，用来指定 label selector ，圈定 Deployment 管理的 pod 范围。\n如果被指定， .spec.selector 必须匹配 .spec.template.metadata.labels，否则它将被 API 拒绝。如果 .spec.selector 没有被指定， .spec.selector.matchLabels 默认是 .spec.template.metadata.labels。\n在 Pod 的 template 跟 .spec.template 不同或者数量超过了 .spec.replicas 规定的数量的情况下，Deployment 会杀掉 label 跟 selector 不同的 Pod。\n**注意：**您不应该再创建其他 label 跟这个 selector 匹配的 pod，或者通过其他 Deployment，或者通过其他 Controller，例如 ReplicaSet 和 ReplicationController。否则该 Deployment 会被把它们当成都是自己创建的。Kubernetes 不会阻止您这么做。\n如果您有多个 controller 使用了重复的 selector，controller 们就会互相打架并导致不正确的行为。\n策略 link.spec.strategy 指定新的 Pod 替换旧的 Pod 的策略。 .spec.strategy.type 可以是 “Recreate” 或者是 “RollingUpdate”。“RollingUpdate” 是默认值。\nRecreate Deployment link.spec.strategy.type==Recreate 时，在创建出新的 Pod 之前会先杀掉所有已存在的 Pod。\nRolling Update Deployment link.spec.strategy.type==RollingUpdate 时，Deployment 使用 Rolling Update 的方式更新 Pod 。您可以指定 maxUnavailable 和 maxSurge 来控制 rolling update 进程。\nMax Unavailable link.spec.strategy.rollingUpdate.maxUnavailable 是可选配置项，用来指定在升级过程中不可用 Pod 的最大数量。该值可以是一个绝对值（例如 5），也可以是期望 Pod 数量的百分比（例如 10%）。通过计算百分比的绝对值向下取整。如果 .spec.strategy.rollingUpdate.maxSurge 为 0 时，这个值不可以为 0。默认值是 1。\n例如，该值设置成 30%，启动 rolling update 后旧的 ReplicatSet 将会立即缩容到期望的 Pod 数量的 70%。新的 Pod ready 后，随着新的 ReplicaSet 的扩容，旧的 ReplicaSet 会进一步缩容，确保在升级的所有时刻可以用的 Pod 数量至少是期望 Pod 数量的 70%。\nMax Surge link.spec.strategy.rollingUpdate.maxSurge 是可选配置项，用来指定可以超过期望的 Pod 数量的最大个数。该值可以是一个绝对值（例如 5）或者是期望的 Pod 数量的百分比（例如 10%）。当 MaxUnavailable 为 0 时该值不可以为 0。通过百分比计算的绝对值向上取整。默认值是 1。\n例如，该值设置成 30%，启动 rolling update 后新的 ReplicatSet 将会立即扩容，新老 Pod 的总数不能超过期望的 Pod 数量的 130%。旧的 Pod 被杀掉后，新的 ReplicaSet 将继续扩容，旧的 ReplicaSet 会进一步缩容，确保在升级的所有时刻所有的 Pod 数量和不会超过期望 Pod 数量的 130%。\nProgress Deadline Seconds link.spec.progressDeadlineSeconds 是可选配置项，用来指定在系统报告 Deployment 的 failed progressing —— 表现为 resource 的状态中 type=Progressing、Status=False、 Reason=ProgressDeadlineExceeded 前可以等待的 Deployment 进行的秒数。Deployment controller 会继续重试该 Deployment。未来，在实现了自动回滚后， deployment controller 在观察到这种状态时就会自动回滚。\n如果设置该参数，该值必须大于 .spec.minReadySeconds。\nMin Ready Seconds link.spec.minReadySeconds 是一个可选配置项，用来指定没有任何容器 crash 的 Pod 并被认为是可用状态的最小秒数。默认是 0（Pod 在 ready 后就会被认为是可用状态）。进一步了解什么什么后 Pod 会被认为是 ready 状态，参阅 Container Probes。\nRollback To link.spec.rollbackTo 是一个可以选配置项，用来配置 Deployment 回退的配置。设置该参数将触发回退操作，每次回退完成后，该值就会被清除。\nRevision link.spec.rollbackTo.revision 是一个可选配置项，用来指定回退到的 revision。默认是 0，意味着回退到上一个 revision。\nRevision History Limit linkDeployment revision history 存储在它控制的 ReplicaSets 中。\n.spec.revisionHistoryLimit 是一个可选配置项，用来指定可以保留的旧的 ReplicaSet 数量。该理想值取决于心 Deployment 的频率和稳定性。如果该值没有设置的话，默认所有旧的 Replicaset 或会被保留，将资源存储在 etcd 中，是用 kubectl get rs 查看输出。每个 Deployment 的该配置都保存在 ReplicaSet 中，然而，一旦您删除的旧的 RepelicaSet，您的 Deployment 就无法再回退到那个 revison 了。\n如果您将该值设置为 0，所有具有 0 个 replica 的 ReplicaSet 都会被删除。在这种情况下，新的 Deployment rollout 无法撤销，因为 revision history 都被清理掉了。\nPaused link.spec.paused 是可以可选配置项，boolean 值。用来指定暂停和恢复 Deployment。Paused 和没有 paused 的 Deployment 之间的唯一区别就是，所有对 paused deployment 中的 PodTemplateSpec 的修改都不会触发新的 rollout。Deployment 被创建之后默认是非 paused。\n"
            }
        );
    index.add(
            {
                id:  56 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/statefulset\/",
                title: "StatefulSet",
                description: "StatefulSet 作为 Controller 为 Pod 提供唯一的标识。它可以保证部署和 scale 的顺序。\n使用案例参考：kubernetes contrib - statefulsets，其中包含zookeeper和kakfa的statefulset设置和使用说明。\nStatefulSet是为了解决有状态服务的问题（对应Deployments和ReplicaSets是为无状态服务而设计），其应用场景包括：\n稳定的持久化存储，即Pod重新调度后还是能访问到相同的持久化数据，基于PVC来实现 稳定的网络标志，即Pod重新调度后其PodName和HostName不变，基于Headless Service（即没有Cluster IP的Service）来实现 有序部署，有序扩展，即Pod是有顺序的，在部署或者扩展的时候要依据定义的顺序依次依次进行（即从0到N-1，在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态），基于init containers来实现 有序收缩，有序删除（即从N-1到0） 从上面的应用场景可以发现，StatefulSet由以下几个部分组成：\n用于定义网络标志（DNS domain）的Headless Service 用于创建PersistentVolumes的volumeClaimTemplates 定义具体应用的StatefulSet StatefulSet中每个Pod的DNS格式为statefulSetName-{0..N-1}.serviceName.namespace.svc.cluster.local，其中\n",
                content: "StatefulSet 作为 Controller 为 Pod 提供唯一的标识。它可以保证部署和 scale 的顺序。\n使用案例参考：kubernetes contrib - statefulsets，其中包含zookeeper和kakfa的statefulset设置和使用说明。\nStatefulSet是为了解决有状态服务的问题（对应Deployments和ReplicaSets是为无状态服务而设计），其应用场景包括：\n稳定的持久化存储，即Pod重新调度后还是能访问到相同的持久化数据，基于PVC来实现 稳定的网络标志，即Pod重新调度后其PodName和HostName不变，基于Headless Service（即没有Cluster IP的Service）来实现 有序部署，有序扩展，即Pod是有顺序的，在部署或者扩展的时候要依据定义的顺序依次依次进行（即从0到N-1，在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态），基于init containers来实现 有序收缩，有序删除（即从N-1到0） 从上面的应用场景可以发现，StatefulSet由以下几个部分组成：\n用于定义网络标志（DNS domain）的Headless Service 用于创建PersistentVolumes的volumeClaimTemplates 定义具体应用的StatefulSet StatefulSet中每个Pod的DNS格式为statefulSetName-{0..N-1}.serviceName.namespace.svc.cluster.local，其中\nserviceName为Headless Service的名字 0..N-1为Pod所在的序号，从0开始到N-1 statefulSetName为StatefulSet的名字 namespace为服务所在的namespace，Headless Servic和StatefulSet必须在相同的namespace .cluster.local为Cluster Domain 使用 StatefulSet linkStatefulSet 适用于有以下某个或多个需求的应用：\n稳定，唯一的网络标志。 稳定，持久化存储。 有序，优雅地部署和 scale。 有序，优雅地删除和终止。 有序，自动的滚动升级。 在上文中，稳定是 Pod （重新）调度中持久性的代名词。 如果应用程序不需要任何稳定的标识符、有序部署、删除和 scale，则应该使用提供一组无状态副本的 controller 来部署应用程序，例如 Deployment 或 ReplicaSet 可能更适合您的无状态需求。\n限制 link StatefulSet 是 beta 资源，Kubernetes 1.5 以前版本不支持。 对于所有的 alpha/beta 的资源，您都可以通过在 apiserver 中设置 --runtime-config 选项来禁用。 给定 Pod 的存储必须由 PersistentVolume Provisioner 根据请求的 storage class 进行配置，或由管理员预先配置。 删除或 scale StatefulSet 将_不会_删除与 StatefulSet 相关联的 volume。 这样做是为了确保数据安全性，这通常比自动清除所有相关 StatefulSet 资源更有价值。 StatefulSets 目前要求 Headless Service 负责 Pod 的网络身份。 您有责任创建此服务。 组件 link下面的示例中描述了 StatefulSet 中的组件。\n一个名为 nginx 的 headless service，用于控制网络域。 一个名为 web 的 StatefulSet，它的 Spec 中指定在有 3 个运行 nginx 容器的 Pod。 volumeClaimTemplates 使用 PersistentVolume Provisioner 提供的 PersistentVolumes 作为稳定存储。 apiVersion: v1 kind: Service metadata: name: nginx labels: app: nginx spec: ports: - port: 80 name: web clusterIP: None selector: app: nginx --- apiVersion: apps/v1beta1 kind: StatefulSet metadata: name: web spec: serviceName: \"nginx\" replicas: 3 template: metadata: labels: app: nginx spec: terminationGracePeriodSeconds: 10 containers: - name: nginx image: gcr.io/google_containers/nginx-slim:0.8 ports: - containerPort: 80 name: web volumeMounts: - name: www mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: www annotations: volume.beta.kubernetes.io/storage-class: anything spec: accessModes: [ \"ReadWriteOnce\" ] resources: requests: storage: 1Gi Pod 身份 linkStatefulSet Pod 具有唯一的身份，包括序数，稳定的网络身份和稳定的存储。 身份绑定到 Pod 上，不管它（重新）调度到哪个节点上。\n序数 link对于一个有 N 个副本的 StatefulSet，每个副本都会被指定一个整数序数，在 [0,N)之间，且唯一。\n稳定的网络 ID linkStatefulSet 中的每个 Pod 从 StatefulSet 的名称和 Pod 的序数派生其主机名。构造的主机名的模式是$（statefulset名称)-$(序数)。 上面的例子将创建三个名为web-0，web-1，web-2的 Pod。\nStatefulSet 可以使用 Headless Service 来控制其 Pod 的域。此服务管理的域的格式为：$(服务名称).$(namespace).svc.cluster.local，其中 “cluster.local” 是集群域。\n在创建每个Pod时，它将获取一个匹配的 DNS 子域，采用以下形式：$(pod 名称).$(管理服务域)，其中管理服务由 StatefulSet 上的 serviceName 字段定义。\n以下是 Cluster Domain，服务名称，StatefulSet 名称以及如何影响 StatefulSet 的 Pod 的 DNS 名称的一些示例。\nCluster Domain Service (ns/name) StatefulSet (ns/name) StatefulSet Domain Pod DNS Pod Hostname cluster.local default/nginx default/web nginx.default.svc.cluster.local web-{0..N-1}.nginx.default.svc.cluster.local web-{0..N-1} cluster.local foo/nginx foo/web nginx.foo.svc.cluster.local web-{0..N-1}.nginx.foo.svc.cluster.local web-{0..N-1} kube.local foo/nginx foo/web nginx.foo.svc.kube.local web-{0..N-1}.nginx.foo.svc.kube.local web-{0..N-1} 注意 Cluster Domain 将被设置成 cluster.local 除非进行了其他配置。\n稳定存储 linkKubernetes 为每个 VolumeClaimTemplate 创建一个 PersistentVolume。上面的 nginx 的例子中，每个 Pod 将具有一个由 anything 存储类创建的 1 GB 存储的 PersistentVolume。当该 Pod （重新）调度到节点上，volumeMounts 将挂载与 PersistentVolume Claim 相关联的 PersistentVolume。请注意，与 PersistentVolume Claim 相关联的 PersistentVolume 在 产出 Pod 或 StatefulSet 的时候不会被删除。这必须手动完成。\n部署和 Scale 保证 link 对于有 N 个副本的 StatefulSet，Pod 将按照 {0..N-1} 的顺序被创建和部署。 当 删除 Pod 的时候，将按照逆序来终结，从{N-1..0} 对 Pod 执行 scale 操作之前，它所有的前任必须处于 Running 和 Ready 状态。 在终止 Pod 前，它所有的继任者必须处于完全关闭状态。 不应该将 StatefulSet 的 pod.Spec.TerminationGracePeriodSeconds 设置为 0。这样是不安全的且强烈不建议您这样做。进一步解释，请参阅 强制删除 StatefulSet Pod。\n上面的 nginx 示例创建后，3 个 Pod 将按照如下顺序创建 web-0，web-1，web-2。在 web-0 处于 运行并就绪 状态之前，web-1 将不会被部署，同样当 web-1 处于运行并就绪状态之前 web-2也不会被部署。如果在 web-1 运行并就绪后，web-2 启动之前， web-0 失败了，web-2 将不会启动，直到 web-0 成功重启并处于运行并就绪状态。\n如果用户通过修补 StatefulSet 来 scale 部署的示例，以使 replicas=1，则 web-2 将首先被终止。 在 web-2 完全关闭和删除之前，web-1 不会被终止。 如果 web-0 在 web-2 终止并且完全关闭之后，但是在 web-1 终止之前失败，则 web-1 将不会终止，除非 web-0 正在运行并准备就绪。\nPod 管理策略 link在 Kubernetes 1.7 和之后版本，StatefulSet 允许您放开顺序保证，同时通过 .spec.podManagementPolicy 字段保证身份的唯一性。\nOrderedReady Pod 管理 linkStatefulSet 中默认使用的是 OrderedReady pod 管理。它实现了 如上 所述的行为。\n并行 Pod 管理 linkParallel pod 管理告诉 StatefulSet controller 并行的启动和终止 Pod，在启动和终止其他 Pod 之前不会等待 Pod 变成 运行并就绪或完全终止状态。\n更新策略 link在 kubernetes 1.7 和以上版本中，StatefulSet 的 .spec.updateStrategy 字段允许您配置和禁用 StatefulSet 中的容器、label、resource request/limit、annotation 的滚动更新。\n删除 linkOnDelete 更新策略实现了遗留（1.6和以前）的行为。 当 spec.updateStrategy 未指定时，这是默认策略。 当StatefulSet 的 .spec.updateStrategy.type 设置为 OnDelete 时，StatefulSet 控制器将不会自动更新 StatefulSet 中的 Pod。 用户必须手动删除 Pod 以使控制器创建新的 Pod，以反映对StatefulSet的 .spec.template 进行的修改。\n滚动更新 linkRollingUpdate 更新策略在 StatefulSet 中实现 Pod 的自动滚动更新。 当StatefulSet的 .spec.updateStrategy.type 设置为 RollingUpdate 时，StatefulSet 控制器将在 StatefulSet 中删除并重新创建每个 Pod。 它将以与 Pod 终止相同的顺序进行（从最大的序数到最小的序数），每次更新一个 Pod。 在更新其前身之前，它将等待正在更新的 Pod 状态变成正在运行并就绪。\n分区 link可以通过指定 .spec.updateStrategy.rollingUpdate.partition 来对 RollingUpdate 更新策略进行分区。如果指定了分区，则当 StatefulSet 的 .spec.template 更新时，具有大于或等于分区序数的所有 Pod 将被更新。具有小于分区的序数的所有 Pod 将不会被更新，即使删除它们也将被重新创建。如果 StatefulSet 的 .spec.updateStrategy.rollingUpdate.partition 大于其 .spec.replicas，则其 .spec.template 的更新将不会传播到 Pod。\n在大多数情况下，您不需要使用分区，但如果您想要进行分阶段更新，使用金丝雀发布或执行分阶段发布，它们将非常有用。\n简单示例 link以一个简单的nginx服务web.yaml为例：\n--- apiVersion: v1 kind: Service metadata: name: nginx labels: app: nginx spec: ports: - port: 80 name: web clusterIP: None selector: app: nginx --- apiVersion: apps/v1beta1 kind: StatefulSet metadata: name: web spec: serviceName: \"nginx\" replicas: 2 template: metadata: labels: app: nginx spec: containers: - name: nginx image: gcr.io/google_containers/nginx-slim:0.8 ports: - containerPort: 80 name: web volumeMounts: - name: www mountPath: /usr/share/nginx/html volumeClaimTemplates: - metadata: name: www annotations: volume.alpha.kubernetes.io/storage-class: anything spec: accessModes: [ \"ReadWriteOnce\" ] resources: requests: storage: 1Gi $ kubectl create -f web.yaml service \"nginx\" created statefulset \"web\" created # 查看创建的headless service和statefulset $ kubectl get service nginx NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE nginx None 80/TCP 1m $ kubectl get statefulset web NAME DESIRED CURRENT AGE web 2 2 2m # 根据volumeClaimTemplates自动创建PVC（在GCE中会自动创建kubernetes.io/gce-pd类型的volume） $ kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESSMODES AGE www-web-0 Bound pvc-d064a004-d8d4-11e6-b521-42010a800002 1Gi RWO 16s www-web-1 Bound pvc-d06a3946-d8d4-11e6-b521-42010a800002 1Gi RWO 16s # 查看创建的Pod，他们都是有序的 $ kubectl get pods -l app=nginx NAME READY STATUS RESTARTS AGE web-0 1/1 Running 0 5m web-1 1/1 Running 0 4m # 使用nslookup查看这些Pod的DNS $ kubectl run -i --tty --image busybox dns-test --restart=Never --rm /bin/sh / # nslookup web-0.nginx Server: 10.0.0.10 Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local Name: web-0.nginx Address 1: 10.244.2.10 / # nslookup web-1.nginx Server: 10.0.0.10 Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local Name: web-1.nginx Address 1: 10.244.3.12 / # nslookup web-0.nginx.default.svc.cluster.local Server: 10.0.0.10 Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local Name: web-0.nginx.default.svc.cluster.local Address 1: 10.244.2.10 还可以进行其他的操作\n# 扩容 $ kubectl scale statefulset web --replicas=5 # 缩容 $ kubectl patch statefulset web -p '{\"spec\":{\"replicas\":3}}' # 镜像更新（目前还不支持直接更新image，需要patch来间接实现） $ kubectl patch statefulset web --type='json' -p='[{\"op\": \"replace\", \"path\": \"/spec/template/spec/containers/0/image\", \"value\":\"gcr.io/google_containers/nginx-slim:0.7\"}]' # 删除StatefulSet和Headless Service $ kubectl delete statefulset web $ kubectl delete service nginx # StatefulSet删除后PVC还会保留着，数据不再使用的话也需要删除 $ kubectl delete pvc www-web-0 www-web-1 zookeeper link另外一个更能说明StatefulSet强大功能的示例为zookeeper.yaml，这个例子仅为讲解，实际可用的配置请使用 https://github.com/kubernetes/contrib/tree/master/statefulsets 中的配置。\n--- apiVersion: v1 kind: Service metadata: name: zk-headless labels: app: zk-headless spec: ports: - port: 2888 name: server - port: 3888 name: leader-election clusterIP: None selector: app: zk --- apiVersion: v1 kind: ConfigMap metadata: name: zk-config data: ensemble: \"zk-0;zk-1;zk-2\" jvm.heap: \"2G\" tick: \"2000\" init: \"10\" sync: \"5\" client.cnxns: \"60\" snap.retain: \"3\" purge.interval: \"1\" --- apiVersion: policy/v1beta1 kind: PodDisruptionBudget metadata: name: zk-budget spec: selector: matchLabels: app: zk minAvailable: 2 --- apiVersion: apps/v1beta1 kind: StatefulSet metadata: name: zk spec: serviceName: zk-headless replicas: 3 template: metadata: labels: app: zk annotations: pod.alpha.kubernetes.io/initialized: \"true\" scheduler.alpha.kubernetes.io/affinity: \u003e { \"podAntiAffinity\": { \"requiredDuringSchedulingRequiredDuringExecution\": [{ \"labelSelector\": { \"matchExpressions\": [{ \"key\": \"app\", \"operator\": \"In\", \"values\": [\"zk-headless\"] }] }, \"topologyKey\": \"kubernetes.io/hostname\" }] } } spec: containers: - name: k8szk imagePullPolicy: Always image: gcr.io/google_samples/k8szk:v1 resources: requests: memory: \"4Gi\" cpu: \"1\" ports: - containerPort: 2181 name: client - containerPort: 2888 name: server - containerPort: 3888 name: leader-election env: - name : ZK_ENSEMBLE valueFrom: configMapKeyRef: name: zk-config key: ensemble - name : ZK_HEAP_SIZE valueFrom: configMapKeyRef: name: zk-config key: jvm.heap - name : ZK_TICK_TIME valueFrom: configMapKeyRef: name: zk-config key: tick - name : ZK_INIT_LIMIT valueFrom: configMapKeyRef: name: zk-config key: init - name : ZK_SYNC_LIMIT valueFrom: configMapKeyRef: name: zk-config key: tick - name : ZK_MAX_CLIENT_CNXNS valueFrom: configMapKeyRef: name: zk-config key: client.cnxns - name: ZK_SNAP_RETAIN_COUNT valueFrom: configMapKeyRef: name: zk-config key: snap.retain - name: ZK_PURGE_INTERVAL valueFrom: configMapKeyRef: name: zk-config key: purge.interval - name: ZK_CLIENT_PORT value: \"2181\" - name: ZK_SERVER_PORT value: \"2888\" - name: ZK_ELECTION_PORT value: \"3888\" command: - sh - -c - zkGenConfig.sh \u0026\u0026 zkServer.sh start-foreground readinessProbe: exec: command: - \"zkOk.sh\" initialDelaySeconds: 15 timeoutSeconds: 5 livenessProbe: exec: command: - \"zkOk.sh\" initialDelaySeconds: 15 timeoutSeconds: 5 volumeMounts: - name: datadir mountPath: /var/lib/zookeeper securityContext: runAsUser: 1000 fsGroup: 1000 volumeClaimTemplates: - metadata: name: datadir annotations: volume.alpha.kubernetes.io/storage-class: anything spec: accessModes: [ \"ReadWriteOnce\" ] resources: requests: storage: 20Gi kubectl create -f zookeeper.yaml 详细的使用说明见zookeeper stateful application。\n关于StatefulSet的更多示例请参阅 github.com/kubernetes/contrib - statefulsets，其中包括了zookeeper和kafka。\n集群外部访问StatefulSet的Pod link我们设想一下这样的场景：在kubernetes集群外部调试StatefulSet中有序的Pod，那么如何访问这些的pod呢？\n方法是为pod设置label，然后用kubectl expose将其以NodePort的方式暴露到集群外部，以上面的zookeeper的例子来说明，下面使用命令的方式来暴露其中的两个zookeeper节点，也可以写一个serivce配置yaml文件。\nkubectl label pod zk-0 zkInst=0 kubectl label pod zk-1 zkInst=1 kubectl expose po zk-0 --port=2181 --target-port=2181 --name=zk-0 --selector=zkInst=0 --type=NodePort kubectl expose po zk-1 --port=2181 --target-port=2181 --name=zk-1 --selector=zkInst=1 --type=NodePort 这样在kubernetes集群外部就可以根据pod所在的主机所映射的端口来访问了。\n查看zk-0这个service可以看到如下结果：\nNAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE zk-0 10.254.98.14 2181:31693/TCP 5m 集群外部就可以使用所有的node中的任何一个IP:31693来访问这个zookeeper实例。\n参考 link https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/\nkubernetes contrib - statefulsets\n"
            }
        );
    index.add(
            {
                id:  57 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/deamonset\/",
                title: "DaemonSet",
                description: "本文将为您介绍 DaemonSet 的基本概念。\n什么是 DaemonSet？ linkDaemonSet 确保全部（或者一些）Node 上运行一个 Pod 的副本。当有 Node 加入集群时，也会为他们新增一个 Pod 。当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。\n使用 DaemonSet 的一些典型用法：\n运行集群存储 daemon，例如在每个 Node 上运行 glusterd、ceph。 在每个 Node 上运行日志收集 daemon，例如fluentd、logstash。 在每个 Node 上运行监控 daemon，例如 Prometheus Node Exporter、collectd、Datadog 代理、New Relic 代理，或 Ganglia gmond。 一个简单的用法是，在所有的 Node 上都存在一个 DaemonSet，将被作为每种类型的 daemon 使用。 一个稍微复杂的用法可能是，对单独的每种类型的 daemon 使用多个 DaemonSet，但具有不同的标志，和/或对不同硬件类型具有不同的内存、CPU要求。\n",
                content: "本文将为您介绍 DaemonSet 的基本概念。\n什么是 DaemonSet？ linkDaemonSet 确保全部（或者一些）Node 上运行一个 Pod 的副本。当有 Node 加入集群时，也会为他们新增一个 Pod 。当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。\n使用 DaemonSet 的一些典型用法：\n运行集群存储 daemon，例如在每个 Node 上运行 glusterd、ceph。 在每个 Node 上运行日志收集 daemon，例如fluentd、logstash。 在每个 Node 上运行监控 daemon，例如 Prometheus Node Exporter、collectd、Datadog 代理、New Relic 代理，或 Ganglia gmond。 一个简单的用法是，在所有的 Node 上都存在一个 DaemonSet，将被作为每种类型的 daemon 使用。 一个稍微复杂的用法可能是，对单独的每种类型的 daemon 使用多个 DaemonSet，但具有不同的标志，和/或对不同硬件类型具有不同的内存、CPU要求。\n编写 DaemonSet Spec link必需字段 link和其它所有 Kubernetes 配置一样，DaemonSet 需要 apiVersion、kind 和 metadata字段。有关配置文件的通用信息，详见文档 部署应用、配置容器 和资源管理。\nDaemonSet 也需要一个 .spec配置段。\nPod 模板 link.spec 唯一必需的字段是 .spec.template。\n.spec.template 是一个 Pod 模板。 它与 Pod 具有相同的 schema，除了它是嵌套的，而且不具有 apiVersion 或 kind 字段。\nPod 除了必须字段外，在 DaemonSet 中的 Pod 模板必须指定合理的标签（查看 pod selector）。\n在 DaemonSet 中的 Pod 模板必需具有一个值为 Always 的 RestartPolicy，或者未指定它的值，默认是 Always。\nPod Selector link.spec.selector 字段表示 Pod Selector，它与 Job 或其它资源的 .spec.selector 的原理是相同的。\nspec.selector 表示一个对象，它由如下两个字段组成：\nmatchLabels - 与 ReplicationController 的 .spec.selector 的原理相同。 matchExpressions - 允许构建更加复杂的 Selector，可以通过指定 key、value 列表，以及与 key 和 value 列表的相关的操作符。 当上述两个字段都指定时，结果表示的是 AND 关系。\n如果指定了 .spec.selector，必须与 .spec.template.metadata.labels 相匹配。如果没有指定，它们默认是等价的。如果与它们配置的不匹配，则会被 API 拒绝。\n如果 Pod 的 label 与 selector 匹配，或者直接基于其它的 DaemonSet、或者 Controller（例如 ReplicationController），也不可以创建任何 Pod。 否则 DaemonSet Controller 将认为那些 Pod 是它创建的。Kubernetes 不会阻止这样做。一个场景是，可能希望在一个具有不同值的、用来测试用的 Node 上手动创建 Pod。\n仅在相同的 Node 上运行 Pod link如果指定了 .spec.template.spec.nodeSelector，DaemonSet Controller 将在能够匹配上 Node Selector 的 Node 上创建 Pod。 类似这种情况，可以指定 .spec.template.spec.affinity，然后 DaemonSet Controller 将在能够匹配上 Node Affinity 的 Node 上创建 Pod。 如果根本就没有指定，则 DaemonSet Controller 将在所有 Node 上创建 Pod。\n如何调度 Daemon Pod link正常情况下，Pod 运行在哪个机器上是由 Kubernetes 调度器进行选择的。然而，由 Daemon Controller 创建的 Pod 已经确定了在哪个机器上（Pod 创建时指定了 .spec.nodeName），因此：\nDaemonSet Controller 并不关心一个 Node 的 unschedulable 字段。 DaemonSet Controller 可以创建 Pod，即使调度器还没有被启动，这对集群启动是非常有帮助的。 Daemon Pod 关心 Taint 和 Toleration，它们会为没有指定 tolerationSeconds 的 node.alpha.kubernetes.io/notReady 和 node.alpha.kubernetes.io/unreachable 的 Taint，而创建具有 NoExecute 的 Toleration。这确保了当 alpha 特性的 TaintBasedEvictions 被启用，当 Node 出现故障，比如网络分区，这时它们将不会被清除掉（当 TaintBasedEvictions 特性没有启用，在这些场景下也不会被清除，但会因为 NodeController 的硬编码行为而被清除，Toleration 是不会的）。\n与 Daemon Pod 通信 link与 DaemonSet 中的 Pod 进行通信，几种可能的模式如下：\nPush：配置 DaemonSet 中的 Pod 向其它 Service 发送更新，例如统计数据库。它们没有客户端。 NodeIP 和已知端口：DaemonSet 中的 Pod 可以使用 hostPort，从而可以通过 Node IP 访问到 Pod。客户端能通过某种方法知道 Node IP 列表，并且基于此也可以知道端口。 DNS：创建具有相同 Pod Selector 的 Headless Service，然后通过使用 endpoints 资源或从 DNS 检索到多个 A 记录来发现 DaemonSet。 Service：创建具有相同 Pod Selector 的 Service，并使用该 Service 访问到某个随机 Node 上的 daemon。（没有办法访问到特定 Node） 更新 DaemonSet link如果修改了 Node Label，DaemonSet 将立刻向新匹配上的 Node 添加 Pod，同时删除新近无法匹配上的 Node 上的 Pod。\n可以修改 DaemonSet 创建的 Pod。然而，不允许对 Pod 的所有字段进行更新。当下次 Node（即使具有相同的名称）被创建时，DaemonSet Controller 还会使用最初的模板。\n可以删除一个 DaemonSet。如果使用 kubectl 并指定 --cascade=false 选项，则 Pod 将被保留在 Node 上。然后可以创建具有不同模板的新 DaemonSet。具有不同模板的新 DaemonSet 将鞥能够通过 Label 匹配识别所有已经存在的 Pod。它不会修改或删除它们，即使是错误匹配了 Pod 模板。通过删除 Pod 或者 删除 Node，可以强制创建新的 Pod。\n在 Kubernetes 1.6 或以后版本，可以在 DaemonSet 上 执行滚动升级。\ninit 脚本 link很可能通过直接在一个 Node 上启动 daemon 进程（例如，使用 init、upstartd、或 systemd）。这非常好，然而基于 DaemonSet 来运行这些进程有如下一些好处：\n像对待应用程序一样，具备为 daemon 提供监控和管理日志的能力。 为 daemon 和应用程序使用相同的配置语言和工具（如 Pod 模板、kubectl）。 Kubernetes 未来版本可能会支持对 DaemonSet 创建 Pod 与 Node升级工作流进行集成。 在资源受限的容器中运行 daemon，能够增加 daemon 和应用容器的隔离性。然而这也实现了在容器中运行 daemon，但却不能在 Pod 中运行（例如，直接基于 Docker 启动）。 裸 Pod link可能要直接创建 Pod，同时指定其运行在特定的 Node 上。 然而，DaemonSet 替换了由于任何原因被删除或终止的 Pod，例如 Node 失败、例行节点维护，比如内核升级。由于这个原因，我们应该使用 DaemonSet 而不是单独创建 Pod。\n静态 Pod link很可能，通过在一个指定目录下编写文件来创建 Pod，该目录受 Kubelet 所监视。这些 Pod 被称为 静态 Pod。 不像 DaemonSet，静态 Pod 不受 kubectl 和 其它 Kubernetes API 客户端管理。静态 Pod 不依赖于 apiserver，这使得它们在集群启动的情况下非常有用。 而且，未来静态 Pod 可能会被废弃掉。\nReplication Controller linkDaemonSet 与 Replication Controller 非常类似，它们都能创建 Pod，这些 Pod 都具有不期望被终止的进程（例如，Web 服务器、存储服务器）。 为无状态的 Service 使用 Replication Controller，像 frontend，实现对副本的数量进行扩缩容、平滑升级，比之于精确控制 Pod 运行在某个主机上要重要得多。需要 Pod 副本总是运行在全部或特定主机上，并需要先于其他 Pod 启动，当这被认为非常重要时，应该使用 Daemon Controller。\n"
            }
        );
    index.add(
            {
                id:  58 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/replicaset\/",
                title: "ReplicationController 和 ReplicaSet",
                description: "ReplicationController 用来确保容器应用的副本数始终保持在用户定义的副本数，即如果有容器异常退出，会自动创建新的 Pod 来替代；而如果异常多出来的容器也会自动回收。\n在新版本的 Kubernetes 中建议使用 ReplicaSet 来取代 ReplicationController。ReplicaSet 跟 ReplicationController 没有本质的不同，只是名字不一样，并且 ReplicaSet 支持集合式的 selector。\n虽然 ReplicaSet 可以独立使用，但一般还是建议使用 Deployment 来自动管理 ReplicaSet，这样就无需担心跟其他机制的不兼容问题（比如 ReplicaSet 不支持 rolling-update 但 Deployment 支持）。\nReplicaSet 示例：\napiVersion: extensions/v1beta1 kind: ReplicaSet metadata: name: frontend # these labels can be applied automatically # from the labels in the pod template if not set # labels: # app: guestbook # tier: frontend spec: # this replicas value is default # modify it according to your case replicas: 3 # selector can be applied automatically # from the labels in the pod template if not set, # but we are specifying the selector here to # demonstrate its usage. selector: matchLabels: tier: frontend matchExpressions: - {key: tier, operator: In, values: [frontend]} template: metadata: labels: app: guestbook tier: frontend spec: containers: - name: php-redis image: gcr.io/google_samples/gb-frontend:v3 resources: requests: cpu: 100m memory: 100Mi env: - name: GET_HOSTS_FROM value: dns # If your cluster config does not include a dns service, then to # instead access environment variables to find service host # info, comment out the 'value: dns' line above, and uncomment the # line below. # value: env ports: - containerPort: 80 ",
                content: "ReplicationController 用来确保容器应用的副本数始终保持在用户定义的副本数，即如果有容器异常退出，会自动创建新的 Pod 来替代；而如果异常多出来的容器也会自动回收。\n在新版本的 Kubernetes 中建议使用 ReplicaSet 来取代 ReplicationController。ReplicaSet 跟 ReplicationController 没有本质的不同，只是名字不一样，并且 ReplicaSet 支持集合式的 selector。\n虽然 ReplicaSet 可以独立使用，但一般还是建议使用 Deployment 来自动管理 ReplicaSet，这样就无需担心跟其他机制的不兼容问题（比如 ReplicaSet 不支持 rolling-update 但 Deployment 支持）。\nReplicaSet 示例：\napiVersion: extensions/v1beta1 kind: ReplicaSet metadata: name: frontend # these labels can be applied automatically # from the labels in the pod template if not set # labels: # app: guestbook # tier: frontend spec: # this replicas value is default # modify it according to your case replicas: 3 # selector can be applied automatically # from the labels in the pod template if not set, # but we are specifying the selector here to # demonstrate its usage. selector: matchLabels: tier: frontend matchExpressions: - {key: tier, operator: In, values: [frontend]} template: metadata: labels: app: guestbook tier: frontend spec: containers: - name: php-redis image: gcr.io/google_samples/gb-frontend:v3 resources: requests: cpu: 100m memory: 100Mi env: - name: GET_HOSTS_FROM value: dns # If your cluster config does not include a dns service, then to # instead access environment variables to find service host # info, comment out the 'value: dns' line above, and uncomment the # line below. # value: env ports: - containerPort: 80 "
            }
        );
    index.add(
            {
                id:  59 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/job_cronjob\/",
                title: "Job \u0026 CronJob",
                description: "Job linkJob 负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个 Pod 成功结束。\nJob Spec 格式 link spec.template 格式同 Pod RestartPolicy 仅支持 Never 或 OnFailure 单个 Pod 时，默认 Pod 成功运行后 Job 即结束 .spec.completions 标志 Job 结束需要成功运行的 Pod 个数，默认为 1 .spec.parallelism 标志并行运行的 Pod 的个数，默认为 1 spec.activeDeadlineSeconds 标志失败 Pod 的重试最大时间，超过这个时间不会继续重试 一个简单的例子：\napiVersion: batch/v1 kind: Job metadata: name: pi spec: template: metadata: name: pi spec: containers: - name: pi image: perl command: [\"perl\", \"-Mbignum=bpi\", \"-wle\", \"print bpi(2000)\"] restartPolicy: Never $ kubectl create -f ./job.yaml job \"pi\" created $ pods=$(kubectl get pods --selector=job-name=pi --output=jsonpath={.items..metadata.name}) $ kubectl logs $pods -c pi 3.141592653589793238462643383279502... Bare Pod link所谓 Bare Pod 是指直接用 PodSpec 来创建的 Pod（即不在 ReplicaSet 或者 ReplicationController 的管理之下的 Pod）。这些 Pod 在 Node 重启后不会自动重启，但 Job 则会创建新的 Pod 继续任务。所以，推荐使用 Job 来替代 Bare Pod，即便是应用只需要一个 Pod。\n",
                content: "Job linkJob 负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个 Pod 成功结束。\nJob Spec 格式 link spec.template 格式同 Pod RestartPolicy 仅支持 Never 或 OnFailure 单个 Pod 时，默认 Pod 成功运行后 Job 即结束 .spec.completions 标志 Job 结束需要成功运行的 Pod 个数，默认为 1 .spec.parallelism 标志并行运行的 Pod 的个数，默认为 1 spec.activeDeadlineSeconds 标志失败 Pod 的重试最大时间，超过这个时间不会继续重试 一个简单的例子：\napiVersion: batch/v1 kind: Job metadata: name: pi spec: template: metadata: name: pi spec: containers: - name: pi image: perl command: [\"perl\", \"-Mbignum=bpi\", \"-wle\", \"print bpi(2000)\"] restartPolicy: Never $ kubectl create -f ./job.yaml job \"pi\" created $ pods=$(kubectl get pods --selector=job-name=pi --output=jsonpath={.items..metadata.name}) $ kubectl logs $pods -c pi 3.141592653589793238462643383279502... Bare Pod link所谓 Bare Pod 是指直接用 PodSpec 来创建的 Pod（即不在 ReplicaSet 或者 ReplicationController 的管理之下的 Pod）。这些 Pod 在 Node 重启后不会自动重启，但 Job 则会创建新的 Pod 继续任务。所以，推荐使用 Job 来替代 Bare Pod，即便是应用只需要一个 Pod。\nCronJob linkCron Job 管理基于时间的 Job，即：\n在给定时间点只运行一次 周期性地在给定时间点运行 一个 CronJob 对象类似于 crontab （cron table）文件中的一行。它根据指定的预定计划周期性地运行一个 Job，格式可以参考 Cron 。\n前提条件 link当前使用的 Kubernetes 集群，版本 \u003e= 1.8（对 CronJob）。对于先前版本的集群，版本 \u003c 1.8，启动 API Server（参考 为集群开启或关闭 API 版本 获取更多信息）时，通过传递选项 --runtime-config=batch/v2alpha1=true 可以开启 batch/v2alpha1 API。\n典型的用法如下所示：\n在给定的时间点调度 Job 运行 创建周期性运行的 Job，例如：数据库备份、发送邮件。 CronJob Spec link .spec.schedule：调度，必需字段，指定任务运行周期，格式同 Cron\n.spec.jobTemplate：Job 模板，必需字段，指定需要运行的任务，格式同 Job\n.spec.startingDeadlineSeconds ：启动 Job 的期限（秒级别），该字段是可选的。如果因为任何原因而错过了被调度的时间，那么错过执行时间的 Job 将被认为是失败的。如果没有指定，则没有期限\n.spec.concurrencyPolicy：并发策略，该字段也是可选的。它指定了如何处理被 Cron Job 创建的 Job 的并发执行。只允许指定下面策略中的一种：\nAllow（默认）：允许并发运行 Job Forbid：禁止并发运行，如果前一个还没有完成，则直接跳过下一个 Replace：取消当前正在运行的 Job，用一个新的来替换 注意，当前策略只能应用于同一个 Cron Job 创建的 Job。如果存在多个 Cron Job，它们创建的 Job 之间总是允许并发运行。\n.spec.suspend ：挂起，该字段也是可选的。如果设置为 true，后续所有执行都会被挂起。它对已经开始执行的 Job 不起作用。默认值为 false。\n.spec.successfulJobsHistoryLimit 和 .spec.failedJobsHistoryLimit ：历史限制，是可选的字段。它们指定了可以保留多少完成和失败的 Job。\n默认情况下，它们分别设置为 3 和 1。设置限制的值为 0，相关类型的 Job 完成后将不会被保留。\napiVersion: batch/v1beta1 kind: CronJob metadata: name: hello spec: schedule: \"*/1 * * * *\" jobTemplate: spec: template: spec: containers: - name: hello image: busybox args: - /bin/sh - -c - date; echo Hello from the Kubernetes cluster restartPolicy: OnFailure $ kubectl create -f cronjob.yaml cronjob \"hello\" created 当然，也可以用kubectl run来创建一个CronJob：\nkubectl run hello --schedule=\"*/1 * * * *\" --restart=OnFailure --image=busybox -- /bin/sh -c \"date; echo Hello from the Kubernetes cluster\" $ kubectl get cronjob NAME SCHEDULE SUSPEND ACTIVE LAST-SCHEDULE hello */1 * * * * False 0 $ kubectl get jobs NAME DESIRED SUCCESSFUL AGE hello-1202039034 1 1 49s $ pods=$(kubectl get pods --selector=job-name=hello-1202039034 --output=jsonpath={.items..metadata.name}) $ kubectl logs $pods Mon Aug 29 21:34:09 UTC 2016 Hello from the Kubernetes cluster # 注意，删除 cronjob 的时候不会自动删除 job，这些 job 可以用 kubectl delete job 来删除 $ kubectl delete cronjob hello cronjob \"hello\" deleted Cron Job 限制 linkCron Job 在每次调度运行时间内 大概 会创建一个 Job 对象。我们之所以说 大概 ，是因为在特定的环境下可能会创建两个 Job，或者一个 Job 都没创建。我们尝试少发生这种情况，但却不能完全避免。因此，创建 Job 操作应该是 幂等的。\nJob 根据它所创建的 Pod 的并行度，负责重试创建 Pod，并就决定这一组 Pod 的成功或失败。Cron Job 根本就不会去检查 Pod。\n删除 Cron Job link一旦不再需要 Cron Job，简单地可以使用 kubectl 命令删除它：\n$ kubectl delete cronjob hello cronjob \"hello\" deleted 这将会终止正在创建的 Job。然而，运行中的 Job 将不会被终止，不会删除 Job 或 它们的 Pod。为了清理那些 Job 和 Pod，需要列出该 Cron Job 创建的全部 Job，然后删除它们：\n$ kubectl get jobs NAME DESIRED SUCCESSFUL AGE hello-1201907962 1 1 11m hello-1202039034 1 1 8m ... $ kubectl delete jobs hello-1201907962 hello-1202039034 ... job \"hello-1201907962\" deleted job \"hello-1202039034\" deleted ... 一旦 Job 被删除，由 Job 创建的 Pod 也会被删除。注意，所有由名称为 “hello” 的 Cron Job 创建的 Job 会以前缀字符串 “hello-” 进行命名。如果想要删除当前 Namespace 中的所有 Job，可以通过命令 kubectl delete jobs --all 立刻删除它们。\n"
            }
        );
    index.add(
            {
                id:  60 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/ingress\/",
                title: "Ingress",
                description: "Ingress 是从 Kubernetes 集群外部访问集群内部服务的入口，这篇文章部分译自 Kubernetes 官方文档 Ingress Resource，后面的章节会讲到使用 Traefik 来做 Ingress controller，文章末尾给出了几个相关链接。\n",
                content: "Ingress 是从 Kubernetes 集群外部访问集群内部服务的入口，这篇文章部分译自 Kubernetes 官方文档 Ingress Resource，后面的章节会讲到使用 Traefik 来做 Ingress controller，文章末尾给出了几个相关链接。\n**术语 **\n在本篇文章中你将会看到一些在其他地方被交叉使用的术语，为了防止产生歧义，我们首先来澄清下。\n节点：Kubernetes 集群中的一台物理机或者虚拟机。 集群：位于 Internet 防火墙后的节点，这是 kubernetes 管理的主要计算资源。 边界路由器：为集群强制执行防火墙策略的路由器。 这可能是由云提供商或物理硬件管理的网关。 集群网络：一组逻辑或物理链接，可根据 Kubernetes 网络模型 实现群集内的通信。 集群网络的实现包括 Overlay 模型的 flannel 和基于 SDN 的 OVS。 服务：使用标签选择器标识一组 pod 成为的 Kubernetes 服务。 除非另有说明，否则服务假定在集群网络内仅可通过虚拟 IP 访问。 什么是 Ingress？ link通常情况下，service 和 pod 仅可在集群内部网络中通过 IP 地址访问。所有到达边界路由器的流量或被丢弃或被转发到其他地方。从概念上讲，可能像下面这样：\ninternet | ------------ [Services] Ingress 是授权入站连接到达集群服务的规则集合。\ninternet | [Ingress] --|-----|-- [Services] 你可以给 Ingress 配置提供外部可访问的 URL、负载均衡、SSL、基于名称的虚拟主机等。用户通过 POST Ingress 资源到 API server 的方式来请求 ingress。 Ingress controller 负责实现 Ingress，通常使用负载均衡器，它还可以配置边界路由和其他前端，这有助于以高可用的方式处理流量。\n先决条件 link在使用 Ingress 资源之前，有必要先了解下面几件事情。\nIngress 资源对象在 Kubernetes 1.1 之前还没有。 你需要一个 Ingress Controller 来实现 Ingress，单纯的创建一个 Ingress 没有任何意义。 GCE/GKE 会在 master 节点上部署一个 ingress controller。你可以在一个 pod 中部署任意个自定义的 ingress controller。你必须正确地注解每个 ingress，比如运行多个 ingress controller 和关闭 glbc。 在非 GCE/GKE 的环境中，你需要在 pod 中 部署一个 controller，例如 Nginx Ingress Controller。 Ingress 资源 link最简化的 Ingress 配置如下。\n1: apiVersion: extensions/v1beta1 2: kind: Ingress 3: metadata: 4: name: test-ingress 5: spec: 6: rules: 7: - http: 8: paths: 9: - path: /testpath 10: backend: 11: serviceName: test 12: servicePort: 80 如果你没有配置 Ingress controller 就将其 POST 到 API server 不会有任何用处。\n配置说明\n**1-4 行 **：跟 Kubernetes 的其他配置一样，ingress 的配置也需要 apiVersion，kind 和 metadata 字段。配置文件的详细说明请查看 部署应用，配置容器 和使用资源。\n**5-7 行 **: Ingress spec 中包含配置一个 loadbalancer 或 proxy server 的所有信息。最重要的是，它包含了一个匹配所有入站请求的规则列表。目前 ingress 只支持 http 规则。\n**8-9 行 **：每条 http 规则包含以下信息：一个 host 配置项（比如 for.bar.com，在这个例子中默认是 *），path 列表（比如：/testpath），每个 path 都关联一个 backend(比如 test:80)。在 loadbalancer 将流量转发到 backend 之前，所有的入站请求都要先匹配 host 和 path。\n**10-12 行 **：正如 services doc 中描述的那样，backend 是一个 service:port 的组合。Ingress 的流量被转发到它所匹配的 backend。\n全局参数：为了简单起见，Ingress 示例中没有全局参数，请参阅资源完整定义的 API 参考。 在所有请求都不能跟 spec 中的 path 匹配的情况下，请求被发送到 Ingress controller 的默认后端，可以指定全局缺省 backend。\nIngress controller link为了使 Ingress 正常工作，集群中必须运行 Ingress controller。 这与其他类型的控制器不同，其他类型的控制器通常作为 kube-controller-manager 二进制文件的一部分运行，在集群启动时自动启动。 你需要选择最适合自己集群的 Ingress controller 或者自己实现一个。\nKubernetes 当前支持并维护 GCE 和 nginx 两种 controller F5（公司）支持并维护 F5 BIG-IP Controller for Kubernetes Kong 同时支持并维护 社区版 与 企业版 的 Kong Ingress Controller for Kubernetes Traefik 是功能齐全的 ingress controller（Let’s Encrypt, secrets, http2, websocket…）, Containous 也对其提供商业支持。 Istio 使用 CRD Gateway 来 控制 Ingress 流量。 在你开始前 link以下文档描述了 Ingress 资源中公开的一组跨平台功能。 理想情况下，所有的 Ingress controller 都应该符合这个规范，但是我们还没有实现。 GCE 和 Nginx 控制器的文档分别在 这里 和 这里。如果您使用 F5 BIG-IP controller，请参看 这里。\n确保您查看控制器特定的文档，以便您了解每个文档的注意事项。\nIngress 类型 link单 Service Ingress linkKubernetes 中已经存在一些概念可以暴露单个 service（查看 替代方案），但是你仍然可以通过 Ingress 来实现，通过指定一个没有 rule 的默认 backend 的方式。\ningress.yaml 定义文件：\napiVersion: extensions/v1beta1 kind: Ingress metadata: name: test-ingress spec: backend: serviceName: testsvc servicePort: 80 使用kubectl create -f命令创建，然后查看 ingress：\n$ kubectl get ing NAME RULE BACKEND ADDRESS test-ingress - testsvc:80 107.178.254.228 107.178.254.228 就是 Ingress controller 为了实现 Ingress 而分配的 IP 地址。RULE 列表示所有发送给该 IP 的流量都被转发到了 BACKEND 所列的 Kubernetes service 上。\n简单展开 link如前面描述的那样，kubernetes pod 中的 IP 只在集群网络内部可见，我们需要在边界设置一个东西，让它能够接收 ingress 的流量并将它们转发到正确的端点上。这个东西一般是高可用的 loadbalancer。使用 Ingress 能够允许你将 loadbalancer 的个数降低到最少，例如，假如你想要创建这样的一个设置：\nfoo.bar.com -\u003e 178.91.123.132 -\u003e /foo s1:80 /bar s2:80 你需要一个这样的 ingress：\napiVersion: extensions/v1beta1 kind: Ingress metadata: name: test spec: rules: - host: foo.bar.com http: paths: - path: /foo backend: serviceName: s1 servicePort: 80 - path: /bar backend: serviceName: s2 servicePort: 80 使用 kubectl create -f 创建完 ingress 后：\n$ kubectl get ing NAME RULE BACKEND ADDRESS test - foo.bar.com /foo s1:80 /bar s2:80 只要服务（s1，s2）存在，Ingress controller 就会将提供一个满足该 Ingress 的特定 loadbalancer 实现。 这一步完成后，您将在 Ingress 的最后一列看到 loadbalancer 的地址。\n基于名称的虚拟主机 linkName-based 的虚拟主机在同一个 IP 地址下拥有多个主机名。\nfoo.bar.com --| |-\u003e foo.bar.com s1:80 | 178.91.123.132 | bar.foo.com --| |-\u003e bar.foo.com s2:80 下面这个 ingress 说明基于 Host header 的后端 loadbalancer 的路由请求：\napiVersion: extensions/v1beta1 kind: Ingress metadata: name: test spec: rules: - host: foo.bar.com http: paths: - backend: serviceName: s1 servicePort: 80 - host: bar.foo.com http: paths: - backend: serviceName: s2 servicePort: 80 默认 backend：一个没有 rule 的 ingress，如前面章节中所示，所有流量都将发送到一个默认 backend。你可以用该技巧通知 loadbalancer 如何找到你网站的 404 页面，通过制定一些列 rule 和一个默认 backend 的方式。如果请求 header 中的 host 不能跟 ingress 中的 host 匹配，并且 / 或请求的 URL 不能与任何一个 path 匹配，则流量将路由到你的默认 backend。\nTLS link你可以通过指定包含 TLS 私钥和证书的 secret 来加密 Ingress。 目前，Ingress 仅支持单个 TLS 端口 443，并假定 TLS termination。 如果 Ingress 中的 TLS 配置部分指定了不同的主机，则它们将根据通过 SNI TLS 扩展指定的主机名（假如 Ingress controller 支持 SNI）在多个相同端口上进行复用。 TLS secret 中必须包含名为 tls.crt 和 tls.key 的密钥，这里面包含了用于 TLS 的证书和私钥，例如：\napiVersion: v1 data: tls.crt: base64 encoded cert tls.key: base64 encoded key kind: Secret metadata: name: testsecret namespace: default type: Opaque 在 Ingress 中引用这个 secret 将通知 Ingress controller 使用 TLS 加密从将客户端到 loadbalancer 的 channel：\napiVersion: extensions/v1beta1 kind: Ingress metadata: name: no-rules-map spec: tls: - secretName: testsecret backend: serviceName: s1 servicePort: 80 请注意，各种 Ingress controller 支持的 TLS 功能之间存在差距。 请参阅有关 nginx，GCE 或任何其他平台特定 Ingress controller 的文档，以了解 TLS 在你的环境中的工作原理。\nIngress controller 启动时附带一些适用于所有 Ingress 的负载平衡策略设置，例如负载均衡算法，后端权重方案等。更高级的负载平衡概念（例如持久会话，动态权重）尚未在 Ingress 中公开。 你仍然可以通过 service loadbalancer 获取这些功能。 随着时间的推移，我们计划将适用于跨平台的负载平衡模式加入到 Ingress 资源中。\n还值得注意的是，尽管健康检查不直接通过 Ingress 公开，但 Kubernetes 中存在并行概念，例如 准备探查，可以使你达成相同的最终结果。 请查看特定控制器的文档，以了解他们如何处理健康检查（nginx，GCE）。\n更新 Ingress link假如你想要向已有的 ingress 中增加一个新的 Host，你可以编辑和更新该 ingress：\n$ kubectl get ing NAME RULE BACKEND ADDRESS test - 178.91.123.132 foo.bar.com /foo s1:80 $ kubectl edit ing test 这会弹出一个包含已有的 yaml 文件的编辑器，修改它，增加新的 Host 配置。\nspec: rules: - host: foo.bar.com http: paths: - backend: serviceName: s1 servicePort: 80 path: /foo - host: bar.baz.com http: paths: - backend: serviceName: s2 servicePort: 80 path: /foo .. 保存它会更新 API server 中的资源，这会触发 ingress controller 重新配置 loadbalancer。\n$ kubectl get ing NAME RULE BACKEND ADDRESS test - 178.91.123.132 foo.bar.com /foo s1:80 bar.baz.com /foo s2:80 在一个修改过的 ingress yaml 文件上调用kubectl replace -f 命令一样可以达到同样的效果。\n跨可用域故障 link在不同云供应商之间，跨故障域的流量传播技术有所不同。 有关详细信息，请查看相关 Ingress controller 的文档。 有关在 federation 集群中部署 Ingress 的详细信息，请参阅 federation 文档。\n未来计划 link 多样化的 HTTPS/TLS 模型支持（如 SNI，re-encryption） 通过声明来请求 IP 或者主机名 结合 L4 和 L7 Ingress 更多的 Ingress controller 请跟踪 L7 和 Ingress 的 proposal，了解有关资源演进的更多细节，以及 Ingress repository，了解有关各种 Ingress controller 演进的更多详细信息。\n替代方案 link你可以通过很多种方式暴露 service 而不必直接使用 ingress：\n使用 Service.Type=LoadBalancer 使用 Service.Type=NodePort 使用 Port Proxy 部署一个 Service loadbalancer 这允许你在多个 service 之间共享单个 IP，并通过 Service Annotations 实现更高级的负载平衡。 参考 link Kubernetes Ingress Resource - kubernetes.io 使用 NGINX Plus 负载均衡 Kubernetes 服务 - dockone.io 使用 NGINX 和 NGINX Plus 的 Ingress Controller 进行 Kubernetes 的负载均衡 - cnblogs.com "
            }
        );
    index.add(
            {
                id:  61 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/custom_hpa\/",
                title: "自定义指标 HPA",
                description: "Kubernetes 中不仅支持 CPU、内存为指标的 HPA，还支持自定义指标的 HPA，例如 QPS。\n本文中使用的 YAML 文件见 manifests/HPA。\n设置自定义指标 linkKubernetes1.6\n在 Kubernetes1.6 集群中配置自定义指标的 HPA 的说明已废弃。\n在设置定义指标 HPA 之前需要先进行如下配置：\n将 heapster 的启动参数 --api-server 设置为 true\n",
                content: "Kubernetes 中不仅支持 CPU、内存为指标的 HPA，还支持自定义指标的 HPA，例如 QPS。\n本文中使用的 YAML 文件见 manifests/HPA。\n设置自定义指标 linkKubernetes1.6\n在 Kubernetes1.6 集群中配置自定义指标的 HPA 的说明已废弃。\n在设置定义指标 HPA 之前需要先进行如下配置：\n将 heapster 的启动参数 --api-server 设置为 true\n启用 custom metric API\n将 kube-controller-manager 的启动参数中 --horizontal-pod-autoscaler-use-rest-clients 设置为 true，并指定 --master 为 API server 地址，如 --master=http://172.20.0.113:8080\n在 Kubernetes1.5 以前很容易设置，参考 1.6 以前版本的 kubernetes 中开启自定义 HPA，而在 1.6 中因为取消了原来的 annotation 方式设置 custom metric，只能通过 API server 和 kube-aggregator 来获取 custom metric，因为只有两种方式来设置了，一是直接通过 API server 获取 heapster 的 metrics，二是部署 kube-aggragator 来实现。\n我们将在 Kubernetes1.8 版本的 Kubernetes 中，使用聚合的 API server 来实现自定义指标的 HPA。\nKuberentes1.7+\n确认您的 Kubernetes 版本在 1.7 或以上，修改以下配置：\n将 kube-controller-manager 的启动参数中 --horizontal-pod-autoscaler-use-rest-clients 设置为 true，并指定 --master 为 API server 地址，如 --master=http://172.20.0.113:8080 修改 kube-apiserver 的配置文件 apiserver，增加一条配置 --requestheader-client-ca-file=/etc/kubernetes/ssl/ca.pem --requestheader-allowed-names=aggregator --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --proxy-client-cert-file=/etc/kubernetes/ssl/kubernetes.pem --proxy-client-key-file=/etc/kubernetes/ssl/kubernetes-key.pem，用来配置 aggregator 的 CA 证书。 已经内置了 apiregistration.k8s.io/v1beta1 API，可以直接定义 APIService，如：\napiVersion: apiregistration.k8s.io/v1 kind: APIService metadata: name: v1.custom-metrics.metrics.k8s.io spec: insecureSkipTLSVerify: true group: custom-metrics.metrics.k8s.io groupPriorityMinimum: 1000 versionPriority: 5 service: name: api namespace: custom-metrics version: v1alpha1 部署 Prometheus\n使用 prometheus-operator.yaml 文件部署 Prometheus operator。\n注意： 将镜像修改为你自己的镜像仓库地址。\n这产生一个自定义的 API：http://172.20.0.113:8080/apis/custom-metrics.metrics.k8s.io/v1alpha1，可以通过浏览器访问，还可以使用下面的命令可以检查该 API：\n$ kubectl get --raw=apis/custom-metrics.metrics.k8s.io/v1alpha1 {\"kind\":\"APIResourceList\",\"apiVersion\":\"v1\",\"groupVersion\":\"custom-metrics.metrics.k8s.io/v1alpha1\",\"resources\":[{\"name\":\"jobs.batch/http_requests\",\"singularName\":\"\",\"namespaced\":true,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]},{\"name\":\"namespaces/http_requests\",\"singularName\":\"\",\"namespaced\":false,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]},{\"name\":\"jobs.batch/up\",\"singularName\":\"\",\"namespaced\":true,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]},{\"name\":\"pods/up\",\"singularName\":\"\",\"namespaced\":true,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]},{\"name\":\"services/scrape_samples_scraped\",\"singularName\":\"\",\"namespaced\":true,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]},{\"name\":\"namespaces/scrape_samples_scraped\",\"singularName\":\"\",\"namespaced\":false,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]},{\"name\":\"pods/scrape_duration_seconds\",\"singularName\":\"\",\"namespaced\":true,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]},{\"name\":\"services/scrape_duration_seconds\",\"singularName\":\"\",\"namespaced\":true,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]},{\"name\":\"pods/http_requests\",\"singularName\":\"\",\"namespaced\":true,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]},{\"name\":\"pods/scrape_samples_post_metric_relabeling\",\"singularName\":\"\",\"namespaced\":true,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]},{\"name\":\"jobs.batch/scrape_samples_scraped\",\"singularName\":\"\",\"namespaced\":true,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]},{\"name\":\"jobs.batch/scrape_duration_seconds\",\"singularName\":\"\",\"namespaced\":true,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]},{\"name\":\"namespaces/scrape_duration_seconds\",\"singularName\":\"\",\"namespaced\":false,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]},{\"name\":\"namespaces/scrape_samples_post_metric_relabeling\",\"singularName\":\"\",\"namespaced\":false,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]},{\"name\":\"services/scrape_samples_post_metric_relabeling\",\"singularName\":\"\",\"namespaced\":true,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]},{\"name\":\"services/up\",\"singularName\":\"\",\"namespaced\":true,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]},{\"name\":\"pods/scrape_samples_scraped\",\"singularName\":\"\",\"namespaced\":true,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]},{\"name\":\"services/http_requests\",\"singularName\":\"\",\"namespaced\":true,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]},{\"name\":\"jobs.batch/scrape_samples_post_metric_relabeling\",\"singularName\":\"\",\"namespaced\":true,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]},{\"name\":\"namespaces/up\",\"singularName\":\"\",\"namespaced\":false,\"kind\":\"MetricValueList\",\"verbs\":[\"get\"]}]} 参考 link 1.6 以前版本的 kubernetes 中开启自定义 HPA - medium.com Horizontal Pod Autoscaler Walkthrough - kubernetes.io Kubernetes 1.8: Now with 100% Daily Value of Custom Metrics - blog.openshift.com Arbitrary/Custom Metrics in the Horizontal Pod Autoscaler#117 - github.com "
            }
        );
    index.add(
            {
                id:  62 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/admission_controller\/",
                title: "准入控制器（Admission Controller）",
                description: "准入控制器（Admission Controller）位于 API Server 中，在对象被持久化之前，准入控制器拦截对 API Server 的请求，一般用来做身份验证和授权。其中包含两个特殊的控制器：MutatingAdmissionWebhook 和 ValidatingAdmissionWebhook。分别作为配置的变异和验证准入控制 webhook。\n准入控制器包括以下两种：\n变更（Mutating）准入控制：修改请求的对象 验证（Validating）准入控制：验证请求的对象 准入控制器是在 API Server 的启动参数重配置的。一个准入控制器可能属于以上两者中的一种，也可能两者都属于。当请求到达 API Server 的时候首先执行变更准入控制，然后再执行验证准入控制。\n我们在部署 Kubernetes 集群的时候都会默认开启一系列准入控制器，如果没有设置这些准入控制器的话可以说你的 Kubernetes 集群就是在裸奔，应该只有集群管理员可以修改集群的准入控制器。\n",
                content: "准入控制器（Admission Controller）位于 API Server 中，在对象被持久化之前，准入控制器拦截对 API Server 的请求，一般用来做身份验证和授权。其中包含两个特殊的控制器：MutatingAdmissionWebhook 和 ValidatingAdmissionWebhook。分别作为配置的变异和验证准入控制 webhook。\n准入控制器包括以下两种：\n变更（Mutating）准入控制：修改请求的对象 验证（Validating）准入控制：验证请求的对象 准入控制器是在 API Server 的启动参数重配置的。一个准入控制器可能属于以上两者中的一种，也可能两者都属于。当请求到达 API Server 的时候首先执行变更准入控制，然后再执行验证准入控制。\n我们在部署 Kubernetes 集群的时候都会默认开启一系列准入控制器，如果没有设置这些准入控制器的话可以说你的 Kubernetes 集群就是在裸奔，应该只有集群管理员可以修改集群的准入控制器。\n例如我会默认开启如下的准入控制器。\n--admission-control=ServiceAccount,NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota,MutatingAdmissionWebhook,ValidatingAdmissionWebhook 准入控制器列表 linkKubernetes 目前支持的准入控制器有：\nAlwaysPullImages：此准入控制器修改每个 Pod 的时候都强制重新拉取镜像。 DefaultStorageClass：此准入控制器观察创建PersistentVolumeClaim时不请求任何特定存储类的对象，并自动向其添加默认存储类。这样，用户就不需要关注特殊存储类而获得默认存储类。 DefaultTolerationSeconds：此准入控制器将Pod的容忍时间notready:NoExecute和unreachable:NoExecute 默认设置为5分钟。 DenyEscalatingExec：此准入控制器将拒绝exec 和附加命令到以允许访问宿主机的升级了权限运行的pod。 EventRateLimit (alpha)：此准入控制器缓解了 API Server 被事件请求淹没的问题，限制时间速率。 ExtendedResourceToleration：此插件有助于创建具有扩展资源的专用节点。 ImagePolicyWebhook：此准入控制器允许后端判断镜像拉取策略，例如配置镜像仓库的密钥。 Initializers (alpha)：Pod初始化的准入控制器，详情请参考动态准入控制。 LimitPodHardAntiAffinityTopology：此准入控制器拒绝任何在 requiredDuringSchedulingRequiredDuringExecution 的 AntiAffinity 字段中定义除了kubernetes.io/hostname 之外的拓扑关键字的 pod 。 LimitRanger：此准入控制器将确保所有资源请求不会超过 namespace 的 LimitRange。 MutatingAdmissionWebhook （1.9版本中为beta）：该准入控制器调用与请求匹配的任何变更 webhook。匹配的 webhook是串行调用的；如果需要，每个人都可以修改对象。 NamespaceAutoProvision：此准入控制器检查命名空间资源上的所有传入请求，并检查引用的命名空间是否存在。如果不存在就创建一个命名空间。 NamespaceExists：此许可控制器检查除 Namespace 其自身之外的命名空间资源上的所有请求。如果请求引用的命名空间不存在，则拒绝该请求。 NamespaceLifecycle：此准入控制器强制执行正在终止的命令空间中不能创建新对象，并确保Namespace拒绝不存在的请求。此准入控制器还防止缺失三个系统保留的命名空间default、kube-system、kube-public。 NodeRestriction：该准入控制器限制了 kubelet 可以修改的Node和Pod对象。 OwnerReferencesPermissionEnforcement：此准入控制器保护对metadata.ownerReferences对象的访问，以便只有对该对象具有“删除”权限的用户才能对其进行更改。 PodNodeSelector：此准入控制器通过读取命名空间注释和全局配置来限制可在命名空间内使用的节点选择器。 PodPreset：此准入控制器注入一个pod，其中包含匹配的PodPreset中指定的字段，详细信息见Pod Preset。 PodSecurityPolicy：此准入控制器用于创建和修改pod，并根据请求的安全上下文和可用的Pod安全策略确定是否应该允许它。 PodTolerationRestriction：此准入控制器首先验证容器的容忍度与其命名空间的容忍度之间是否存在冲突，并在存在冲突时拒绝该容器请求。 Priority：此控制器使用priorityClassName字段并填充优先级的整数值。如果未找到优先级，则拒绝Pod。 ResourceQuota：此准入控制器将观察传入请求并确保它不违反命名空间的ResourceQuota对象中列举的任何约束。 SecurityContextDeny：此准入控制器将拒绝任何试图设置某些升级的SecurityContext字段的pod 。 ServiceAccount：此准入控制器实现serviceAccounts的自动化。 用中的存储对象保护：该StorageObjectInUseProtection插件将kubernetes.io/pvc-protection或kubernetes.io/pv-protection终结器添加到新创建的持久卷声明（PVC）或持久卷（PV）。在用户删除PVC或PV的情况下，PVC或PV不会被移除，直到PVC或PV保护控制器从PVC或PV中移除终结器。有关更多详细信息，请参阅使用中的存储对象保护。 ValidatingAdmissionWebhook（1.8版本中为alpha；1.9版本中为beta）：该准入控制器调用与请求匹配的任何验证webhook。匹配的webhooks是并行调用的；如果其中任何一个拒绝请求，则请求失败。 推荐配置 linkKubernetes 1.10+\n对于Kubernetes 1.10及更高版本，我们建议使用--enable-admission-plugins标志运行以下一组准入控制器（顺序无关紧要）。\n注意： --admission-control在1.10中已弃用并替换为--enable-admission-plugins。\n--enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota 对于Kubernetes 1.9及更早版本，我们建议使用--admission-control标志（顺序有关）运行以下一组许可控制器。\nKubernetes 1.9\n--admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota 值得重申的是，在1.9中，这些发生在变更阶段和验证阶段，并且例如ResourceQuota在验证阶段运行，因此是运行的最后一个准入控制器。 MutatingAdmissionWebhook在此列表中出现在它之前，因为它在变更阶段运行。\n对于早期版本，没有验证准入控制器和变更准入控制器的概念，并且准入控制器以指定的确切顺序运行。\nKubernetes 1.6 - 1.8\n--admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,PersistentVolumeLabel,DefaultStorageClass,ResourceQuota,DefaultTolerationSeconds 参考 link Using Admission Controllers - kubernetes.io "
            }
        );
    index.add(
            {
                id:  63 ,
                href: "\/docs\/information\/software\/cloud\/k8s_rs_manager\/revision_generation\/",
                title: "ResourceVersion \u0026 Generation",
                description: "最近用kubernetes client-go实现一个监听 deployments 变化的功能，在如何判断 kubernetes 资源的变化有了疑问，查阅文档得知有两个与kubernetes资源对象相关的属性。\nResourceVersion Generation ResourceVersion linkresourceVersion的维护利用了底层存储etcd的Revision机制。\nEtcd Version linkETCD共四种version\nRevision ModRevision Version CreateRevision 字段 作用范围 说明 Version Key 单个Key的修改次数，单调递增 Revision 全局 Key在集群中的全局版本号，全局唯一 ModRevison Key Key 最后一次修改时的 Revision CreateRevision 全局 Key 创建时的 Revision 根据更新资源时是否带有resourceVersion分两种情况：\n未带resourceVersion：无条件更新，获得etcd中最新的数据然后再此基础上更新 带有resourceVersion：和etcd中modRevision对比，不一样就提示版本冲突，说明数据已发生修改，当前要修改的版本已不是最新数据。 Kubernetes资源版本控制采用乐观锁，apiserver在写入etcd时作冲突检测。\nGeneration linkGeneration初始值为1，随Spec内容的改变而自增。\n如果controller更新资源失败，常见的做法是，重新拉取资源，如果资源Generation没有变化，将更新结果Patch到新的资源上再尝试更新。\n",
                content: "最近用kubernetes client-go实现一个监听 deployments 变化的功能，在如何判断 kubernetes 资源的变化有了疑问，查阅文档得知有两个与kubernetes资源对象相关的属性。\nResourceVersion Generation ResourceVersion linkresourceVersion的维护利用了底层存储etcd的Revision机制。\nEtcd Version linkETCD共四种version\nRevision ModRevision Version CreateRevision 字段 作用范围 说明 Version Key 单个Key的修改次数，单调递增 Revision 全局 Key在集群中的全局版本号，全局唯一 ModRevison Key Key 最后一次修改时的 Revision CreateRevision 全局 Key 创建时的 Revision 根据更新资源时是否带有resourceVersion分两种情况：\n未带resourceVersion：无条件更新，获得etcd中最新的数据然后再此基础上更新 带有resourceVersion：和etcd中modRevision对比，不一样就提示版本冲突，说明数据已发生修改，当前要修改的版本已不是最新数据。 Kubernetes资源版本控制采用乐观锁，apiserver在写入etcd时作冲突检测。\nGeneration linkGeneration初始值为1，随Spec内容的改变而自增。\n如果controller更新资源失败，常见的做法是，重新拉取资源，如果资源Generation没有变化，将更新结果Patch到新的资源上再尝试更新。\n"
            }
        );
    index.add(
            {
                id:  64 ,
                href: "\/docs\/information\/software\/serven_rules\/",
                title: "设计模式与七大原则",
                description: "设计模式概述 link设计模式是可复用面向对象软件的设计经验总结，通过23种经典模式解决特定场景下的代码扩展性、复用性、维护性问题。其本质遵循七大核心设计原则：\n七大设计原则详解 link1. 单一职责原则（SRP） link核心思想：一个类只负责一个功能领域中的相应职责\n解决问题：\n避免类因承担过多职责导致的高耦合 减少修改代码时引发连锁错误的风险 示例：\n// 错误示例：用户管理类同时处理信息存储和日志记录 class UserManager { void saveUser() { /* 存储用户 */ } void logActivity() { /* 记录日志 */ } } // 正确拆分 class UserRepository { void saveUser() } class ActivityLogger { void logActivity() } 2. 开闭原则（OCP） link核心思想：对扩展开放，对修改关闭\n解决问题：\n新功能扩展无需修改原有代码 提升系统稳定性与可维护性 示例：\n// 基础图形接口 interface Shape { double area(); } // 新增图形只需扩展接口 class Circle implements Shape { /* 实现圆面积计算 */ } class Square implements Shape { /* 实现正方形面积计算 */ } 3. 里氏替换原则（LSP） link核心思想：子类必须能替换父类且不影响程序正确性\n解决问题：\n",
                content: "设计模式概述 link设计模式是可复用面向对象软件的设计经验总结，通过23种经典模式解决特定场景下的代码扩展性、复用性、维护性问题。其本质遵循七大核心设计原则：\n七大设计原则详解 link1. 单一职责原则（SRP） link核心思想：一个类只负责一个功能领域中的相应职责\n解决问题：\n避免类因承担过多职责导致的高耦合 减少修改代码时引发连锁错误的风险 示例：\n// 错误示例：用户管理类同时处理信息存储和日志记录 class UserManager { void saveUser() { /* 存储用户 */ } void logActivity() { /* 记录日志 */ } } // 正确拆分 class UserRepository { void saveUser() } class ActivityLogger { void logActivity() } 2. 开闭原则（OCP） link核心思想：对扩展开放，对修改关闭\n解决问题：\n新功能扩展无需修改原有代码 提升系统稳定性与可维护性 示例：\n// 基础图形接口 interface Shape { double area(); } // 新增图形只需扩展接口 class Circle implements Shape { /* 实现圆面积计算 */ } class Square implements Shape { /* 实现正方形面积计算 */ } 3. 里氏替换原则（LSP） link核心思想：子类必须能替换父类且不影响程序正确性\n解决问题：\n防止继承关系破坏系统原有逻辑 确保多态的正确使用 经典案例：\n// 错误设计 class Rectangle { int width, height; } class Square extends Rectangle {} // 修改width会自动改变height // 正确做法：通过接口定义形状 interface Quadrilateral { int getWidth(); int getHeight(); } 4. 依赖倒置原则（DIP） link核心思想：高层模块不依赖低层模块，二者都依赖抽象\n解决问题：\n降低模块间耦合度 提高系统可扩展性 场景示例：\ninterface MessageService { void send(); } // 高层模块通过接口调用 class Notification { private MessageService service; Notification(MessageService service) { this.service = service; } } // 可扩展多种实现（EmailService/SMSService） 5. 接口隔离原则（ISP） link核心思想：客户端不应依赖它不需要的接口\n解决问题：\n避免接口臃肿导致实现类冗余 减少接口变更对客户端的影响 实现方式：\n// 错误：大型接口 interface Animal { void eat(); void fly(); // 企鹅不需要此方法 } // 正确拆分 interface Swimmable { void swim(); } interface Flyable { void fly(); } 6. 迪米特法则（LoD） link核心思想：一个对象应尽可能少了解其他对象\n解决问题：\n降低类之间的耦合度 提高模块独立性 应用场景：\n// 直接通信（高耦合） class A { void call(B b) { b.method(); } } // 通过中介类（低耦合） class Mediator { void process() { B b = new B(); b.method(); } } 7. 合成复用原则（CARP） link核心思想：优先使用组合/聚合，而非继承\n解决问题：\n避免继承破坏封装性 更灵活地复用已有功能 对比示例：\n// 错误：通过继承实现复用 class Car extends Engine {} // 正确：通过组合实现复用 class Car { private Engine engine; Car(Engine engine) { this.engine = engine; } } 总结 link 原则 核心价值 典型应用场景 SRP 功能聚焦 模块拆分、微服务设计 OCP 稳定扩展 插件系统、框架设计 LSP 继承安全 多态实现、API设计 DIP 解耦抽象 依赖注入、中间件 ISP 接口精简 SDK设计、协议定义 LoD 最小交互 分层架构、MVC模式 CARP 灵活复用 组件化开发、库封装 核心目标：通过高内聚、低耦合的设计，构建可维护、可扩展、高复用的软件系统\n"
            }
        );
    index.add(
            {
                id:  65 ,
                href: "\/docs\/information\/software\/clean_arch\/",
                title: "简洁架构",
                description: "1. 概念与核心目标 link简洁架构（Clean Architecture）是一种以业务逻辑为核心的软件架构设计方法论。其核心目标是：\n建立框架无关的系统结构 保持业务逻辑的独立性与可测试性 实现双向隔离：业务核心与技术实现的隔离、数据源与展示层的隔离 通过分层设计强制实施依赖规则 2. 核心设计思想 linkgraph TD subgraph 框架层 Web[Web框架] DB[(数据库)] subgraph 接口适配层 Controllers Presenters subgraph 用例层 UseCases subgraph 实体层 Entities end end end end Web --\u003e Controllers Controllers --\u003e UseCases UseCases --\u003e Entities Presenters --\u003e UseCases DB -.-\u003e Entities 2.1 分层结构（同心圆模型） link分层说明： link 实体层（Entities）\n包含核心业务对象与规则 示例：订单实体、用户实体及其验证规则 用例层（Use Cases）\n实现具体业务场景的交互逻辑 示例：“创建订单\"流程、“支付处理\"流程 接口适配层（Interface Adapters）\n转换数据格式适配不同协议 包含：控制器、网关、数据映射器 框架层（Frameworks \u0026 Drivers）\n技术实现细节：数据库、Web框架、UI组件 2.2 依赖规则 link 向内依赖原则：外层可以依赖内层，反之禁止 抽象接口定义在内层，具体实现放在外层 数据流向：从外层到内层必须经过边界接口 3. 解决的关键问题 link 问题类型 传统架构痛点 简洁架构解决方案 代码耦合度 业务逻辑与技术实现深度耦合 通过分层强制解耦 可维护性 修改框架导致业务逻辑变动 业务核心保持技术中立 测试复杂度 需要启动完整环境才能测试 核心层可脱离框架独立测试 技术锁定 更换技术栈成本极高 通过接口适配实现灵活替换 4. 具体实现示例 link4.1 代码结构 link # 实体层 class Order: def __init__(self, items: list, total: float): self._validate(items, total) def _validate(self, items, total): # 核心业务规则实现 # 用例层 class CreateOrderUseCase: def __init__(self, order_repo: OrderRepository): self.repo = order_repo def execute(self, items): order = Order(items) return self.repo.save(order) # 接口适配层（实现内层定义的抽象接口） class SQLOrderRepository: def save(self, order): # 数据库具体实现 # 框架层（FastAPI示例） @app.post(\"/orders\") def create_order(items: list): repo = SQLOrderRepository() use_case = CreateOrderUseCase(repo) return use_case.execute(items) 4.2 依赖管理 linkgraph TD A[Web框架] --\u003e|依赖| B[接口适配器] B --\u003e|实现| C[用例层接口] C --\u003e|依赖| D[实体层] 5. 类似架构思想对比 link 架构类型 核心差异点 适用场景 分层架构 水平分层 vs 同心圆分层 传统企业应用 六边形架构 端口-适配器模式更明确 高交互性系统 DDD 强调领域建模而非结构约束 复杂业务系统 洋葱架构 类似分层但强调领域服务层 长期演进的中大型系统 6. 优势与挑战 link✅ 核心优势：\n",
                content: "1. 概念与核心目标 link简洁架构（Clean Architecture）是一种以业务逻辑为核心的软件架构设计方法论。其核心目标是：\n建立框架无关的系统结构 保持业务逻辑的独立性与可测试性 实现双向隔离：业务核心与技术实现的隔离、数据源与展示层的隔离 通过分层设计强制实施依赖规则 2. 核心设计思想 linkgraph TD subgraph 框架层 Web[Web框架] DB[(数据库)] subgraph 接口适配层 Controllers Presenters subgraph 用例层 UseCases subgraph 实体层 Entities end end end end Web --\u003e Controllers Controllers --\u003e UseCases UseCases --\u003e Entities Presenters --\u003e UseCases DB -.-\u003e Entities 2.1 分层结构（同心圆模型） link分层说明： link 实体层（Entities）\n包含核心业务对象与规则 示例：订单实体、用户实体及其验证规则 用例层（Use Cases）\n实现具体业务场景的交互逻辑 示例：“创建订单\"流程、“支付处理\"流程 接口适配层（Interface Adapters）\n转换数据格式适配不同协议 包含：控制器、网关、数据映射器 框架层（Frameworks \u0026 Drivers）\n技术实现细节：数据库、Web框架、UI组件 2.2 依赖规则 link 向内依赖原则：外层可以依赖内层，反之禁止 抽象接口定义在内层，具体实现放在外层 数据流向：从外层到内层必须经过边界接口 3. 解决的关键问题 link 问题类型 传统架构痛点 简洁架构解决方案 代码耦合度 业务逻辑与技术实现深度耦合 通过分层强制解耦 可维护性 修改框架导致业务逻辑变动 业务核心保持技术中立 测试复杂度 需要启动完整环境才能测试 核心层可脱离框架独立测试 技术锁定 更换技术栈成本极高 通过接口适配实现灵活替换 4. 具体实现示例 link4.1 代码结构 link # 实体层 class Order: def __init__(self, items: list, total: float): self._validate(items, total) def _validate(self, items, total): # 核心业务规则实现 # 用例层 class CreateOrderUseCase: def __init__(self, order_repo: OrderRepository): self.repo = order_repo def execute(self, items): order = Order(items) return self.repo.save(order) # 接口适配层（实现内层定义的抽象接口） class SQLOrderRepository: def save(self, order): # 数据库具体实现 # 框架层（FastAPI示例） @app.post(\"/orders\") def create_order(items: list): repo = SQLOrderRepository() use_case = CreateOrderUseCase(repo) return use_case.execute(items) 4.2 依赖管理 linkgraph TD A[Web框架] --\u003e|依赖| B[接口适配器] B --\u003e|实现| C[用例层接口] C --\u003e|依赖| D[实体层] 5. 类似架构思想对比 link 架构类型 核心差异点 适用场景 分层架构 水平分层 vs 同心圆分层 传统企业应用 六边形架构 端口-适配器模式更明确 高交互性系统 DDD 强调领域建模而非结构约束 复杂业务系统 洋葱架构 类似分层但强调领域服务层 长期演进的中大型系统 6. 优势与挑战 link✅ 核心优势：\n业务核心生存周期可达10年以上 新功能开发效率提升40%（IBM案例研究） 技术迁移成本降低70% ⚠️ 实施挑战：\n初期设计复杂度增加20%-30% 需要团队架构意识的根本转变 对简单CRUD系统可能过度设计 7. 最佳实践建议 link 渐进式改造：从核心模块开始实施 契约测试：确保接口层符合规范 依赖检查：使用工具强制分层规则（如ArchUnit） 文档驱动：维护清晰的架构边界文档 性能监控：关注跨层通信开销 8. 演进趋势 link 与微服务架构融合形成Clean Microservices 结合Serverless的无框架实现 通过WebAssembly实现核心层跨平台 "
            }
        );
    index.add(
            {
                id:  66 ,
                href: "\/docs\/mix\/mermaid\/syntax\/c4\/",
                title: "C4 Diagrams",
                description: "C4 Diagrams link C4 Diagram: This is an experimental diagram for now. The syntax and properties can change in future releases. Proper documentation will be provided when the syntax is stable.\nMermaid’s C4 diagram syntax is compatible with plantUML. See example below:\nC4Context title System Context diagram for Internet Banking System Enterprise_Boundary(b0, \"BankBoundary0\") { Person(customerA, \"Banking Customer A\", \"A customer of the bank, with personal bank accounts.\") Person(customerB, \"Banking Customer B\") Person_Ext(customerC, \"Banking Customer C\", \"desc\") Person(customerD, \"Banking Customer D\", \"A customer of the bank, with personal bank accounts.\") System(SystemAA, \"Internet Banking System\", \"Allows customers to view information about their bank accounts, and make payments.\") Enterprise_Boundary(b1, \"BankBoundary\") { SystemDb_Ext(SystemE, \"Mainframe Banking System\", \"Stores all of the core banking information about customers, accounts, transactions, etc.\") System_Boundary(b2, \"BankBoundary2\") { System(SystemA, \"Banking System A\") System(SystemB, \"Banking System B\", \"A system of the bank, with personal bank accounts. next line.\") } System_Ext(SystemC, \"E-mail system\", \"The internal Microsoft Exchange e-mail system.\") SystemDb(SystemD, \"Banking System D Database\", \"A system of the bank, with personal bank accounts.\") Boundary(b3, \"BankBoundary3\", \"boundary\") { SystemQueue(SystemF, \"Banking System F Queue\", \"A system of the bank.\") SystemQueue_Ext(SystemG, \"Banking System G Queue\", \"A system of the bank, with personal bank accounts.\") } } } BiRel(customerA, SystemAA, \"Uses\") BiRel(SystemAA, SystemE, \"Uses\") Rel(SystemAA, SystemC, \"Sends e-mails\", \"SMTP\") Rel(SystemC, customerA, \"Sends e-mails to\") UpdateElementStyle(customerA, $fontColor=\"red\", $bgColor=\"grey\", $borderColor=\"red\") UpdateRelStyle(customerA, SystemAA, $textColor=\"blue\", $lineColor=\"blue\", $offsetX=\"5\") UpdateRelStyle(SystemAA, SystemE, $textColor=\"blue\", $lineColor=\"blue\", $offsetY=\"-10\") UpdateRelStyle(SystemAA, SystemC, $textColor=\"blue\", $lineColor=\"blue\", $offsetY=\"-40\", $offsetX=\"-50\") UpdateRelStyle(SystemC, customerA, $textColor=\"red\", $lineColor=\"red\", $offsetX=\"-50\", $offsetY=\"20\") UpdateLayoutConfig($c4ShapeInRow=\"3\", $c4BoundaryInRow=\"1\") C4Context title System Context diagram for Internet Banking System Enterprise_Boundary(b0, \"BankBoundary0\") { Person(customerA, \"Banking Customer A\", \"A customer of the bank, with personal bank accounts.\") Person(customerB, \"Banking Customer B\") Person_Ext(customerC, \"Banking Customer C\", \"desc\") Person(customerD, \"Banking Customer D\", \"A customer of the bank, with personal bank accounts.\") System(SystemAA, \"Internet Banking System\", \"Allows customers to view information about their bank accounts, and make payments.\") Enterprise_Boundary(b1, \"BankBoundary\") { SystemDb_Ext(SystemE, \"Mainframe Banking System\", \"Stores all of the core banking information about customers, accounts, transactions, etc.\") System_Boundary(b2, \"BankBoundary2\") { System(SystemA, \"Banking System A\") System(SystemB, \"Banking System B\", \"A system of the bank, with personal bank accounts. next line.\") } System_Ext(SystemC, \"E-mail system\", \"The internal Microsoft Exchange e-mail system.\") SystemDb(SystemD, \"Banking System D Database\", \"A system of the bank, with personal bank accounts.\") Boundary(b3, \"BankBoundary3\", \"boundary\") { SystemQueue(SystemF, \"Banking System F Queue\", \"A system of the bank.\") SystemQueue_Ext(SystemG, \"Banking System G Queue\", \"A system of the bank, with personal bank accounts.\") } } } BiRel(customerA, SystemAA, \"Uses\") BiRel(SystemAA, SystemE, \"Uses\") Rel(SystemAA, SystemC, \"Sends e-mails\", \"SMTP\") Rel(SystemC, customerA, \"Sends e-mails to\") UpdateElementStyle(customerA, $fontColor=\"red\", $bgColor=\"grey\", $borderColor=\"red\") UpdateRelStyle(customerA, SystemAA, $textColor=\"blue\", $lineColor=\"blue\", $offsetX=\"5\") UpdateRelStyle(SystemAA, SystemE, $textColor=\"blue\", $lineColor=\"blue\", $offsetY=\"-10\") UpdateRelStyle(SystemAA, SystemC, $textColor=\"blue\", $lineColor=\"blue\", $offsetY=\"-40\", $offsetX=\"-50\") UpdateRelStyle(SystemC, customerA, $textColor=\"red\", $lineColor=\"red\", $offsetX=\"-50\", $offsetY=\"20\") UpdateLayoutConfig($c4ShapeInRow=\"3\", $c4BoundaryInRow=\"1\") For an example, see the source code demos/index.html\n",
                content: "C4 Diagrams link C4 Diagram: This is an experimental diagram for now. The syntax and properties can change in future releases. Proper documentation will be provided when the syntax is stable.\nMermaid’s C4 diagram syntax is compatible with plantUML. See example below:\nC4Context title System Context diagram for Internet Banking System Enterprise_Boundary(b0, \"BankBoundary0\") { Person(customerA, \"Banking Customer A\", \"A customer of the bank, with personal bank accounts.\") Person(customerB, \"Banking Customer B\") Person_Ext(customerC, \"Banking Customer C\", \"desc\") Person(customerD, \"Banking Customer D\", \"A customer of the bank, with personal bank accounts.\") System(SystemAA, \"Internet Banking System\", \"Allows customers to view information about their bank accounts, and make payments.\") Enterprise_Boundary(b1, \"BankBoundary\") { SystemDb_Ext(SystemE, \"Mainframe Banking System\", \"Stores all of the core banking information about customers, accounts, transactions, etc.\") System_Boundary(b2, \"BankBoundary2\") { System(SystemA, \"Banking System A\") System(SystemB, \"Banking System B\", \"A system of the bank, with personal bank accounts. next line.\") } System_Ext(SystemC, \"E-mail system\", \"The internal Microsoft Exchange e-mail system.\") SystemDb(SystemD, \"Banking System D Database\", \"A system of the bank, with personal bank accounts.\") Boundary(b3, \"BankBoundary3\", \"boundary\") { SystemQueue(SystemF, \"Banking System F Queue\", \"A system of the bank.\") SystemQueue_Ext(SystemG, \"Banking System G Queue\", \"A system of the bank, with personal bank accounts.\") } } } BiRel(customerA, SystemAA, \"Uses\") BiRel(SystemAA, SystemE, \"Uses\") Rel(SystemAA, SystemC, \"Sends e-mails\", \"SMTP\") Rel(SystemC, customerA, \"Sends e-mails to\") UpdateElementStyle(customerA, $fontColor=\"red\", $bgColor=\"grey\", $borderColor=\"red\") UpdateRelStyle(customerA, SystemAA, $textColor=\"blue\", $lineColor=\"blue\", $offsetX=\"5\") UpdateRelStyle(SystemAA, SystemE, $textColor=\"blue\", $lineColor=\"blue\", $offsetY=\"-10\") UpdateRelStyle(SystemAA, SystemC, $textColor=\"blue\", $lineColor=\"blue\", $offsetY=\"-40\", $offsetX=\"-50\") UpdateRelStyle(SystemC, customerA, $textColor=\"red\", $lineColor=\"red\", $offsetX=\"-50\", $offsetY=\"20\") UpdateLayoutConfig($c4ShapeInRow=\"3\", $c4BoundaryInRow=\"1\") C4Context title System Context diagram for Internet Banking System Enterprise_Boundary(b0, \"BankBoundary0\") { Person(customerA, \"Banking Customer A\", \"A customer of the bank, with personal bank accounts.\") Person(customerB, \"Banking Customer B\") Person_Ext(customerC, \"Banking Customer C\", \"desc\") Person(customerD, \"Banking Customer D\", \"A customer of the bank, with personal bank accounts.\") System(SystemAA, \"Internet Banking System\", \"Allows customers to view information about their bank accounts, and make payments.\") Enterprise_Boundary(b1, \"BankBoundary\") { SystemDb_Ext(SystemE, \"Mainframe Banking System\", \"Stores all of the core banking information about customers, accounts, transactions, etc.\") System_Boundary(b2, \"BankBoundary2\") { System(SystemA, \"Banking System A\") System(SystemB, \"Banking System B\", \"A system of the bank, with personal bank accounts. next line.\") } System_Ext(SystemC, \"E-mail system\", \"The internal Microsoft Exchange e-mail system.\") SystemDb(SystemD, \"Banking System D Database\", \"A system of the bank, with personal bank accounts.\") Boundary(b3, \"BankBoundary3\", \"boundary\") { SystemQueue(SystemF, \"Banking System F Queue\", \"A system of the bank.\") SystemQueue_Ext(SystemG, \"Banking System G Queue\", \"A system of the bank, with personal bank accounts.\") } } } BiRel(customerA, SystemAA, \"Uses\") BiRel(SystemAA, SystemE, \"Uses\") Rel(SystemAA, SystemC, \"Sends e-mails\", \"SMTP\") Rel(SystemC, customerA, \"Sends e-mails to\") UpdateElementStyle(customerA, $fontColor=\"red\", $bgColor=\"grey\", $borderColor=\"red\") UpdateRelStyle(customerA, SystemAA, $textColor=\"blue\", $lineColor=\"blue\", $offsetX=\"5\") UpdateRelStyle(SystemAA, SystemE, $textColor=\"blue\", $lineColor=\"blue\", $offsetY=\"-10\") UpdateRelStyle(SystemAA, SystemC, $textColor=\"blue\", $lineColor=\"blue\", $offsetY=\"-40\", $offsetX=\"-50\") UpdateRelStyle(SystemC, customerA, $textColor=\"red\", $lineColor=\"red\", $offsetX=\"-50\", $offsetY=\"20\") UpdateLayoutConfig($c4ShapeInRow=\"3\", $c4BoundaryInRow=\"1\") For an example, see the source code demos/index.html\n5 types of C4 charts are supported.\nSystem Context (C4Context) Container diagram (C4Container) Component diagram (C4Component) Dynamic diagram (C4Dynamic) Deployment diagram (C4Deployment) Please refer to the linked document C4-PlantUML syntax for how to write the C4 diagram.\nC4 diagram is fixed style, such as css color, so different css is not provided under different skins. updateElementStyle and UpdateElementStyle are written in the diagram last part. updateElementStyle is inconsistent with the original definition and updates the style of the relationship, including the offset of the text label relative to the original position.\nThe layout does not use a fully automated layout algorithm. The position of shapes is adjusted by changing the order in which statements are written. So there is no plan to support the following Layout statements. The number of shapes per row and the number of boundaries can be adjusted using UpdateLayoutConfig.\nLayout Lay_U, Lay_Up Lay_D, Lay_Down Lay_L, Lay_Left Lay_R, Lay_Right The following unfinished features are not supported in the short term.\nsprite\ntags\nlink\nLegend\nSystem Context\nPerson(alias, label, ?descr, ?sprite, ?tags, $link) Person_Ext System(alias, label, ?descr, ?sprite, ?tags, $link) SystemDb SystemQueue System_Ext SystemDb_Ext SystemQueue_Ext Boundary(alias, label, ?type, ?tags, $link) Enterprise_Boundary(alias, label, ?tags, $link) System_Boundary Container diagram\nContainer(alias, label, ?techn, ?descr, ?sprite, ?tags, $link) ContainerDb ContainerQueue Container_Ext ContainerDb_Ext ContainerQueue_Ext Container_Boundary(alias, label, ?tags, $link) Component diagram\nComponent(alias, label, ?techn, ?descr, ?sprite, ?tags, $link) ComponentDb ComponentQueue Component_Ext ComponentDb_Ext ComponentQueue_Ext Dynamic diagram\nRelIndex(index, from, to, label, ?tags, $link) Deployment diagram\nDeployment_Node(alias, label, ?type, ?descr, ?sprite, ?tags, $link) Node(alias, label, ?type, ?descr, ?sprite, ?tags, $link): short name of Deployment_Node() Node_L(alias, label, ?type, ?descr, ?sprite, ?tags, $link): left aligned Node() Node_R(alias, label, ?type, ?descr, ?sprite, ?tags, $link): right aligned Node() Relationship Types\nRel(from, to, label, ?techn, ?descr, ?sprite, ?tags, $link) BiRel (bidirectional relationship) Rel_U, Rel_Up Rel_D, Rel_Down Rel_L, Rel_Left Rel_R, Rel_Right Rel_Back RelIndex * Compatible with C4-Plantuml syntax, but ignores the index parameter. The sequence number is determined by the order in which the rel statements are written. Custom tags/stereotypes support and skin param updates\nAddElementTag(tagStereo, ?bgColor, ?fontColor, ?borderColor, ?shadowing, ?shape, ?sprite, ?techn, ?legendText, ?legendSprite): Introduces a new element tag. The styles of the tagged elements are updated and the tag is displayed in the calculated legend. AddRelTag(tagStereo, ?textColor, ?lineColor, ?lineStyle, ?sprite, ?techn, ?legendText, ?legendSprite): Introduces a new Relationship tag. The styles of the tagged relationships are updated and the tag is displayed in the calculated legend. UpdateElementStyle(elementName, ?bgColor, ?fontColor, ?borderColor, ?shadowing, ?shape, ?sprite, ?techn, ?legendText, ?legendSprite): This call updates the default style of the elements (component, …) and creates no additional legend entry. UpdateRelStyle(from, to, ?textColor, ?lineColor, ?offsetX, ?offsetY): This call updates the default relationship colors and creates no additional legend entry. Two new parameters, offsetX and offsetY, are added to set the offset of the original position of the text. RoundedBoxShape(): This call returns the name of the rounded box shape and can be used as ?shape argument. EightSidedShape(): This call returns the name of the eight sided shape and can be used as ?shape argument. DashedLine(): This call returns the name of the dashed line and can be used as ?lineStyle argument. DottedLine(): This call returns the name of the dotted line and can be used as ?lineStyle argument. BoldLine(): This call returns the name of the bold line and can be used as ?lineStyle argument. UpdateLayoutConfig(?c4ShapeInRow, ?c4BoundaryInRow): New. This call updates the default c4ShapeInRow(4) and c4BoundaryInRow(2). There are two ways to assign parameters with question marks. One uses the non-named parameter assignment method in the order of the parameters, and the other uses the named parameter assignment method, where the name must start with a $ symbol.\nExample: UpdateRelStyle(from, to, ?textColor, ?lineColor, ?offsetX, ?offsetY)\nUpdateRelStyle(customerA, bankA, \"red\", \"blue\", \"-40\", \"60\") UpdateRelStyle(customerA, bankA, $offsetX=\"-40\", $offsetY=\"60\", $lineColor=\"blue\", $textColor=\"red\") UpdateRelStyle(customerA, bankA, $offsetY=\"60\") C4 System Context Diagram (C4Context) link C4Context title System Context diagram for Internet Banking System Enterprise_Boundary(b0, \"BankBoundary0\") { Person(customerA, \"Banking Customer A\", \"A customer of the bank, with personal bank accounts.\") Person(customerB, \"Banking Customer B\") Person_Ext(customerC, \"Banking Customer C\", \"desc\") Person(customerD, \"Banking Customer D\", \"A customer of the bank, with personal bank accounts.\") System(SystemAA, \"Internet Banking System\", \"Allows customers to view information about their bank accounts, and make payments.\") Enterprise_Boundary(b1, \"BankBoundary\") { SystemDb_Ext(SystemE, \"Mainframe Banking System\", \"Stores all of the core banking information about customers, accounts, transactions, etc.\") System_Boundary(b2, \"BankBoundary2\") { System(SystemA, \"Banking System A\") System(SystemB, \"Banking System B\", \"A system of the bank, with personal bank accounts. next line.\") } System_Ext(SystemC, \"E-mail system\", \"The internal Microsoft Exchange e-mail system.\") SystemDb(SystemD, \"Banking System D Database\", \"A system of the bank, with personal bank accounts.\") Boundary(b3, \"BankBoundary3\", \"boundary\") { SystemQueue(SystemF, \"Banking System F Queue\", \"A system of the bank.\") SystemQueue_Ext(SystemG, \"Banking System G Queue\", \"A system of the bank, with personal bank accounts.\") } } } BiRel(customerA, SystemAA, \"Uses\") BiRel(SystemAA, SystemE, \"Uses\") Rel(SystemAA, SystemC, \"Sends e-mails\", \"SMTP\") Rel(SystemC, customerA, \"Sends e-mails to\") UpdateElementStyle(customerA, $fontColor=\"red\", $bgColor=\"grey\", $borderColor=\"red\") UpdateRelStyle(customerA, SystemAA, $textColor=\"blue\", $lineColor=\"blue\", $offsetX=\"5\") UpdateRelStyle(SystemAA, SystemE, $textColor=\"blue\", $lineColor=\"blue\", $offsetY=\"-10\") UpdateRelStyle(SystemAA, SystemC, $textColor=\"blue\", $lineColor=\"blue\", $offsetY=\"-40\", $offsetX=\"-50\") UpdateRelStyle(SystemC, customerA, $textColor=\"red\", $lineColor=\"red\", $offsetX=\"-50\", $offsetY=\"20\") UpdateLayoutConfig($c4ShapeInRow=\"3\", $c4BoundaryInRow=\"1\") C4Context title System Context diagram for Internet Banking System Enterprise_Boundary(b0, \"BankBoundary0\") { Person(customerA, \"Banking Customer A\", \"A customer of the bank, with personal bank accounts.\") Person(customerB, \"Banking Customer B\") Person_Ext(customerC, \"Banking Customer C\", \"desc\") Person(customerD, \"Banking Customer D\", \"A customer of the bank, with personal bank accounts.\") System(SystemAA, \"Internet Banking System\", \"Allows customers to view information about their bank accounts, and make payments.\") Enterprise_Boundary(b1, \"BankBoundary\") { SystemDb_Ext(SystemE, \"Mainframe Banking System\", \"Stores all of the core banking information about customers, accounts, transactions, etc.\") System_Boundary(b2, \"BankBoundary2\") { System(SystemA, \"Banking System A\") System(SystemB, \"Banking System B\", \"A system of the bank, with personal bank accounts. next line.\") } System_Ext(SystemC, \"E-mail system\", \"The internal Microsoft Exchange e-mail system.\") SystemDb(SystemD, \"Banking System D Database\", \"A system of the bank, with personal bank accounts.\") Boundary(b3, \"BankBoundary3\", \"boundary\") { SystemQueue(SystemF, \"Banking System F Queue\", \"A system of the bank.\") SystemQueue_Ext(SystemG, \"Banking System G Queue\", \"A system of the bank, with personal bank accounts.\") } } } BiRel(customerA, SystemAA, \"Uses\") BiRel(SystemAA, SystemE, \"Uses\") Rel(SystemAA, SystemC, \"Sends e-mails\", \"SMTP\") Rel(SystemC, customerA, \"Sends e-mails to\") UpdateElementStyle(customerA, $fontColor=\"red\", $bgColor=\"grey\", $borderColor=\"red\") UpdateRelStyle(customerA, SystemAA, $textColor=\"blue\", $lineColor=\"blue\", $offsetX=\"5\") UpdateRelStyle(SystemAA, SystemE, $textColor=\"blue\", $lineColor=\"blue\", $offsetY=\"-10\") UpdateRelStyle(SystemAA, SystemC, $textColor=\"blue\", $lineColor=\"blue\", $offsetY=\"-40\", $offsetX=\"-50\") UpdateRelStyle(SystemC, customerA, $textColor=\"red\", $lineColor=\"red\", $offsetX=\"-50\", $offsetY=\"20\") UpdateLayoutConfig($c4ShapeInRow=\"3\", $c4BoundaryInRow=\"1\") C4 Container diagram (C4Container) link C4Container title Container diagram for Internet Banking System System_Ext(email_system, \"E-Mail System\", \"The internal Microsoft Exchange system\", $tags=\"v1.0\") Person(customer, Customer, \"A customer of the bank, with personal bank accounts\", $tags=\"v1.0\") Container_Boundary(c1, \"Internet Banking\") { Container(spa, \"Single-Page App\", \"JavaScript, Angular\", \"Provides all the Internet banking functionality to cutomers via their web browser\") Container_Ext(mobile_app, \"Mobile App\", \"C#, Xamarin\", \"Provides a limited subset of the Internet banking functionality to customers via their mobile device\") Container(web_app, \"Web Application\", \"Java, Spring MVC\", \"Delivers the static content and the Internet banking SPA\") ContainerDb(database, \"Database\", \"SQL Database\", \"Stores user registration information, hashed auth credentials, access logs, etc.\") ContainerDb_Ext(backend_api, \"API Application\", \"Java, Docker Container\", \"Provides Internet banking functionality via API\") } System_Ext(banking_system, \"Mainframe Banking System\", \"Stores all of the core banking information about customers, accounts, transactions, etc.\") Rel(customer, web_app, \"Uses\", \"HTTPS\") UpdateRelStyle(customer, web_app, $offsetY=\"60\", $offsetX=\"90\") Rel(customer, spa, \"Uses\", \"HTTPS\") UpdateRelStyle(customer, spa, $offsetY=\"-40\") Rel(customer, mobile_app, \"Uses\") UpdateRelStyle(customer, mobile_app, $offsetY=\"-30\") Rel(web_app, spa, \"Delivers\") UpdateRelStyle(web_app, spa, $offsetX=\"130\") Rel(spa, backend_api, \"Uses\", \"async, JSON/HTTPS\") Rel(mobile_app, backend_api, \"Uses\", \"async, JSON/HTTPS\") Rel_Back(database, backend_api, \"Reads from and writes to\", \"sync, JDBC\") Rel(email_system, customer, \"Sends e-mails to\") UpdateRelStyle(email_system, customer, $offsetX=\"-45\") Rel(backend_api, email_system, \"Sends e-mails using\", \"sync, SMTP\") UpdateRelStyle(backend_api, email_system, $offsetY=\"-60\") Rel(backend_api, banking_system, \"Uses\", \"sync/async, XML/HTTPS\") UpdateRelStyle(backend_api, banking_system, $offsetY=\"-50\", $offsetX=\"-140\") C4Container title Container diagram for Internet Banking System System_Ext(email_system, \"E-Mail System\", \"The internal Microsoft Exchange system\", $tags=\"v1.0\") Person(customer, Customer, \"A customer of the bank, with personal bank accounts\", $tags=\"v1.0\") Container_Boundary(c1, \"Internet Banking\") { Container(spa, \"Single-Page App\", \"JavaScript, Angular\", \"Provides all the Internet banking functionality to cutomers via their web browser\") Container_Ext(mobile_app, \"Mobile App\", \"C#, Xamarin\", \"Provides a limited subset of the Internet banking functionality to customers via their mobile device\") Container(web_app, \"Web Application\", \"Java, Spring MVC\", \"Delivers the static content and the Internet banking SPA\") ContainerDb(database, \"Database\", \"SQL Database\", \"Stores user registration information, hashed auth credentials, access logs, etc.\") ContainerDb_Ext(backend_api, \"API Application\", \"Java, Docker Container\", \"Provides Internet banking functionality via API\") } System_Ext(banking_system, \"Mainframe Banking System\", \"Stores all of the core banking information about customers, accounts, transactions, etc.\") Rel(customer, web_app, \"Uses\", \"HTTPS\") UpdateRelStyle(customer, web_app, $offsetY=\"60\", $offsetX=\"90\") Rel(customer, spa, \"Uses\", \"HTTPS\") UpdateRelStyle(customer, spa, $offsetY=\"-40\") Rel(customer, mobile_app, \"Uses\") UpdateRelStyle(customer, mobile_app, $offsetY=\"-30\") Rel(web_app, spa, \"Delivers\") UpdateRelStyle(web_app, spa, $offsetX=\"130\") Rel(spa, backend_api, \"Uses\", \"async, JSON/HTTPS\") Rel(mobile_app, backend_api, \"Uses\", \"async, JSON/HTTPS\") Rel_Back(database, backend_api, \"Reads from and writes to\", \"sync, JDBC\") Rel(email_system, customer, \"Sends e-mails to\") UpdateRelStyle(email_system, customer, $offsetX=\"-45\") Rel(backend_api, email_system, \"Sends e-mails using\", \"sync, SMTP\") UpdateRelStyle(backend_api, email_system, $offsetY=\"-60\") Rel(backend_api, banking_system, \"Uses\", \"sync/async, XML/HTTPS\") UpdateRelStyle(backend_api, banking_system, $offsetY=\"-50\", $offsetX=\"-140\") C4 Component diagram (C4Component) link C4Component title Component diagram for Internet Banking System - API Application Container(spa, \"Single Page Application\", \"javascript and angular\", \"Provides all the internet banking functionality to customers via their web browser.\") Container(ma, \"Mobile App\", \"Xamarin\", \"Provides a limited subset ot the internet banking functionality to customers via their mobile mobile device.\") ContainerDb(db, \"Database\", \"Relational Database Schema\", \"Stores user registration information, hashed authentication credentials, access logs, etc.\") System_Ext(mbs, \"Mainframe Banking System\", \"Stores all of the core banking information about customers, accounts, transactions, etc.\") Container_Boundary(api, \"API Application\") { Component(sign, \"Sign In Controller\", \"MVC Rest Controller\", \"Allows users to sign in to the internet banking system\") Component(accounts, \"Accounts Summary Controller\", \"MVC Rest Controller\", \"Provides customers with a summary of their bank accounts\") Component(security, \"Security Component\", \"Spring Bean\", \"Provides functionality related to singing in, changing passwords, etc.\") Component(mbsfacade, \"Mainframe Banking System Facade\", \"Spring Bean\", \"A facade onto the mainframe banking system.\") Rel(sign, security, \"Uses\") Rel(accounts, mbsfacade, \"Uses\") Rel(security, db, \"Read \u0026 write to\", \"JDBC\") Rel(mbsfacade, mbs, \"Uses\", \"XML/HTTPS\") } Rel_Back(spa, sign, \"Uses\", \"JSON/HTTPS\") Rel(spa, accounts, \"Uses\", \"JSON/HTTPS\") Rel(ma, sign, \"Uses\", \"JSON/HTTPS\") Rel(ma, accounts, \"Uses\", \"JSON/HTTPS\") UpdateRelStyle(spa, sign, $offsetY=\"-40\") UpdateRelStyle(spa, accounts, $offsetX=\"40\", $offsetY=\"40\") UpdateRelStyle(ma, sign, $offsetX=\"-90\", $offsetY=\"40\") UpdateRelStyle(ma, accounts, $offsetY=\"-40\") UpdateRelStyle(sign, security, $offsetX=\"-160\", $offsetY=\"10\") UpdateRelStyle(accounts, mbsfacade, $offsetX=\"140\", $offsetY=\"10\") UpdateRelStyle(security, db, $offsetY=\"-40\") UpdateRelStyle(mbsfacade, mbs, $offsetY=\"-40\") C4Component title Component diagram for Internet Banking System - API Application Container(spa, \"Single Page Application\", \"javascript and angular\", \"Provides all the internet banking functionality to customers via their web browser.\") Container(ma, \"Mobile App\", \"Xamarin\", \"Provides a limited subset ot the internet banking functionality to customers via their mobile mobile device.\") ContainerDb(db, \"Database\", \"Relational Database Schema\", \"Stores user registration information, hashed authentication credentials, access logs, etc.\") System_Ext(mbs, \"Mainframe Banking System\", \"Stores all of the core banking information about customers, accounts, transactions, etc.\") Container_Boundary(api, \"API Application\") { Component(sign, \"Sign In Controller\", \"MVC Rest Controller\", \"Allows users to sign in to the internet banking system\") Component(accounts, \"Accounts Summary Controller\", \"MVC Rest Controller\", \"Provides customers with a summary of their bank accounts\") Component(security, \"Security Component\", \"Spring Bean\", \"Provides functionality related to singing in, changing passwords, etc.\") Component(mbsfacade, \"Mainframe Banking System Facade\", \"Spring Bean\", \"A facade onto the mainframe banking system.\") Rel(sign, security, \"Uses\") Rel(accounts, mbsfacade, \"Uses\") Rel(security, db, \"Read \u0026 write to\", \"JDBC\") Rel(mbsfacade, mbs, \"Uses\", \"XML/HTTPS\") } Rel_Back(spa, sign, \"Uses\", \"JSON/HTTPS\") Rel(spa, accounts, \"Uses\", \"JSON/HTTPS\") Rel(ma, sign, \"Uses\", \"JSON/HTTPS\") Rel(ma, accounts, \"Uses\", \"JSON/HTTPS\") UpdateRelStyle(spa, sign, $offsetY=\"-40\") UpdateRelStyle(spa, accounts, $offsetX=\"40\", $offsetY=\"40\") UpdateRelStyle(ma, sign, $offsetX=\"-90\", $offsetY=\"40\") UpdateRelStyle(ma, accounts, $offsetY=\"-40\") UpdateRelStyle(sign, security, $offsetX=\"-160\", $offsetY=\"10\") UpdateRelStyle(accounts, mbsfacade, $offsetX=\"140\", $offsetY=\"10\") UpdateRelStyle(security, db, $offsetY=\"-40\") UpdateRelStyle(mbsfacade, mbs, $offsetY=\"-40\") C4 Dynamic diagram (C4Dynamic) link C4Dynamic title Dynamic diagram for Internet Banking System - API Application ContainerDb(c4, \"Database\", \"Relational Database Schema\", \"Stores user registration information, hashed authentication credentials, access logs, etc.\") Container(c1, \"Single-Page Application\", \"JavaScript and Angular\", \"Provides all of the Internet banking functionality to customers via their web browser.\") Container_Boundary(b, \"API Application\") { Component(c3, \"Security Component\", \"Spring Bean\", \"Provides functionality Related to signing in, changing passwords, etc.\") Component(c2, \"Sign In Controller\", \"Spring MVC Rest Controller\", \"Allows users to sign in to the Internet Banking System.\") } Rel(c1, c2, \"Submits credentials to\", \"JSON/HTTPS\") Rel(c2, c3, \"Calls isAuthenticated() on\") Rel(c3, c4, \"select * from users where username = ?\", \"JDBC\") UpdateRelStyle(c1, c2, $textColor=\"red\", $offsetY=\"-40\") UpdateRelStyle(c2, c3, $textColor=\"red\", $offsetX=\"-40\", $offsetY=\"60\") UpdateRelStyle(c3, c4, $textColor=\"red\", $offsetY=\"-40\", $offsetX=\"10\") C4Dynamic title Dynamic diagram for Internet Banking System - API Application ContainerDb(c4, \"Database\", \"Relational Database Schema\", \"Stores user registration information, hashed authentication credentials, access logs, etc.\") Container(c1, \"Single-Page Application\", \"JavaScript and Angular\", \"Provides all of the Internet banking functionality to customers via their web browser.\") Container_Boundary(b, \"API Application\") { Component(c3, \"Security Component\", \"Spring Bean\", \"Provides functionality Related to signing in, changing passwords, etc.\") Component(c2, \"Sign In Controller\", \"Spring MVC Rest Controller\", \"Allows users to sign in to the Internet Banking System.\") } Rel(c1, c2, \"Submits credentials to\", \"JSON/HTTPS\") Rel(c2, c3, \"Calls isAuthenticated() on\") Rel(c3, c4, \"select * from users where username = ?\", \"JDBC\") UpdateRelStyle(c1, c2, $textColor=\"red\", $offsetY=\"-40\") UpdateRelStyle(c2, c3, $textColor=\"red\", $offsetX=\"-40\", $offsetY=\"60\") UpdateRelStyle(c3, c4, $textColor=\"red\", $offsetY=\"-40\", $offsetX=\"10\") C4 Deployment diagram (C4Deployment) link C4Deployment title Deployment Diagram for Internet Banking System - Live Deployment_Node(mob, \"Customer's mobile device\", \"Apple IOS or Android\"){ Container(mobile, \"Mobile App\", \"Xamarin\", \"Provides a limited subset of the Internet Banking functionality to customers via their mobile device.\") } Deployment_Node(comp, \"Customer's computer\", \"Microsoft Windows or Apple macOS\"){ Deployment_Node(browser, \"Web Browser\", \"Google Chrome, Mozilla Firefox, Apple Safari or Microsoft Edge\"){ Container(spa, \"Single Page Application\", \"JavaScript and Angular\", \"Provides all of the Internet Banking functionality to customers via their web browser.\") } } Deployment_Node(plc, \"Big Bank plc\", \"Big Bank plc data center\"){ Deployment_Node(dn, \"bigbank-api*** x8\", \"Ubuntu 16.04 LTS\"){ Deployment_Node(apache, \"Apache Tomcat\", \"Apache Tomcat 8.x\"){ Container(api, \"API Application\", \"Java and Spring MVC\", \"Provides Internet Banking functionality via a JSON/HTTPS API.\") } } Deployment_Node(bb2, \"bigbank-web*** x4\", \"Ubuntu 16.04 LTS\"){ Deployment_Node(apache2, \"Apache Tomcat\", \"Apache Tomcat 8.x\"){ Container(web, \"Web Application\", \"Java and Spring MVC\", \"Delivers the static content and the Internet Banking single page application.\") } } Deployment_Node(bigbankdb01, \"bigbank-db01\", \"Ubuntu 16.04 LTS\"){ Deployment_Node(oracle, \"Oracle - Primary\", \"Oracle 12c\"){ ContainerDb(db, \"Database\", \"Relational Database Schema\", \"Stores user registration information, hashed authentication credentials, access logs, etc.\") } } Deployment_Node(bigbankdb02, \"bigbank-db02\", \"Ubuntu 16.04 LTS\") { Deployment_Node(oracle2, \"Oracle - Secondary\", \"Oracle 12c\") { ContainerDb(db2, \"Database\", \"Relational Database Schema\", \"Stores user registration information, hashed authentication credentials, access logs, etc.\") } } } Rel(mobile, api, \"Makes API calls to\", \"json/HTTPS\") Rel(spa, api, \"Makes API calls to\", \"json/HTTPS\") Rel_U(web, spa, \"Delivers to the customer's web browser\") Rel(api, db, \"Reads from and writes to\", \"JDBC\") Rel(api, db2, \"Reads from and writes to\", \"JDBC\") Rel_R(db, db2, \"Replicates data to\") UpdateRelStyle(spa, api, $offsetY=\"-40\") UpdateRelStyle(web, spa, $offsetY=\"-40\") UpdateRelStyle(api, db, $offsetY=\"-20\", $offsetX=\"5\") UpdateRelStyle(api, db2, $offsetX=\"-40\", $offsetY=\"-20\") UpdateRelStyle(db, db2, $offsetY=\"-10\") C4Deployment title Deployment Diagram for Internet Banking System - Live Deployment_Node(mob, \"Customer's mobile device\", \"Apple IOS or Android\"){ Container(mobile, \"Mobile App\", \"Xamarin\", \"Provides a limited subset of the Internet Banking functionality to customers via their mobile device.\") } Deployment_Node(comp, \"Customer's computer\", \"Microsoft Windows or Apple macOS\"){ Deployment_Node(browser, \"Web Browser\", \"Google Chrome, Mozilla Firefox, Apple Safari or Microsoft Edge\"){ Container(spa, \"Single Page Application\", \"JavaScript and Angular\", \"Provides all of the Internet Banking functionality to customers via their web browser.\") } } Deployment_Node(plc, \"Big Bank plc\", \"Big Bank plc data center\"){ Deployment_Node(dn, \"bigbank-api*** x8\", \"Ubuntu 16.04 LTS\"){ Deployment_Node(apache, \"Apache Tomcat\", \"Apache Tomcat 8.x\"){ Container(api, \"API Application\", \"Java and Spring MVC\", \"Provides Internet Banking functionality via a JSON/HTTPS API.\") } } Deployment_Node(bb2, \"bigbank-web*** x4\", \"Ubuntu 16.04 LTS\"){ Deployment_Node(apache2, \"Apache Tomcat\", \"Apache Tomcat 8.x\"){ Container(web, \"Web Application\", \"Java and Spring MVC\", \"Delivers the static content and the Internet Banking single page application.\") } } Deployment_Node(bigbankdb01, \"bigbank-db01\", \"Ubuntu 16.04 LTS\"){ Deployment_Node(oracle, \"Oracle - Primary\", \"Oracle 12c\"){ ContainerDb(db, \"Database\", \"Relational Database Schema\", \"Stores user registration information, hashed authentication credentials, access logs, etc.\") } } Deployment_Node(bigbankdb02, \"bigbank-db02\", \"Ubuntu 16.04 LTS\") { Deployment_Node(oracle2, \"Oracle - Secondary\", \"Oracle 12c\") { ContainerDb(db2, \"Database\", \"Relational Database Schema\", \"Stores user registration information, hashed authentication credentials, access logs, etc.\") } } } Rel(mobile, api, \"Makes API calls to\", \"json/HTTPS\") Rel(spa, api, \"Makes API calls to\", \"json/HTTPS\") Rel_U(web, spa, \"Delivers to the customer's web browser\") Rel(api, db, \"Reads from and writes to\", \"JDBC\") Rel(api, db2, \"Reads from and writes to\", \"JDBC\") Rel_R(db, db2, \"Replicates data to\") UpdateRelStyle(spa, api, $offsetY=\"-40\") UpdateRelStyle(web, spa, $offsetY=\"-40\") UpdateRelStyle(api, db, $offsetY=\"-20\", $offsetX=\"5\") UpdateRelStyle(api, db2, $offsetX=\"-40\", $offsetY=\"-20\") UpdateRelStyle(db, db2, $offsetY=\"-10\") "
            }
        );
    index.add(
            {
                id:  67 ,
                href: "\/docs\/mix\/mermaid\/syntax\/classdiagram\/",
                title: "Class diagrams",
                description: "Class diagrams link “In software engineering, a class diagram in the Unified Modeling Language (UML) is a type of static structure diagram that describes the structure of a system by showing the system’s classes, their attributes, operations (or methods), and the relationships among objects.”\n-Wikipedia\nThe class diagram is the main building block of object-oriented modeling. It is used for general conceptual modeling of the structure of the application, and for detailed modeling to translate the models into programming code. Class diagrams can also be used for data modeling. The classes in a class diagram represent both the main elements, interactions in the application, and the classes to be programmed.\n",
                content: "Class diagrams link “In software engineering, a class diagram in the Unified Modeling Language (UML) is a type of static structure diagram that describes the structure of a system by showing the system’s classes, their attributes, operations (or methods), and the relationships among objects.”\n-Wikipedia\nThe class diagram is the main building block of object-oriented modeling. It is used for general conceptual modeling of the structure of the application, and for detailed modeling to translate the models into programming code. Class diagrams can also be used for data modeling. The classes in a class diagram represent both the main elements, interactions in the application, and the classes to be programmed.\nMermaid can render class diagrams.\n--- title: Animal example --- classDiagram note \"From Duck till Zebra\" Animal \u003c|-- Duck note for Duck \"can fly\\ncan swim\\ncan dive\\ncan help in debugging\" Animal \u003c|-- Fish Animal \u003c|-- Zebra Animal : +int age Animal : +String gender Animal: +isMammal() Animal: +mate() class Duck{ +String beakColor +swim() +quack() } class Fish{ -int sizeInFeet -canEat() } class Zebra{ +bool is_wild +run() } --- title: Animal example --- classDiagram note \"From Duck till Zebra\" Animal \u003c|-- Duck note for Duck \"can fly\\ncan swim\\ncan dive\\ncan help in debugging\" Animal \u003c|-- Fish Animal \u003c|-- Zebra Animal : +int age Animal : +String gender Animal: +isMammal() Animal: +mate() class Duck{ +String beakColor +swim() +quack() } class Fish{ -int sizeInFeet -canEat() } class Zebra{ +bool is_wild +run() } Syntax linkClass linkUML provides mechanisms to represent class members, such as attributes and methods, and additional information about them. A single instance of a class in the diagram contains three compartments:\nThe top compartment contains the name of the class. It is printed in bold and centered, and the first letter is capitalized. It may also contain optional annotation text describing the nature of the class. The middle compartment contains the attributes of the class. They are left-aligned and the first letter is lowercase. The bottom compartment contains the operations the class can execute. They are also left-aligned and the first letter is lowercase. --- title: Bank example --- classDiagram class BankAccount BankAccount : +String owner BankAccount : +Bigdecimal balance BankAccount : +deposit(amount) BankAccount : +withdrawal(amount) --- title: Bank example --- classDiagram class BankAccount BankAccount : +String owner BankAccount : +Bigdecimal balance BankAccount : +deposit(amount) BankAccount : +withdrawal(amount) Define a class linkThere are two ways to define a class:\nExplicitly using keyword class like class Animal which would define the Animal class. Via a relationship which defines two classes at a time along with their relationship. For instance, Vehicle \u003c|-- Car. classDiagram class Animal Vehicle \u003c|-- Car classDiagram class Animal Vehicle \u003c|-- Car Naming convention: a class name should be composed only of alphanumeric characters (including unicode), underscores, and dashes (-).\nClass labels linkIn case you need to provide a label for a class, you can use the following syntax:\nclassDiagram class Animal[\"Animal with a label\"] class Car[\"Car with *! symbols\"] Animal --\u003e Car classDiagram class Animal[\"Animal with a label\"] class Car[\"Car with *! symbols\"] Animal --\u003e Car You can also use backticks to escape special characters in the label:\nclassDiagram class `Animal Class!` class `Car Class` `Animal Class!` --\u003e `Car Class` classDiagram class `Animal Class!` class `Car Class` `Animal Class!` --\u003e `Car Class` Defining Members of a class linkUML provides mechanisms to represent class members such as attributes and methods, as well as additional information about them.\nMermaid distinguishes between attributes and functions/methods based on if the parenthesis () are present or not. The ones with () are treated as functions/methods, and all others as attributes.\nThere are two ways to define the members of a class, and regardless of whichever syntax is used to define the members, the output will still be same. The two different ways are :\nAssociate a member of a class using : (colon) followed by member name, useful to define one member at a time. For example: classDiagram class BankAccount BankAccount : +String owner BankAccount : +BigDecimal balance BankAccount : +deposit(amount) BankAccount : +withdrawal(amount) classDiagram class BankAccount BankAccount : +String owner BankAccount : +BigDecimal balance BankAccount : +deposit(amount) BankAccount : +withdrawal(amount) Associate members of a class using {} brackets, where members are grouped within curly brackets. Suitable for defining multiple members at once. For example: classDiagram class BankAccount{ +String owner +BigDecimal balance +deposit(amount) +withdrawal(amount) } classDiagram class BankAccount{ +String owner +BigDecimal balance +deposit(amount) +withdrawal(amount) } Return Type linkOptionally you can end a method/function definition with the data type that will be returned (note: there must be a space between the final ) and the return type). An example:\nclassDiagram class BankAccount{ +String owner +BigDecimal balance +deposit(amount) bool +withdrawal(amount) int } classDiagram class BankAccount{ +String owner +BigDecimal balance +deposit(amount) bool +withdrawal(amount) int } Generic Types linkMembers can be defined using generic types, such as List, for fields, parameters, and return types by enclosing the type within ~ (tilde). Nested type declarations such as List"
            }
        );
    index.add(
            {
                id:  68 ,
                href: "\/docs\/mix\/mermaid\/syntax\/entityrelationshipdiagram\/",
                title: "Entity Relationship Diagrams",
                description: "Entity Relationship Diagrams link An entity–relationship model (or ER model) describes interrelated things of interest in a specific domain of knowledge. A basic ER model is composed of entity types (which classify the things of interest) and specifies relationships that can exist between entities (instances of those entity types). Wikipedia.\nNote that practitioners of ER modelling almost always refer to entity types simply as entities. For example the CUSTOMER entity type would be referred to simply as the CUSTOMER entity. This is so common it would be inadvisable to do anything else, but technically an entity is an abstract instance of an entity type, and this is what an ER diagram shows - abstract instances, and the relationships between them. This is why entities are always named using singular nouns.\n",
                content: "Entity Relationship Diagrams link An entity–relationship model (or ER model) describes interrelated things of interest in a specific domain of knowledge. A basic ER model is composed of entity types (which classify the things of interest) and specifies relationships that can exist between entities (instances of those entity types). Wikipedia.\nNote that practitioners of ER modelling almost always refer to entity types simply as entities. For example the CUSTOMER entity type would be referred to simply as the CUSTOMER entity. This is so common it would be inadvisable to do anything else, but technically an entity is an abstract instance of an entity type, and this is what an ER diagram shows - abstract instances, and the relationships between them. This is why entities are always named using singular nouns.\nMermaid can render ER diagrams\n--- title: Order example --- erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses --- title: Order example --- erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses Entity names are often capitalised, although there is no accepted standard on this, and it is not required in Mermaid.\nRelationships between entities are represented by lines with end markers representing cardinality. Mermaid uses the most popular crow’s foot notation. The crow’s foot intuitively conveys the possibility of many instances of the entity that it connects to.\nER diagrams can be used for various purposes, ranging from abstract logical models devoid of any implementation details, through to physical models of relational database tables. It can be useful to include attribute definitions on ER diagrams to aid comprehension of the purpose and meaning of entities. These do not necessarily need to be exhaustive; often a small subset of attributes is enough. Mermaid allows them to be defined in terms of their type and name.\nerDiagram CUSTOMER ||--o{ ORDER : places CUSTOMER { string name string custNumber string sector } ORDER ||--|{ LINE-ITEM : contains ORDER { int orderNumber string deliveryAddress } LINE-ITEM { string productCode int quantity float pricePerUnit } erDiagram CUSTOMER ||--o{ ORDER : places CUSTOMER { string name string custNumber string sector } ORDER ||--|{ LINE-ITEM : contains ORDER { int orderNumber string deliveryAddress } LINE-ITEM { string productCode int quantity float pricePerUnit } When including attributes on ER diagrams, you must decide whether to include foreign keys as attributes. This probably depends on how closely you are trying to represent relational table structures. If your diagram is a logical model which is not meant to imply a relational implementation, then it is better to leave these out because the associative relationships already convey the way that entities are associated. For example, a JSON data structure can implement a one-to-many relationship without the need for foreign key properties, using arrays. Similarly an object-oriented programming language may use pointers or references to collections. Even for models that are intended for relational implementation, you might decide that inclusion of foreign key attributes duplicates information already portrayed by the relationships, and does not add meaning to entities. Ultimately, it’s your choice.\nSyntax linkEntities and Relationships linkMermaid syntax for ER diagrams is compatible with PlantUML, with an extension to label the relationship. Each statement consists of the following parts:\n[ : ] Where:\nfirst-entity is the name of an entity. Names must begin with an alphabetic character or an underscore (from v10.5.0+), and may also contain digits and hyphens. relationship describes the way that both entities inter-relate. See below. second-entity is the name of the other entity. relationship-label describes the relationship from the perspective of the first entity. For example:\nPROPERTY ||--|{ ROOM : contains This statement can be read as a property contains one or more rooms, and a room is part of one and only one property. You can see that the label here is from the first entity’s perspective: a property contains a room, but a room does not contain a property. When considered from the perspective of the second entity, the equivalent label is usually very easy to infer. (Some ER diagrams label relationships from both perspectives, but this is not supported here, and is usually superfluous).\nOnly the first-entity part of a statement is mandatory. This makes it possible to show an entity with no relationships, which can be useful during iterative construction of diagrams. If any other parts of a statement are specified, then all parts are mandatory.\nRelationship Syntax linkThe relationship part of each statement can be broken down into three sub-components:\nthe cardinality of the first entity with respect to the second, whether the relationship confers identity on a ‘child’ entity the cardinality of the second entity with respect to the first Cardinality is a property that describes how many elements of another entity can be related to the entity in question. In the above example a PROPERTY can have one or more ROOM instances associated to it, whereas a ROOM can only be associated with one PROPERTY. In each cardinality marker there are two characters. The outermost character represents a maximum value, and the innermost character represents a minimum value. The table below summarises possible cardinalities.\nValue (left) Value (right) Meaning |o o| Zero or one || || Exactly one }o o{ Zero or more (no upper limit) }| |{ One or more (no upper limit) Aliases\nValue (left) Value (right) Alias for one or zero one or zero Zero or one zero or one zero or one Zero or one one or more one or more One or more one or many one or many One or more many(1) many(1) One or more 1+ 1+ One or more zero or more zero or more Zero or more zero or many zero or many Zero or more many(0) many(1) Zero or more 0+ 0+ Zero or more only one only one Exactly one 1 1 Exactly one Identification linkRelationships may be classified as either identifying or non-identifying and these are rendered with either solid or dashed lines respectively. This is relevant when one of the entities in question can not have independent existence without the other. For example a firm that insures people to drive cars might need to store data on NAMED-DRIVERs. In modelling this we might start out by observing that a CAR can be driven by many PERSON instances, and a PERSON can drive many CARs - both entities can exist without the other, so this is a non-identifying relationship that we might specify in Mermaid as: PERSON }|..|{ CAR : \"driver\". Note the two dots in the middle of the relationship that will result in a dashed line being drawn between the two entities. But when this many-to-many relationship is resolved into two one-to-many relationships, we observe that a NAMED-DRIVER cannot exist without both a PERSON and a CAR - the relationships become identifying and would be specified using hyphens, which translate to a solid line:\nAliases\nValue Alias for to identifying optionally to non-identifying erDiagram CAR ||--o{ NAMED-DRIVER : allows PERSON ||--o{ NAMED-DRIVER : is erDiagram CAR ||--o{ NAMED-DRIVER : allows PERSON ||--o{ NAMED-DRIVER : is Attributes linkAttributes can be defined for entities by specifying the entity name followed by a block containing multiple type name pairs, where a block is delimited by an opening { and a closing }. The attributes are rendered inside the entity boxes. For example:\nerDiagram CAR ||--o{ NAMED-DRIVER : allows CAR { string registrationNumber string make string model } PERSON ||--o{ NAMED-DRIVER : is PERSON { string firstName string lastName int age } erDiagram CAR ||--o{ NAMED-DRIVER : allows CAR { string registrationNumber string make string model } PERSON ||--o{ NAMED-DRIVER : is PERSON { string firstName string lastName int age } The type values must begin with an alphabetic character and may contain digits, hyphens, underscores, parentheses and square brackets. The name values follow a similar format to type, but may start with an asterisk as another option to indicate an attribute is a primary key. Other than that, there are no restrictions, and there is no implicit set of valid data types.\nEntity Name Aliases (v10.5.0+) linkAn alias can be added to an entity using square brackets. If provided, the alias will be showed in the diagram instead of the entity name.\nerDiagram p[Person] { string firstName string lastName } a[\"Customer Account\"] { string email } p ||--o| a : has erDiagram p[Person] { string firstName string lastName } a[\"Customer Account\"] { string email } p ||--o| a : has Attribute Keys and Comments linkAttributes may also have a key or comment defined. Keys can be PK, FK or UK, for Primary Key, Foreign Key or Unique Key. To specify multiple key constraints on a single attribute, separate them with a comma (e.g., PK, FK).. A comment is defined by double quotes at the end of an attribute. Comments themselves cannot have double-quote characters in them.\nerDiagram CAR ||--o{ NAMED-DRIVER : allows CAR { string registrationNumber PK string make string model string[] parts } PERSON ||--o{ NAMED-DRIVER : is PERSON { string driversLicense PK \"The license #\" string(99) firstName \"Only 99 characters are allowed\" string lastName string phone UK int age } NAMED-DRIVER { string carRegistrationNumber PK, FK string driverLicence PK, FK } MANUFACTURER only one to zero or more CAR : makes erDiagram CAR ||--o{ NAMED-DRIVER : allows CAR { string registrationNumber PK string make string model string[] parts } PERSON ||--o{ NAMED-DRIVER : is PERSON { string driversLicense PK \"The license #\" string(99) firstName \"Only 99 characters are allowed\" string lastName string phone UK int age } NAMED-DRIVER { string carRegistrationNumber PK, FK string driverLicence PK, FK } MANUFACTURER only one to zero or more CAR : makes Other Things link If you want the relationship label to be more than one word, you must use double quotes around the phrase If you don’t want a label at all on a relationship, you must use an empty double-quoted string Styling linkConfig options linkFor simple color customization:\nName Used as fill Background color of an entity or attribute stroke Border color of an entity or attribute, line color of a relationship Classes used linkThe following CSS class selectors are available for richer styling:\nSelector Description .er.attributeBoxEven The box containing attributes on even-numbered rows .er.attributeBoxOdd The box containing attributes on odd-numbered rows .er.entityBox The box representing an entity .er.entityLabel The label for an entity .er.relationshipLabel The label for a relationship .er.relationshipLabelBox The box surrounding a relationship label .er.relationshipLine The line representing a relationship between entities "
            }
        );
    index.add(
            {
                id:  69 ,
                href: "\/docs\/mix\/mermaid\/syntax\/examples\/",
                title: "Examples",
                description: "Examples linkThis page contains a collection of examples of diagrams and charts that can be created through mermaid and its myriad applications.\nIf you wish to learn how to support mermaid on your webpage, read the Beginner’s Guide.\nIf you wish to learn about mermaid’s syntax, Read the ",
                content: "Examples linkThis page contains a collection of examples of diagrams and charts that can be created through mermaid and its myriad applications.\nIf you wish to learn how to support mermaid on your webpage, read the Beginner’s Guide.\nIf you wish to learn about mermaid’s syntax, Read the "
            }
        );
    index.add(
            {
                id:  70 ,
                href: "\/docs\/mix\/mermaid\/syntax\/flowchart\/",
                title: "Flowcharts - Basic Syntax",
                description: "Flowcharts - Basic Syntax linkFlowcharts are composed of nodes (geometric shapes) and edges (arrows or lines). The Mermaid code defines how nodes and edges are made and accommodates different arrow types, multi-directional arrows, and any linking to and from subgraphs.\nWarning If you are using the word “end” in a Flowchart node, capitalize the entire word or any of the letters (e.g., “End” or “END”), or apply this workaround. Typing “end” in all lowercase letters will break the Flowchart.\n",
                content: "Flowcharts - Basic Syntax linkFlowcharts are composed of nodes (geometric shapes) and edges (arrows or lines). The Mermaid code defines how nodes and edges are made and accommodates different arrow types, multi-directional arrows, and any linking to and from subgraphs.\nWarning If you are using the word “end” in a Flowchart node, capitalize the entire word or any of the letters (e.g., “End” or “END”), or apply this workaround. Typing “end” in all lowercase letters will break the Flowchart.\nA node (default) link --- title: Node --- flowchart LR id --- title: Node --- flowchart LR id Note The id is what is displayed in the box.\n💡 Tip Instead of flowchart one can also use graph.\nA node with text linkIt is also possible to set text in the box that differs from the id. If this is done several times, it is the last text found for the node that will be used. Also if you define edges for the node later on, you can omit text definitions. The one previously defined will be used when rendering the box.\n--- title: Node with text --- flowchart LR id1[This is the text in the box] --- title: Node with text --- flowchart LR id1[This is the text in the box] Unicode text linkUse \" to enclose the unicode text.\nflowchart LR id[\"This ❤ Unicode\"] flowchart LR id[\"This ❤ Unicode\"] Markdown formatting linkUse double quotes and backticks “` text `” to enclose the markdown text.\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%% flowchart LR markdown[\"`This **is** _Markdown_`\"] newLines[\"`Line1 Line 2 Line 3`\"] markdown --\u003e newLines %%{init: {\"flowchart\": {\"htmlLabels\": false}} }%% flowchart LR markdown[\"`This **is** _Markdown_`\"] newLines[\"`Line1 Line 2 Line 3`\"] markdown --\u003e newLines Direction linkThis statement declares the direction of the Flowchart.\nThis declares the flowchart is oriented from top to bottom (TD or TB).\nflowchart TD Start --\u003e Stop flowchart TD Start --\u003e Stop This declares the flowchart is oriented from left to right (LR).\nflowchart LR Start --\u003e Stop flowchart LR Start --\u003e Stop Possible FlowChart orientations are:\nTB - Top to bottom TD - Top-down/ same as top to bottom BT - Bottom to top RL - Right to left LR - Left to right Node shapes linkA node with round edges link flowchart LR id1(This is the text in the box) flowchart LR id1(This is the text in the box) A stadium-shaped node link flowchart LR id1([This is the text in the box]) flowchart LR id1([This is the text in the box]) A node in a subroutine shape link flowchart LR id1[[This is the text in the box]] flowchart LR id1[[This is the text in the box]] A node in a cylindrical shape link flowchart LR id1[(Database)] flowchart LR id1[(Database)] A node in the form of a circle link flowchart LR id1((This is the text in the circle)) flowchart LR id1((This is the text in the circle)) A node in an asymmetric shape link flowchart LR id1\u003eThis is the text in the box] flowchart LR id1\u003eThis is the text in the box] Currently only the shape above is possible and not its mirror. This might change with future releases.\nA node (rhombus) link flowchart LR id1{This is the text in the box} flowchart LR id1{This is the text in the box} A hexagon node link flowchart LR id1{{This is the text in the box}} flowchart LR id1{{This is the text in the box}} Parallelogram link flowchart TD id1[/This is the text in the box/] flowchart TD id1[/This is the text in the box/] Parallelogram alt link flowchart TD id1[\\This is the text in the box\\] flowchart TD id1[\\This is the text in the box\\] Trapezoid link flowchart TD A[/Christmas\\] flowchart TD A[/Christmas\\] Trapezoid alt link flowchart TD B[\\Go shopping/] flowchart TD B[\\Go shopping/] Double circle link flowchart TD id1(((This is the text in the circle))) flowchart TD id1(((This is the text in the circle))) Links between nodes linkNodes can be connected with links/edges. It is possible to have different types of links or attach a text string to a link.\nA link with arrow head link flowchart LR A--\u003eB flowchart LR A--\u003eB An open link link flowchart LR A --- B flowchart LR A --- B Text on links link flowchart LR A-- This is the text! ---B flowchart LR A-- This is the text! ---B or\nflowchart LR A---|This is the text|B flowchart LR A---|This is the text|B A link with arrow head and text link flowchart LR A--\u003e|text|B flowchart LR A--\u003e|text|B or\nflowchart LR A-- text --\u003eB flowchart LR A-- text --\u003eB Dotted link link flowchart LR A-.-\u003eB; flowchart LR A-.-\u003eB; Dotted link with text link flowchart LR A-. text .-\u003e B flowchart LR A-. text .-\u003e B Thick link link flowchart LR A ==\u003e B flowchart LR A ==\u003e B Thick link with text link flowchart LR A == text ==\u003e B flowchart LR A == text ==\u003e B An invisible link linkThis can be a useful tool in some instances where you want to alter the default positioning of a node.\nflowchart LR A ~~~ B flowchart LR A ~~~ B Chaining of links linkIt is possible declare many links in the same line as per below:\nflowchart LR A -- text --\u003e B -- text2 --\u003e C flowchart LR A -- text --\u003e B -- text2 --\u003e C It is also possible to declare multiple nodes links in the same line as per below:\nflowchart LR a --\u003e b \u0026 c--\u003e d flowchart LR a --\u003e b \u0026 c--\u003e d You can then describe dependencies in a very expressive way. Like the one-liner below:\nflowchart TB A \u0026 B--\u003e C \u0026 D flowchart TB A \u0026 B--\u003e C \u0026 D If you describe the same diagram using the the basic syntax, it will take four lines. A word of warning, one could go overboard with this making the flowchart harder to read in markdown form. The Swedish word lagom comes to mind. It means, not too much and not too little. This goes for expressive syntaxes as well.\nflowchart TB A --\u003e C A --\u003e D B --\u003e C B --\u003e D flowchart TB A --\u003e C A --\u003e D B --\u003e C B --\u003e D New arrow types linkThere are new types of arrows supported as per below:\nflowchart LR A --o B B --x C flowchart LR A --o B B --x C Multi directional arrows linkThere is the possibility to use multidirectional arrows.\nflowchart LR A o--o B B \u003c--\u003e C C x--x D flowchart LR A o--o B B \u003c--\u003e C C x--x D Minimum length of a link linkEach node in the flowchart is ultimately assigned to a rank in the rendered graph, i.e. to a vertical or horizontal level (depending on the flowchart orientation), based on the nodes to which it is linked. By default, links can span any number of ranks, but you can ask for any link to be longer than the others by adding extra dashes in the link definition.\nIn the following example, two extra dashes are added in the link from node B to node E, so that it spans two more ranks than regular links:\nflowchart TD A[Start] --\u003e B{Is it?} B --\u003e|Yes| C[OK] C --\u003e D[Rethink] D --\u003e B B ----\u003e|No| E[End] flowchart TD A[Start] --\u003e B{Is it?} B --\u003e|Yes| C[OK] C --\u003e D[Rethink] D --\u003e B B ----\u003e|No| E[End] Note Links may still be made longer than the requested number of ranks by the rendering engine to accommodate other requests.\nWhen the link label is written in the middle of the link, the extra dashes must be added on the right side of the link. The following example is equivalent to the previous one:\nflowchart TD A[Start] --\u003e B{Is it?} B -- Yes --\u003e C[OK] C --\u003e D[Rethink] D --\u003e B B -- No ----\u003e E[End] flowchart TD A[Start] --\u003e B{Is it?} B -- Yes --\u003e C[OK] C --\u003e D[Rethink] D --\u003e B B -- No ----\u003e E[End] For dotted or thick links, the characters to add are equals signs or dots, as summed up in the following table:\nLength 1 2 3 Normal --- ---- ----- Normal with arrow --\u003e ---\u003e ----\u003e Thick === ==== ===== Thick with arrow ==\u003e ===\u003e ====\u003e Dotted -.- -..- -...- Dotted with arrow -.-\u003e -..-\u003e -...-\u003e Special characters that break syntax linkIt is possible to put text within quotes in order to render more troublesome characters. As in the example below:\nflowchart LR id1[\"This is the (text) in the box\"] flowchart LR id1[\"This is the (text) in the box\"] Entity codes to escape characters linkIt is possible to escape characters using the syntax exemplified here.\nflowchart LR A[\"A double quote:#quot;\"] --\u003e B[\"A dec char:#9829;\"] flowchart LR A[\"A double quote:#quot;\"] --\u003e B[\"A dec char:#9829;\"] Numbers given are base 10, so # can be encoded as #35;. It is also supported to use HTML character names.\nSubgraphs linksubgraph title graph definition end An example below:\nflowchart TB c1--\u003ea2 subgraph one a1--\u003ea2 end subgraph two b1--\u003eb2 end subgraph three c1--\u003ec2 end flowchart TB c1--\u003ea2 subgraph one a1--\u003ea2 end subgraph two b1--\u003eb2 end subgraph three c1--\u003ec2 end You can also set an explicit id for the subgraph.\nflowchart TB c1--\u003ea2 subgraph ide1 [one] a1--\u003ea2 end flowchart TB c1--\u003ea2 subgraph ide1 [one] a1--\u003ea2 end flowcharts linkWith the graphtype flowchart it is also possible to set edges to and from subgraphs as in the flowchart below.\nflowchart TB c1--\u003ea2 subgraph one a1--\u003ea2 end subgraph two b1--\u003eb2 end subgraph three c1--\u003ec2 end one --\u003e two three --\u003e two two --\u003e c2 flowchart TB c1--\u003ea2 subgraph one a1--\u003ea2 end subgraph two b1--\u003eb2 end subgraph three c1--\u003ec2 end one --\u003e two three --\u003e two two --\u003e c2 Direction in subgraphs linkWith the graphtype flowcharts you can use the direction statement to set the direction which the subgraph will render like in this example.\nflowchart LR subgraph TOP direction TB subgraph B1 direction RL i1 --\u003ef1 end subgraph B2 direction BT i2 --\u003ef2 end end A --\u003e TOP --\u003e B B1 --\u003e B2 flowchart LR subgraph TOP direction TB subgraph B1 direction RL i1 --\u003ef1 end subgraph B2 direction BT i2 --\u003ef2 end end A --\u003e TOP --\u003e B B1 --\u003e B2 Limitation linkIf any of a subgraph’s nodes are linked to the outside, subgraph direction will be ignored. Instead the subgraph will inherit the direction of the parent graph:\nflowchart LR subgraph subgraph1 direction TB top1[top] --\u003e bottom1[bottom] end subgraph subgraph2 direction TB top2[top] --\u003e bottom2[bottom] end %% ^ These subgraphs are identical, except for the links to them: %% Link *to* subgraph1: subgraph1 direction is maintained outside --\u003e subgraph1 %% Link *within* subgraph2: %% subgraph2 inherits the direction of the top-level graph (LR) outside ---\u003e top2 flowchart LR subgraph subgraph1 direction TB top1[top] --\u003e bottom1[bottom] end subgraph subgraph2 direction TB top2[top] --\u003e bottom2[bottom] end %% ^ These subgraphs are identical, except for the links to them: %% Link *to* subgraph1: subgraph1 direction is maintained outside --\u003e subgraph1 %% Link *within* subgraph2: %% subgraph2 inherits the direction of the top-level graph (LR) outside ---\u003e top2 Markdown Strings linkThe “Markdown Strings” feature enhances flowcharts and mind maps by offering a more versatile string type, which supports text formatting options such as bold and italics, and automatically wraps text within labels.\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%% flowchart LR subgraph \"One\" a(\"`The **cat** in the hat`\") -- \"edge label\" --\u003e b{{\"`The **dog** in the hog`\"}} end subgraph \"`**Two**`\" c(\"`The **cat** in the hat`\") -- \"`Bold **edge label**`\" --\u003e d(\"The dog in the hog\") end %%{init: {\"flowchart\": {\"htmlLabels\": false}} }%% flowchart LR subgraph \"One\" a(\"`The **cat** in the hat`\") -- \"edge label\" --\u003e b{{\"`The **dog** in the hog`\"}} end subgraph \"`**Two**`\" c(\"`The **cat** in the hat`\") -- \"`Bold **edge label**`\" --\u003e d(\"The dog in the hog\") end Formatting:\nFor bold text, use double asterisks (**) before and after the text. For italics, use single asterisks (*) before and after the text. With traditional strings, you needed to add tags for text to wrap in nodes. However, markdown strings automatically wrap text when it becomes too long and allows you to start a new line by simply using a newline character instead of a tag. This feature is applicable to node labels, edge labels, and subgraph labels.\nInteraction linkIt is possible to bind a click event to a node, the click can lead to either a javascript callback or to a link which will be opened in a new browser tab.\nNote This functionality is disabled when using securityLevel='strict' and enabled when using securityLevel='loose'.\nclick nodeId callback click nodeId call callback() nodeId is the id of the node callback is the name of a javascript function defined on the page displaying the graph, the function will be called with the nodeId as parameter. Examples of tooltip usage below:\nThe tooltip text is surrounded in double quotes. The styles of the tooltip are set by the class .mermaidTooltip.\nflowchart LR A--\u003eB B--\u003eC C--\u003eD click A callback \"Tooltip for a callback\" click B \"https://www.github.com\" \"This is a tooltip for a link\" click C call callback() \"Tooltip for a callback\" click D href \"https://www.github.com\" \"This is a tooltip for a link\" flowchart LR A--\u003eB B--\u003eC C--\u003eD click A callback \"Tooltip for a callback\" click B \"https://www.github.com\" \"This is a tooltip for a link\" click C call callback() \"Tooltip for a callback\" click D href \"https://www.github.com\" \"This is a tooltip for a link\" Success The tooltip functionality and the ability to link to urls are available from version 0.5.2.\n?\u003e Due to limitations with how Docsify handles JavaScript callback functions, an alternate working demo for the above code can be viewed at this jsfiddle.\nLinks are opened in the same browser tab/window by default. It is possible to change this by adding a link target to the click definition (_self, _blank, _parent and _top are supported):\nflowchart LR A--\u003eB B--\u003eC C--\u003eD D--\u003eE click A \"https://www.github.com\" _blank click B \"https://www.github.com\" \"Open this in a new tab\" _blank click C href \"https://www.github.com\" _blank click D href \"https://www.github.com\" \"Open this in a new tab\" _blank flowchart LR A--\u003eB B--\u003eC C--\u003eD D--\u003eE click A \"https://www.github.com\" _blank click B \"https://www.github.com\" \"Open this in a new tab\" _blank click C href \"https://www.github.com\" _blank click D href \"https://www.github.com\" \"Open this in a new tab\" _blank Beginner’s tip—a full example using interactive links in a html context:\nflowchart LR A--\u003eB B--\u003eC C--\u003eD click A callback \"Tooltip\" click B \"https://www.github.com\" \"This is a link\" click C call callback() \"Tooltip\" click D href \"https://www.github.com\" \"This is a link\" Comments linkComments can be entered within a flow diagram, which will be ignored by the parser. Comments need to be on their own line, and must be prefaced with %% (double percent signs). Any text after the start of the comment to the next newline will be treated as a comment, including any flow syntax\nflowchart LR %% this is a comment A -- text --\u003e B{node} A -- text --\u003e B -- text2 --\u003e C flowchart LR %% this is a comment A -- text --\u003e B{node} A -- text --\u003e B -- text2 --\u003e C Styling and classes linkStyling links linkIt is possible to style links. For instance, you might want to style a link that is going backwards in the flow. As links have no ids in the same way as nodes, some other way of deciding what style the links should be attached to is required. Instead of ids, the order number of when the link was defined in the graph is used, or use default to apply to all links. In the example below the style defined in the linkStyle statement will belong to the fourth link in the graph:\nlinkStyle 3 stroke:#ff3,stroke-width:4px,color:red; It is also possible to add style to multiple links in a single statement, by separating link numbers with commas:\nlinkStyle 1,2,7 color:blue; Styling line curves linkIt is possible to style the type of curve used for lines between items, if the default method does not meet your needs. Available curve styles include basis, bumpX, bumpY, cardinal, catmullRom, linear, monotoneX, monotoneY, natural, step, stepAfter, and stepBefore.\nIn this example, a left-to-right graph uses the stepBefore curve style:\n%%{ init: { 'flowchart': { 'curve': 'stepBefore' } } }%% graph LR For a full list of available curves, including an explanation of custom curves, refer to the Shapes documentation in the d3-shape project.\nStyling a node linkIt is possible to apply specific styles such as a thicker border or a different background color to a node.\nflowchart LR id1(Start)--\u003eid2(Stop) style id1 fill:#f9f,stroke:#333,stroke-width:4px style id2 fill:#bbf,stroke:#f66,stroke-width:2px,color:#fff,stroke-dasharray: 5 5 flowchart LR id1(Start)--\u003eid2(Stop) style id1 fill:#f9f,stroke:#333,stroke-width:4px style id2 fill:#bbf,stroke:#f66,stroke-width:2px,color:#fff,stroke-dasharray: 5 5 Classes linkMore convenient than defining the style every time is to define a class of styles and attach this class to the nodes that should have a different look.\nA class definition looks like the example below:\nclassDef className fill:#f9f,stroke:#333,stroke-width:4px; Also, it is possible to define style to multiple classes in one statement:\nclassDef firstClassName,secondClassName font-size:12pt; Attachment of a class to a node is done as per below:\nclass nodeId1 className; It is also possible to attach a class to a list of nodes in one statement:\nclass nodeId1,nodeId2 className; A shorter form of adding a class is to attach the classname to the node using the :::operator as per below:\nflowchart LR A:::someclass --\u003e B classDef someclass fill:#f96 flowchart LR A:::someclass --\u003e B classDef someclass fill:#f96 This form can be used when declaring multiple links between nodes:\nflowchart LR A:::foo \u0026 B:::bar --\u003e C:::foobar classDef foo stroke:#f00 classDef bar stroke:#0f0 classDef foobar stroke:#00f flowchart LR A:::foo \u0026 B:::bar --\u003e C:::foobar classDef foo stroke:#f00 classDef bar stroke:#0f0 classDef foobar stroke:#00f CSS classes linkIt is also possible to predefine classes in CSS styles that can be applied from the graph definition as in the example below:\nExample style\nExample definition\nflowchart LR A--\u003eB[AAABBB] B--\u003eD class A cssClass flowchart LR A--\u003eB[AAABBB] B--\u003eD class A cssClass Default class linkIf a class is named default it will be assigned to all classes without specific class definitions.\nclassDef default fill:#f9f,stroke:#333,stroke-width:4px; Basic support for fontawesome linkIt is possible to add icons from fontawesome.\nThe icons are accessed via the syntax fa:#icon class name#.\nflowchart TD B[\"fa:fa-twitter for peace\"] B--\u003eC[fa:fa-ban forbidden] B--\u003eD(fa:fa-spinner) B--\u003eE(A fa:fa-camera-retro perhaps?) flowchart TD B[\"fa:fa-twitter for peace\"] B--\u003eC[fa:fa-ban forbidden] B--\u003eD(fa:fa-spinner) B--\u003eE(A fa:fa-camera-retro perhaps?) Mermaid is compatible with Font Awesome up to version 5, Free icons only. Check that the icons you use are from the supported set of icons.\nGraph declarations with spaces between vertices and link and without semicolon link In graph declarations, the statements also can now end without a semicolon. After release 0.2.16, ending a graph statement with semicolon is just optional. So the below graph declaration is also valid along with the old declarations of the graph.\nA single space is allowed between vertices and the link. However there should not be any space between a vertex and its text and a link and its text. The old syntax of graph declaration will also work and hence this new feature is optional and is introduced to improve readability.\nBelow is the new declaration of the graph edges which is also valid along with the old declaration of the graph edges.\nflowchart LR A[Hard edge] --\u003e|Link text| B(Round edge) B --\u003e C{Decision} C --\u003e|One| D[Result one] C --\u003e|Two| E[Result two] flowchart LR A[Hard edge] --\u003e|Link text| B(Round edge) B --\u003e C{Decision} C --\u003e|One| D[Result one] C --\u003e|Two| E[Result two] Configuration linkRenderer linkThe layout of the diagram is done with the renderer. The default renderer is dagre.\nStarting with Mermaid version 9.4, you can use an alternate renderer named elk. The elk renderer is better for larger and/or more complex diagrams.\nThe elk renderer is an experimental feature. You can change the renderer to elk by adding this directive:\n%%{init: {\"flowchart\": {\"defaultRenderer\": \"elk\"}} }%% Note Note that the site needs to use mermaid version 9.4+ for this to work and have this featured enabled in the lazy-loading configuration.\nWidth linkIt is possible to adjust the width of the rendered flowchart.\nThis is done by defining mermaid.flowchartConfig or by the CLI to use a JSON file with the configuration. How to use the CLI is described in the mermaidCLI page. mermaid.flowchartConfig can be set to a JSON string with config parameters or the corresponding object.\nmermaid.flowchartConfig = { width: 100% } "
            }
        );
    index.add(
            {
                id:  71 ,
                href: "\/docs\/mix\/mermaid\/syntax\/gantt\/",
                title: "Gantt diagrams",
                description: "Gantt diagrams link A Gantt chart is a type of bar chart, first developed by Karol Adamiecki in 1896, and independently by Henry Gantt in the 1910s, that illustrates a project schedule and the amount of time it would take for any one project to finish. Gantt charts illustrate number of days between the start and finish dates of the terminal elements and summary elements of a project.\nA note to users linkGantt Charts will record each scheduled task as one continuous bar that extends from the left to the right. The x axis represents time and the y records the different tasks and the order in which they are to be completed.\n",
                content: "Gantt diagrams link A Gantt chart is a type of bar chart, first developed by Karol Adamiecki in 1896, and independently by Henry Gantt in the 1910s, that illustrates a project schedule and the amount of time it would take for any one project to finish. Gantt charts illustrate number of days between the start and finish dates of the terminal elements and summary elements of a project.\nA note to users linkGantt Charts will record each scheduled task as one continuous bar that extends from the left to the right. The x axis represents time and the y records the different tasks and the order in which they are to be completed.\nIt is important to remember that when a date, day, or collection of dates specific to a task are “excluded”, the Gantt Chart will accommodate those changes by extending an equal number of days, towards the right, not by creating a gap inside the task. As shown here However, if the excluded dates are between two tasks that are set to start consecutively, the excluded dates will be skipped graphically and left blank, and the following task will begin after the end of the excluded dates. As shown here A Gantt chart is useful for tracking the amount of time it would take before a project is finished, but it can also be used to graphically represent “non-working days”, with a few tweaks.\nMermaid can render Gantt diagrams as SVG, PNG or a MarkDown link that can be pasted into docs.\ngantt title A Gantt Diagram dateFormat YYYY-MM-DD section Section A task :a1, 2014-01-01, 30d Another task :after a1, 20d section Another Task in Another :2014-01-12, 12d another task :24d gantt title A Gantt Diagram dateFormat YYYY-MM-DD section Section A task :a1, 2014-01-01, 30d Another task :after a1, 20d section Another Task in Another :2014-01-12, 12d another task :24d Syntax link gantt dateFormat YYYY-MM-DD title Adding GANTT diagram functionality to mermaid excludes weekends %% (`excludes` accepts specific dates in YYYY-MM-DD format, days of the week (\"sunday\") or \"weekends\", but not the word \"weekdays\".) section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d section Critical tasks Completed task in the critical line :crit, done, 2014-01-06,24h Implement parser and jison :crit, done, after des1, 2d Create tests for parser :crit, active, 3d Future task in critical line :crit, 5d Create tests for renderer :2d Add to mermaid :1d Functionality added :milestone, 2014-01-25, 0d section Documentation Describe gantt syntax :active, a1, after des1, 3d Add gantt diagram to demo page :after a1 , 20h Add another diagram to demo page :doc1, after a1 , 48h section Last section Describe gantt syntax :after doc1, 3d Add gantt diagram to demo page :20h Add another diagram to demo page :48h gantt dateFormat YYYY-MM-DD title Adding GANTT diagram functionality to mermaid excludes weekends %% (`excludes` accepts specific dates in YYYY-MM-DD format, days of the week (\"sunday\") or \"weekends\", but not the word \"weekdays\".) section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d section Critical tasks Completed task in the critical line :crit, done, 2014-01-06,24h Implement parser and jison :crit, done, after des1, 2d Create tests for parser :crit, active, 3d Future task in critical line :crit, 5d Create tests for renderer :2d Add to mermaid :1d Functionality added :milestone, 2014-01-25, 0d section Documentation Describe gantt syntax :active, a1, after des1, 3d Add gantt diagram to demo page :after a1 , 20h Add another diagram to demo page :doc1, after a1 , 48h section Last section Describe gantt syntax :after doc1, 3d Add gantt diagram to demo page :20h Add another diagram to demo page :48h It is possible to set multiple dependencies separated by space:\ngantt apple :a, 2017-07-20, 1w banana :crit, b, 2017-07-23, 1d cherry :active, c, after b a, 1d gantt apple :a, 2017-07-20, 1w banana :crit, b, 2017-07-23, 1d cherry :active, c, after b a, 1d Title linkThe title is an optional string to be displayed at the top of the Gantt chart to describe the chart as a whole.\nSection statements linkYou can divide the chart into various sections, for example to separate different parts of a project like development and documentation.\nTo do so, start a line with the section keyword and give it a name. (Note that unlike with the title for the entire chart, this name is required.\nMilestones linkYou can add milestones to the diagrams. Milestones differ from tasks as they represent a single instant in time and are identified by the keyword milestone. Below is an example on how to use milestones. As you may notice, the exact location of the milestone is determined by the initial date for the milestone and the “duration” of the task this way: initial date+duration/2.\ngantt dateFormat HH:mm axisFormat %H:%M Initial milestone : milestone, m1, 17:49, 2m Task A : 10m Task B : 5m Final milestone : milestone, m2, 18:08, 4m gantt dateFormat HH:mm axisFormat %H:%M Initial milestone : milestone, m1, 17:49, 2m Task A : 10m Task B : 5m Final milestone : milestone, m2, 18:08, 4m Setting dates linkdateFormat defines the format of the date input of your gantt elements. How these dates are represented in the rendered chart output are defined by axisFormat.\nInput date format linkThe default input date format is YYYY-MM-DD. You can define your custom dateFormat.\ndateFormat YYYY-MM-DD The following formatting options are supported:\nInput Example Description YYYY 2014 4 digit year YY 14 2 digit year Q 1..4 Quarter of year. Sets month to first month in quarter. M MM 1..12 Month number MMM MMMM January..Dec Month name in locale set by dayjs.locale() D DD 1..31 Day of month Do 1st..31st Day of month with ordinal DDD DDDD 1..365 Day of year X 1410715640.579 Unix timestamp x 1410715640579 Unix ms timestamp H HH 0..23 24 hour time h hh 1..12 12 hour time used with a A. a A am pm Post or ante meridiem m mm 0..59 Minutes s ss 0..59 Seconds S 0..9 Tenths of a second SS 0..99 Hundreds of a second SSS 0..999 Thousandths of a second Z ZZ +12:00 Offset from UTC as +-HH:mm, +-HHmm, or Z More info in: https://day.js.org/docs/en/parse/string-format/\nOutput date format on the axis linkThe default output date format is YYYY-MM-DD. You can define your custom axisFormat, like 2020-Q1 for the first quarter of the year 2020.\naxisFormat %Y-%m-%d The following formatting strings are supported:\nFormat Definition %a abbreviated weekday name %A full weekday name %b abbreviated month name %B full month name %c date and time, as “%a %b %e %H:%M:%S %Y” %d zero-padded day of the month as a decimal number [01,31] %e space-padded day of the month as a decimal number [ 1,31]; equivalent to %_d %H hour (24-hour clock) as a decimal number [00,23] %I hour (12-hour clock) as a decimal number [01,12] %j day of the year as a decimal number [001,366] %m month as a decimal number [01,12] %M minute as a decimal number [00,59] %L milliseconds as a decimal number [000, 999] %p either AM or PM %S second as a decimal number [00,61] %U week number of the year (Sunday as the first day of the week) as a decimal number [00,53] %w weekday as a decimal number [0(Sunday),6] %W week number of the year (Monday as the first day of the week) as a decimal number [00,53] %x date, as “%m/%d/%Y” %X time, as “%H:%M:%S” %y year without century as a decimal number [00,99] %Y year with century as a decimal number %Z time zone offset, such as “-0700” %% a literal “%” character More info in: https://github.com/d3/d3-time-format/tree/v4.0.0#locale_format\nAxis ticks (v10.3.0+) linkThe default output ticks are auto. You can custom your tickInterval, like 1day or 1week.\ntickInterval 1day The pattern is:\n/^([1-9][0-9]*)(millisecond|second|minute|hour|day|week|month)$/; More info in: https://github.com/d3/d3-time#interval_every\nWeek-based tickIntervals start the week on sunday by default. If you wish to specify another weekday on which the tickInterval should start, use the weekday option:\ngantt tickInterval 1week weekday monday gantt tickInterval 1week weekday monday Warning \u003e millisecond and second support was added in vMERMAID_RELEASE_VERSION\nOutput in compact mode linkThe compact mode allows you to display multiple tasks in the same row. Compact mode can be enabled for a gantt chart by setting the display mode of the graph via preceeding YAML settings.\n--- displayMode: compact --- gantt title A Gantt Diagram dateFormat YYYY-MM-DD section Section A task :a1, 2014-01-01, 30d Another task :a2, 2014-01-20, 25d Another one :a3, 2014-02-10, 20d --- displayMode: compact --- gantt title A Gantt Diagram dateFormat YYYY-MM-DD section Section A task :a1, 2014-01-01, 30d Another task :a2, 2014-01-20, 25d Another one :a3, 2014-02-10, 20d Comments linkComments can be entered within a gantt chart, which will be ignored by the parser. Comments need to be on their own line and must be prefaced with %% (double percent signs). Any text after the start of the comment to the next newline will be treated as a comment, including any diagram syntax.\ngantt title A Gantt Diagram %% This is a comment dateFormat YYYY-MM-DD section Section A task :a1, 2014-01-01, 30d Another task :after a1, 20d section Another Task in Another :2014-01-12, 12d another task :24d gantt title A Gantt Diagram %% This is a comment dateFormat YYYY-MM-DD section Section A task :a1, 2014-01-01, 30d Another task :after a1, 20d section Another Task in Another :2014-01-12, 12d another task :24d Styling linkStyling of the Gantt diagram is done by defining a number of CSS classes. During rendering, these classes are extracted from the file located at src/diagrams/gantt/styles.js\nClasses used link Class Description grid.tick Styling for the Grid Lines grid.path Styling for the Grid’s borders .taskText Task Text Styling .taskTextOutsideRight Styling for Task Text that exceeds the activity bar towards the right. .taskTextOutsideLeft Styling for Task Text that exceeds the activity bar, towards the left. todayMarker Toggle and Styling for the “Today Marker” Sample stylesheet link .grid .tick { stroke: lightgrey; opacity: 0.3; shape-rendering: crispEdges; } .grid path { stroke-width: 0; } #tag { color: white; background: #fa283d; width: 150px; position: absolute; display: none; padding: 3px 6px; margin-left: -80px; font-size: 11px; } #tag:before { border: solid transparent; content: ' '; height: 0; left: 50%; margin-left: -5px; position: absolute; width: 0; border-width: 10px; border-bottom-color: #fa283d; top: -20px; } .taskText { fill: white; text-anchor: middle; } .taskTextOutsideRight { fill: black; text-anchor: start; } .taskTextOutsideLeft { fill: black; text-anchor: end; } Today marker linkYou can style or hide the marker for the current date. To style it, add a value for the todayMarker key.\ntodayMarker stroke-width:5px,stroke:#0f0,opacity:0.5 To hide the marker, set todayMarker to off.\ntodayMarker off Configuration linkIt is possible to adjust the margins for rendering the gantt diagram.\nThis is done by defining the ganttConfig part of the configuration object. How to use the CLI is described in the mermaidCLI page.\nmermaid.ganttConfig can be set to a JSON string with config parameters or the corresponding object.\nmermaid.ganttConfig = { titleTopMargin: 25, barHeight: 20, barGap: 4, topPadding: 75, sidePadding: 75, }; Possible configuration params: link Param Description Default value mirrorActor Turns on/off the rendering of actors below the diagram as well as above it false bottomMarginAdj Adjusts how far down the graph ended. Wide borders styles with css could generate unwanted clipping which is why this config param exists. 1 Interaction linkIt is possible to bind a click event to a task. The click can lead to either a javascript callback or to a link which will be opened in the current browser tab. Note: This functionality is disabled when using securityLevel='strict' and enabled when using securityLevel='loose'.\nclick taskId call callback(arguments) click taskId href URL taskId is the id of the task callback is the name of a javascript function defined on the page displaying the graph, the function will be called with the taskId as the parameter if no other arguments are specified. Beginner’s tip—a full example using interactive links in an html context:\ngantt dateFormat YYYY-MM-DD section Clickable Visit mermaidjs :active, cl1, 2014-01-07, 3d Print arguments :cl2, after cl1, 3d Print task :cl3, after cl2, 3d click cl1 href \"https://mermaidjs.github.io/\" click cl2 call printArguments(\"test1\", \"test2\", test3) click cl3 call printTask() Examples linkBar chart (using gantt chart) link gantt title Git Issues - days since last update dateFormat X axisFormat %s section Issue19062 71 : 0, 71 section Issue19401 36 : 0, 36 section Issue193 34 : 0, 34 section Issue7441 9 : 0, 9 section Issue1300 5 : 0, 5 gantt title Git Issues - days since last update dateFormat X axisFormat %s section Issue19062 71 : 0, 71 section Issue19401 36 : 0, 36 section Issue193 34 : 0, 34 section Issue7441 9 : 0, 9 section Issue1300 5 : 0, 5 "
            }
        );
    index.add(
            {
                id:  72 ,
                href: "\/docs\/mix\/mermaid\/syntax\/gitgraph\/",
                title: "Gitgraph Diagrams",
                description: "Gitgraph Diagrams link A Git Graph is a pictorial representation of git commits and git actions(commands) on various branches.\nThese kind of diagram are particularly helpful to developers and devops teams to share their Git branching strategies. For example, it makes it easier to visualize how git flow works.\nMermaid can render Git diagrams\n--- title: Example Git diagram --- gitGraph commit commit branch develop checkout develop commit commit checkout main merge develop commit commit --- title: Example Git diagram --- gitGraph commit commit branch develop checkout develop commit commit checkout main merge develop commit commit In Mermaid, we support the basic git operations like:\n",
                content: "Gitgraph Diagrams link A Git Graph is a pictorial representation of git commits and git actions(commands) on various branches.\nThese kind of diagram are particularly helpful to developers and devops teams to share their Git branching strategies. For example, it makes it easier to visualize how git flow works.\nMermaid can render Git diagrams\n--- title: Example Git diagram --- gitGraph commit commit branch develop checkout develop commit commit checkout main merge develop commit commit --- title: Example Git diagram --- gitGraph commit commit branch develop checkout develop commit commit checkout main merge develop commit commit In Mermaid, we support the basic git operations like:\ncommit : Representing a new commit on the current branch. branch : To create \u0026 switch to a new branch, setting it as the current branch. checkout : To checking out an existing branch and setting it as the current branch. merge : To merge an existing branch onto the current branch. With the help of these key git commands, you will be able to draw a gitgraph in Mermaid very easily and quickly. Entity names are often capitalized, although there is no accepted standard on this, and it is not required in Mermaid.\nSyntax linkMermaid syntax for a gitgraph is very straight-forward and simple. It follows a declarative-approach, where each commit is drawn on the timeline in the diagram, in order of its occurrences/presence in code. Basically, it follows the insertion order for each command.\nFirst thing you do is to declare your diagram type using the gitgraph keyword. This gitgraph keyword, tells Mermaid that you wish to draw a gitgraph, and parse the diagram code accordingly.\nEach gitgraph, is initialized with main branch. So unless you create a different branch, by-default the commits will go to the main branch. This is driven with how git works, where in the beginning you always start with the main branch (formerly called as master branch). And by-default, main branch is set as your current branch.\nYou make use of commit keyword to register a commit on the current branch. Let see how this works:\nA simple gitgraph showing three commits on the default (main) branch:\ngitGraph commit commit commit gitGraph commit commit commit If you look closely at the previous example, you can see the default branch main along with three commits. Also, notice that by default each commit has been given a unique \u0026 random ID. What if you wanted to give your own custom ID to a commit? Yes, it is possible to do that with Mermaid.\nAdding custom commit id linkFor a given commit you may specify a custom ID at the time of declaring it using the id attribute, followed by : and your custom value within a \"\" quote. For example: commit id: \"your_custom_id\"\nLet us see how this works with the help of the following diagram:\ngitGraph commit id: \"Alpha\" commit id: \"Beta\" commit id: \"Gamma\" gitGraph commit id: \"Alpha\" commit id: \"Beta\" commit id: \"Gamma\" In this example, we have given our custom IDs to the commits.\nModifying commit type linkIn Mermaid, a commit can be of three type, which render a bit different in the diagram. These types are:\nNORMAL : Default commit type. Represented by a solid circle in the diagram REVERSE : To emphasize a commit as a reverse commit. Represented by a crossed solid circle in the diagram. HIGHLIGHT : To highlight a particular commit in the diagram. Represented by a filled rectangle in the diagram. For a given commit you may specify its type at the time of declaring it using the type attribute, followed by : and the required type option discussed above. For example: commit type: HIGHLIGHT\nNOTE: If no commit type is specified, NORMAL is picked as default.\nLet us see how these different commit type look with the help of the following diagram:\ngitGraph commit id: \"Normal\" commit commit id: \"Reverse\" type: REVERSE commit commit id: \"Highlight\" type: HIGHLIGHT commit gitGraph commit id: \"Normal\" commit commit id: \"Reverse\" type: REVERSE commit commit id: \"Highlight\" type: HIGHLIGHT commit In this example, we have specified different types to each commit. Also, see how we have included both id and type together at the time of declaring our commits.\nAdding Tags linkFor a given commit you may decorate it as a tag, similar to the concept of tags or release version in git world. You can attach a custom tag at the time of declaring a commit using the tag attribute, followed by : and your custom value within \"\" quote. For example: commit tag: \"your_custom_tag\"\nLet us see how this works with the help of the following diagram:\ngitGraph commit commit id: \"Normal\" tag: \"v1.0.0\" commit commit id: \"Reverse\" type: REVERSE tag: \"RC_1\" commit commit id: \"Highlight\" type: HIGHLIGHT tag: \"8.8.4\" commit gitGraph commit commit id: \"Normal\" tag: \"v1.0.0\" commit commit id: \"Reverse\" type: REVERSE tag: \"RC_1\" commit commit id: \"Highlight\" type: HIGHLIGHT tag: \"8.8.4\" commit In this example, we have given custom tags to the commits. Also, see how we have combined all these attributes in a single commit declaration. You can mix-match these attributes as you like.\nCreate a new branch linkIn Mermaid, in-order to create a new branch, you make use of the branch keyword. You also need to provide a name of the new branch. The name has to be unique and cannot be that of an existing branch. A branch name that could be confused for a keyword must be quoted within \"\". Usage examples: branch develop, branch \"cherry-pick\"\nWhen Mermaid, reads the branch keyword, it creates a new branch and sets it as the current branch. Equivalent to you creating a new branch and checking it out in Git world.\nLet see this in an example:\ngitGraph commit commit branch develop commit commit commit gitGraph commit commit branch develop commit commit commit In this example, see how we started with default main branch, and pushed two commits on that. Then we created the develop branch, and all commits afterwards are put on the develop branch as it became the current branch.\nChecking out an existing branch linkIn Mermaid, in order to switch to an existing branch, you make use of the checkout keyword. You also need to provide a name of an existing branch. If no branch is found with the given name, it will result in console error. Usage example: checkout develop\nWhen Mermaid, reads the checkout keyword, it finds the given branch and sets it as the current branch. Equivalent to checking out a branch in the Git world.\nLet see modify our previous example:\ngitGraph commit commit branch develop commit commit commit checkout main commit commit gitGraph commit commit branch develop commit commit commit checkout main commit commit In this example, see how we started with default main branch, and pushed two commits on that. Then we created the develop branch, and all three commits afterwards are put on the develop branch as it became the current branch. After this we made use of the checkout keyword to set the current branch as main, and all commit that follow are registered against the current branch, i.e. main.\nMerging two branches linkIn Mermaid, in order to merge or join to an existing branch, you make use of the merge keyword. You also need to provide the name of an existing branch to merge from. If no branch is found with the given name, it will result in console error. Also, you can only merge two separate branches, and cannot merge a branch with itself. In such case an error is throw.\nUsage example: merge develop\nWhen Mermaid, reads the merge keyword, it finds the given branch and its head commit (the last commit on that branch), and joins it with the head commit on the current branch. Each merge results in a merge commit, represented in the diagram with filled double circle.\nLet us modify our previous example to merge our two branches:\ngitGraph commit commit branch develop commit commit commit checkout main commit commit merge develop commit commit gitGraph commit commit branch develop commit commit commit checkout main commit commit merge develop commit commit In this example, see how we started with default main branch, and pushed two commits on that. Then we created the develop branch, and all three commits afterwards are put on the develop branch as it became the current branch. After this we made use of the checkout keyword to set the current branch as main, and all commits that follow are registered against the current branch, i.e. main. After this we merge the develop branch onto the current branch main, resulting in a merge commit. Since the current branch at this point is still main, the last two commits are registered against that.\nYou can also decorate your merge with similar attributes as you did for the commit using:\nid–\u003e To override the default ID with custom ID tag–\u003e To add a custom tag to your merge commit type–\u003e To override the default shape of merge commit. Here you can use other commit type mentioned earlier. And you can choose to use none, some or all of these attributes together. For example: merge develop id: \"my_custom_id\" tag: \"my_custom_tag\" type: REVERSE\nLet us see how this works with the help of the following diagram:\ngitGraph commit id: \"1\" commit id: \"2\" branch nice_feature checkout nice_feature commit id: \"3\" checkout main commit id: \"4\" checkout nice_feature branch very_nice_feature checkout very_nice_feature commit id: \"5\" checkout main commit id: \"6\" checkout nice_feature commit id: \"7\" checkout main merge nice_feature id: \"customID\" tag: \"customTag\" type: REVERSE checkout very_nice_feature commit id: \"8\" checkout main commit id: \"9\" gitGraph commit id: \"1\" commit id: \"2\" branch nice_feature checkout nice_feature commit id: \"3\" checkout main commit id: \"4\" checkout nice_feature branch very_nice_feature checkout very_nice_feature commit id: \"5\" checkout main commit id: \"6\" checkout nice_feature commit id: \"7\" checkout main merge nice_feature id: \"customID\" tag: \"customTag\" type: REVERSE checkout very_nice_feature commit id: \"8\" checkout main commit id: \"9\" Cherry Pick commit from another branch linkSimilar to how ‘git’ allows you to cherry-pick a commit from another branch onto the current branch, Mermaid also supports this functionality. You can also cherry-pick a commit from another branch using the cherry-pick keyword.\nTo use the cherry-pick keyword, you must specify the id using the id attribute, followed by : and your desired commit id within a \"\" quote. For example:\ncherry-pick id: \"your_custom_id\"\nHere, a new commit representing the cherry-pick is created on the current branch, and is visually highlighted in the diagram with a cherry and a tag depicting the commit id from which it is cherry-picked from.\nA few important rules to note here are:\nYou need to provide the id for an existing commit to be cherry-picked. If given commit id does not exist it will result in an error. For this, make use of the commit id:$value format of declaring commits. See the examples from above. The given commit must not exist on the current branch. The cherry-picked commit must always be a different branch than the current branch. Current branch must have at least one commit, before you can cherry-pick, otherwise it will cause an error is throw. Let see an example:\ngitGraph commit id: \"ZERO\" branch develop commit id:\"A\" checkout main commit id:\"ONE\" checkout develop commit id:\"B\" checkout main commit id:\"TWO\" cherry-pick id:\"A\" commit id:\"THREE\" checkout develop commit id:\"C\" gitGraph commit id: \"ZERO\" branch develop commit id:\"A\" checkout main commit id:\"ONE\" checkout develop commit id:\"B\" checkout main commit id:\"TWO\" cherry-pick id:\"A\" commit id:\"THREE\" checkout develop commit id:\"C\" Gitgraph specific configuration options linkIn Mermaid, you have the option to configure the gitgraph diagram. You can configure the following options:\nshowBranches : Boolean, default is true. If set to false, the branches are not shown in the diagram. showCommitLabel : Boolean, default is true. If set to false, the commit labels are not shown in the diagram. mainBranchName : String, default is main. The name of the default/root branch. mainBranchOrder : Position of the main branch in the list of branches. default is 0, meaning, by default main branch is the first in the order. Let’s look at them one by one.\nHiding Branch names and lines linkSometimes you may want to hide the branch names and lines from the diagram. You can do this by using the showBranches keyword. By default its value is true. You can set it to false using directives.\nUsage example:\n%%{init: { 'logLevel': 'debug', 'theme': 'base', 'gitGraph': {'showBranches': false}} }%% gitGraph commit branch hotfix checkout hotfix commit branch develop checkout develop commit id:\"ash\" tag:\"abc\" branch featureB checkout featureB commit type:HIGHLIGHT checkout main checkout hotfix commit type:NORMAL checkout develop commit type:REVERSE checkout featureB commit checkout main merge hotfix checkout featureB commit checkout develop branch featureA commit checkout develop merge hotfix checkout featureA commit checkout featureB commit checkout develop merge featureA branch release checkout release commit checkout main commit checkout release merge main checkout develop merge release %%{init: { 'logLevel': 'debug', 'theme': 'base', 'gitGraph': {'showBranches': false}} }%% gitGraph commit branch hotfix checkout hotfix commit branch develop checkout develop commit id:\"ash\" tag:\"abc\" branch featureB checkout featureB commit type:HIGHLIGHT checkout main checkout hotfix commit type:NORMAL checkout develop commit type:REVERSE checkout featureB commit checkout main merge hotfix checkout featureB commit checkout develop branch featureA commit checkout develop merge hotfix checkout featureA commit checkout featureB commit checkout develop merge featureA branch release checkout release commit checkout main commit checkout release merge main checkout develop merge release Commit labels Layout: Rotated or Horizontal linkMermaid supports two types of commit labels layout. The default layout is rotated, which means the labels are placed below the commit circle, rotated at 45 degrees for better readability. This is particularly useful for commits with long labels.\nThe other option is horizontal, which means the labels are placed below the commit circle centred horizontally, and are not rotated. This is particularly useful for commits with short labels.\nYou can change the layout of the commit labels by using the rotateCommitLabel keyword in the directive. It defaults to true, which means the commit labels are rotated.\nUsage example: Rotated commit labels\n%%{init: { 'logLevel': 'debug', 'theme': 'base', 'gitGraph': {'rotateCommitLabel': true}} }%% gitGraph commit id: \"feat(api): ...\" commit id: \"a\" commit id: \"b\" commit id: \"fix(client): .extra long label..\" branch c2 commit id: \"feat(modules): ...\" commit id: \"test(client): ...\" checkout main commit id: \"fix(api): ...\" commit id: \"ci: ...\" branch b1 commit branch b2 commit %%{init: { 'logLevel': 'debug', 'theme': 'base', 'gitGraph': {'rotateCommitLabel': true}} }%% gitGraph commit id: \"feat(api): ...\" commit id: \"a\" commit id: \"b\" commit id: \"fix(client): .extra long label..\" branch c2 commit id: \"feat(modules): ...\" commit id: \"test(client): ...\" checkout main commit id: \"fix(api): ...\" commit id: \"ci: ...\" branch b1 commit branch b2 commit Usage example: Horizontal commit labels\n%%{init: { 'logLevel': 'debug', 'theme': 'base', 'gitGraph': {'rotateCommitLabel': false}} }%% gitGraph commit id: \"feat(api): ...\" commit id: \"a\" commit id: \"b\" commit id: \"fix(client): .extra long label..\" branch c2 commit id: \"feat(modules): ...\" commit id: \"test(client): ...\" checkout main commit id: \"fix(api): ...\" commit id: \"ci: ...\" branch b1 commit branch b2 commit %%{init: { 'logLevel': 'debug', 'theme': 'base', 'gitGraph': {'rotateCommitLabel': false}} }%% gitGraph commit id: \"feat(api): ...\" commit id: \"a\" commit id: \"b\" commit id: \"fix(client): .extra long label..\" branch c2 commit id: \"feat(modules): ...\" commit id: \"test(client): ...\" checkout main commit id: \"fix(api): ...\" commit id: \"ci: ...\" branch b1 commit branch b2 commit Hiding commit labels linkSometimes you may want to hide the commit labels from the diagram. You can do this by using the showCommitLabel keyword. By default its value is true. You can set it to false using directives.\nUsage example:\n%%{init: { 'logLevel': 'debug', 'theme': 'base', 'gitGraph': {'showBranches': false,'showCommitLabel': false}} }%% gitGraph commit branch hotfix checkout hotfix commit branch develop checkout develop commit id:\"ash\" branch featureB checkout featureB commit type:HIGHLIGHT checkout main checkout hotfix commit type:NORMAL checkout develop commit type:REVERSE checkout featureB commit checkout main merge hotfix checkout featureB commit checkout develop branch featureA commit checkout develop merge hotfix checkout featureA commit checkout featureB commit checkout develop merge featureA branch release checkout release commit checkout main commit checkout release merge main checkout develop merge release %%{init: { 'logLevel': 'debug', 'theme': 'base', 'gitGraph': {'showBranches': false,'showCommitLabel': false}} }%% gitGraph commit branch hotfix checkout hotfix commit branch develop checkout develop commit id:\"ash\" branch featureB checkout featureB commit type:HIGHLIGHT checkout main checkout hotfix commit type:NORMAL checkout develop commit type:REVERSE checkout featureB commit checkout main merge hotfix checkout featureB commit checkout develop branch featureA commit checkout develop merge hotfix checkout featureA commit checkout featureB commit checkout develop merge featureA branch release checkout release commit checkout main commit checkout release merge main checkout develop merge release Customizing main branch name linkSometimes you may want to customize the name of the main/default branch. You can do this by using the mainBranchName keyword. By default its value is main. You can set it to any string using directives.\nUsage example:\n%%{init: { 'logLevel': 'debug', 'theme': 'base', 'gitGraph': {'showBranches': true, 'showCommitLabel':true,'mainBranchName': 'MetroLine1'}} }%% gitGraph commit id:\"NewYork\" commit id:\"Dallas\" branch MetroLine2 commit id:\"LosAngeles\" commit id:\"Chicago\" commit id:\"Houston\" branch MetroLine3 commit id:\"Phoenix\" commit type: HIGHLIGHT id:\"Denver\" commit id:\"Boston\" checkout MetroLine1 commit id:\"Atlanta\" merge MetroLine3 commit id:\"Miami\" commit id:\"Washington\" merge MetroLine2 tag:\"MY JUNCTION\" commit id:\"Boston\" commit id:\"Detroit\" commit type:REVERSE id:\"SanFrancisco\" %%{init: { 'logLevel': 'debug', 'theme': 'base', 'gitGraph': {'showBranches': true, 'showCommitLabel':true,'mainBranchName': 'MetroLine1'}} }%% gitGraph commit id:\"NewYork\" commit id:\"Dallas\" branch MetroLine2 commit id:\"LosAngeles\" commit id:\"Chicago\" commit id:\"Houston\" branch MetroLine3 commit id:\"Phoenix\" commit type: HIGHLIGHT id:\"Denver\" commit id:\"Boston\" checkout MetroLine1 commit id:\"Atlanta\" merge MetroLine3 commit id:\"Miami\" commit id:\"Washington\" merge MetroLine2 tag:\"MY JUNCTION\" commit id:\"Boston\" commit id:\"Detroit\" commit type:REVERSE id:\"SanFrancisco\" Look at the imaginary railroad map created using Mermaid. Here, we have changed the default main branch name to MetroLine1.\nCustomizing branch ordering linkIn Mermaid, by default the branches are shown in the order of their definition or appearance in the diagram code.\nSometimes you may want to customize the order of the branches. You can do this by using the order keyword next the branch definition. You can set it to a positive number.\nMermaid follows the given precedence order of the order keyword.\nMain branch is always shown first as it has default order value of 0. (unless its order is modified and changed from 0 using the mainBranchOrder keyword in the config) Next, All branches without an order are shown in the order of their appearance in the diagram code. Next, All branches with an order are shown in the order of their order value. To fully control the order of all the branches, you must define order for all the branches.\nUsage example:\n%%{init: { 'logLevel': 'debug', 'theme': 'base', 'gitGraph': {'showBranches': true, 'showCommitLabel':true}} }%% gitGraph commit branch test1 order: 3 branch test2 order: 2 branch test3 order: 1 %%{init: { 'logLevel': 'debug', 'theme': 'base', 'gitGraph': {'showBranches': true, 'showCommitLabel':true}} }%% gitGraph commit branch test1 order: 3 branch test2 order: 2 branch test3 order: 1 Look at the diagram, all the branches are following the order defined.\nUsage example:\n%%{init: { 'logLevel': 'debug', 'theme': 'base', 'gitGraph': {'showBranches': true, 'showCommitLabel':true,'mainBranchOrder': 2}} }%% gitGraph commit branch test1 order: 3 branch test2 branch test3 branch test4 order: 1 %%{init: { 'logLevel': 'debug', 'theme': 'base', 'gitGraph': {'showBranches': true, 'showCommitLabel':true,'mainBranchOrder': 2}} }%% gitGraph commit branch test1 order: 3 branch test2 branch test3 branch test4 order: 1 Look at the diagram, here, all the branches without a specified order are drawn in their order of definition. Then, test4 branch is drawn because the order of 1. Then, main branch is drawn because the order of 2. And, lastly test1is drawn because the order of 3.\nNOTE: Because we have overridden the mainBranchOrder to 2, the main branch is not drawn in the beginning, instead follows the ordering.\nHere, we have changed the default main branch name to MetroLine1.\nOrientation (v10.3.0+) linkMermaid supports two graph orientations: Left-to-Right (default) and Top-to-Bottom.\nYou can set this with either LR: (for Left-to-Right) or TB: (for Top-to-Bottom) after gitGraph.\nLeft to Right (default, LR:) linkIn Mermaid, the default orientation is for commits to run from left to right and for branches to be stacked on top of one another.\nHowever, you can set this explicitly with LR: after gitGraph.\nUsage example:\ngitGraph LR: commit commit branch develop commit commit checkout main commit commit merge develop commit commit gitGraph LR: commit commit branch develop commit commit checkout main commit commit merge develop commit commit Top to Bottom (TB:) linkIn TB (Top-to-Bottom) orientation, the commits run from top to bottom of the graph and branches are arranged side-by-side.\nTo orient the graph this way, you need to add TB: after gitGraph.\nUsage example:\ngitGraph TB: commit commit branch develop commit commit checkout main commit commit merge develop commit commit gitGraph TB: commit commit branch develop commit commit checkout main commit commit merge develop commit commit Themes linkMermaid supports a bunch of pre-defined themes which you can use to find the right one for you. PS: you can actually override an existing theme’s variable to get your own custom theme going. Learn more about theming your diagram here.\nThe following are the different pre-defined theme options:\nbase forest dark default neutral NOTE: To change theme you can either use the initialize call or directives. Learn more about directives Let’s put them to use, and see how our sample diagram looks in different themes:\nBase Theme link %%{init: { 'logLevel': 'debug', 'theme': 'base' } }%% gitGraph commit branch hotfix checkout hotfix commit branch develop checkout develop commit id:\"ash\" tag:\"abc\" branch featureB checkout featureB commit type:HIGHLIGHT checkout main checkout hotfix commit type:NORMAL checkout develop commit type:REVERSE checkout featureB commit checkout main merge hotfix checkout featureB commit checkout develop branch featureA commit checkout develop merge hotfix checkout featureA commit checkout featureB commit checkout develop merge featureA branch release checkout release commit checkout main commit checkout release merge main checkout develop merge release %%{init: { 'logLevel': 'debug', 'theme': 'base' } }%% gitGraph commit branch hotfix checkout hotfix commit branch develop checkout develop commit id:\"ash\" tag:\"abc\" branch featureB checkout featureB commit type:HIGHLIGHT checkout main checkout hotfix commit type:NORMAL checkout develop commit type:REVERSE checkout featureB commit checkout main merge hotfix checkout featureB commit checkout develop branch featureA commit checkout develop merge hotfix checkout featureA commit checkout featureB commit checkout develop merge featureA branch release checkout release commit checkout main commit checkout release merge main checkout develop merge release Forest Theme link %%{init: { 'logLevel': 'debug', 'theme': 'forest' } }%% gitGraph commit branch hotfix checkout hotfix commit branch develop checkout develop commit id:\"ash\" tag:\"abc\" branch featureB checkout featureB commit type:HIGHLIGHT checkout main checkout hotfix commit type:NORMAL checkout develop commit type:REVERSE checkout featureB commit checkout main merge hotfix checkout featureB commit checkout develop branch featureA commit checkout develop merge hotfix checkout featureA commit checkout featureB commit checkout develop merge featureA branch release checkout release commit checkout main commit checkout release merge main checkout develop merge release %%{init: { 'logLevel': 'debug', 'theme': 'forest' } }%% gitGraph commit branch hotfix checkout hotfix commit branch develop checkout develop commit id:\"ash\" tag:\"abc\" branch featureB checkout featureB commit type:HIGHLIGHT checkout main checkout hotfix commit type:NORMAL checkout develop commit type:REVERSE checkout featureB commit checkout main merge hotfix checkout featureB commit checkout develop branch featureA commit checkout develop merge hotfix checkout featureA commit checkout featureB commit checkout develop merge featureA branch release checkout release commit checkout main commit checkout release merge main checkout develop merge release Default Theme link %%{init: { 'logLevel': 'debug', 'theme': 'default' } }%% gitGraph commit type:HIGHLIGHT branch hotfix checkout hotfix commit branch develop checkout develop commit id:\"ash\" tag:\"abc\" branch featureB checkout featureB commit type:HIGHLIGHT checkout main checkout hotfix commit type:NORMAL checkout develop commit type:REVERSE checkout featureB commit checkout main merge hotfix checkout featureB commit checkout develop branch featureA commit checkout develop merge hotfix checkout featureA commit checkout featureB commit checkout develop merge featureA branch release checkout release commit checkout main commit checkout release merge main checkout develop merge release %%{init: { 'logLevel': 'debug', 'theme': 'default' } }%% gitGraph commit type:HIGHLIGHT branch hotfix checkout hotfix commit branch develop checkout develop commit id:\"ash\" tag:\"abc\" branch featureB checkout featureB commit type:HIGHLIGHT checkout main checkout hotfix commit type:NORMAL checkout develop commit type:REVERSE checkout featureB commit checkout main merge hotfix checkout featureB commit checkout develop branch featureA commit checkout develop merge hotfix checkout featureA commit checkout featureB commit checkout develop merge featureA branch release checkout release commit checkout main commit checkout release merge main checkout develop merge release Dark Theme link %%{init: { 'logLevel': 'debug', 'theme': 'dark' } }%% gitGraph commit branch hotfix checkout hotfix commit branch develop checkout develop commit id:\"ash\" tag:\"abc\" branch featureB checkout featureB commit type:HIGHLIGHT checkout main checkout hotfix commit type:NORMAL checkout develop commit type:REVERSE checkout featureB commit checkout main merge hotfix checkout featureB commit checkout develop branch featureA commit checkout develop merge hotfix checkout featureA commit checkout featureB commit checkout develop merge featureA branch release checkout release commit checkout main commit checkout release merge main checkout develop merge release %%{init: { 'logLevel': 'debug', 'theme': 'dark' } }%% gitGraph commit branch hotfix checkout hotfix commit branch develop checkout develop commit id:\"ash\" tag:\"abc\" branch featureB checkout featureB commit type:HIGHLIGHT checkout main checkout hotfix commit type:NORMAL checkout develop commit type:REVERSE checkout featureB commit checkout main merge hotfix checkout featureB commit checkout develop branch featureA commit checkout develop merge hotfix checkout featureA commit checkout featureB commit checkout develop merge featureA branch release checkout release commit checkout main commit checkout release merge main checkout develop merge release Neutral Theme link %%{init: { 'logLevel': 'debug', 'theme': 'neutral' } }%% gitGraph commit branch hotfix checkout hotfix commit branch develop checkout develop commit id:\"ash\" tag:\"abc\" branch featureB checkout featureB commit type:HIGHLIGHT checkout main checkout hotfix commit type:NORMAL checkout develop commit type:REVERSE checkout featureB commit checkout main merge hotfix checkout featureB commit checkout develop branch featureA commit checkout develop merge hotfix checkout featureA commit checkout featureB commit checkout develop merge featureA branch release checkout release commit checkout main commit checkout release merge main checkout develop merge release %%{init: { 'logLevel': 'debug', 'theme': 'neutral' } }%% gitGraph commit branch hotfix checkout hotfix commit branch develop checkout develop commit id:\"ash\" tag:\"abc\" branch featureB checkout featureB commit type:HIGHLIGHT checkout main checkout hotfix commit type:NORMAL checkout develop commit type:REVERSE checkout featureB commit checkout main merge hotfix checkout featureB commit checkout develop branch featureA commit checkout develop merge hotfix checkout featureA commit checkout featureB commit checkout develop merge featureA branch release checkout release commit checkout main commit checkout release merge main checkout develop merge release Customize using Theme Variables linkMermaid allows you to customize your diagram using theme variables which govern the look and feel of various elements of the diagram.\nFor understanding let us take a sample diagram with theme default, the default values of the theme variables is picked automatically from the theme. Later on we will see how to override the default values of the theme variables.\nSee how the default theme is used to set the colors for the branches:\n%%{init: { 'logLevel': 'debug', 'theme': 'default' } }%% gitGraph commit branch develop commit tag:\"v1.0.0\" commit checkout main commit type: HIGHLIGHT commit merge develop commit branch featureA commit %%{init: { 'logLevel': 'debug', 'theme': 'default' } }%% gitGraph commit branch develop commit tag:\"v1.0.0\" commit checkout main commit type: HIGHLIGHT commit merge develop commit branch featureA commit IMPORTANT: linkMermaid supports the theme variables to override the default values for up to 8 branches, i.e., you can set the color/styling of up to 8 branches using theme variables. After this threshold of 8 branches, the theme variables are reused in the cyclic manner, i.e. the 9th branch will use the color/styling of the 1st branch, or the branch at index position ‘8’ will use the color/styling of the branch at index position ‘0’. More on this in the next section. See examples on Customizing branch label colors below\nCustomizing branch colors linkYou can customize the branch colors using the git0 to git7 theme variables. Mermaid allows you to set the colors for up-to 8 branches, where git0 variable will drive the value of the first branch, git1 will drive the value of the second branch and so on.\nNOTE: Default values for these theme variables are picked from the selected theme. If you want to override the default values, you can use the initialize call to add your custom theme variable values.\nExample:\nNow let’s override the default values for the git0 to git3 variables:\n%%{init: { 'logLevel': 'debug', 'theme': 'default' , 'themeVariables': { 'git0': '#ff0000', 'git1': '#00ff00', 'git2': '#0000ff', 'git3': '#ff00ff', 'git4': '#00ffff', 'git5': '#ffff00', 'git6': '#ff00ff', 'git7': '#00ffff' } } }%% gitGraph commit branch develop commit tag:\"v1.0.0\" commit checkout main commit type: HIGHLIGHT commit merge develop commit branch featureA commit %%{init: { 'logLevel': 'debug', 'theme': 'default' , 'themeVariables': { 'git0': '#ff0000', 'git1': '#00ff00', 'git2': '#0000ff', 'git3': '#ff00ff', 'git4': '#00ffff', 'git5': '#ffff00', 'git6': '#ff00ff', 'git7': '#00ffff' } } }%% gitGraph commit branch develop commit tag:\"v1.0.0\" commit checkout main commit type: HIGHLIGHT commit merge develop commit branch featureA commit See how the branch colors are changed to the values specified in the theme variables.\nCustomizing branch label colors linkYou can customize the branch label colors using the gitBranchLabel0 to gitBranchLabel7 theme variables. Mermaid allows you to set the colors for up-to 8 branches, where gitBranchLabel0 variable will drive the value of the first branch label, gitBranchLabel1 will drive the value of the second branch label and so on.\nLets see how the default theme is used to set the colors for the branch labels:\nNow let’s override the default values for the gitBranchLabel0 to gitBranchLabel2 variables:\n%%{init: { 'logLevel': 'debug', 'theme': 'default' , 'themeVariables': { 'gitBranchLabel0': '#ffffff', 'gitBranchLabel1': '#ffffff', 'gitBranchLabel2': '#ffffff', 'gitBranchLabel3': '#ffffff', 'gitBranchLabel4': '#ffffff', 'gitBranchLabel5': '#ffffff', 'gitBranchLabel6': '#ffffff', 'gitBranchLabel7': '#ffffff', 'gitBranchLabel8': '#ffffff', 'gitBranchLabel9': '#ffffff' } } }%% gitGraph checkout main branch branch1 branch branch2 branch branch3 branch branch4 branch branch5 branch branch6 branch branch7 branch branch8 branch branch9 checkout branch1 commit %%{init: { 'logLevel': 'debug', 'theme': 'default' , 'themeVariables': { 'gitBranchLabel0': '#ffffff', 'gitBranchLabel1': '#ffffff', 'gitBranchLabel2': '#ffffff', 'gitBranchLabel3': '#ffffff', 'gitBranchLabel4': '#ffffff', 'gitBranchLabel5': '#ffffff', 'gitBranchLabel6': '#ffffff', 'gitBranchLabel7': '#ffffff', 'gitBranchLabel8': '#ffffff', 'gitBranchLabel9': '#ffffff' } } }%% gitGraph checkout main branch branch1 branch branch2 branch branch3 branch branch4 branch branch5 branch branch6 branch branch7 branch branch8 branch branch9 checkout branch1 commit Here, you can see that branch8 and branch9 colors and the styles are being picked from branch at index position 0 (main) and 1(branch1) respectively, i.e., branch themeVariables are repeated cyclically.\nCustomizing Commit colors linkYou can customize commit using the commitLabelColor and commitLabelBackground theme variables for changes in the commit label color and background color respectively.\nExample: Now let’s override the default values for the commitLabelColor to commitLabelBackground variables:\n%%{init: { 'logLevel': 'debug', 'theme': 'default' , 'themeVariables': { 'commitLabelColor': '#ff0000', 'commitLabelBackground': '#00ff00' } } }%% gitGraph commit branch develop commit tag:\"v1.0.0\" commit checkout main commit type: HIGHLIGHT commit merge develop commit branch featureA commit %%{init: { 'logLevel': 'debug', 'theme': 'default' , 'themeVariables': { 'commitLabelColor': '#ff0000', 'commitLabelBackground': '#00ff00' } } }%% gitGraph commit branch develop commit tag:\"v1.0.0\" commit checkout main commit type: HIGHLIGHT commit merge develop commit branch featureA commit See how the commit label color and background color are changed to the values specified in the theme variables.\nCustomizing Commit Label Font Size linkYou can customize commit using the commitLabelFontSize theme variables for changing in the font soze of the commit label .\nExample: Now let’s override the default values for the commitLabelFontSize variable:\n%%{init: { 'logLevel': 'debug', 'theme': 'default' , 'themeVariables': { 'commitLabelColor': '#ff0000', 'commitLabelBackground': '#00ff00', 'commitLabelFontSize': '16px' } } }%% gitGraph commit branch develop commit tag:\"v1.0.0\" commit checkout main commit type: HIGHLIGHT commit merge develop commit branch featureA commit %%{init: { 'logLevel': 'debug', 'theme': 'default' , 'themeVariables': { 'commitLabelColor': '#ff0000', 'commitLabelBackground': '#00ff00', 'commitLabelFontSize': '16px' } } }%% gitGraph commit branch develop commit tag:\"v1.0.0\" commit checkout main commit type: HIGHLIGHT commit merge develop commit branch featureA commit See how the commit label font size changed.\nCustomizing Tag Label Font Size linkYou can customize commit using the tagLabelFontSize theme variables for changing in the font soze of the tag label .\nExample: Now let’s override the default values for the tagLabelFontSize variable:\n%%{init: { 'logLevel': 'debug', 'theme': 'default' , 'themeVariables': { 'commitLabelColor': '#ff0000', 'commitLabelBackground': '#00ff00', 'tagLabelFontSize': '16px' } } }%% gitGraph commit branch develop commit tag:\"v1.0.0\" commit checkout main commit type: HIGHLIGHT commit merge develop commit branch featureA commit %%{init: { 'logLevel': 'debug', 'theme': 'default' , 'themeVariables': { 'commitLabelColor': '#ff0000', 'commitLabelBackground': '#00ff00', 'tagLabelFontSize': '16px' } } }%% gitGraph commit branch develop commit tag:\"v1.0.0\" commit checkout main commit type: HIGHLIGHT commit merge develop commit branch featureA commit See how the tag label font size changed.\nCustomizing Tag colors linkYou can customize tag using the tagLabelColor,tagLabelBackground and tagLabelBorder theme variables for changes in the tag label color,tag label background color and tag label border respectively. Example: Now let’s override the default values for the tagLabelColor, tagLabelBackground and to tagLabelBorder variables:\n%%{init: { 'logLevel': 'debug', 'theme': 'default' , 'themeVariables': { 'tagLabelColor': '#ff0000', 'tagLabelBackground': '#00ff00', 'tagLabelBorder': '#0000ff' } } }%% gitGraph commit branch develop commit tag:\"v1.0.0\" commit checkout main commit type: HIGHLIGHT commit merge develop commit branch featureA commit %%{init: { 'logLevel': 'debug', 'theme': 'default' , 'themeVariables': { 'tagLabelColor': '#ff0000', 'tagLabelBackground': '#00ff00', 'tagLabelBorder': '#0000ff' } } }%% gitGraph commit branch develop commit tag:\"v1.0.0\" commit checkout main commit type: HIGHLIGHT commit merge develop commit branch featureA commit See how the tag colors are changed to the values specified in the theme variables.\nCustomizing Highlight commit colors linkYou can customize the highlight commit colors in relation to the branch it is on using the gitInv0 to gitInv7 theme variables. Mermaid allows you to set the colors for up-to 8 branches specific highlight commit, where gitInv0 variable will drive the value of the first branch’s highlight commits, gitInv1 will drive the value of the second branch’s highlight commit label and so on.\nExample:\nNow let’s override the default values for the git0 to git3 variables:\n%%{init: { 'logLevel': 'debug', 'theme': 'default' , 'themeVariables': { 'gitInv0': '#ff0000' } } }%% gitGraph commit branch develop commit tag:\"v1.0.0\" commit checkout main commit type: HIGHLIGHT commit merge develop commit branch featureA commit %%{init: { 'logLevel': 'debug', 'theme': 'default' , 'themeVariables': { 'gitInv0': '#ff0000' } } }%% gitGraph commit branch develop commit tag:\"v1.0.0\" commit checkout main commit type: HIGHLIGHT commit merge develop commit branch featureA commit See how the highlighted commit color on the first branch is changed to the value specified in the theme variable gitInv0.\n"
            }
        );
    index.add(
            {
                id:  73 ,
                href: "\/docs\/mix\/mermaid\/",
                title: "Mermaid@v10.6.1 Syntax",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  74 ,
                href: "\/docs\/mix\/mermaid\/syntax\/mindmap\/",
                title: "Mindmap",
                description: "Mindmap link Mindmap: This is an experimental diagram for now. The syntax and properties can change in future releases. The syntax is stable except for the icon integration which is the experimental part.\n“A mind map is a diagram used to visually organize information into a hierarchy, showing relationships among pieces of the whole. It is often created around a single concept, drawn as an image in the center of a blank page, to which associated representations of ideas such as images, words and parts of words are added. Major ideas are connected directly to the central concept, and other ideas branch out from those major ideas.” Wikipedia\n",
                content: "Mindmap link Mindmap: This is an experimental diagram for now. The syntax and properties can change in future releases. The syntax is stable except for the icon integration which is the experimental part.\n“A mind map is a diagram used to visually organize information into a hierarchy, showing relationships among pieces of the whole. It is often created around a single concept, drawn as an image in the center of a blank page, to which associated representations of ideas such as images, words and parts of words are added. Major ideas are connected directly to the central concept, and other ideas branch out from those major ideas.” Wikipedia\nAn example of a mindmap. link mindmap root((mindmap)) Origins Long history ::icon(fa fa-book) Popularisation British popular psychology author Tony Buzan Research On effectivenessand features On Automatic creation Uses Creative techniques Strategic planning Argument mapping Tools Pen and paper Mermaid mindmap root((mindmap)) Origins Long history ::icon(fa fa-book) Popularisation British popular psychology author Tony Buzan Research On effectivenessand features On Automatic creation Uses Creative techniques Strategic planning Argument mapping Tools Pen and paper Mermaid Syntax linkThe syntax for creating Mindmaps is simple and relies on indentation for setting the levels in the hierarchy.\nIn the following example you can see how there are 3 different levels. One with starting at the left of the text and another level with two rows starting at the same column, defining the node A. At the end there is one more level where the text is indented further than the previous lines defining the nodes B and C.\nmindmap Root A B C In summary is a simple text outline where there is one node at the root level called Root which has one child A. A in turn has two children Band C. In the diagram below we can see this rendered as a mindmap.\nmindmap Root A B C mindmap Root A B C In this way we can use a text outline to generate a hierarchical mindmap.\nDifferent shapes linkMermaid mindmaps can show nodes using different shapes. When specifying a shape for a node the syntax is similar to flowchart nodes, with an id followed by the shape definition and with the text within the shape delimiters. Where possible we try/will try to keep the same shapes as for flowcharts, even though they are not all supported from the start.\nMindmap can show the following shapes:\nSquare link mindmap id[I am a square] mindmap id[I am a square] Rounded square link mindmap id(I am a rounded square) mindmap id(I am a rounded square) Circle link mindmap id((I am a circle)) mindmap id((I am a circle)) Bang link mindmap id))I am a bang(( mindmap id))I am a bang(( Cloud link mindmap id)I am a cloud( mindmap id)I am a cloud( Hexagon link mindmap id{{I am a hexagon}} mindmap id{{I am a hexagon}} Default link mindmap I am the default shape mindmap I am the default shape More shapes will be added, beginning with the shapes available in flowcharts.\nIcons and classes linkIcons linkAs with flowcharts you can add icons to your nodes but with an updated syntax. The styling for the font based icons are added during the integration so that they are available for the web page. This is not something a diagram author can do but has to be done with the site administrator or the integrator. Once the icon fonts are in place you add them to the mind map nodes using the ::icon() syntax. You place the classes for the icon within the parenthesis like in the following example where icons for material design and Font Awesome 5 are displayed. The intention is that this approach should be used for all diagrams supporting icons. Experimental feature: This wider scope is also the reason Mindmaps are experimental as this syntax and approach could change.\nmindmap Root A ::icon(fa fa-book) B(B) ::icon(mdi mdi-skull-outline) mindmap Root A ::icon(fa fa-book) B(B) ::icon(mdi mdi-skull-outline) Classes linkAgain the syntax for adding classes is similar to flowcharts. You can add classes using a triple colon following a number of css classes separated by space. In the following example one of the nodes has two custom classes attached urgent turning the background red and the text white and large increasing the font size:\nmindmap Root A[A] :::urgent large B(B) C mindmap Root A[A] :::urgent large B(B) C These classes need to be supplied by the site administrator.\nUnclear indentation linkThe actual indentation does not really matter only compared with the previous rows. If we take the previous example and disrupt it a little we can see how the calculations are performed. Let us start with placing C with a smaller indentation than B but larger then A.\nmindmap Root A B C This outline is unclear as B clearly is a child of A but when we move on to C the clarity is lost. C is not a child of B with a higher indentation nor does it have the same indentation as B. The only thing that is clear is that the first node with smaller indentation, indicating a parent, is A. Then Mermaid relies on this known truth and compensates for the unclear indentation and selects A as a parent of C leading till the same diagram with B and C as siblings.\nmindmap Root A B C mindmap Root A B C Markdown Strings linkThe “Markdown Strings” feature enhances mind maps by offering a more versatile string type, which supports text formatting options such as bold and italics, and automatically wraps text within labels.\nmindmap id1[\"`**Root** with a second line Unicode works too: 🤓`\"] id2[\"`The dog in **the** hog... a *very long text* that wraps to a new line`\"] id3[Regular labels still works] mindmap id1[\"`**Root** with a second line Unicode works too: 🤓`\"] id2[\"`The dog in **the** hog... a *very long text* that wraps to a new line`\"] id3[Regular labels still works] Formatting:\nFor bold text, use double asterisks ** before and after the text. For italics, use single asterisks * before and after the text. With traditional strings, you needed to add tags for text to wrap in nodes. However, markdown strings automatically wrap text when it becomes too long and allows you to start a new line by simply using a newline character instead of a tag. Integrating with your library/website. linkMindmap uses the experimental lazy loading \u0026 async rendering features which could change in the future. From version 9.4.0 this diagram is included in mermaid but use lazy loading in order to keep the size of mermaid down. This is important in order to be able to add additional diagrams going forward.\nYou can still use the pre 9.4.0 method to add mermaid with mindmaps to a web page:\nFrom version 9.4.0 you can simplify this code to:\nYou can also refer the implementation in the live editor here to see how the async loading is done.\n"
            }
        );
    index.add(
            {
                id:  75 ,
                href: "\/docs\/mix\/mermaid\/syntax\/pie\/",
                title: "Pie chart diagrams",
                description: "Pie chart diagrams link A pie chart (or a circle chart) is a circular statistical graphic, which is divided into slices to illustrate numerical proportion. In a pie chart, the arc length of each slice (and consequently its central angle and area), is proportional to the quantity it represents. While it is named for its resemblance to a pie which has been sliced, there are variations on the way it can be presented. The earliest known pie chart is generally credited to William Playfair’s Statistical Breviary of 1801 -Wikipedia\n",
                content: "Pie chart diagrams link A pie chart (or a circle chart) is a circular statistical graphic, which is divided into slices to illustrate numerical proportion. In a pie chart, the arc length of each slice (and consequently its central angle and area), is proportional to the quantity it represents. While it is named for its resemblance to a pie which has been sliced, there are variations on the way it can be presented. The earliest known pie chart is generally credited to William Playfair’s Statistical Breviary of 1801 -Wikipedia\nMermaid can render Pie Chart diagrams.\npie title Pets adopted by volunteers \"Dogs\" : 386 \"Cats\" : 85 \"Rats\" : 15 pie title Pets adopted by volunteers \"Dogs\" : 386 \"Cats\" : 85 \"Rats\" : 15 Syntax linkDrawing a pie chart is really simple in mermaid.\nStart with pie keyword to begin the diagram showData to render the actual data values after the legend text. This is OPTIONAL Followed by title keyword and its value in string to give a title to the pie-chart. This is OPTIONAL Followed by dataSet. Pie slices will be ordered clockwise in the same order as the labels. label for a section in the pie diagram within \" \" quotes. Followed by : colon as separator Followed by positive numeric value (supported up to two decimal places) [pie] [showData] (OPTIONAL) [title] [titlevalue] (OPTIONAL) “[datakey1]” : [dataValue1] “[datakey2]” : [dataValue2] “[datakey3]” : [dataValue3] . .\nExample link %%{init: {\"pie\": {\"textPosition\": 0.5}, \"themeVariables\": {\"pieOuterStrokeWidth\": \"5px\"}} }%% pie showData title Key elements in Product X \"Calcium\" : 42.96 \"Potassium\" : 50.05 \"Magnesium\" : 10.01 \"Iron\" : 5 %%{init: {\"pie\": {\"textPosition\": 0.5}, \"themeVariables\": {\"pieOuterStrokeWidth\": \"5px\"}} }%% pie showData title Key elements in Product X \"Calcium\" : 42.96 \"Potassium\" : 50.05 \"Magnesium\" : 10.01 \"Iron\" : 5 Configuration linkPossible pie diagram configuration parameters:\nParameter Description Default value textPosition The axial position of the pie slice labels, from 0.0 at the center to 1.0 at the outside edge of the circle. 0.75 "
            }
        );
    index.add(
            {
                id:  76 ,
                href: "\/docs\/mix\/mermaid\/syntax\/quadrantchart\/",
                title: "Quadrant Chart",
                description: "Quadrant Chart link A quadrant chart is a visual representation of data that is divided into four quadrants. It is used to plot data points on a two-dimensional grid, with one variable represented on the x-axis and another variable represented on the y-axis. The quadrants are determined by dividing the chart into four equal parts based on a set of criteria that is specific to the data being analyzed. Quadrant charts are often used to identify patterns and trends in data, and to prioritize actions based on the position of data points within the chart. They are commonly used in business, marketing, and risk management, among other fields.\n",
                content: "Quadrant Chart link A quadrant chart is a visual representation of data that is divided into four quadrants. It is used to plot data points on a two-dimensional grid, with one variable represented on the x-axis and another variable represented on the y-axis. The quadrants are determined by dividing the chart into four equal parts based on a set of criteria that is specific to the data being analyzed. Quadrant charts are often used to identify patterns and trends in data, and to prioritize actions based on the position of data points within the chart. They are commonly used in business, marketing, and risk management, among other fields.\nExample link quadrantChart title Reach and engagement of campaigns x-axis Low Reach --\u003e High Reach y-axis Low Engagement --\u003e High Engagement quadrant-1 We should expand quadrant-2 Need to promote quadrant-3 Re-evaluate quadrant-4 May be improved Campaign A: [0.3, 0.6] Campaign B: [0.45, 0.23] Campaign C: [0.57, 0.69] Campaign D: [0.78, 0.34] Campaign E: [0.40, 0.34] Campaign F: [0.35, 0.78] quadrantChart title Reach and engagement of campaigns x-axis Low Reach --\u003e High Reach y-axis Low Engagement --\u003e High Engagement quadrant-1 We should expand quadrant-2 Need to promote quadrant-3 Re-evaluate quadrant-4 May be improved Campaign A: [0.3, 0.6] Campaign B: [0.45, 0.23] Campaign C: [0.57, 0.69] Campaign D: [0.78, 0.34] Campaign E: [0.40, 0.34] Campaign F: [0.35, 0.78] Syntax link Note If there are no points available in the chart both axis text and quadrant will be rendered in the center of the respective quadrant. If there are points x-axis labels will rendered from the left of the respective quadrant also they will be displayed at the bottom of the chart, and y-axis labels will be rendered at the bottom of the respective quadrant, the quadrant text will render at the top of the respective quadrant.\nNote For points x and y value min value is 0 and max value is 1.\nTitle linkThe title is a short description of the chart and it will always render on top of the chart.\nExample linkquadrantChart title This is a sample example x-axis linkThe x-axis determines what text would be displayed in the x-axis. In x-axis there is two part left and right you can pass both or you can pass only left. The statement should start with x-axis then the left axis text followed by the delimiter --\u003e then right axis text.\nExample link x-axis --\u003e both the left and right axis text will be rendered. x-axis only the left axis text will be rendered. y-axis linkThe y-axis determines what text would be displayed in the y-axis. In y-axis there is two part top and bottom you can pass both or you can pass only bottom. The statement should start with y-axis then the bottom axis text followed by the delimiter --\u003e then top axis text.\nExample link y-axis --\u003e both the bottom and top axis text will be rendered. y-axis only the bottom axis text will be rendered. Quadrants text linkThe quadrant-[1,2,3,4] determine what text would be displayed inside the quadrants.\nExample link quadrant-1 determine what text will be rendered inside the top right quadrant. quadrant-2 determine what text will be rendered inside the top left quadrant. quadrant-3 determine what text will be rendered inside the bottom left quadrant. quadrant-4 determine what text will be rendered inside the bottom right quadrant. Points linkPoints are used to plot a circle inside the quadrantChart. The syntax is : [x, y] here x and y value is in the range 0 - 1.\nExample link Point 1: [0.75, 0.80] here the Point 1 will be drawn in the top right quadrant. Point 2: [0.35, 0.24] here the Point 2 will be drawn in the bottom left quadrant. Chart Configurations link Parameter Description Default value chartWidth Width of the chart 500 chartHeight Height of the chart 500 titlePadding Top and Bottom padding of the title 10 titleFontSize Title font size 20 quadrantPadding Padding outside all the quadrants 5 quadrantTextTopPadding Quadrant text top padding when text is drawn on top ( not data points are there) 5 quadrantLabelFontSize Quadrant text font size 16 quadrantInternalBorderStrokeWidth Border stroke width inside the quadrants 1 quadrantExternalBorderStrokeWidth Quadrant external border stroke width 2 xAxisLabelPadding Top and bottom padding of x-axis text 5 xAxisLabelFontSize X-axis texts font size 16 xAxisPosition Position of x-axis (top , bottom) if there are points the x-axis will always be rendered in bottom ’top' yAxisLabelPadding Left and Right padding of y-axis text 5 yAxisLabelFontSize Y-axis texts font size 16 yAxisPosition Position of y-axis (left , right) ’left' pointTextPadding Padding between point and the below text 5 pointLabelFontSize Point text font size 12 pointRadius Radius of the point to be drawn 5 Chart Theme Variables link Parameter Description quadrant1Fill Fill color of the top right quadrant quadrant2Fill Fill color of the top left quadrant quadrant3Fill Fill color of the bottom left quadrant quadrant4Fill Fill color of the bottom right quadrant quadrant1TextFill Text color of the top right quadrant quadrant2TextFill Text color of the top left quadrant quadrant3TextFill Text color of the bottom left quadrant quadrant4TextFill Text color of the bottom right quadrant quadrantPointFill Points fill color quadrantPointTextFill Points text color quadrantXAxisTextFill X-axis text color quadrantYAxisTextFill Y-axis text color quadrantInternalBorderStrokeFill Quadrants inner border color quadrantExternalBorderStrokeFill Quadrants outer border color quadrantTitleFill Title color Example on config and theme link %%{init: {\"quadrantChart\": {\"chartWidth\": 400, \"chartHeight\": 400}, \"themeVariables\": {\"quadrant1TextFill\": \"#ff0000\"} }}%% quadrantChart x-axis Urgent --\u003e Not Urgent y-axis Not Important --\u003e \"Important ❤\" quadrant-1 Plan quadrant-2 Do quadrant-3 Delegate quadrant-4 Delete %%{init: {\"quadrantChart\": {\"chartWidth\": 400, \"chartHeight\": 400}, \"themeVariables\": {\"quadrant1TextFill\": \"#ff0000\"} }}%% quadrantChart x-axis Urgent --\u003e Not Urgent y-axis Not Important --\u003e \"Important ❤\" quadrant-1 Plan quadrant-2 Do quadrant-3 Delegate quadrant-4 Delete "
            }
        );
    index.add(
            {
                id:  77 ,
                href: "\/docs\/mix\/mermaid\/syntax\/requirementdiagram\/",
                title: "Requirement Diagram",
                description: "Requirement Diagram link A Requirement diagram provides a visualization for requirements and their connections, to each other and other documented elements. The modeling specs follow those defined by SysML v1.6.\nRendering requirements is straightforward.\nrequirementDiagram requirement test_req { id: 1 text: the test text. risk: high verifymethod: test } element test_entity { type: simulation } test_entity - satisfies -\u003e test_req requirementDiagram requirement test_req { id: 1 text: the test text. risk: high verifymethod: test } element test_entity { type: simulation } test_entity - satisfies -\u003e test_req Syntax linkThere are three types of components to a requirement diagram: requirement, element, and relationship.\n",
                content: "Requirement Diagram link A Requirement diagram provides a visualization for requirements and their connections, to each other and other documented elements. The modeling specs follow those defined by SysML v1.6.\nRendering requirements is straightforward.\nrequirementDiagram requirement test_req { id: 1 text: the test text. risk: high verifymethod: test } element test_entity { type: simulation } test_entity - satisfies -\u003e test_req requirementDiagram requirement test_req { id: 1 text: the test text. risk: high verifymethod: test } element test_entity { type: simulation } test_entity - satisfies -\u003e test_req Syntax linkThere are three types of components to a requirement diagram: requirement, element, and relationship.\nThe grammar for defining each is defined below. Words denoted in angle brackets, such as , are enumerated keywords that have options elaborated in a table. user_defined_... is use in any place where user input is expected.\nAn important note on user text: all input can be surrounded in quotes or not. For example, both Id: \"here is an example\" and Id: here is an example are both valid. However, users must be careful with unquoted input. The parser will fail if another keyword is detected.\nRequirement linkA requirement definition contains a requirement type, name, id, text, risk, and verification method. The syntax follows:\nuser_defined_name { id: user_defined_id text: user_defined text risk: verifymethod: } Type, risk, and method are enumerations defined in SysML.\nKeyword Options Type requirement, functionalRequirement, interfaceRequirement, performanceRequirement, physicalRequirement, designConstraint Risk Low, Medium, High VerificationMethod Analysis, Inspection, Test, Demonstration Element linkAn element definition contains an element name, type, and document reference. These three are all user defined. The element feature is intended to be lightweight but allow requirements to be connected to portions of other documents.\nelement user_defined_name { type: user_defined_type docref: user_defined_ref } Relationship linkRelationships are comprised of a source node, destination node, and relationship type.\nEach follows the definition format of\n{name of source} - -\u003e {name of destination} or\n{name of destination} \u003c- - {name of source} “name of source” and “name of destination” should be names of requirement or element nodes defined elsewhere.\nA relationship type can be one of contains, copies, derives, satisfies, verifies, refines, or traces.\nEach relationship is labeled in the diagram.\nLarger Example linkThis example uses all features of the diagram.\nrequirementDiagram requirement test_req { id: 1 text: the test text. risk: high verifymethod: test } functionalRequirement test_req2 { id: 1.1 text: the second test text. risk: low verifymethod: inspection } performanceRequirement test_req3 { id: 1.2 text: the third test text. risk: medium verifymethod: demonstration } interfaceRequirement test_req4 { id: 1.2.1 text: the fourth test text. risk: medium verifymethod: analysis } physicalRequirement test_req5 { id: 1.2.2 text: the fifth test text. risk: medium verifymethod: analysis } designConstraint test_req6 { id: 1.2.3 text: the sixth test text. risk: medium verifymethod: analysis } element test_entity { type: simulation } element test_entity2 { type: word doc docRef: reqs/test_entity } element test_entity3 { type: \"test suite\" docRef: github.com/all_the_tests } test_entity - satisfies -\u003e test_req2 test_req - traces -\u003e test_req2 test_req - contains -\u003e test_req3 test_req3 - contains -\u003e test_req4 test_req4 - derives -\u003e test_req5 test_req5 - refines -\u003e test_req6 test_entity3 - verifies -\u003e test_req5 test_req \u003c- copies - test_entity2 requirementDiagram requirement test_req { id: 1 text: the test text. risk: high verifymethod: test } functionalRequirement test_req2 { id: 1.1 text: the second test text. risk: low verifymethod: inspection } performanceRequirement test_req3 { id: 1.2 text: the third test text. risk: medium verifymethod: demonstration } interfaceRequirement test_req4 { id: 1.2.1 text: the fourth test text. risk: medium verifymethod: analysis } physicalRequirement test_req5 { id: 1.2.2 text: the fifth test text. risk: medium verifymethod: analysis } designConstraint test_req6 { id: 1.2.3 text: the sixth test text. risk: medium verifymethod: analysis } element test_entity { type: simulation } element test_entity2 { type: word doc docRef: reqs/test_entity } element test_entity3 { type: \"test suite\" docRef: github.com/all_the_tests } test_entity - satisfies -\u003e test_req2 test_req - traces -\u003e test_req2 test_req - contains -\u003e test_req3 test_req3 - contains -\u003e test_req4 test_req4 - derives -\u003e test_req5 test_req5 - refines -\u003e test_req6 test_entity3 - verifies -\u003e test_req5 test_req \u003c- copies - test_entity2 "
            }
        );
    index.add(
            {
                id:  78 ,
                href: "\/docs\/mix\/mermaid\/syntax\/sankey\/",
                title: "Sankey diagram (v10.3.0+)",
                description: "Sankey diagram (v10.3.0+) link A sankey diagram is a visualization used to depict a flow from one set of values to another.\nWarning This is an experimental diagram. Its syntax are very close to plain CSV, but it is to be extended in the nearest future.\nThe things being connected are called nodes and the connections are called links.\nExample linkThis example taken from observable. It may be rendered a little bit differently, though, in terms of size and colors.\n",
                content: "Sankey diagram (v10.3.0+) link A sankey diagram is a visualization used to depict a flow from one set of values to another.\nWarning This is an experimental diagram. Its syntax are very close to plain CSV, but it is to be extended in the nearest future.\nThe things being connected are called nodes and the connections are called links.\nExample linkThis example taken from observable. It may be rendered a little bit differently, though, in terms of size and colors.\n--- config: sankey: showValues: false --- sankey-beta Agricultural 'waste',Bio-conversion,124.729 Bio-conversion,Liquid,0.597 Bio-conversion,Losses,26.862 Bio-conversion,Solid,280.322 Bio-conversion,Gas,81.144 Biofuel imports,Liquid,35 Biomass imports,Solid,35 Coal imports,Coal,11.606 Coal reserves,Coal,63.965 Coal,Solid,75.571 District heating,Industry,10.639 District heating,Heating and cooling - commercial,22.505 District heating,Heating and cooling - homes,46.184 Electricity grid,Over generation / exports,104.453 Electricity grid,Heating and cooling - homes,113.726 Electricity grid,H2 conversion,27.14 Electricity grid,Industry,342.165 Electricity grid,Road transport,37.797 Electricity grid,Agriculture,4.412 Electricity grid,Heating and cooling - commercial,40.858 Electricity grid,Losses,56.691 Electricity grid,Rail transport,7.863 Electricity grid,Lighting \u0026 appliances - commercial,90.008 Electricity grid,Lighting \u0026 appliances - homes,93.494 Gas imports,Ngas,40.719 Gas reserves,Ngas,82.233 Gas,Heating and cooling - commercial,0.129 Gas,Losses,1.401 Gas,Thermal generation,151.891 Gas,Agriculture,2.096 Gas,Industry,48.58 Geothermal,Electricity grid,7.013 H2 conversion,H2,20.897 H2 conversion,Losses,6.242 H2,Road transport,20.897 Hydro,Electricity grid,6.995 Liquid,Industry,121.066 Liquid,International shipping,128.69 Liquid,Road transport,135.835 Liquid,Domestic aviation,14.458 Liquid,International aviation,206.267 Liquid,Agriculture,3.64 Liquid,National navigation,33.218 Liquid,Rail transport,4.413 Marine algae,Bio-conversion,4.375 Ngas,Gas,122.952 Nuclear,Thermal generation,839.978 Oil imports,Oil,504.287 Oil reserves,Oil,107.703 Oil,Liquid,611.99 Other waste,Solid,56.587 Other waste,Bio-conversion,77.81 Pumped heat,Heating and cooling - homes,193.026 Pumped heat,Heating and cooling - commercial,70.672 Solar PV,Electricity grid,59.901 Solar Thermal,Heating and cooling - homes,19.263 Solar,Solar Thermal,19.263 Solar,Solar PV,59.901 Solid,Agriculture,0.882 Solid,Thermal generation,400.12 Solid,Industry,46.477 Thermal generation,Electricity grid,525.531 Thermal generation,Losses,787.129 Thermal generation,District heating,79.329 Tidal,Electricity grid,9.452 UK land based bioenergy,Bio-conversion,182.01 Wave,Electricity grid,19.013 Wind,Electricity grid,289.366 --- config: sankey: showValues: false --- sankey-beta Agricultural 'waste',Bio-conversion,124.729 Bio-conversion,Liquid,0.597 Bio-conversion,Losses,26.862 Bio-conversion,Solid,280.322 Bio-conversion,Gas,81.144 Biofuel imports,Liquid,35 Biomass imports,Solid,35 Coal imports,Coal,11.606 Coal reserves,Coal,63.965 Coal,Solid,75.571 District heating,Industry,10.639 District heating,Heating and cooling - commercial,22.505 District heating,Heating and cooling - homes,46.184 Electricity grid,Over generation / exports,104.453 Electricity grid,Heating and cooling - homes,113.726 Electricity grid,H2 conversion,27.14 Electricity grid,Industry,342.165 Electricity grid,Road transport,37.797 Electricity grid,Agriculture,4.412 Electricity grid,Heating and cooling - commercial,40.858 Electricity grid,Losses,56.691 Electricity grid,Rail transport,7.863 Electricity grid,Lighting \u0026 appliances - commercial,90.008 Electricity grid,Lighting \u0026 appliances - homes,93.494 Gas imports,Ngas,40.719 Gas reserves,Ngas,82.233 Gas,Heating and cooling - commercial,0.129 Gas,Losses,1.401 Gas,Thermal generation,151.891 Gas,Agriculture,2.096 Gas,Industry,48.58 Geothermal,Electricity grid,7.013 H2 conversion,H2,20.897 H2 conversion,Losses,6.242 H2,Road transport,20.897 Hydro,Electricity grid,6.995 Liquid,Industry,121.066 Liquid,International shipping,128.69 Liquid,Road transport,135.835 Liquid,Domestic aviation,14.458 Liquid,International aviation,206.267 Liquid,Agriculture,3.64 Liquid,National navigation,33.218 Liquid,Rail transport,4.413 Marine algae,Bio-conversion,4.375 Ngas,Gas,122.952 Nuclear,Thermal generation,839.978 Oil imports,Oil,504.287 Oil reserves,Oil,107.703 Oil,Liquid,611.99 Other waste,Solid,56.587 Other waste,Bio-conversion,77.81 Pumped heat,Heating and cooling - homes,193.026 Pumped heat,Heating and cooling - commercial,70.672 Solar PV,Electricity grid,59.901 Solar Thermal,Heating and cooling - homes,19.263 Solar,Solar Thermal,19.263 Solar,Solar PV,59.901 Solid,Agriculture,0.882 Solid,Thermal generation,400.12 Solid,Industry,46.477 Thermal generation,Electricity grid,525.531 Thermal generation,Losses,787.129 Thermal generation,District heating,79.329 Tidal,Electricity grid,9.452 UK land based bioenergy,Bio-conversion,182.01 Wave,Electricity grid,19.013 Wind,Electricity grid,289.366 Syntax linkThe idea behind syntax is that a user types sankey-beta keyword first, then pastes raw CSV below and get the result.\nIt implements CSV standard as described here with subtle differences:\nCSV must contain 3 columns only It is allowed to have empty lines without comma separators for visual purposes Basic linkIt is implied that 3 columns inside CSV should represent source, target and value accordingly:\nsankey-beta %% source,target,value Electricity grid,Over generation / exports,104.453 Electricity grid,Heating and cooling - homes,113.726 Electricity grid,H2 conversion,27.14 sankey-beta %% source,target,value Electricity grid,Over generation / exports,104.453 Electricity grid,Heating and cooling - homes,113.726 Electricity grid,H2 conversion,27.14 Empty Lines linkCSV does not support empty lines without comma delimiters by default. But you can add them if needed:\nsankey-beta Bio-conversion,Losses,26.862 Bio-conversion,Solid,280.322 Bio-conversion,Gas,81.144 sankey-beta Bio-conversion,Losses,26.862 Bio-conversion,Solid,280.322 Bio-conversion,Gas,81.144 Commas linkIf you need to have a comma, wrap it in double quotes:\nsankey-beta Pumped heat,\"Heating and cooling, homes\",193.026 Pumped heat,\"Heating and cooling, commercial\",70.672 sankey-beta Pumped heat,\"Heating and cooling, homes\",193.026 Pumped heat,\"Heating and cooling, commercial\",70.672 Double Quotes linkIf you need to have double quote, put a pair of them inside quoted string:\nsankey-beta Pumped heat,\"Heating and cooling, \"\"homes\"\"\",193.026 Pumped heat,\"Heating and cooling, \"\"commercial\"\"\",70.672 sankey-beta Pumped heat,\"Heating and cooling, \"\"homes\"\"\",193.026 Pumped heat,\"Heating and cooling, \"\"commercial\"\"\",70.672 Configuration linkYou can customize link colors, node alignments and diagram dimensions.\nLinks Coloring linkYou can adjust links’ color by setting linkColor to one of those:\nsource - link will be of a source node color target - link will be of a target node color gradient - link color will be smoothly transient between source and target node colors hex code of color, like #a1a1a1 Node Alignment linkGraph layout can be changed by setting nodeAlignment to:\njustify center left right "
            }
        );
    index.add(
            {
                id:  79 ,
                href: "\/docs\/mix\/mermaid\/syntax\/sequencediagram\/",
                title: "Sequence diagrams",
                description: "Sequence diagrams link A Sequence diagram is an interaction diagram that shows how processes operate with one another and in what order.\nMermaid can render sequence diagrams.\nsequenceDiagram Alice-\u003e\u003eJohn: Hello John, how are you? John--\u003e\u003eAlice: Great! Alice-)John: See you later! sequenceDiagram Alice-\u003e\u003eJohn: Hello John, how are you? John--\u003e\u003eAlice: Great! Alice-)John: See you later! Note A note on nodes, the word “end” could potentially break the diagram, due to the way that the mermaid language is scripted.\n",
                content: "Sequence diagrams link A Sequence diagram is an interaction diagram that shows how processes operate with one another and in what order.\nMermaid can render sequence diagrams.\nsequenceDiagram Alice-\u003e\u003eJohn: Hello John, how are you? John--\u003e\u003eAlice: Great! Alice-)John: See you later! sequenceDiagram Alice-\u003e\u003eJohn: Hello John, how are you? John--\u003e\u003eAlice: Great! Alice-)John: See you later! Note A note on nodes, the word “end” could potentially break the diagram, due to the way that the mermaid language is scripted.\nIf unavoidable, one must use parentheses(), quotation marks “”, or brackets {},[], to enclose the word “end”. i.e : (end), [end], {end}.\nSyntax linkParticipants linkThe participants can be defined implicitly as in the first example on this page. The participants or actors are rendered in order of appearance in the diagram source text. Sometimes you might want to show the participants in a different order than how they appear in the first message. It is possible to specify the actor’s order of appearance by doing the following:\nsequenceDiagram participant Alice participant Bob Alice-\u003e\u003eBob: Hi Bob Bob-\u003e\u003eAlice: Hi Alice sequenceDiagram participant Alice participant Bob Alice-\u003e\u003eBob: Hi Bob Bob-\u003e\u003eAlice: Hi Alice Actors linkIf you specifically want to use the actor symbol instead of a rectangle with text you can do so by using actor statements as per below.\nsequenceDiagram actor Alice actor Bob Alice-\u003e\u003eBob: Hi Bob Bob-\u003e\u003eAlice: Hi Alice sequenceDiagram actor Alice actor Bob Alice-\u003e\u003eBob: Hi Bob Bob-\u003e\u003eAlice: Hi Alice Aliases linkThe actor can have a convenient identifier and a descriptive label.\nsequenceDiagram participant A as Alice participant J as John A-\u003e\u003eJ: Hello John, how are you? J-\u003e\u003eA: Great! sequenceDiagram participant A as Alice participant J as John A-\u003e\u003eJ: Hello John, how are you? J-\u003e\u003eA: Great! Actor Creation and Destruction (v10.3.0+) linkIt is possible to create and destroy actors by messages. To do so, add a create or destroy directive before the message.\ncreate participant B A --\u003e B: Hello Create directives support actor/participant distinction and aliases. The sender or the recipient of a message can be destroyed but only the recipient can be created.\nsequenceDiagram Alice-\u003e\u003eBob: Hello Bob, how are you ? Bob-\u003e\u003eAlice: Fine, thank you. And you? create participant Carl Alice-\u003e\u003eCarl: Hi Carl! create actor D as Donald Carl-\u003e\u003eD: Hi! destroy Carl Alice-xCarl: We are too many destroy Bob Bob-\u003e\u003eAlice: I agree sequenceDiagram Alice-\u003e\u003eBob: Hello Bob, how are you ? Bob-\u003e\u003eAlice: Fine, thank you. And you? create participant Carl Alice-\u003e\u003eCarl: Hi Carl! create actor D as Donald Carl-\u003e\u003eD: Hi! destroy Carl Alice-xCarl: We are too many destroy Bob Bob-\u003e\u003eAlice: I agree Grouping / Box linkThe actor(s) can be grouped in vertical boxes. You can define a color (if not, it will be transparent) and/or a descriptive label using the following notation:\nbox Aqua Group Description ... actors ... end box Group without description ... actors ... end box rgb(33,66,99) ... actors ... end Note If your group name is a color you can force the color to be transparent:\nbox transparent Aqua ... actors ... end sequenceDiagram box Purple Alice \u0026 John participant A participant J end box Another Group participant B participant C end A-\u003e\u003eJ: Hello John, how are you? J-\u003e\u003eA: Great! A-\u003e\u003eB: Hello Bob, how is Charly? B-\u003e\u003eC: Hello Charly, how are you? sequenceDiagram box Purple Alice \u0026 John participant A participant J end box Another Group participant B participant C end A-\u003e\u003eJ: Hello John, how are you? J-\u003e\u003eA: Great! A-\u003e\u003eB: Hello Bob, how is Charly? B-\u003e\u003eC: Hello Charly, how are you? Messages linkMessages can be of two displayed either solid or with a dotted line.\n[Actor][Arrow][Actor]:Message text There are six types of arrows currently supported:\nType Description -\u003e Solid line without arrow --\u003e Dotted line without arrow -\u003e\u003e Solid line with arrowhead --\u003e\u003e Dotted line with arrowhead -x Solid line with a cross at the end --x Dotted line with a cross at the end. -) Solid line with an open arrow at the end (async) --) Dotted line with a open arrow at the end (async) Activations linkIt is possible to activate and deactivate an actor. (de)activation can be dedicated declarations:\nsequenceDiagram Alice-\u003e\u003eJohn: Hello John, how are you? activate John John--\u003e\u003eAlice: Great! deactivate John sequenceDiagram Alice-\u003e\u003eJohn: Hello John, how are you? activate John John--\u003e\u003eAlice: Great! deactivate John There is also a shortcut notation by appending +/- suffix to the message arrow:\nsequenceDiagram Alice-\u003e\u003e+John: Hello John, how are you? John--\u003e\u003e-Alice: Great! sequenceDiagram Alice-\u003e\u003e+John: Hello John, how are you? John--\u003e\u003e-Alice: Great! Activations can be stacked for same actor:\nsequenceDiagram Alice-\u003e\u003e+John: Hello John, how are you? Alice-\u003e\u003e+John: John, can you hear me? John--\u003e\u003e-Alice: Hi Alice, I can hear you! John--\u003e\u003e-Alice: I feel great! sequenceDiagram Alice-\u003e\u003e+John: Hello John, how are you? Alice-\u003e\u003e+John: John, can you hear me? John--\u003e\u003e-Alice: Hi Alice, I can hear you! John--\u003e\u003e-Alice: I feel great! Notes linkIt is possible to add notes to a sequence diagram. This is done by the notation Note [ right of | left of | over ] [Actor]: Text in note content\nSee the example below:\nsequenceDiagram participant John Note right of John: Text in note sequenceDiagram participant John Note right of John: Text in note It is also possible to create notes spanning two participants:\nsequenceDiagram Alice-\u003eJohn: Hello John, how are you? Note over Alice,John: A typical interaction sequenceDiagram Alice-\u003eJohn: Hello John, how are you? Note over Alice,John: A typical interaction It is also possible to add a line break (applies to text input in general):\nsequenceDiagram Alice-\u003eJohn: Hello John, how are you? Note over Alice,John: A typical interactionBut now in two lines sequenceDiagram Alice-\u003eJohn: Hello John, how are you? Note over Alice,John: A typical interactionBut now in two lines Loops linkIt is possible to express loops in a sequence diagram. This is done by the notation\nloop Loop text ... statements ... end See the example below:\nsequenceDiagram Alice-\u003eJohn: Hello John, how are you? loop Every minute John--\u003eAlice: Great! end sequenceDiagram Alice-\u003eJohn: Hello John, how are you? loop Every minute John--\u003eAlice: Great! end Alt linkIt is possible to express alternative paths in a sequence diagram. This is done by the notation\nalt Describing text ... statements ... else ... statements ... end or if there is sequence that is optional (if without else).\nopt Describing text ... statements ... end See the example below:\nsequenceDiagram Alice-\u003e\u003eBob: Hello Bob, how are you? alt is sick Bob-\u003e\u003eAlice: Not so good :( else is well Bob-\u003e\u003eAlice: Feeling fresh like a daisy end opt Extra response Bob-\u003e\u003eAlice: Thanks for asking end sequenceDiagram Alice-\u003e\u003eBob: Hello Bob, how are you? alt is sick Bob-\u003e\u003eAlice: Not so good :( else is well Bob-\u003e\u003eAlice: Feeling fresh like a daisy end opt Extra response Bob-\u003e\u003eAlice: Thanks for asking end Parallel linkIt is possible to show actions that are happening in parallel.\nThis is done by the notation\npar [Action 1] ... statements ... and [Action 2] ... statements ... and [Action N] ... statements ... end See the example below:\nsequenceDiagram par Alice to Bob Alice-\u003e\u003eBob: Hello guys! and Alice to John Alice-\u003e\u003eJohn: Hello guys! end Bob--\u003e\u003eAlice: Hi Alice! John--\u003e\u003eAlice: Hi Alice! sequenceDiagram par Alice to Bob Alice-\u003e\u003eBob: Hello guys! and Alice to John Alice-\u003e\u003eJohn: Hello guys! end Bob--\u003e\u003eAlice: Hi Alice! John--\u003e\u003eAlice: Hi Alice! It is also possible to nest parallel blocks.\nsequenceDiagram par Alice to Bob Alice-\u003e\u003eBob: Go help John and Alice to John Alice-\u003e\u003eJohn: I want this done today par John to Charlie John-\u003e\u003eCharlie: Can we do this today? and John to Diana John-\u003e\u003eDiana: Can you help us today? end end sequenceDiagram par Alice to Bob Alice-\u003e\u003eBob: Go help John and Alice to John Alice-\u003e\u003eJohn: I want this done today par John to Charlie John-\u003e\u003eCharlie: Can we do this today? and John to Diana John-\u003e\u003eDiana: Can you help us today? end end Critical Region linkIt is possible to show actions that must happen automatically with conditional handling of circumstances.\nThis is done by the notation\ncritical [Action that must be performed] ... statements ... option [Circumstance A] ... statements ... option [Circumstance B] ... statements ... end See the example below:\nsequenceDiagram critical Establish a connection to the DB Service--\u003eDB: connect option Network timeout Service--\u003eService: Log error option Credentials rejected Service--\u003eService: Log different error end sequenceDiagram critical Establish a connection to the DB Service--\u003eDB: connect option Network timeout Service--\u003eService: Log error option Credentials rejected Service--\u003eService: Log different error end It is also possible to have no options at all\nsequenceDiagram critical Establish a connection to the DB Service--\u003eDB: connect end sequenceDiagram critical Establish a connection to the DB Service--\u003eDB: connect end This critical block can also be nested, equivalently to the par statement as seen above.\nBreak linkIt is possible to indicate a stop of the sequence within the flow (usually used to model exceptions).\nThis is done by the notation\nbreak [something happened] ... statements ... end See the example below:\nsequenceDiagram Consumer--\u003eAPI: Book something API--\u003eBookingService: Start booking process break when the booking process fails API--\u003eConsumer: show failure end API--\u003eBillingService: Start billing process sequenceDiagram Consumer--\u003eAPI: Book something API--\u003eBookingService: Start booking process break when the booking process fails API--\u003eConsumer: show failure end API--\u003eBillingService: Start billing process Background Highlighting linkIt is possible to highlight flows by providing colored background rects. This is done by the notation\nThe colors are defined using rgb and rgba syntax.\nrect rgb(0, 255, 0) ... content ... end rect rgba(0, 0, 255, .1) ... content ... end See the examples below:\nsequenceDiagram participant Alice participant John rect rgb(191, 223, 255) note right of Alice: Alice calls John. Alice-\u003e\u003e+John: Hello John, how are you? rect rgb(200, 150, 255) Alice-\u003e\u003e+John: John, can you hear me? John--\u003e\u003e-Alice: Hi Alice, I can hear you! end John--\u003e\u003e-Alice: I feel great! end Alice -\u003e\u003e+ John: Did you want to go to the game tonight? John --\u003e\u003e- Alice: Yeah! See you there. sequenceDiagram participant Alice participant John rect rgb(191, 223, 255) note right of Alice: Alice calls John. Alice-\u003e\u003e+John: Hello John, how are you? rect rgb(200, 150, 255) Alice-\u003e\u003e+John: John, can you hear me? John--\u003e\u003e-Alice: Hi Alice, I can hear you! end John--\u003e\u003e-Alice: I feel great! end Alice -\u003e\u003e+ John: Did you want to go to the game tonight? John --\u003e\u003e- Alice: Yeah! See you there. Comments linkComments can be entered within a sequence diagram, which will be ignored by the parser. Comments need to be on their own line, and must be prefaced with %% (double percent signs). Any text after the start of the comment to the next newline will be treated as a comment, including any diagram syntax\nsequenceDiagram Alice-\u003e\u003eJohn: Hello John, how are you? %% this is a comment John--\u003e\u003eAlice: Great! sequenceDiagram Alice-\u003e\u003eJohn: Hello John, how are you? %% this is a comment John--\u003e\u003eAlice: Great! Entity codes to escape characters linkIt is possible to escape characters using the syntax exemplified here.\nsequenceDiagram A-\u003e\u003eB: I #9829; you! B-\u003e\u003eA: I #9829; you #infin; times more! sequenceDiagram A-\u003e\u003eB: I #9829; you! B-\u003e\u003eA: I #9829; you #infin; times more! Numbers given are base 10, so # can be encoded as #35;. It is also supported to use HTML character names.\nBecause semicolons can be used instead of line breaks to define the markup, you need to use #59; to include a semicolon in message text.\nsequenceNumbers linkIt is possible to get a sequence number attached to each arrow in a sequence diagram. This can be configured when adding mermaid to the website as shown below:\nIt can also be turned on via the diagram code as in the diagram:\nsequenceDiagram autonumber Alice-\u003e\u003eJohn: Hello John, how are you? loop Healthcheck John-\u003e\u003eJohn: Fight against hypochondria end Note right of John: Rational thoughts! John--\u003e\u003eAlice: Great! John-\u003e\u003eBob: How about you? Bob--\u003e\u003eJohn: Jolly good! sequenceDiagram autonumber Alice-\u003e\u003eJohn: Hello John, how are you? loop Healthcheck John-\u003e\u003eJohn: Fight against hypochondria end Note right of John: Rational thoughts! John--\u003e\u003eAlice: Great! John-\u003e\u003eBob: How about you? Bob--\u003e\u003eJohn: Jolly good! Actor Menus linkActors can have popup-menus containing individualized links to external pages. For example, if an actor represented a web service, useful links might include a link to the service health dashboard, repo containing the code for the service, or a wiki page describing the service.\nThis can be configured by adding one or more link lines with the format:\nlink : @ sequenceDiagram participant Alice participant John link Alice: Dashboard @ https://dashboard.contoso.com/alice link Alice: Wiki @ https://wiki.contoso.com/alice link John: Dashboard @ https://dashboard.contoso.com/john link John: Wiki @ https://wiki.contoso.com/john Alice-\u003e\u003eJohn: Hello John, how are you? John--\u003e\u003eAlice: Great! Alice-)John: See you later! sequenceDiagram participant Alice participant John link Alice: Dashboard @ https://dashboard.contoso.com/alice link Alice: Wiki @ https://wiki.contoso.com/alice link John: Dashboard @ https://dashboard.contoso.com/john link John: Wiki @ https://wiki.contoso.com/john Alice-\u003e\u003eJohn: Hello John, how are you? John--\u003e\u003eAlice: Great! Alice-)John: See you later! Advanced Menu Syntax linkThere is an advanced syntax that relies on JSON formatting. If you are comfortable with JSON format, then this exists as well.\nThis can be configured by adding the links lines with the format:\nlinks : An example is below:\nsequenceDiagram participant Alice participant John links Alice: {\"Dashboard\": \"https://dashboard.contoso.com/alice\", \"Wiki\": \"https://wiki.contoso.com/alice\"} links John: {\"Dashboard\": \"https://dashboard.contoso.com/john\", \"Wiki\": \"https://wiki.contoso.com/john\"} Alice-\u003e\u003eJohn: Hello John, how are you? John--\u003e\u003eAlice: Great! Alice-)John: See you later! sequenceDiagram participant Alice participant John links Alice: {\"Dashboard\": \"https://dashboard.contoso.com/alice\", \"Wiki\": \"https://wiki.contoso.com/alice\"} links John: {\"Dashboard\": \"https://dashboard.contoso.com/john\", \"Wiki\": \"https://wiki.contoso.com/john\"} Alice-\u003e\u003eJohn: Hello John, how are you? John--\u003e\u003eAlice: Great! Alice-)John: See you later! Styling linkStyling of a sequence diagram is done by defining a number of css classes. During rendering these classes are extracted from the file located at src/themes/sequence.scss\nClasses used link Class Description actor Style for the actor box at the top of the diagram. text.actor Styles for text in the actor box at the top of the diagram. actor-line The vertical line for an actor. messageLine0 Styles for the solid message line. messageLine1 Styles for the dotted message line. messageText Defines styles for the text on the message arrows. labelBox Defines styles label to left in a loop. labelText Styles for the text in label for loops. loopText Styles for the text in the loop box. loopLine Defines styles for the lines in the loop box. note Styles for the note box. noteText Styles for the text on in the note boxes. Sample stylesheet link body { background: white; } .actor { stroke: #ccccff; fill: #ececff; } text.actor { fill: black; stroke: none; font-family: Helvetica; } .actor-line { stroke: grey; } .messageLine0 { stroke-width: 1.5; stroke-dasharray: '2 2'; marker-end: 'url(#arrowhead)'; stroke: black; } .messageLine1 { stroke-width: 1.5; stroke-dasharray: '2 2'; stroke: black; } #arrowhead { fill: black; } .messageText { fill: black; stroke: none; font-family: 'trebuchet ms', verdana, arial; font-size: 14px; } .labelBox { stroke: #ccccff; fill: #ececff; } .labelText { fill: black; stroke: none; font-family: 'trebuchet ms', verdana, arial; } .loopText { fill: black; stroke: none; font-family: 'trebuchet ms', verdana, arial; } .loopLine { stroke-width: 2; stroke-dasharray: '2 2'; marker-end: 'url(#arrowhead)'; stroke: #ccccff; } .note { stroke: #decc93; fill: #fff5ad; } .noteText { fill: black; stroke: none; font-family: 'trebuchet ms', verdana, arial; font-size: 14px; } Configuration linkIt is possible to adjust the margins for rendering the sequence diagram.\nThis is done by defining mermaid.sequenceConfig or by the CLI to use a json file with the configuration. How to use the CLI is described in the mermaidCLI page. mermaid.sequenceConfig can be set to a JSON string with config parameters or the corresponding object.\nmermaid.sequenceConfig = { diagramMarginX: 50, diagramMarginY: 10, boxTextMargin: 5, noteMargin: 10, messageMargin: 35, mirrorActors: true, }; Possible configuration parameters: link Parameter Description Default value mirrorActors Turns on/off the rendering of actors below the diagram as well as above it false bottomMarginAdj Adjusts how far down the graph ended. Wide borders styles with css could generate unwanted clipping which is why this config param exists. 1 actorFontSize Sets the font size for the actor’s description 14 actorFontFamily Sets the font family for the actor’s description “Open Sans”, sans-serif actorFontWeight Sets the font weight for the actor’s description “Open Sans”, sans-serif noteFontSize Sets the font size for actor-attached notes 14 noteFontFamily Sets the font family for actor-attached notes “trebuchet ms”, verdana, arial noteFontWeight Sets the font weight for actor-attached notes “trebuchet ms”, verdana, arial noteAlign Sets the text alignment for text in actor-attached notes center messageFontSize Sets the font size for actor\u003c-\u003eactor messages 16 messageFontFamily Sets the font family for actor\u003c-\u003eactor messages “trebuchet ms”, verdana, arial messageFontWeight Sets the font weight for actor\u003c-\u003eactor messages “trebuchet ms”, verdana, arial "
            }
        );
    index.add(
            {
                id:  80 ,
                href: "\/docs\/mix\/mermaid\/syntax\/statediagram\/",
                title: "State diagrams",
                description: "State diagrams link “A state diagram is a type of diagram used in computer science and related fields to describe the behavior of systems. State diagrams require that the system described is composed of a finite number of states; sometimes, this is indeed the case, while at other times this is a reasonable abstraction.” Wikipedia\nMermaid can render state diagrams. The syntax tries to be compliant with the syntax used in plantUml as this will make it easier for users to share diagrams between mermaid and plantUml.\n",
                content: "State diagrams link “A state diagram is a type of diagram used in computer science and related fields to describe the behavior of systems. State diagrams require that the system described is composed of a finite number of states; sometimes, this is indeed the case, while at other times this is a reasonable abstraction.” Wikipedia\nMermaid can render state diagrams. The syntax tries to be compliant with the syntax used in plantUml as this will make it easier for users to share diagrams between mermaid and plantUml.\n--- title: Simple sample --- stateDiagram-v2 [*] --\u003e Still Still --\u003e [*] Still --\u003e Moving Moving --\u003e Still Moving --\u003e Crash Crash --\u003e [*] --- title: Simple sample --- stateDiagram-v2 [*] --\u003e Still Still --\u003e [*] Still --\u003e Moving Moving --\u003e Still Moving --\u003e Crash Crash --\u003e [*] Older renderer:\nstateDiagram [*] --\u003e Still Still --\u003e [*] Still --\u003e Moving Moving --\u003e Still Moving --\u003e Crash Crash --\u003e [*] stateDiagram [*] --\u003e Still Still --\u003e [*] Still --\u003e Moving Moving --\u003e Still Moving --\u003e Crash Crash --\u003e [*] In state diagrams systems are described in terms of states and how one state can change to another state via a transition. The example diagram above shows three states: Still, Moving and Crash. You start in the Still state. From Still you can change to the Moving state. From Moving you can change either back to the Still state or to the Crash state. There is no transition from Still to Crash. (You can’t crash if you’re still.)\nStates linkA state can be declared in multiple ways. The simplest way is to define a state with just an id:\nstateDiagram-v2 stateId stateDiagram-v2 stateId Another way is by using the state keyword with a description as per below:\nstateDiagram-v2 state \"This is a state description\" as s2 stateDiagram-v2 state \"This is a state description\" as s2 Another way to define a state with a description is to define the state id followed by a colon and the description:\nstateDiagram-v2 s2 : This is a state description stateDiagram-v2 s2 : This is a state description Transitions linkTransitions are path/edges when one state passes into another. This is represented using text arrow, “–\u003e”.\nWhen you define a transition between two states and the states are not already defined, the undefined states are defined with the id from the transition. You can later add descriptions to states defined this way.\nstateDiagram-v2 s1 --\u003e s2 stateDiagram-v2 s1 --\u003e s2 It is possible to add text to a transition to describe what it represents:\nstateDiagram-v2 s1 --\u003e s2: A transition stateDiagram-v2 s1 --\u003e s2: A transition Start and End linkThere are two special states indicating the start and stop of the diagram. These are written with the [*] syntax and the direction of the transition to it defines it either as a start or a stop state.\nstateDiagram-v2 [*] --\u003e s1 s1 --\u003e [*] stateDiagram-v2 [*] --\u003e s1 s1 --\u003e [*] Composite states linkIn a real world use of state diagrams you often end up with diagrams that are multidimensional as one state can have several internal states. These are called composite states in this terminology.\nIn order to define a composite state you need to use the state keyword followed by an id and the body of the composite state between {}. See the example below:\nstateDiagram-v2 [*] --\u003e First state First { [*] --\u003e second second --\u003e [*] } stateDiagram-v2 [*] --\u003e First state First { [*] --\u003e second second --\u003e [*] } You can do this in several layers:\nstateDiagram-v2 [*] --\u003e First state First { [*] --\u003e Second state Second { [*] --\u003e second second --\u003e Third state Third { [*] --\u003e third third --\u003e [*] } } } stateDiagram-v2 [*] --\u003e First state First { [*] --\u003e Second state Second { [*] --\u003e second second --\u003e Third state Third { [*] --\u003e third third --\u003e [*] } } } You can also define transitions also between composite states:\nstateDiagram-v2 [*] --\u003e First First --\u003e Second First --\u003e Third state First { [*] --\u003e fir fir --\u003e [*] } state Second { [*] --\u003e sec sec --\u003e [*] } state Third { [*] --\u003e thi thi --\u003e [*] } stateDiagram-v2 [*] --\u003e First First --\u003e Second First --\u003e Third state First { [*] --\u003e fir fir --\u003e [*] } state Second { [*] --\u003e sec sec --\u003e [*] } state Third { [*] --\u003e thi thi --\u003e [*] } You can not define transitions between internal states belonging to different composite states\nChoice linkSometimes you need to model a choice between two or more paths, you can do so using \u003c"
            }
        );
    index.add(
            {
                id:  81 ,
                href: "\/docs\/mix\/mermaid\/syntax\/timeline\/",
                title: "Timeline Diagram",
                description: "Timeline Diagram link Timeline: This is an experimental diagram for now. The syntax and properties can change in future releases. The syntax is stable except for the icon integration which is the experimental part.\n“A timeline is a type of diagram used to illustrate a chronology of events, dates, or periods of time. It is usually presented graphically to indicate the passing of time, and it is usually organized chronologically. A basic timeline presents a list of events in chronological order, usually using dates as markers. A timeline can also be used to show the relationship between events, such as the relationship between the events of a person’s life.” Wikipedia\n",
                content: "Timeline Diagram link Timeline: This is an experimental diagram for now. The syntax and properties can change in future releases. The syntax is stable except for the icon integration which is the experimental part.\n“A timeline is a type of diagram used to illustrate a chronology of events, dates, or periods of time. It is usually presented graphically to indicate the passing of time, and it is usually organized chronologically. A basic timeline presents a list of events in chronological order, usually using dates as markers. A timeline can also be used to show the relationship between events, such as the relationship between the events of a person’s life.” Wikipedia\nAn example of a timeline. link timeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter timeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter Syntax linkThe syntax for creating Timeline diagram is simple. You always start with the timeline keyword to let mermaid know that you want to create a timeline diagram.\nAfter that there is a possibility to add a title to the timeline. This is done by adding a line with the keyword title followed by the title text.\nThen you add the timeline data, where you always start with a time period, followed by a colon and then the text for the event. Optionally you can add a second colon and then the text for the event. So, you can have one or more events per time period.\n{time period} : {event} or\n{time period} : {event} : {event} or\n{time period} : {event} : {event} : {event} NOTE: Both time period and event are simple text, and not limited to numbers.\nLet us look at the syntax for the example above.\ntimeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter timeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter In this way we can use a text outline to generate a timeline diagram. The sequence of time period and events is important, as it will be used to draw the timeline. The first time period will be placed at the left side of the timeline, and the last time period will be placed at the right side of the timeline.\nSimilarly, the first event will be placed at the top for that specific time period, and the last event will be placed at the bottom.\nGrouping of time periods in sections/ages linkYou can group time periods in sections/ages. This is done by adding a line with the keyword section followed by the section name.\nAll subsequent time periods will be placed in this section until a new section is defined.\nIf no section is defined, all time periods will be placed in the default section.\nLet us look at an example, where we have grouped the time periods in sections.\ntimeline title Timeline of Industrial Revolution section 17th-20th century Industry 1.0 : Machinery, Water power, Steam power Industry 2.0 : Electricity, Internal combustion engine, Mass production Industry 3.0 : Electronics, Computers, Automation section 21st century Industry 4.0 : Internet, Robotics, Internet of Things Industry 5.0 : Artificial intelligence, Big data,3D printing timeline title Timeline of Industrial Revolution section 17th-20th century Industry 1.0 : Machinery, Water power, Steam power Industry 2.0 : Electricity, Internal combustion engine, Mass production Industry 3.0 : Electronics, Computers, Automation section 21st century Industry 4.0 : Internet, Robotics, Internet of Things Industry 5.0 : Artificial intelligence, Big data,3D printing As you can see, the time periods are placed in the sections, and the sections are placed in the order they are defined.\nAll time periods and events under a given section follow a similar color scheme. This is done to make it easier to see the relationship between time periods and events.\nWrapping of text for long time-periods or events linkBy default, the text for time-periods and events will be wrapped if it is too long. This is done to avoid that the text is drawn outside the diagram.\nYou can also use to force a line break.\nLet us look at another example, where we have a long time period, and a long event.\ntimeline title England's History Timeline section Stone Age 7600 BC : Britain's oldest known house was built in Orkney, Scotland 6000 BC : Sea levels rise and Britain becomes an island.\nThe people who live here are hunter-gatherers. section Bronze Age 2300 BC : People arrive from Europe and settle in Britain. They bring farming and metalworking. : New styles of pottery and ways of burying the dead appear. 2200 BC : The last major building works are completed at Stonehenge.\nPeople now bury their dead in stone circles. : The first metal objects are made in Britain.Some other nice things happen. it is a good time to be alive. timeline title England's History Timeline section Stone Age 7600 BC : Britain's oldest known house was built in Orkney, Scotland 6000 BC : Sea levels rise and Britain becomes an island.\nThe people who live here are hunter-gatherers. section Bronze Age 2300 BC : People arrive from Europe and settle in Britain. They bring farming and metalworking. : New styles of pottery and ways of burying the dead appear. 2200 BC : The last major building works are completed at Stonehenge.\nPeople now bury their dead in stone circles. : The first metal objects are made in Britain.Some other nice things happen. it is a good time to be alive. timeline title MermaidChart 2023 Timeline section 2023 Q1 Release Personal Tier Buttet 1 : sub-point 1a : sub-point 1b : sub-point 1c Bullet 2 : sub-point 2a : sub-point 2b section 2023 Q2 Release XYZ Tier Buttet 3 : sub-point 3a : sub-point 3b : sub-point 3c Bullet 4 : sub-point 4a : sub-point 4b timeline title MermaidChart 2023 Timeline section 2023 Q1 Release Personal Tier Buttet 1 : sub-point 1a : sub-point 1b : sub-point 1c Bullet 2 : sub-point 2a : sub-point 2b section 2023 Q2 Release XYZ Tier Buttet 3 : sub-point 3a : sub-point 3b : sub-point 3c Bullet 4 : sub-point 4a : sub-point 4b Styling of time periods and events linkAs explained earlier, each section has a color scheme, and each time period and event under a section follow the similar color scheme.\nHowever, if there is no section defined, then we have two possibilities:\nStyle time periods individually, i.e. each time period(and its coressponding events) will have its own color scheme. This is the DEFAULT behavior. timeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter timeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter Note that there are no sections defined, and each time period and its corresponding events will have its own color scheme.\nDisable the multiColor option using the disableMultiColor option. This will make all time periods and events follow the same color scheme. You will need to add this option either via mermaid.initialize function or directives.\nmermaid.initialize({ theme: 'base', startOnLoad: true, logLevel: 0, timeline: { disableMulticolor: false, }, ... ... let us look at same example, where we have disabled the multiColor option.\n%%{init: { 'logLevel': 'debug', 'theme': 'base', 'timeline': {'disableMulticolor': true}}}%% timeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter %%{init: { 'logLevel': 'debug', 'theme': 'base', 'timeline': {'disableMulticolor': true}}}%% timeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter Customizing Color scheme linkYou can customize the color scheme using the cScale0 to cScale11 theme variables, which will change the background colors. Mermaid allows you to set unique colors for up-to 12 sections, where cScale0 variable will drive the value of the first section or time-period, cScale1 will drive the value of the second section and so on. In case you have more than 12 sections, the color scheme will start to repeat.\nIf you also want to change the foreground color of a section, you can do so use theme variables corresponding cScaleLabel0 to cScaleLabel11 variables.\nNOTE: Default values for these theme variables are picked from the selected theme. If you want to override the default values, you can use the initialize call to add your custom theme variable values.\nExample:\nNow let’s override the default values for the cScale0 to cScale2 variables:\n%%{init: { 'logLevel': 'debug', 'theme': 'default' , 'themeVariables': { 'cScale0': '#ff0000', 'cScaleLabel0': '#ffffff', 'cScale1': '#00ff00', 'cScale2': '#0000ff', 'cScaleLabel2': '#ffffff' } } }%% timeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter 2007 : Tumblr 2008 : Instagram 2010 : Pinterest %%{init: { 'logLevel': 'debug', 'theme': 'default' , 'themeVariables': { 'cScale0': '#ff0000', 'cScaleLabel0': '#ffffff', 'cScale1': '#00ff00', 'cScale2': '#0000ff', 'cScaleLabel2': '#ffffff' } } }%% timeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter 2007 : Tumblr 2008 : Instagram 2010 : Pinterest See how the colors are changed to the values specified in the theme variables.\nThemes linkMermaid supports a bunch of pre-defined themes which you can use to find the right one for you. PS: you can actually override an existing theme’s variable to get your own custom theme going. Learn more about theming your diagram here.\nThe following are the different pre-defined theme options:\nbase forest dark default neutral NOTE: To change theme you can either use the initialize call or directives. Learn more about directives Let’s put them to use, and see how our sample diagram looks in different themes:\nBase Theme link %%{init: { 'logLevel': 'debug', 'theme': 'base' } }%% timeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter 2007 : Tumblr 2008 : Instagram 2010 : Pinterest %%{init: { 'logLevel': 'debug', 'theme': 'base' } }%% timeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter 2007 : Tumblr 2008 : Instagram 2010 : Pinterest Forest Theme link %%{init: { 'logLevel': 'debug', 'theme': 'forest' } }%% timeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter 2007 : Tumblr 2008 : Instagram 2010 : Pinterest %%{init: { 'logLevel': 'debug', 'theme': 'forest' } }%% timeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter 2007 : Tumblr 2008 : Instagram 2010 : Pinterest Dark Theme link %%{init: { 'logLevel': 'debug', 'theme': 'dark' } }%% timeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter 2007 : Tumblr 2008 : Instagram 2010 : Pinterest %%{init: { 'logLevel': 'debug', 'theme': 'dark' } }%% timeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter 2007 : Tumblr 2008 : Instagram 2010 : Pinterest Default Theme link %%{init: { 'logLevel': 'debug', 'theme': 'default' } }%% timeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter 2007 : Tumblr 2008 : Instagram 2010 : Pinterest %%{init: { 'logLevel': 'debug', 'theme': 'default' } }%% timeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter 2007 : Tumblr 2008 : Instagram 2010 : Pinterest Neutral Theme link %%{init: { 'logLevel': 'debug', 'theme': 'neutral' } }%% timeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter 2007 : Tumblr 2008 : Instagram 2010 : Pinterest %%{init: { 'logLevel': 'debug', 'theme': 'neutral' } }%% timeline title History of Social Media Platform 2002 : LinkedIn 2004 : Facebook : Google 2005 : Youtube 2006 : Twitter 2007 : Tumblr 2008 : Instagram 2010 : Pinterest Integrating with your library/website. linkTimeline uses experimental lazy loading \u0026 async rendering features which could change in the future.The lazy loading is important in order to be able to add additional diagrams going forward.\nYou can use this method to add mermaid including the timeline diagram to a web page:\nYou can also refer the implementation in the live editor here to see how the async loading is done.\n"
            }
        );
    index.add(
            {
                id:  82 ,
                href: "\/docs\/mix\/mermaid\/syntax\/userjourney\/",
                title: "User Journey Diagram",
                description: "User Journey Diagram link User journeys describe at a high level of detail exactly what steps different users take to complete a specific task within a system, application or website. This technique shows the current (as-is) user workflow, and reveals areas of improvement for the to-be workflow. (Wikipedia)\nMermaid can render user journey diagrams:\njourney title My working day section Go to work Make tea: 5: Me Go upstairs: 3: Me Do work: 1: Me, Cat section Go home Go downstairs: 5: Me Sit down: 5: Me journey title My working day section Go to work Make tea: 5: Me Go upstairs: 3: Me Do work: 1: Me, Cat section Go home Go downstairs: 5: Me Sit down: 5: Me Each user journey is split into sections, these describe the part of the task the user is trying to complete.\n",
                content: "User Journey Diagram link User journeys describe at a high level of detail exactly what steps different users take to complete a specific task within a system, application or website. This technique shows the current (as-is) user workflow, and reveals areas of improvement for the to-be workflow. (Wikipedia)\nMermaid can render user journey diagrams:\njourney title My working day section Go to work Make tea: 5: Me Go upstairs: 3: Me Do work: 1: Me, Cat section Go home Go downstairs: 5: Me Sit down: 5: Me journey title My working day section Go to work Make tea: 5: Me Go upstairs: 3: Me Do work: 1: Me, Cat section Go home Go downstairs: 5: Me Sit down: 5: Me Each user journey is split into sections, these describe the part of the task the user is trying to complete.\nTasks syntax is Task name: : "
            }
        );
    index.add(
            {
                id:  83 ,
                href: "\/docs\/mix\/mermaid\/syntax\/xychart\/",
                title: "XY Chart",
                description: "XY Chart link In the context of mermaid-js, the XY chart is a comprehensive charting module that encompasses various types of charts that utilize both x-axis and y-axis for data representation. Presently, it includes two fundamental chart types: the bar chart and the line chart. These charts are designed to visually display and analyze data that involve two numerical variables.\nIt’s important to note that while the current implementation of mermaid-js includes these two chart types, the framework is designed to be dynamic and adaptable. Therefore, it has the capacity for expansion and the inclusion of additional chart types in the future. This means that users can expect an evolving suite of charting options within the XY chart module, catering to various data visualization needs as new chart types are introduced over time.\n",
                content: "XY Chart link In the context of mermaid-js, the XY chart is a comprehensive charting module that encompasses various types of charts that utilize both x-axis and y-axis for data representation. Presently, it includes two fundamental chart types: the bar chart and the line chart. These charts are designed to visually display and analyze data that involve two numerical variables.\nIt’s important to note that while the current implementation of mermaid-js includes these two chart types, the framework is designed to be dynamic and adaptable. Therefore, it has the capacity for expansion and the inclusion of additional chart types in the future. This means that users can expect an evolving suite of charting options within the XY chart module, catering to various data visualization needs as new chart types are introduced over time.\nExample link xychart-beta title \"Sales Revenue\" x-axis [jan, feb, mar, apr, may, jun, jul, aug, sep, oct, nov, dec] y-axis \"Revenue (in $)\" 4000 --\u003e 11000 bar [5000, 6000, 7500, 8200, 9500, 10500, 11000, 10200, 9200, 8500, 7000, 6000] line [5000, 6000, 7500, 8200, 9500, 10500, 11000, 10200, 9200, 8500, 7000, 6000] xychart-beta title \"Sales Revenue\" x-axis [jan, feb, mar, apr, may, jun, jul, aug, sep, oct, nov, dec] y-axis \"Revenue (in $)\" 4000 --\u003e 11000 bar [5000, 6000, 7500, 8200, 9500, 10500, 11000, 10200, 9200, 8500, 7000, 6000] line [5000, 6000, 7500, 8200, 9500, 10500, 11000, 10200, 9200, 8500, 7000, 6000] Syntax link Note All text values that contain only one word can be written without \". If a text value has many words in it, specifically if it contains spaces, enclose the value in \"\nOrientations linkThe chart can be drawn horizontal or vertical, default value is vertical.\nxychart-beta horizontal ... Title linkThe title is a short description of the chart and it will always render on top of the chart.\nExample linkxychart-beta title \"This is a simple example\" ... Note If the title is a single word one no need to use \", but if it has space \" is needed\nx-axis linkThe x-axis primarily serves as a categorical value, although it can also function as a numeric range value when needed.\nExample link x-axis title min --\u003e max x-axis will function as numeric with the given range x-axis \"title with space\" [cat1, \"cat2 with space\", cat3] x-axis if categorical, categories are text type y-axis linkThe y-axis is employed to represent numerical range values, it cannot have categorical values.\nExample link y-axis title min --\u003e max y-axis title it will only add the title, the range will be auto generated from data. Note Both x and y axis are optional if not provided we will try to create the range\nLine chart linkA line chart offers the capability to graphically depict lines.\nExample link line [2.3, 45, .98, -3.4] it can have all valid numeric values. Bar chart linkA bar chart offers the capability to graphically depict bars.\nExample link bar [2.3, 45, .98, -3.4] it can have all valid numeric values. Simplest example linkThe only two things required are the chart name (xychart-beta) and one data set. So you will be able to draw a chart with a simple config like\nxychart-beta line [+1.3, .6, 2.4, -.34] Chart Configurations link Parameter Description Default value width Width of the chart 700 height Height of the chart 500 titlePadding Top and Bottom padding of the title 10 titleFontSize Title font size 20 showTitle Title to be shown or not true xAxis xAxis configuration AxisConfig yAxis yAxis configuration AxisConfig chartOrientation ‘vertical’ or ‘horizontal’ ‘vertical’ plotReservedSpacePercent Minimum space plots will take inside the chart 50 AxisConfig link Parameter Description Default value showLabel Show axis labels or tick values true labelFontSize Font size of the label to be drawn 14 labelPadding Top and Bottom padding of the label 5 showTitle Axis title to be shown or not true titleFontSize Axis title font size 16 titlePadding Top and Bottom padding of Axis title 5 showTick Tick to be shown or not true tickLength How long the tick will be 5 tickWidth How width the tick will be 2 showAxisLine Axis line to be shown or not true axisLineWidth Thickness of the axis line 2 Chart Theme Variables link Note Themes for xychart resides inside xychart attribute so to set the variables use this syntax %%{init: { “themeVariables”: {“xyChart”: {“titleColor”: “#ff0000”} } }}%%\nParameter Description backgroundColor Background color of the whole chart titleColor Color of the Title text xAxisLableColor Color of the x-axis labels xAxisTitleColor Color of the x-axis title xAxisTickColor Color of the x-axis tick xAxisLineColor Color of the x-axis line yAxisLableColor Color of the y-axis labels yAxisTitleColor Color of the y-axis title yAxisTickColor Color of the y-axis tick yAxisLineColor Color of the y-axis line plotColorPalette String of colors separated by comma e.g. “#f3456, #43445” Example on config and theme link --- config: xyChart: width: 900 height: 600 themeVariables: xyChart: titleColor: \"#ff0000\" --- xychart-beta title \"Sales Revenue\" x-axis [jan, feb, mar, apr, may, jun, jul, aug, sep, oct, nov, dec] y-axis \"Revenue (in $)\" 4000 --\u003e 11000 bar [5000, 6000, 7500, 8200, 9500, 10500, 11000, 10200, 9200, 8500, 7000, 6000] line [5000, 6000, 7500, 8200, 9500, 10500, 11000, 10200, 9200, 8500, 7000, 6000] --- config: xyChart: width: 900 height: 600 themeVariables: xyChart: titleColor: \"#ff0000\" --- xychart-beta title \"Sales Revenue\" x-axis [jan, feb, mar, apr, may, jun, jul, aug, sep, oct, nov, dec] y-axis \"Revenue (in $)\" 4000 --\u003e 11000 bar [5000, 6000, 7500, 8200, 9500, 10500, 11000, 10200, 9200, 8500, 7000, 6000] line [5000, 6000, 7500, 8200, 9500, 10500, 11000, 10200, 9200, 8500, 7000, 6000] "
            }
        );
    index.add(
            {
                id:  84 ,
                href: "\/docs\/mix\/",
                title: "杂",
                description: "",
                content: ""
            }
        );
    index.add(
            {
                id:  85 ,
                href: "\/docs\/",
                title: "Docs",
                description: "",
                content: ""
            }
        );
    search.addEventListener('input', show_results, true);

    function show_results(){
        const maxResult =  5 ;
        const minlength =  0 ;
        var searchQuery = sanitizeHTML(this.value);
        var results = index.search(searchQuery, {limit: maxResult, enrich: true});

        
        const flatResults = new Map(); 
        for (const result of results.flatMap(r => r.result)) {
        if (flatResults.has(result.doc.href)) continue;
        flatResults.set(result.doc.href, result.doc);
        }

        suggestions.innerHTML = "";
        suggestions.classList.remove('d-none');

        
        if (searchQuery.length < minlength) {
            const minCharMessage = document.createElement('div')
            minCharMessage.innerHTML = `Please type at least <strong>${minlength}</strong> characters`
            minCharMessage.classList.add("suggestion__no-results");
            suggestions.appendChild(minCharMessage);
            return;
        } else {
            
            if (flatResults.size === 0 && searchQuery) {
                const noResultsMessage = document.createElement('div')
                noResultsMessage.innerHTML = "No results for" + ` "<strong>${searchQuery}</strong>"`
                noResultsMessage.classList.add("suggestion__no-results");
                suggestions.appendChild(noResultsMessage);
                return;
            }
        }

        
        for(const [href, doc] of flatResults) {
            const entry = document.createElement('div');
            suggestions.appendChild(entry);

            const a = document.createElement('a');
            a.href = href;
            entry.appendChild(a);

            const title = document.createElement('span');
            title.textContent = doc.title;
            title.classList.add("suggestion__title");
            a.appendChild(title);

            const description = document.createElement('span');
            description.textContent = doc.description;
            description.classList.add("suggestion__description");
            a.appendChild(description);

            suggestions.appendChild(entry);

            if(suggestions.childElementCount == maxResult) break;
        }
    }
    }());
</script></body></html>